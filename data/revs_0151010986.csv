,isbn,user_link,ranking,review
0,0151010986,http://goodreads.com/user/show/175635-trevor,5,"I found this a remarkably challenging book to read. There was a time when I thought psychology was an odd sort of discipline. As someone who had studied physics for a while I couldn’t really bring myself to call it a science and as someone who studied philosophy I also felt it had failings on that score too. My understanding of psychology was fairly limited, but Freudian, Jungian, Behaviourist and god knows what other –isms all seemed to me to depend too much on a foundation that seemed much too arbitrary. The books I’ve been reading lately on psychology, however, are much less ‘ideological’ and much more scientific.I’ve read this book in about three days – and that despite also having about four other books on the go at the same time. This one pushed all the others I’ve started to the bottom of the list. Like I said, a lot of this book I found very challenging, but all of it very compelling.One of the psychological insights that has been messing around with my mind lately is the idea that if you ask someone who is studying to become a doctor why one of their fellow students is also becoming a doctor they are likely to say that it is obvious that that person is virtually made to be a doctor. In fact, they are likely to think that virtually everyone else in their course is there because they are almost constitutionally designed to become a doctor. But if you ask the person themselves why they are becoming a doctor they are likely to say that they are in the course more or less by accident. That there have been a network of lines that intersected and by a series of coincidences they have ended up here. And this is not just true of people’s understanding of those around them when it comes to career choices – but virtually everything else they do too. The tendency is for us to greatly over-rate what others do as being a manifestation of their ‘essential nature’ and what we do as being an unpredictable consequence of arbitrary and random forces.But this has consequences that go far beyond a mere curiosity related to people’s chosen career paths. When we find that a friend has engaged in what we might consider to be an ‘act of betrayal’ against us this same tendency kicks in again and we are likely to see this betrayal not as a momentary lapse on our friends part caused by them being carried away by circumstance, but as an indication of what is their essential nature. Our acts of betrayal against our friends, on the other hand, we tend to see as either momentary lapses or justified retaliation given their infinitely worse behaviour.This book looks at the consequences that our tendencies to under-rate our own culpability for mistakes and misdemeanours has and to over-rate the intention and severity of the actions of others when committed against us. The ‘us’ here is not just ourselves personally, but also the ‘us’ as a group or as a society as a whole. Some of the examples given in this book range from case studies of marriages falling apart (something that had cringe-making moments for me as I saw some of the very much less attractive parts of my own personality displayed before me in vivid Technicolor in relation to both my current relationship and my marriage breakdown) all the way up to the long standing problems existing between Iran and the United States. The book also looks at how people who were involved in what should really be referred to as the ‘recovered memory scandal’ have dealt with their role in this. The most generous answer is ‘not very well’. But this isn’t a book about pointing the finger and complaining about how pathetic some people are, you know, the sorts of people who make mistakes. Rather, it is a book that tries to show that we humans are all too prone to self-justification and this is a terrible danger particularly when we do things that are by any definition not things that we can be proud of. The book points out that despite our often simple-minded ideas that some people are just basically bad and that they do things just to be evil, in fact, most people who ‘do evil’ imagine they are doing good. The road to Hell is paved with good intentions and kept shining after being buffed clean by our rationalisations.If you look up a dictionary definition of ‘evil politician’ it wouldn’t be too surprising if there was a picture of Hitler. But even if you had the chance to interview Hitler in the bunker just before he popped his pill, it is very unlikely that he would have admitted that he had made many (any) mistakes. It is also unlikely that he would think that anything he had done was either wrong or bad. No, he would have the (to us) remarkable perspective that not only he had done good (and probably not just ‘on balance’) and had acted in the best interests of the future of all humanity, but that one day people would even realise that he was as wonderful as he had always thought himself. I think we (or perhaps just I) find this hard to accept, because we like to believe that deep down the people we consider to be evil know they are bad. If only the world was so simple.The image that stays with me from the last few years is of Lynndie England and her thumbs-up sign while she was standing beside a pyramid of naked Iraqi men. It is hard not to think that here is an instance of someone with some sort of moral deficiency, someone who clearly gains enjoyment out of the humiliation of others and therefore she must be someone devoid of some basic human quality – and that lacking is what separates her from us. Unfortunately, even that proves not to be the case. The most disturbing bit of research quoted in this book (and there are lots of disturbing bits of research discussed in this book) is that those most likely to become utter monsters are those who have high self-esteem and they are most likely to become monsters towards those who have virtually no power to retaliate. Why? Because we do not want to think of ourselves as bad people, particularly those of us with high self-esteem. But if we start to do horrible things to our enemies then we need to be able to justify those terrible acts – and we tend to do that by saying that they deserved it, that they are less than human, that they do worse to their enemies, that we are acting in a way that is pure and good and (dare we say it) humane, and in fact, that they are the ones (these powerless victims of ours) who are to blame.The section of this book on police interrogation methods should be made compulsory reading. Years ago I read a book that talked about a psychological experiment that has stayed with me since. People were asked to come to a room in a university to do a memory test involving a series of nonsense syllables. When they got to the room they were told that the experiment was running a little late, so would they mind sitting in a chair for a few minutes. Directly in front of the chair was a poster – one of those graphic posters that show police at a car accident and warning about drink driving or something of the kind. The poster was both graphic and directly in front of the people – so not something they were likely to not notice. When they were finally let into the room to do the test half of them were actually given the syllables to learn for half an hour, the other half of them were asked if they had noticed the poster in the waiting room. These people were then quizzed for half an hour on as many details as they could remember from the poster. What colour was the car, how many policemen were there, was it the man’s right or left leg that had been cut off in the accident? You know the sort of thing. Lots and lots of detail.Now for the interesting bit. At the end of the half hour both groups of people (the ones who did the syllables and the ones who did the ‘remembering’ of the poster) were shown another copy of the poster and asked if this was the poster they had seen in the waiting room. Virtually everyone who did the memorising of the nonsense syllables said it was – however, virtually no one who had spent half an hour ‘remembering’ the poster said it was. Why? Because those who had spent half an hour ‘remembering’ the poster had decided for sure there were three police officers, and the guy on the road was wearing a green shirt and there was a bicycle in the background and in the poster they were being shown none of those things were there.When I first heard about this experiment (remember, we are talking about events that have all taken place in a span of slightly more than half an hour) I was shocked at what this experiment implied about our justice system. In short, we are very suggestible creatures and the legal system (particularly the police force) needs to be very careful not to pollute witnesses to crimes in ways that can destroy any hope of justice for the accused – something that should be of foremost concern. However, this book makes my concerns over the justice system seem terribly naïve. I’ve learnt that you also have to add to this mix humans who are convinced they are right, people who refuse to consider any evidence other than that which supports their conclusion after they have reached it, who take it as a professional slight if they are challenged to support or (god forbid) reconsider their favourite theory, people who won’t even change their view of the guilt of the accused after irrefutable evidence is presented to them. The need to rethink our justice system so as to take into consideration the latest findings psychology presents us with becomes all rather urgent.This is, as I said, a deeply troubling book. Parts of this book felt like a mirror had been held up to me and I have to say that I really didn’t like what I saw. But this is a very important book and one that demands to be read. I recommend it without hesitation."
1,0151010986,http://goodreads.com/user/show/1923002-mara,4,"
""People will do anything, no matter how absurd, to avoid facing their own souls."" - 
C.G. Jung
 

""Memory is a complicated thing, a relative to truth, but not its twin."" - 
Barbara Kingsolver Neither of the quotes above were included in this book, but they speak to some of the ideas at its core. Anyone who has any social psychology, experimental methods course, and/or paid cursory attention to the bevy of material out there about how the human mind and we, as people, work, will find a lot of familiar concepts in 

Mistakes Were Made

. That is not to say, however, that it's not worth reading.  The overarching principles being examined are those of 
cognitive
 dissonance and 
self-justification
. And, before you get all defensive (get it?), these are normal and necessary facets of a human mind-brain (as Krieger might call it). I was going to go into this elaborate robot ""does not compute"" comparison to illustrate the nature of cognitive dissonance, but then I figured that I'd leave it to Lucille Bluth.  

 Basically the reasoning parts of our brain shut down when confronted with ""dissonant"" information, and the emotion circuits light up. 
""These mechanisms provide a neurological basis for the observation that once our minds are made up, it is hard to change them.""
 As Lucille points out, much of this occurs with respect to our sense of self as well as our need to find explanations for current problems are situations. 
Confirmation bias
 and 
confabulation
 are just two of the means by which we find evidence for what we're looking for, and causes that aren't there and there are plenty of great research and case studies (some of which is in this book) that illustrate these ideas. These ubiquitous feats of mental gymnastics give rise to various appalling truths, one of which is best described by research psychologist John Kihlstrom. 

""The weakness of the relationship between accuracy and confidence is one of the best-documented phenomena in the 100-year history of eyewitness memory research.""


So, basically, the least accurate (in this case witnesses) tend to have the most confidence in their accuracy. And the implications of this aren't restricted to the courtroom. I'm not sure I love the choice of case studies of this phenomenon among professionals in this book (the recovered memory movement in therapy, and gross miscarriages of justice in, well, the justice system), as they undermine quotidian examples (we literally do this all day every day). However, the finding that was, to me, most chilling was that in these cases 
""training does not increase accuracy; it increases people's confidence in their accuracy.""
 So, in keeping with the spirit of the book, I have to acknowledge my own sequential bias, I've read a lot of other books that covered this material and because it was new to me then, I'm prejudiced to think it was more interesting in those books...so do with that what you will.  Recommended reading: - Moral Tribes: Emotion, Reason, and the Gap Between Us and Them - Predictably Irrational: The Hidden Forces That Shape Our Decisions - How We Decide - Sway: The Irresistible Pull of Irrational Behavior"
2,0151010986,http://goodreads.com/user/show/3897817-morgan-blackledge,5,"OMFG. This book is relentless. Reading it is an ordeal. A wonderful, fruitful ordeal. But an ordeal none the less. Every page and chapter has been an opportunity for self examination and (I hope) enhanced self honesty, insight and personal growth.And just in case that sounds to woo woo for you. It should be noted that the assertions made in the book are backed by decades worth of hard, experimentally derived evidence. It doesn't get much better than that.Both authors are respected researchers in the field of social psychology. A field that is no stranger to dramatic overstatement (to say the least). But also, a field that produces some of the most denuding, insight producing, and frankly, disturbing findings of all the sub fields of psychology. The central construct explored in the book is Cognitive Dissonance. Leon Festinger's venerable finding that individuals who hold two or more contradictory beliefs, ideas, or values at the same time, or who behave in ways that contradict there values and beliefs will experience excessive mental stress and discomfort. Furthermore, individuals suffering from said mental stress and discomfort will be motivated to reduce the crappy feeling by lying to themselves and others, and even bending and recasting memories of events, in order justify their hypocritical positions and actions. In case your wondering who those blind, tortured souls are who think and behave in such insane, self delusional and amoral ways. It's you, me and everyone else we know. In other words, everyone. This thing (Cognitive Dissonance) is in fact a feature (not a flaw) of the human mind/brain. But as is the case with so many human psychological features, it can get us in a FUCK TON of trouble if allowed to operate unchecked. Imagine (just imagine) living in a 360 degree wrap around lie in which we falsely perceive ourselves as heroic victims to our own needless and profound detriment (let the finger pointing begin). Sounds pretty bad right. That is what's at stake here. But fear not, there is a pathway out of the matrix*.As I mentioned. Encountering the material in this book is very growth engendering. The book is literally a partial antidote to the poison it describes. But be warned, the antidote burns as it goes down. The cost that the reader pays for the afore mentioned rewards (enhanced self honesty, growth, insight etc), is the very experience of painful dissonance the book so expertly describes. The cost incurred to exit the matrix is minor in hindsight. But paying that cost is aversive enough to prevent all of us at one time or another to run and hide from the truth. The cost that I'm referring to, is the naked experience of the pain of realizing that we are in fact human after all. Ironically, the unwillingness to face and experience these feelings is the active ingredient. And the crazy webs we weave in order to maintain said experiential avoidance is the aforementioned poison. This is a circuitous way of saying that you can't help but recognize and feel the pain of the human condition when you read this fantastically well executed, educational and therapeutic book.For an equally eye opening, and decidedly more fun exploration of analogous territory, read Robert Kurzban's Why Everyone (else) Is a Hypocrite. Someone in my FB feed shared that their therapist recommended that she not read Nietzsche or Camus while she was experiencing a bout of depression (see if you can count the pretentious statements masquerading as self deprecating humor in that statement). I'd have to include this little gem in that list. You definitely want to be on stable footing when you read this thing. If not, than hide the sharp objects and designate a trusted friend to be at the ready to talk you down when it hits you how hopelessly self delusional all us humans actually is. That being said. I call this absolutely essential reading. It's as necessary as Khanaman's Thinking Fast and Slow. A dreadfully boring but crucial read for anyone who hasn't had the privilege/curse of studying Cognitive Psychology, or even if you have. Identifying that and how the Human mind/brain is biased (or rather. evolutionarily conditioned) to interpret information and instruct behavior accordingly programmatic ways is as close as we currently have to taking the red pill*.* Note: The red pill and its opposite, the blue pill, are pop culture symbols (originating in the comic and film The Matrix) representing the choice between embracing the sometimes painful truth of reality (red pill) and the blissful ignorance of illusion (blue pill).So go ahead. Read the book, eat the red pill, embrace the painful glare of the light of day, and live a life of more freedom. This is psychology at its most potent best."
3,0151010986,http://goodreads.com/user/show/766968-tami,5,"Sometimes, I think that the world is full of hypocrites. The news is full of politicians who preach family values and then are caught in an affair. Everyday we see religious advocates who call for peace and in the same breath state that their God is the only true God. Then, there's the business world where lying and cheating seem to be part of the game. Sometimes, I wonder how these people live with themselves. Mistake Were Made (but not by me) addresses that exact question. It would seem that the human mind is designed to selectively remember and process information. Thus, the politician, religious leader, business person, or even ourselves often don't realize that we are being hypocritical. Moreover, as our actions and logic become further and further separated, we tend to hold tighter onto our original notions. Instead of admitting that we were wrong, we justify our actions even more strongly. Mistake Were Made (but not by me) was a huge eye opener. People don't justify stupid decisions because they are bad people. On the contrary, no one wants to admit they are a fool. Look within, what beliefs do you fight the most adamantly about? "
4,0151010986,http://goodreads.com/user/show/5722119-alyssa,2,"Ultimately, I think that Tavris's conclusions about self-justification are probably correct, but her argument was flawed. There were a number of things that put me off from this book. Here's my list of gripes:1) The book relied much too heavily on anecdotal evidence to prove its points. Tavris did back up her claims about self-justification with some psychological research (that sounded like it was peer-reviewed, I guess), but it was pretty sparse (like 1 study per chapter if that---as opposed to anecdote after anecdote after anecdote). Plus, she never really discussed the full context of the studies she cited, nor did she ever give any qualifications for the research or her own conclusions.2) The overly sanctimonious, self-righteous tone of the book was a total turn-off. For the most part, I felt that it really condemned the people in the examples of self-justification that Tavris wrote about. Even though she had a good point, I feel that most of the situations are more complex than she made them out to be.3) She used a lot of logical fallacies. Her pet metaphor of the ""pyramid"" is just another version of the slippery slope fallacy. And she heavily relied on either-or logic to support her claims.4) Throughout the whole book she speaks about self-justification as though it were a fundamental flaw in human psychology. I think that is far from the truth. My contention is that evolution created the human brain the way it is for a reason. If it didn't serve a purpose, self-justification would have been discarded long, long ago because it would have caused humans to make disastrously bad decisions. But the truth is, self-justification and other illusions we create about ourselves and our world are extremely important to our ability to function in the world. I don't have time to go through all of the useful purposes that these cognitive processes serve, but here's a few: seeing ourselves as good people allows us to achieve more than people who are depressed and who have a more realistic perception of themselves---and applying patterns from old situations to new ones helps us to adapt to novelty and change more effectively. In short, a more nuanced acknowledgement of the complexity of the human brain would have been better---and more informative.I'd read Invisible Gorilla instead. It says the same basic thing at this book, but in a much more compelling and informative way."
5,0151010986,http://goodreads.com/user/show/21493936-clumsy-storyteller,0,"This was really a GREAT book, but a lot has changed since i picked it up *but i promise that i'll get back to you and read THE WHOLE book this time not just few pages. it's not you sweetie it's me....sometimes i talk to books like they're real people, not creepy at all*! i got really distracted by shiny new books that were delivered to my house and i just couldn't focus on this one. Sorry.."
6,0151010986,http://goodreads.com/user/show/851962-ryan,3,"This is yet another wonderful book written by social psychologists, although it is probably unlikely to make the New York Times best seller list for a couple of reasons. First, this book ranks right up there with Jimmy Carter’s famed “Great Malaise” speech that pointed an accusing finger at the American people for all of their problems. No one wants to know that WE are the cause of the problem, just like no one really wants to know that I made a mistake, not someone else. This book is about cognitive dissonance and the power of rationalization in many domains of life. The problem with this topic (as I have found after many quarters of teaching it to college students), is that even after learning the concept, literally no one likes to think that they actually engage in these mental gymnastics. Biases in perception, even the automatic activation of stereotypes are easier to get people to believe than trying to show them how every decision or experience we have is colored by the process of making ourselves appear consistent. In reality, we are all highly hypocritical in countless ways, but as the authors show over and over again, this is much easier to detect in others than in ourselves. Only suggestion I would make is to try to use more examples from across the political spectrum to arrest any rationalization ammo for critics of the book. Would recommend to everyone (along with Aronson’s other books). "
7,0151010986,http://goodreads.com/user/show/81985901-jagadish,5,"In this book we see the the trail of self-justification through the territories of family, memory, therapy, law, prejudice, conflict, and war.How we do self justification before the decision and after the decision is taken Example : U.S - Iraq war It show how self justification work in Iraq war.It started with Iraq had pile of weapon of mass destruction but at the end of event there was no such thing still we try to justified the event with other matter such as stability in Middle East democracy and terrorism etc .People even see lack of evidence as an evidence .Consequence of self-justification: how it exacerbates prejudice and corruption, distorts memory, turns professional confidence into arrogance, creates and perpetuates injustice, warps love, and generates feuds and rifts.How cognitive dissonance works?cognitive dissonance, the hardwired psychological mechanism that creates self-justification and protects our certainties, self-esteem, and affiliations.Then book talk about of Bias of memory .How Memory is reconstructive and subjective to source of confusion.Parent blaming is popular and convenient form of self justification .Memories create our stories, but our stories also create our memories. Once we have a narrative, we shape our memories to fit into it and assemble as mosaic form .Imagination inflammationMORAL OF THE BOOKThe moral of the book is easy to say, and difficult to execute. When you screw up, try saying this: ""I made a mistake. I need to understand what went wrong. I don't want to make the same mistake again.An appreciation of how dissonance works, in ourselves and others, gives us some ways to override our wiring. And protect us from those who can't."
8,0151010986,http://goodreads.com/user/show/651773-david,5,"As someone interested in the psychology of religion, it's always interesting to me how cognitive weaknesses play a role in establishing and maintaining religious beliefs. Some atheists are wont to believe that religion is a kind of mental illness, but this book (and others) make it clear that's really not so. The vast majority of religious people are cognitively normal. It's just that normal human cognition is very prone to making certain kinds of errors, and religious memes propagate very easily on this substrate. As an example, for a religious person to admit that there are no gods, they have to confront the enormous cognitive dissonance that they think of themselves as smart, well-educated, pragmatic - but have, for many years, been putting vast amounts of effort, emotion, thought, and perhaps money into something that hasn't the slightest basis in reality. For someone who was devoutly religious, this is the granddaddy of all cognitive dissonance. That so many people manage to confront this and deal with it is quite impressive. One of the things I like about this book is that for every section on various instantiations of cognitive dissonance and self-justification, they close by talking about someone who has overcome this natural propensity, and done right. The therapist who confronts the fact that she helped people ""recover"" false memories of abuse, and meets with the affected families to try to set things right. The prosecutor who accepts that he had an innocent man incarcerated for years, and comes back to the case. One of the best examples in my opinion is Edzard Ernst, who is not in this book, as they don't discuss ""alternative"" medicine. He confronted the fact that he had been giving people useless medical treatments for years, as a homeopathic doctor, and has since become a crusader for science-based medicine.One of the most disappointing realizations for me, as an educator, is that clear explanation with ample evidence generally will not change people's minds. Many people who think they've been abducted by aliens are well aware of the phenomenon of sleep paralysis, but - for no justifiable reason - reject it as an explanation of their experiences. I've spoken with a climate change denialist who swore up and down that they understood the greenhouse effect just fine - and then immediately turned around and said something clearly contradicting this theory.Education isn't entirely futile, though. First, if we can educate people before they've formed their opinions on the subject, that will have a dramatic difference. Second, a large-scale, concerted education effort can change some minds. This can lead to changes of the intellectual environment that can persuade others via non-rational means. Smokers in the 1940s didn't understand the link between smoking and lung cancer. Almost every smoker today does understand this link (although they smoke anyway, exercising ample self-justification). But we've managed to convince enough people that the society in the US has changed, and smoking is much less accepted (and as a result much less common).Science was developed to counteract all the problems mentioned in this book. Nobody likes to be wrong, and scientists are no exception, but they are professionally forced to be. To be sure, being too wrong can cost them prestige, money, or jobs, but they're expected to be wrong fairly frequently. And the whole endeavor of science is set up to make it clear when someone is wrong. Scientists aren't allowed to conduct their arguments in a vague or metaphorical manner, and must be vulnerable to proof that they are wrong (mathematical or empirical). And while individual scientists can be recalcitrant, the discipline as a whole is self-correcting, and moves on. The world would be a vastly better place if everyone aspired to the scientific ideal."
9,0151010986,http://goodreads.com/user/show/10407443-ross-blocher,5,"This is my favorite book, period! Carol Tavris and Elliot Aronson demonstrate how cognitive dissonance accounts for our inability to see our faults, from our personal lives all the way to the highest levels of government. This will change the way you view your own thoughts and actions, and make you a better person as a result."
10,0151010986,http://goodreads.com/user/show/12287031-kiwi-begs2differ,5,"Extremely interesting social psychology book on the reasons why do people do the things they do.The author presents compelling arguments (supported by the evidence of many studies and experiments) for some puzzling human behaviours, such as why people insist on justifying indefensible positions long after they are proven wrong. She explains, among other things, the power of gifts (even low value) in swaying decision making, the reasoning behind stereotypes and strongly denied biases (and why no one is immune of such behaviour), the fallacy of memory (distorted or confabulated memories leading to the extremes of believing themselves victims of sexual abuse or alien abduction). Other areas for which dissonance and obstinate self-justification are problematic include law enforcement (that could results in false confessions and wrong criminal prosecution), relationships (leading to nasty quarrels and divorce) and conflicts (to extremes of torture and war crimes).Highly recommended. 4 stars rounded up because I just loved the last chapter on the attitudes to learning and the importance of encouraging children to accept their mistakes.As per usual, a selection of my favourite quotes (and there are many, many more):Between the conscious lie to fool others and unconscious self-justification to fool ourselves lies a fascinating gray area, patrolled by that unreliable, self-serving historian—memory. Memories are often pruned and shaped by an ego-enhancing bias that blurs the edges of past events, softens culpability, and distorts what really happened.Prejudices emerge from the disposition of the human mind to perceive and process information in categories. ""Categories"" is a nicer, more neutral word than ""stereotypes,"" but it's the same thing.The brain is designed with blind spots, optical and psychological, and one of its cleverest tricks is to confer on us the comforting delusion that we, personally, do not have any. In a sense, dissonance theory is a theory of blind spots—of how and why people unintentionally blind themselves so that they fail to notice vital events and information that might make them question their behavior or their convictions.Just as we can identify hypocrisy in everyone but ourselves, just as it's obvious that others can be influenced by money but not ourselves, so we can see prejudices in everyone else but ourselves. Thanks to our ego-preserving blind spots, we cannot possibly have a prejudice, which is an irrational or mean-spirited feeling about all members of another group. Because we are not irrational or mean spirited, any negative feelings we have about another group are justified; our dislikes are rational and well founded. It's theirs we need to suppress.Understanding how the mind yearns for consonance, and rejects information that questions our beliefs, decisions, or preferences, teaches us to be open to the possibility of error. It also helps us let go of the need to be right. … When confidence and convictions are unleavened by humility, by an acceptance of fallibility, people can easily cross the line from healthy self-assurance to arrogance.At all ages, people can learn to see mistakes not as terrible personal failings to be denied or justified, but as inevitable aspects of life that help us grow, and grow up."
11,0151010986,http://goodreads.com/user/show/13779-k,4,"Four words:Cognitive dissonanceConfirmation biasAccording to the authors, therein lies the explanation for people's unwillingness to admit mistakes, even to themselves, in a variety of realms. This far-reaching book tackles irrational prejudices, false memories, misjudgement as a psychotherapist, prosecuting the wrong individual, blaming one's spouse for marital problems, etc. And it offers a basic explanation: we have a difficult time integrating two conflicting beliefs, such as ""I'm a great person"" and ""I messed up"" (cognitive dissonance). We will therefore respond by coming up with all kinds of creative ways to challenge the less desirable belief (usually ""I messed up"") in favor of clinging to the more desirable belief (""I'm a great person""). In an effort to convince ourselves that the more desirable belief is the correct one, we will selectively focus on evidence supporting the more desirable belief and deny, ignore, or minimize evidence supporting the less desirable belief (confirmation bias).The authors' examples are fascinating and it's a great topic. Their explanations are arguably a little facile. Can we really know what's going on inside someone's head? Are all self-justifications a matter of cognitive dissonance? Are people ever correct for clinging to a belief or course of action even in the face of conflicting evidence? The fact that the points feel belabored at times suggests that the thesis may be too simple and one-dimensional to explain all the various anecdotes.Criticism notwithstanding, this is a great topic. We could all do with a little more self-reflection when it comes to stubbornly clinging to beliefs or actions that may be detrimental. And although the actual explanations for this phenomenon are probably more complex and varied, the authors offer a good start at facing this problem and attempting to understand and hopefully challenge people's unwillingness to admit mistakes."
12,0151010986,http://goodreads.com/user/show/12925436-annie,4,"The title of the book gives the impression that it's a self-help book. It's more of a psychology book explaining how people can make mistakes, think they are right, and honestly believe that. A good example is false memories. How often have you said, ""I could have sworn I did that."" You see the event in your head, yet evidence shows it didn't happen. You rationalize it (""someone must have moved it"") instead of accepting the most obvious answer (""I was mistaken in thinking that I did it"").The book goes even further into big mistakes that people make and refuse to admit, such as in the criminal system where suspects are locked away for years (""I know he's the rapist so I'll interrogate him for hours until he finally confesses"") until DNA finally proves their innocence. Fortunately for most people, they are not making mistakes that mean life or death. The book contains many extreme examples. Still, this is a great book to read to understand and recognize your own mistakes. For example, maybe a friend asked for a favor and you said no. Initially, you felt a little guilty for saying no. Then you start justifying the answer, ""She wouldn't have helped me if I had asked for a favor. She's always looking for someone to do her work."" So that your guilty feeling goes away. It's a rude awakening to realize how your feelings have completely changed -- from feeling guilty to thinking your friend is selfish and lazy."
13,0151010986,http://goodreads.com/user/show/308912-tucker,4,"The authors describe a ""dissonance theory"" of self-justification. We don't like thinking of ourselves as ignorant or ill-intentioned, so to avoid this dissonance, we try to convince ourselves and others that we are doing the right thing. We may justify to protect our high self-esteem or even our low self-esteem, if that is our default state that we are reluctant to leave. Justification of incorrect beliefs or forbidden actions is easy when it is done incrementally, what we often call a ""slippery slope"". (The famous Milgram experiment in which college students were willing to electrocute other research subjects was an example of such incremental self-justification, because if the student can justify 50 volts than he can eventually justify 450 volts.) Depending on which way we first lean from the top of the pyramid, we can land at different sides of the pyramid, because once we start on a course of action we tend to continue justifying our actions in the same direction. As we self-justify and confabulate, we may develop false memories of things like having been abducted by aliens, molested as a child, imprisoned in a concentration camp or kept in an orphanage. We may unfairly persecute or wrongfully convict others.Children under five have trouble differentiating between things they have heard and things they have actually experienced; in adulthood, we tend to forget details as years go by, so we wind up with a related problem of being unable to distinguish reality from our fantasized or chosen narratives. This is most apparent when comparing relationship narratives between happy couples and divorcing couples. Under other circumstances, in a compressed time frame of interrogation, but according to a similar mental process, some people confess to crimes they did not commit.Introspection, rather than fixing the problem, unfortunately often triggers even more self-justification. We all have blind spots, prejudices, and a tendency to prefer ""us"" over ""them,"" but it's difficult for us to see our own limitations. Assuming we are reasonable by nature, we sometimes forgo the scientific method or engage in a biased version of it and assume that our thoughts must be reasonable because we, not someone else, thought them. We say ""that's the way I am"" to excuse our own behavior and we say ""that's the way they are"" to condemn others' behavior."
14,0151010986,http://goodreads.com/user/show/567236-adam,5,"This was by far the best book I have read in quite a few years. Highly recommended. It was so informative and engaging that I think I wore out my welcome reading it out loud to anyone who was nearby.Written by two social psychologists and based on years of research, it provides a fascinating overview of cognitive dissonance, and how it applies to prejudice, memory, law, marriage, and war. The most chilling aspect of the book is that it points out how we all are subject to dealing with dissonance (usually in self-justifying ways), what we think we know or remember is probably not the case, regardless of which side we're on, and most of our leaders and public figures shirk responsibility for mistakes.Some highlights:- Reasoning areas of the brain ""virtually shut down"" when we are confronted with dissonant information, and emotion circuits light up when consonance is restored. Basically, this shows that there is a neurological basis for the fact that once we make up our minds, it is pretty hard to change them.- ""Naïve realism"" - the ""inescapable conviction"" that we all have, that we see things as they really are. If someone has a different opinion they obviously aren't seeing things clearly.- Being ""absolutely, positively sure"" a memory is correct doesn't mean it is. We can even have vivid false memories full of emotion and detail. For example, people can recover memories of abuse, which is shown to be dubious (notably the authors mention how Martha Nibley Beck, Hugh Nibley's daughter, created memories of abuse by her father that she was convinced of). Some people even experience alien abduction without it actually happening. Basically, we can have experiences that we think are real, especially in the past, yet they never happened. Without some outside confirming source, we cannot trust our memories too much.- ""Parent blaming"" - a convenient form of self-justification; it allows people to live with regrets or mistakes because all the mistakes were made ""by them.""- Both Bill Clinton and George W. Bush have been guilty of self-justification and failure to admit their mistakes. In fact, the last president to clearly admit to a major mistake was John F. Kennedy. Really, are we convinced that no president since then has messed up? What was really interesting is that the two presidents to use the phrase ""mistakes were made"" the most, were none other than Richard Nixon (of course) and, wait for it, the beloved Ronald Reagan. What is so insidious about the phrase (which Clinton even joked about using it so much) is that it is a complete avoidance of responsibility.- Finally, resolving dissonance is not completely bad, and does serve to preserve our beliefs, confidence, and self-esteem. However, it also gets us into trouble. Hence, the authors suggest that it is possible to remain committed to a religion, political party, or partner, yet understand that ""it is not disloyal to disagree with actions or policies"" that one believes are inappropriate, misguided, or immoral."
15,0151010986,http://goodreads.com/user/show/8101737-peter-tillman,4,"Rather than actually write a review three years on, I will refer you to my colleague Susan Stepney's first-rate review: https://www-users.cs.york.ac.uk/susan...""No-one is a monster in their own view, yet people do monstrous things. At a less extreme level, people do petty and mean things too. Why?The thesis of this book is that we rewrite our memories to overcome cognitive dissonance. How can we have done a bad thing, if we are good people?""The best review I saw here is by Trevor: https://www.goodreads.com/review/show...""... a deeply troubling book. Parts of this book felt like a mirror had been held up to me and I have to say that I really didn’t like what I saw. But this is a very important book and one that demands to be read. I recommend it without hesitation."""
16,0151010986,http://goodreads.com/user/show/148805-matthew,5,"I've been a longtime fan of both authors (especially Tavris), so my expectations were pleasantly met. Most of it, of course, is hammering away at how the fundamental attribution error influences relationships between couples, coworkers, or nations. They reframe the psychobabble as ""self-justification"" as the root of these conflicts and ongoing interpersonal difficulties. Their citations of clinical works also brings up the interesting possibility that mindfulness-based interventions may be most effective when they undermine self-justification, inserting some space between events and affect, but that's fodder for a much longer post."
17,0151010986,http://goodreads.com/user/show/2294090-darwin8u,3,"A bit uneven and towards the end a bit too Oprah-centric. Felt like the book drifted from a scientific/psychological work to a clinical/self-help piece (a rational, scientifically grounded self-help book, but still one regardless). It was interesting, but sadly disappointing too."
18,0151010986,http://goodreads.com/user/show/2222886-aasem-bakhshi,4,"In the beginning, you think it's a fresh application of Festinger's theory; then you think it's about human species in general; then you think, aah, it's about politics too; about history, about ideas as well; finally, you realize it's primarily about you, the reader. A very interesting take on an idea which is now half a century old."
19,0151010986,http://goodreads.com/user/show/266762-piezocuttlefish,4," Mistakes Were Made is a tour through the different ways in which cognitive dissonance motivates otherwise normal, good people to do wretched things. Making such stops as the tragedies of recovering so-called repressed memories, the unfortunate bias of the parts of the legal system which are immune to criticism, and growing disparities of perception between perpetrators and victims,  Mistakes Were Made also highlights many other scientific and psychological tidbits.  Carol Tavris and Elliot Aronson weave a slowly accelerating narrative of the power of cognitive dissonance in our lives, one that grows ever closer to home. At the end of each chapter and at the end of the text, the authors provide examples of people who chose the better path. As for an explanation of how to do so, it is lacking, but in my own reading I oft thought about my own dissonances and my own mistakes.  Mistakes Were Made highlights the biases we have toward creation delusional or unproductive stories to guide our lives. It is up to us to create the more accurate stories.""When a friend makes a mistake, the friend remains a friend, and the mistake remains a mistake."" — Israeli Prime Minister Shimon Peres"
20,0151010986,http://goodreads.com/user/show/69716492-aya-hamouda,3,"""A tree Is Known By its Fruit "" , so as this book  The title of the book was precisely picked .It was such a great experience and trip for me to read such a wonderful and well written socio psychological book. The Author really did a great job to the extent that every page was a new experience for me . -Through this book You will understand ""why some people try hard to justify their own mistakes and not to admit them"" -as the author wrote : “In the horrifying calculus of self-deception, the greater the pain we inflict on others, the greater the need to justify it to maintain our feelings of decency and self-worth.”-AND one of the best parts I admired in this book is the following part : “This habit starts awfully early. Social psychologist Marilynn Brewer, who has been studying the nature of stereotypes for many years, once reported that her daughter returned from kindergarten complaining that “boys are crybabies.”25 The child’s evidence was that she had seen two boys crying on their first day away from home. Brewer, ever the scientist, asked whether there hadn’t also been little girls who cried. “Oh yes,” said her daughter. “But only some girls cry. I didn’t cry.” Brewer’s little girl was already dividing the world, as everyone does, into us and them. Us is the most fundamental social category in the brain’s organizing system, and it’s hardwired.”"
21,0151010986,http://goodreads.com/user/show/961166-eric-phillips,4,"A highly engaging discussion on how people use self-justification to avoid admitting they've made a mistake or hurt someone or otherwise deal with the ""cognitive dissonance"" we encounter when one of our cherished beliefs runs aground on the rock of cold, hard reality. The one quibble I would have is the division the authors make of the world into ""perpetrators"" and ""victims"" -- a language that masks the real complexity of certain relationships and interactions in which both parties are one and the same and at the same time neither -- which is when the conflicts become really intractable and the self-justifications that much harder to see through and to walk away from. Nonetheless, it is eye opening and provides a useful tool for self-diagnosis, even if the suggestions for how to deal with someone else suffering from ""cognitive dissonance"" and ""confirmation bias"" are little light (not that I wouldn't have minded having read that last chapter about a week earlier, considering some recent going-ons here and there)."
22,0151010986,http://goodreads.com/user/show/47369055,5,"A really great book that has shown me many misconceptions that I had about human nature and mistakes that I do but thought did not consider them to be mine. I especially enjoyed the last chapter of the book were the author talked about the importance of mistakes in learning, something I personally believe to be missing from many cultures and most definitely missing in mine."
23,0151010986,http://goodreads.com/user/show/6412647-geoff-ball,5,"This book attempts to explain and provide an answer to the question, ""how do you sleep at night?"" Despite everything we do—even when it is at odds with our beliefs—cognitive dissonance allows us to say, ""very well, thank you."" As the authors write, ""without self-justification, we might be left standing emotionally naked, unprotected, in a pool of regrets and losses."" Although cognitive dissonance allows us to tell ourselves that we're decent human beings, it can lead to great contempt and embarrassment that prevents the ""truth"" from ever setting us free.The book does a great job of explaining cognitive dissonance—the tension between the beliefs one holds and the actions they take—and how we self-justify to vindicate our behaviour. The authors refer to a ""pyramid of choice"" to explain how dissonance comes not from abrupt decisions, but after many choices, in which our actions slowly shift away from our beliefs. Unlike a lie, which is something (1) we know is wrong and (2) tell to others, self-justification is something we tell ourselves, and we may not even know it is taking place. To an outsider, our actions may appear absurd, but to us they might seem completely rational—the ""right"" choice.The book goes through myriad examples to explain how and why self-justification and cognitive dissonance exist and persist. From relationships to interrogations, the examples in this book can be directly related to your life experiences (though hopefully you haven't experienced too many interrogations). There's even some humour thrown in; the authors are telling a story of a man (Criner) who was wrongly convicted of rape, and the inability of the prosecutor (McDougal) to admit his error of the wrongful conviction. They write, ""technically, of course, McDougal is right; Criner could have raped the woman in Texas and ejaculated somewhere else—Arkansas, perhaps.""I have read of cognitive dissonance in previous studies of social psychology, but never in as fulfilling a book as Tavris and Aronson's. There was an excellent balance of theory and example, which made it a book I didn't want to put down. It seems like every five pages had an ""Ah ha!"" moment that I could apply to my own life: the closed loop of confirmation bias; the pain of being the victim but the indifference of being the perpetrator; and the increased need to justify our actions to ourselves as we inflict more pain on others (or as we invest more in a project that is criticized by others).As with (hopefully) any book, there were a few questions I had along the way as I read. First, what good can be served by cognitive dissonance? As I mentioned at the outset, it allows us to sleep at night. I'm sure all of us have done things in life we're not proud of; can you imagine if you reminded yourself every day how terrible you are? Sometimes, we need to lie to ourselves, but when is it easier/better to admit we're wrong than to take the emotional toll of lying to ourselves and others?Second, if we tend to support our previous decisions by telling ourselves they were the right ones, why do we so frequently experience what I can only call ""the grass is greener on the other side"" thoughts? I wish the book had addressed that idea.Third, how can this book be applied to matters that are seemingly intractable, such as abortion? When the two sides don't even agree over what the issue is (time of conception for pro-life; women's rights for pro-choice), it becomes very difficult, if not impossible, to compromise. And how do you ""compromise"" over such an important issue? This, along with the existence of God, is something I cannot imagine will ever be solved, but cognitive dissonance and confirmation bias make it that much more difficult.Near the end of the book, I started thinking of the concept of karma. Here is an idea based in Eastern Religion that I can only imagine focuses on the self—""if I do 
this
, I will somehow be affected in the future."" Yet somehow, karma has become something we assign to others—""He'll get what's coming to him."" In a way, we seem to justify our responses to others by what they've done: if he wronged me, it's simply karma that I'm doing harm back to him. The authors covered this very well in their discussion of the conflict between Muslims and Christians. Who started it, and when? Each side has drifted so far down (opposing sides of) the pyramid that they aren't even using the same rule book anymore.At one point, the authors discussed how people sometimes become so entrenched in their position, that the position itself becomes secondary. Consider the Israeli demands for peace in the Middle East. When presented to Israelis, they are largely supported. However, when those same demands are presented to Israelis but tabled as if they were Palestinian demands, they are largely rejected by Israelis. This reminds me a lot of politics in North America: it doesn't seem to matter what is said anymore (the ideas of most politicians all tend to converge toward the center anyway), but who said it. An idea is heralded by Republicans when it came from Bush; the same idea is denounced as near-treason when it comes from Obama. Liberals fully support an idea from Trudeau but reject it from Harper. We need to recognize our cognitive dissonance and listen to the message.If there's only one thing I'll take from this book, it's that we need to be aware of dissonance, expect it, and try to understand it—especially within ourselves—if we have any chance of overcoming it. It will destroy relationships, companies, and lives, and although it certainly has its place, it does more harm than good."
24,0151010986,http://goodreads.com/user/show/6163905-knig,5,"I was (uncomfortably) shocked to the core reading this- others attest to same. Particularly disturbing are the passages on the judiciary. None of it sits comfortably on any level, and I found myself 'guilty' on most charges. Working on ways currently to mitigate the self-justification effect for myself: but its sooooo hard. Especially when you don't realise you're doing it."
25,0151010986,http://goodreads.com/user/show/2531665-charlene,5,"I have dubbed this book, 'The Analytical Sledgehammer.' Mistakes Were Made has become one of my favorite books of all time. It should be required reading for every human being. At its heart, this book examines everything humans believe about their own selves and the world at large. How have we come to believe what we do about ourselves, the people we love, & those we punish? Where did ideas of fairness come from. Why is it so hard to admit fault? What does it all mean on a personal and societal level? This book will appeal to anyone with a human brain. The studies used in the book are sound and the authors take a wonderfully critically approach to everything they present. If you are capable of even the tiniest bit of self-reflection, this book will delight you in ways you never imagined. Each page will force you to ask if you really know yourself at all. You might have read books about heuristics, but this book is more accessible than Kahneman's book (thought Kahneman will give you a more thorough education about various heuristics) and is more entertaining and empirically sound that You Are Not So Smart by McRaney. A+"
26,0151010986,http://goodreads.com/user/show/4834819-muneel-zaidi,5,"Cognitive dissonance is a topic everyone should look into, but people placed in positions of leadership or responsibility would really benefit from a study on the matter. I enjoyed the examples presented in this book and related with a few of them as well, which helped me really understand the concept better. The the main issue I had with this book was its diminishing marginal return, the more I read the less I got out of it. Once the concept of cognitive dissonance is explained (very well too), the additional proses is just more in-depth examples and case studies. These examples are actually pretty interesting in their own right and kept me engaged in the book, but did not introduce any new concepts. Highly recommended for people interested in human psychology, people in positions of power, and anyone who's ever made a mistake. I listened to this book on Audiobook. "
27,0151010986,http://goodreads.com/user/show/13298726-michael-perkins,5,"The most disturbing chapter is about the U.S. legal system, how we like to ""railroad"" suspects, including through phony forensics. Prosecutors and judges resist appeals because such ""blemishes"" would get in the way of moving up in their careers. Forensic science is not what we see on TV. Most of it is not dependable and often used to convict people falselyhttps://www.youtube.com/watch?v=JjuxV...more....https://www.propublica.org/article/wh..."
28,0151010986,http://goodreads.com/user/show/369112-melody,4,"Fascinating and eye-opening analysis of cognitive dissonance and the steps we take to reduce the dissonance. Politicians are the easy targets, and exploited here as such, but Tavris & Aronson also delve into personal stories. Several of them held up a mirror to my own self-justifications and made me flinch. Riveting and insightful. Recommended."
29,0151010986,http://goodreads.com/user/show/41884184-elizabeta,4,"Excellent book about cognitive dissonance and self-justification in everyday life, criminal law, marriage... Highly recommended for everybody."
30,0151010986,http://goodreads.com/user/show/11966043-lia,5,"4.5 starsI think this is one of the best non-fiction books I've ever read. It is so fascinating and it is so well-written. I've learned so much, about others and about myself. I honestly think that reading this book makes you a better person. I couldn't recommend it more."
31,0151010986,http://goodreads.com/user/show/23790728-amani,5,This was a very interesting and informative read. 
32,0151010986,http://goodreads.com/user/show/522647-kathy,4,"I'm so depressed. Humans, grrr. If you've ever wondered why people won't admit mistakes even in the face of verifiable truth contradicting their actions or beliefs, this book explains why. With sections on cognitive dissonance, why we think we're above outside influence, memory (yes, we make up our own ""memories""), scientific research fallacies, law enforcement/prosecution proceedings and relationship killers the gamut is pretty much covered. And, it's depressing. Did I mention that already? Well, it bears mentioning twice. We humans are geared to stick to our figurative guns no matter what. I have no hope for our current political unrest in the USA to get better any time soon. Sigh."
33,0151010986,http://goodreads.com/user/show/64733542-nafisa,5,"""A nation's character, and an individual's integrity, do not depend on being error-free. It depends on what we do after making an error.""Once in a while, I come across a book that makes me question my self-concept; this book is one of them. Broadly, it is about cognitive dissonance -- the psychological stress we face when our actions contradict our beliefs and ideals. Since we don't like to think of ourselves as incompetent or ill-intentioned, our natural tendency is to convince ourselves that we did the right thing. Mindless self-justification in the face of cognitive dissonance can have far-reaching (and often devastating) consequences, and the authors do a commendable job of documenting such examples from numerous distinct domains ranging from the criminal justice system, politics, medicine, and even marriage and relationships. A fresh set of ideas, quite compelling, and sometimes challenging to read as they force you to constantly self-reflect. I highly recommend it to anyone with an interest in psychology. The book is not intended to be self-help but offers a lot of scope for personal growth."
34,0151010986,http://goodreads.com/user/show/3669193-mah-ebr,5,i think everyone should read this one! 
35,0151010986,http://goodreads.com/user/show/901342-jacob,4,"This covers ground related to Evil Genes: Why Rome Fell, Hitler Rose, Enron Failed, and My Sister Stole My Mother's Boyfriend and The Honest Truth About Dishonesty: How We Lie to Everyone--Especially Ourselves, but it's specifically about self-justification. It's attempting to answer the question ""Why do people self-justify obvious mistakes?"" and look at the impact of doing so. It's pretty straightforward and quite readable.Self-justification is a useful and even essential way for humans to protect their ego and mental health, but it can get pretty out of whack. Self-justification is not only sad when it helps us decide to do things we shouldn't, it's extra sad when people do things they shouldn't only because they are trying to support an existing self-justification for a previous bad decision. One of the elaborated examples is when innocent people go to jail: it's bad enough when police and attorneys justify acting unethically in order to convict someone they ""know"" is guilty. Where it becomes absolutely unconscionable is where they work hard to prevent people from being proven innocent after the fact so they don't have to admit screwing up.On a lighter note, with books about human fallibility you have to chuckle when the authors display the very fallibility they're decrying. In one case, they claim to be certain about someone's motivation for making poor remarks without allowing for those remarks to be caused by that person looking for any excuse to self-justify behavior. In another case, they berate therapists for not thinking scientifically and not examining the disconfirming cases, then talk about the Gottmans' work on predicting divorce without examining the disconfirming cases (where the Gottmans predicted divorce and were wrong). They mention a case where of 10 of 47 couples were predicted to divorce, all 7 who did divorce were predicted ones. Of the remaining 40, all they say is that the 90% accuracy is impressive. But they don't address that 30% of the predicted divorces didn't happen, which pokes a hole in their nice theory about self-justification causing divorce. That wouldn't be a problem if they hadn't already spent a chapter bagging on therapists for having pet theories without looking at evidence that would contradict the theory.One of the reasons you chuckle over those kinds of mistakes instead of criticizing is because we ALL do those things. I'm not immune from doing those very same things, and neither is anyone else. But we might become less that way if we are aware of the phenomenon and try to identify when we are justifying ourselves."
36,0151010986,http://goodreads.com/user/show/7399266-camie,4,"I should start by saying I find social psychology fascinating! This book is about cognitive dissonance , which basically means having two conflicting beliefs and the measures we will resort to in order to defend and justify our beliefs , decisions, and actions. Backed by much research, this very insightful book explains how we all are capable of self deception, why we do it, why it is harmful, and how to overcome the very human mechanism of justifying our foolish beliefs, improper actions, poor decisions, and hurtful acts, and more importantly how to keep small things from escalating to disastrous proportions. Looking at everything from political situations, criminal acts, war, marriage, and personal levels it offers answers to how impossible atrocities come about , one justification at a time. ""How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self justification will do the rest."" From the politician who can't publically admit his actions, the torturer who feels no guilt, to the person who will say anything to win an argument, this book explains why it is so easy to see the hypocrisy of others while being totally blind to our own. Co-written by Elliot Aronson, author of The Social Animal , a great textbook, this is a very readable informative book. The introduction is called Knaves, Fools, Villains, and Hypocrites: How Do They Live With Themselves.... lol how do we ?? 4 stars"
37,0151010986,http://goodreads.com/user/show/51519663-diana-nahirna,5,"Well, that explains a lot of my recent purchases, Iraq, and why marriages fail. "
38,0151010986,http://goodreads.com/user/show/1974052-milan,5,"Mistakes Were Made (But Not by Me) is quite an enlightening book by Carol Tavris and Elliot Aronson. The authors examine our deep-rooted tendencies to underplay our faults and errors and to exaggerate the mistakes of others, especially when they go against us. ""Cognitive dissonance occurs when a person holds two or more contradictory beliefs, ideas, or values, or participates in an action that goes against one of these three, and experiences psychological stress because of that."" Two lessons from this theory: “First, the ability to reduce dissonance helps us in countless ways, preserving our beliefs, confidence, decisions, self-esteem, and well-being. Second, this ability can get us into big trouble.”The self-justification mechanisms like cognitive dissonance, confirmation bias, and fabricated memory play such an important role in our lives that they are hard to ignore. The authors provide very vivid examples from politics, therapy, conflict, wars, marriage, police and court procedures to show how these biases work. A few important lessons: •	 “Most human beings and institutions are going to do everything in their power to reduce dissonance in ways that are favorable to them, that allow them to justify their mistakes and maintain business as usual.” •	“Most people, when directly confronted by evidence that they are wrong, do not change their point of view or course of action but justify it even more tenaciously. Even irrefutable evidence is rarely enough to pierce the mental armor of self-justification.”•	Our ‘mistake-phobic’ culture causes people not to learn from their mistakes.•	Naive realism: the believe that everyone else sees the world as we do•	We all self-justify as a way to protect against cognitive dissonance, whether positively or negatively.•	Memories are easily modified to fit a narrative to reduce cognitive dissonance.•	We must be careful to not allow memory distortion to justify previous decisions.•	Therapists should be very concerned about confirmation bias, their expert assessments and also in their evaluations of people.•	Confessions can be elicited from accused legally by using deceit, trickery, etc.•	Successful couples will give the benefit of the doubt to their partners, just as they would to themselves. Unsuccessful couples do the opposite.•	We must strive to take self-justification into account in our lives and relationships to prevent incorrect decisions making.Two things to keep in mind – our personal life will suffer if we don’t admit our mistakes and society will work better if people admitted when they’re wrong."
39,0151010986,http://goodreads.com/user/show/28602450-vladyslav-sitalo,4,"You think about yourself as a reasonably nice person, with not perfect but good enough memory. Maybe you've done some things in your life, that you don't particularly like, but you think that in most cases, given the situation you were in, most of the people would've done the same.So you ain't perfect but better than the most, right?Well, this book would get you to at least question, how accurate is the description above. And it will also tell you how come you (and most of the people, even most morally flawed, from your perspective, people) think of themselves in this way.The book will tell you how your mind is desperately trying to maintain the self-image, you have about yourself and protect beliefs your hold. How it change your perceptions of things around you to fit this image/beliefs. And here comes more fun: it also employs your memory to justify your current self-perception/beliefs. So your memory is gradually, with each recall, become more compliant with this image. And eventually, all you left with is the nice, coherent story of your life that corresponds to your current view of yourself and your beliefs. But this story often has little or nothing to do with reality.As authors call it: Memory is your self-justifying historian (I would also highly recommend a novelette by Ted Chiang - ""The Truth of Fact, the Truth of Feeling"" as an exploration of this aspect of our memory: https://www.goodreads.com/book/show/1...).And the thing is that this process influences pretty much every aspect of your life regardless of your age/education or other things, you might think would influence the situation.So the process kicks in:When you're a nice, kind boy, who find himself in a company that is bullying a weaker guy. You don't particularly like the process but, as you want to be a part of this social group - you continue to participate in it. But there is dissonance here: how come you, as a nice, kind boy become a bully? So here the self-justification comes to your help: ""It's totally the guy's responsibility that he got bullied. Let's modify our image of the guy to leave our self-image preserved and justify what've done. Yay! And hey we're justified to continue to bully him as he is such a ....""Or let's say you're a student who don't have any strong position on cheating. You know it's generally considered a ""bad thing"" but you don't have any personal conviction either way. You haven't done it earlier because you didn't need to. But now you're in the situation when you need either cheat or fail this particular course. So situation can go in two ways from here:World 1: You've decided to cheat. ""Self-justification process: Ok we've cheated, as we know we're a generally good person, so we could not have possibly done a bad thing, so we may conclude that cheating is not a big deal"".World 2: You've decided not to cheat. ""Self-justification process: Ok we've failed the course. That's unfortunate but, well we didn't have any other option, right? We wouldn't even consider doing such a terrible thing as cheating"".Or you're a detective and you've interrogated your suspect to the point that he have given you a confession. But here comes the strong evidence (like DNA test or videotape) that he is innocent. So here it goes: ""I'm an honest infallible detective and my interrogation methods are great, and, after all, the guy has given confession after only 36 consecutive hours of interrogation. The evidence must be wrong""And let's upgrade a bit more. You're an honest politician, who is right now flying with a lobbyist on a luxury private plane to spend a nice weekend in some luxury resort. ""As we're an honest, good man, this situation can't possibly influence our political judgment in any way, right?"" (To understand how you got in this situation in a first place and for a lot of other good examples - read the book ;)The more deeply held self-belief that is contradicting to what you did the more actively you would justify the deed as the kind of deed that don't contradict this self-belief.You probably think to yourself: ""Ok maybe some of the cases described in this book can be true about me, but in most of them I would not have employed this level of self-justification""Well, the problem is that self-justification is largely unconscious process so when you do something that don't correspond to your self-image or see information that contradicts your belief - the justification process kicks in automatically in the background.So usually, you don't even notice on the conscious level that you've maybe done something wrong or that you hold a questionable belief. And correspondingly you don't have a chance to fix the situation before you internalize it as the normal state of things.That's why it's often said ""Hypocrite is obvious to all but himself""So you would probably at this point like to know - are we doomed? Can we do better? And the answer is yes we can! The book advises us to institute impartial external overview committees wherever possible (if necessary even against the will of involved people/institutions) because the external observer can usually notice an error much easier than somebody who have committed it. As he is not emotionally/financially/in other way invested in this decision.In the situations where setting up such an institutions is not feasible or reasonable (For example in the case of personal relationships), make sure that you and people around are aware and conscious about the magic of self-justification. You also can, to some level, train yourself to recognize the typical situations where the process may kick in and be especially careful when facing them. Also, be aware of the fact that this magic works on other people, so when you try to point out his/her error to somebody, be careful to do it in a way that will not make them self-defensive and more likely to justify this error.And don't be afraid to admit your errors, because as you relinquish wrong beliefs you become wiser, as you own up to your errors you gain more respect from people and you're less likely to make the same error in the future. Everybody makes mistakes, but you only can learn from yours, when you admit them."
40,0151010986,http://goodreads.com/user/show/21170365-amy-anderson,5,"I loved this book and found it so applicable to everyone. While we need justification to move forward in life and not second guess our every decision, we also need to be aware that justification can lead us to be blind sighted to truth. Its a fine line to walk. I could quote this whole book, but here are my favorites:""Self-justification is more powerful and dangerous than the explicit lie. It allows people to convince themselves that what they did was the best thing they could have done. In fact, come to think of it, it was the right thing."" p.4""Self-justification not only minimizes our mistakes and bad decision, it is also the reason that everyone can see a hypocrite in action except the hypocrite."" p.4""How in the world can they live with themselves? The answer is exactly the way the rest of us do."" p.9""Yet mindless self-justification, like quicksand, can draw us deeper into disaster. It blocks our ability to even see our errors, let alone correct them. It distorts reality, keeping us from getting all the information we need and assessing the issues clearly. It prolongs and widens rifts between lovers, friends, and nations. It keeps us from letting go of unhealthy habits. IT permits the guilty to avoid taking responsibility for their deeds."" p.9""I will look at any additional evidence to confirm the opinion to which I have already come."" Lord Molson p.17""These mechanisms provide a neurological basis for the observation that once our minds are made up, it is hard to change them."" p.19""People become more certain they are right about something they just did if they can't undo it."" p.22""Decades of experimental research have found exactly the opposite: that when people vent their feelings aggressively they often feel worse, pump up their blood pressure and make themselves angrier."" p.26""Aggression begets self-justification, which begets more aggression."" p.27""How do you get an honest man to lose his ethical compass? You get hi to take one step at a time, and self-justification will do the rest."" p.37""Parent blaming is a popular and convenient form of self-justification because it allows people to live less uncomfortably with their regrets and imperfections."" p.76""...current self-concepts blurred their memories, bringing their past selves into harmony with their present ones."" p.79""If a memory is a central part of your identity, a self-serving distortion is even more likely."" p.79""For those who are trying to remember something that never happened, writing analyzing dreams, and drawing pictures- techniques that are the staples of many psychotherapists- are all methods that quickly conflate imagination with reality."" p.86""Once the seed of belief was planted [they] began to search for confirming evidence."" p.90""...the story fits the needs of the experiences."" p.91"",,,experiences have internalized their new false memories and cannot now distinguish them from true ones. They have come to believe their own stories."" p.93""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives."" p.93""Successful partners extend to each other the same self-forgiving ways of thinking we extend to ourselves: They forgive each other's missteps as being due to the situation, but give each other credit for the thoughtful and loving things they do."" p.169""It may sometimes be hard to define good, but evil has its unmistakable odor: Every child knows what pain is. Therefore, each time we deliberately inflict pain on another, we know what we are doing. We are doing evil."" Amoz p.198""Would you rather admit you're wrong now or wait until someone else proves it?"" p.221""People will pursue self-destructive courses of action to protect the wisdom of their initial decisions."" p.222""They will treat people they have hurt even more harshly, because they convince themselves that their victims deserve it."" p.222""People who are insecure in their religious beliefs may feel the impulse to silence and harass those who disagree with them, because their mere existence arouses the painful dissonance of doubt."" p.222"
41,0151010986,http://goodreads.com/user/show/5301457-sergei-moska,4,"Although this book didn't actually teach me anything new in terms of theory (but did provide me with many details of practical cases), it nonetheless surprised me. First, I decided to read this book at this time because I've been a bit burned out from dense reading and wanted something useful but light. It was in fact both these things, but it was also far, far more depressing than I had expected. I expected this to be a “Ha ha, let's look at our foibles!” type of read. No, it's more of a “your identity is a joke and the world systematically does evil things. And so do you.” kind of experience. Structurally speaking, the book is very simple. The first part posits a simplified theory, and the rest of the book demonstrates the theory in action, in a few select areas of life. The theory is that we need to overcome the cognitive dissonance that emerges when our actions conflict with our self-image or beliefs. At such a moment, we are said to be at the top of a “pyramid” (a 2-dimensional triangle would be a better image), and the authors believe that whether or not we choose to justify ourselves to ourselves in such moments will lead us down one side of the pyramid or the other, with drastically different outcomes once we hit either side of the base of the pyramid. I may give up the idea that I'm such a great guy, or I can decide that the other person deserved the treatment, that it really wasn't a big deal, etc. The authors believe that whatever choice we make will cause us – in order to avoid further cognitive dissonance – to more extreme positions in order to justify our initial choice. A number of surprising findings come about as a result. For instance, the more helpless the victim, the more we will tend to denigrate him in order to justify our initial mistreatment of him. Beating up an angry drunk at a bar doesn't necessarily require much justification (“He was being threatening, and it's fine to beat up people that are threatening”), but participating in bullying usually does (“I'm a nice guy and beating him up, so it must be because he's a weenie who deserves to be humiliated. Plus he'd do it if he had the chance”.)A fun book to read, although it was too simplified for my taste in at least two ways. First, the authors' theory is *very* simple, and at times their application of the theory seems too universal. For instance, why do innocent people confess to crimes? The authors only seem to entertain the notion that it's in order to reduce cognitive dissonance: “I didn't do anything, but all the cops say that they have proof. The cops are honest and good people, so I must be the problem.” Yet at times this just seems dubious. The explanation is far more convincing when they apply it to the decision by the police to continue interrogation even in the absence of evidence. The second way that the book was too simplified for my taste is in its structure. After a very good exposition of their theory, I was hoping that the subsequent material would help develop the theory further. But what it turned out to be was “Here's a theory, and now we're going to show you the theory in X, Y, and Z.” This is a matter of taste, but I really don't like that format. What's more, I do think it hurts the authors, since it implies that the answer to the subtitle of the book is monolithic. I don't think that to be the case, and I suspect the authors don't either. In fairness, they do incidentally go through a number of additional mechanisms that are attached to the problem of cognitive dissonance, including a wonderful treatment on the foibles of memory, but it would have been really nice to make their answer more complex and complete, even at the risk of making it less parsimonious. Normally that kind of issue would be a big turn-off for me, but the book really is saved (for me) by their incredibly chilling accounts, especially in chapters 3-6. The writing is very clear and engaging, and the book is also thoroughly annotated, all of which makes me fall a little bit in love with the authors."
42,0151010986,http://goodreads.com/user/show/1677868-steven-peterson,4,"This is a well written, snappy book that addresses an important issue, best described by the book's title and subtitle: ""Mistakes Were Made (but not by me): Why we justify foolish beliefs, bad decisions, and hurtful acts."" The two authors, both well reputed psychologists, use the theory of cognitive dissonance as their starting point. Leon Festinger was one of the major theorists of this approach. The authors of this book simply define the perspective thus (page 13): ""Cognitive dissonance is a state of tension that occurs whenever a person holds two cognitions (ideas, attitudes, beliefs, opinions) that are psychologically inconsistent, such as 'Smoking is a dumb thing to do because it could kill me' and 'I smoke two packs a day.'"" How does one deal with this? By adopting one of the positions and then downgrading or rejecting the other. The end result is self-justification, self-deception, seeking out evidence to support the choice that we have made while rejecting evidence that does not fit with our choice. The brain itself shows evidence of the operation of cognitive dissonance. The example on page 19 of functional Magnetic Resonance Imaging (fMRI) and processing information about presidential candidates is telling. The end result is ""blind spots,"" in which people (page 42) ""fail to notice vital events and information that might make them question their behavior or their convictions."" As such, the authors note that cognitive dissonance makes mincemeat of such theoretical views as rational actor theory and psychoanalytic theory. One result of cognitive dissonance is what is called ""confirmation bias,"" the attending to evidence that supports our views and the rejection/suppression of evidence that does not support our views. Many examples are advanced to illustrate the case that the authors make. Issues include: moral lapses (e.g., Watergate participants), ""made up"" memories (raising serious questions about the whole idea of repressed memories), criminal justice system decisions on guilt or innocence, and so on. Much is at stake with cognitive dissonance as it operates. In the closing chapter, the authors try to indicate how understanding cognitive dissonance might help us to limit the damage that may occur as a result of its operation. Convincing? I'm not so sure, but this discussion does get one thinking about how we might address the harmful side effects of cognitive dissonance. A readable book that raises important issues. I think that more use of neuroscientific research could have strengthened this book that much more. Also, the work by cognitive psychologists like Kahneman and Tversky could have spoken to key points as well. This book might also profitably be read in tandem with another recent book on a similar subject, Cordelia Fine, ""A Mind of Its Own."" In addition, Linden's ""accidental Mind"" provides a perspective on related issues from a neuroscience viewpoint. "
43,0151010986,http://goodreads.com/user/show/9281934-louise,5,"Prior to reading this, I had only considered the theory of cognitive dissonance as it applied to holding two contrary opinions, the classic example being that of the racist with friends who are members of the race s/he denigrates. Tavris and Aronson demonstrate further applications of this theory and how destructive the behavior it spawns continues to be.The 1980's/90's day care scandals pre-dated the 24 hour cable cycle (imagine this being covered today by Fox) so it blipped in and out of my attention. I remember thinking how it didn't add up, but I wasn't really following it. Today, somewhere below my radar screen are the DNA absolved prisoners, and their continued incarceration doesn't add up either. Tavris and Aronson show how the professionals involved continued and continue to stick to their long fought for opinion, even as evidence pours in against it. As the dissonance theory predicts, the greater the commitment to the opinion the more the mind works to re-enforce it.The book is most convincing on the personal level such as the damage caused by the dynamics in divorce or accusations such as those made by those in the recovered memory therapies.While cognitive dissonance is undoubtedly operative, it is not the only culprit in the inability to admit mistakes. For commercial and public policy issues there is liability to be paid either through job loss, litigation, an election, or even everyday office politics. If the culprit is a principal player on a big stage, it could be a career ender for not only the decider, but his/her staff. It is not just the mind that keeps out contrary information, there is undoubtedly social support for the bad decision by those who also made the mistake or assisted in its execution. There are also families to consider, you admit the mistake, you could lose your job and there will be no college education for your kids. The books speaks of these barriers, but sticks to its purpose of illustrating the theory.For barriers beyond cognitive dissonance, I think of George Bush and the Iraq war. If he could bring himself to admit the mistake, he would face huge institutional and social acrimony from the policy makers who assisted him, the party who supported him, the military as an institution and the families who lost their loved ones. Ultimate decision makers on the Iraq War will wait, like Robert McNamara did, until the mistake is universally recognized.This is an excellent book. The authors develop their theory for the lay person with good examples from both everyday life and the world of public policy. I highly recommend it. "
44,0151010986,http://goodreads.com/user/show/2414293-adelle,3,"The authors' political biases came through as they used the beginning and the ending of the book to castigate then (2007) President George W. Bush, and to call Newt Gingrich a “hypocrite” for criticizing (now former) President Bill Clinton’s sexual affair…WITHOUT any allusion to Clinton’s defensive “I did not have sex with that woman…Miss Lewinski” statement. But most of the center sections of the book--which thankfully were relatively free of politics--- I found endlessly fascinating. Oh, how tenaciously we cling to “our version” of the story, filtering the facts so that what WE did/or didn’t do is seen to be of negligible consequence or perhaps even honorable, and what THE OTHER GUY did/or didn’t do is seen to be righteously reprehensible, obviously beyond the pale. I loved, too, the authors’ many demonstrations that the act that alienates one party or the other is not a stand-alone event. To reference Aesop, it is much more likely to be the straw that broke the camel’s back. Hurts and grievances in both parties have probably been building for some time. “Who were the victims? It depends on how many years, decades, and centuries you take into account” (206). Consider Kosovo. Consider the Crusades. As the authors describe these tragic events, IF one is not emotionally involved with one side or the other, one can see BOTH points of view. Likewise in personal relationships. “Of all the stories that people construct to justify their lives, loves, and losses, the ones they weave to account for being the instigator or the recipient of injustice or harm are the most compelling and have the most far-reaching consequences” (191). Tavris and Aronson continue, “We have all done something that made others angry at us, and we have all been spurred to anger by what others have done to us. We all have, intentionally or unintentionally, hurt another person who will forever regard us as the villain, the betrayer, the scoundrel. And we have all … [been:] on the receiving end” (191). It would seem it is seldom the absolute fault of “the other guy.” But…that would mean…and humans on the whole have SUCH a vested interest in protecting their own self-image.A interesting, engaging read."
45,0151010986,http://goodreads.com/user/show/25763919-mimi,4," This is phenomenal! .......it made me love Psychology even more.This book has a protagonist , well ,i think it's more of an antagonist (to us) named : cognitive dissonance (i am so in love with this character hhhhh) ""Mistakes Were Made But Not By Me"" discusses all SORTS of lengths human being may go in order to reduce cognitive dissonance.Acting in contradiction to what u believe (cognitive dissonance) is 'painful' 'uncomfortable' so what we do? the remedy is employed extensively by all yet little know about it : it's self justification.How it works: you hate cheating (this is your belief), it happened and you cheated once voluntarily (contradicting behavior) ====== results is cognitive dissonance ( your self image is shaken ,because your belief about 'cheating' has being shaken)Huh! now comes the remedy time : cheating isn't that bad. the exam was unfairly difficult that's why i cheated these are some of the thoughts we may have once we start justifying our actions (cheating) to reduce cognitive dissonance.OK , now let me introduce you other cognitive biases that leads u to screwing up immensely:Confirmation bias : this dude screws rational healthy discussions... for it blinds you for one side of an argument completely. You believe in one side, you keep looking for info to prove it without EVER checking the arguments and evidence the opposite view might present ( this is what makes some peoples' craniums rock-hard , never allowing the penetration of any of your ideas or arguments ) Snap decisions/judgements : this guys are super bad , if you could just turn them off when you are presented with anything which needs you opinion ....when you take a snap decision you are done for , it becomes harder to see the other angles of a person , an idea ...unless you knew how dangerous these guys are for your objectivity and try harder to make a balanced judgment. Sadly humans are hardwired with many biases that makes them fallible creatures....and without knowing them they will be extra fallible."
46,0151010986,http://goodreads.com/user/show/17485839-zena-ryder,4,"If you don't know what cognitive dissonance is, this is a great introduction. If you do know what it is, this is an easy, enjoyable read, with interesting stories and experiments that illustrate dissonance and the resulting self-justification, which will likely deepen your understanding of this all too human phenomenon. The authors also talk about the fascinating and related phenomenon of false memories — our memories tend to get distorted (or even created!) to be self-serving. I found the section on how easily children can be persuaded to have memories of things that didn't really happen both fascinating and disturbing. The authors also talk about the how police officers' confirmation bias and the need to avoid dissonance by those involved at the various stages of the justice system can and does lead to terrible miscarriages of justice.I guess the biggest thing that was missing, for me, was more detail of when we don't give in to self-justification in order to avoid dissonance. The authors do talk about this, but I would have liked more detail. I would also like more detail on people with low self esteem, who don't tend to resolve their dissonance in self-serving ways, but rather in ways that fit their self image of being incompetent, unlovable etc.While knowing about cognitive biases and flaws isn't enough to make them magically go away, the authors suggest that being aware of them should make us less confident in our own convictions and memories, especially when they are self-serving. I think that is an important lesson for anyone."
47,0151010986,http://goodreads.com/user/show/4532156-alaa-a,5,"This year I started to be more interested in social psychology books in my hope to change my default sitting to the world and understand it better, and what better way than saying I was wrong to your self and owning the mistakes to your self...Its a very challenging book to read its started to with an eases of pointing the mistakes of politics and countries and introducing the conformation biases then going to personal stories that we are confined that happened when all evidenced are against.One of the psychological insights that has been messing around with my mind is the selective memory and that even if you feel strongly sure and emotionally attached to it can be wrong or even planted made me question my memories and if I am a hypocrite the explanation for people's unwillingness to admit mistakes, even to themselves, in a variety of realms. This far-reaching BOOK tackles irrational prejudices, false memories, misjudgement as a psychotherapist, prosecuting the wrong individual, blaming one's spousethe part of repressed memory therapy of rape victimise was eye opening for me as how easy for as to follow :Cognitive dissonanceConfirmation biasI read in the book ""thinking fast and slow "" that knowing this biases dose not stop you form doing it even for the experts in this felid but it can make you stop your self and question why you think or act this way, and that is about it what you can do!! "
48,0151010986,http://goodreads.com/user/show/5856337-mark,5,"Having been put off by several popular books by social psychologists I read in recent years which I felt failed to deliver on the promised goods (""Emotional Intelligence"" and ""Social Intelligence,"" both by Daniel Goldman come quickly to mind), I was both relieved and impressed as I listened to the audiobook version of ""Mistakes Were Made.""The authors not only convincingly support and develop their thesis from start to finish, they do so in an entertaining fashion. Furthermore, the book offers plenty of opportunity for practical application for any casual reader who dares to pause to consider how his or her own pride, cognitive dissonance, confirmation biases, etc. may cause him/her to re-write history, justify themselves and their experiences, blind themselves from seeing the truth, etc. I will mention one area where the authors may possibly be a little ""off."" Toward the end of the book, they share an example of Japanese encouraging mistakes in the classroom and seem to generalize this example for Asian culture. However, across mainland China, Japan, Taiwan, and Korea, societies seems to be somewhat intolerant of mistakes. Having said all that, this is still a great book. Read it!"
49,0151010986,http://goodreads.com/user/show/2050800-kathy,1,"Although the authors have some good points about self-justification in a few sections of the book, they clearly spend way too much time on the ""problem"" and their political biases than a plausible solution to overcoming self-justification. I read the last page of the book in complete disgust as to the topic they chose to end with and completely irritated that very few solutions were offered to help minimize self-justification in ourselves as well as others. I guess I should have read the title a little closer: It states ""Why we..."" and not ""How to overcome why we..."" Also found it very fitting based on the severe bias that shone through the entire book that there was not one mention of the infamous ""I did not have sexual relations with that woman"" by Bill Clinton. Now that's a perfect example of self-justification if I've ever seen one!There is nothing more irritating to me than reading 200 pages about a problem and then getting to the end and realizing the author offered no real solutions but a ton of biased opinions. What a waste!"
50,0151010986,http://goodreads.com/user/show/1347209-jacob,5,"As much as I read, there are few books that are enlightening, educational, and entertaining enough for me to rate them so highly. This is one of those books that every time you put it down you have to run and find someone to tell what you just read. You find the content so interesting that you can't help but share it with others.The authors do a great job at explaining cognitive dissonance and how it leads to self-justification. They also apply the concepts well by focusing a chapter on a specific realm of how this impacts our world (legal interrogation, false memory recovery, etc).If you have ever read ""Leadership and Self Deception"" I think you would enjoy this book also. More of the science behind the story.Read this and then apply the information in your life. It is blessing me and those around me and I'm sure it will you."
51,0151010986,http://goodreads.com/user/show/1984886-tim-kadlec,3,"The book was full of good information, and good discussions around cognitive dissonance. It's fault, however, was that the anecdotes tended to be very politically charged, and very biased.Unfortunately, the authors bias came through very strongly in several of the examples used, and this distracts from the points the authors are attempting to make. In addition, a few of the examples felt like they didn't really fit in with the subject matter, and were instead used to continue to justify the authors biases (ironic I know)."
52,0151010986,http://goodreads.com/user/show/26434622-sophiacoming,5,"One of my favorite books! make me more aware of my silly impulses. I think understanding these limitation is the basis for having a crucial conversation, and making peace with yourself and people around you."
53,0151010986,http://goodreads.com/user/show/58909202-edu,2,"The concept is very interesting, even necessary to know, and mindblowing, wich I liked a lot. But there were many many examples and much of them from USA politics, which I don't care so much about. "
54,0151010986,http://goodreads.com/user/show/8778400-rebekka-steg,5,"This week I've been reading Mistakes Were Made (But Not by Me): Why We Justify Foolish Beliefs, Bad Decisions, and Hurtful Acts by Carol Tavris and Elliot Aronson, an absolutely amazing book, which everyone should be acquired to read.The book deals with the issue of self-justification, and the role it plays in all of our lives, from such ""minor"" issues as arguments within a relationship, to bullying, prejudicialness, torture, fraud etc.Written by two psychologist, the book is backed by research as well as real life cases and examples. It's easy to read, incredibly thought-provoking and it deals with such an important topic, which affects us all.

 Quotes ""We are all capable of believing things which we know to be untrue, and then, when we are finally proved wrong, impudently twisting the facts so as to show that we were right. Intellectually, it is possible to carry on this process for an indefinite time: the only check on it is that sooner or later a false belief bumps up against solid reality, usually on a battlefield.""- George Orwell (1946)""For example, Elliot predicted that if people go through a great deal of pain, discomfort, effort, or embarrassment to get something, they will be happier with that ""something"" than if it came to them easily. For behaviorists this was a preposterous prediction. Why would people like anything associated with pain? But for Elliot, the answer was obvious: self-justification. The cognition that I am a sensible, competent person is dissonant with the cognition that I went through a painful procedure to achieve something - say, joining a group that turned out to be boring and worthless. Therefore, I would distort my perceptions of the group in a positive direction, trying to find good things about them and ignoring the downside.""""Venting is especially likely to backfire if a person commits an aggressive act against another person directly, which is exactly what cognitive dissonance theory would predict. When you do anything that harms someone else - get them in trouble, verbally abuse them or punch them out - a powerful new factor comes into play: the need to justify what you did. Take a boy who goes along with a group of his fellow seventh graders who are taunting and bullying a weaker kid who did them no harm. The boy likes being part of the gang but his heart really isn't in the bullying. Later, he feels some dissonance about what he did. ""How can a decent kid like me,"" he wonders, ""have done such a cruel thing to a nice, innocent little kid like him?"" To reduce dissonance, he will try to convince himself that the victim is neither nice nor innocent: ""He is such a nerd and cry-baby. Besides, he would have done the same to me if he had the chance."" Once the boy starts down the path of blaming the victim, he becomes more likely to beat up on the victim with even greater ferocity the next chance he gets. Justifying his first hurtful act sets the stage for more aggression. That's why the catharsis hypothesis is wrong.""""Our convictions about who we are carry us through the day, and we are constantly interpreting the things that happen to us through the filter of those core beliefs. When they are violated, even by a good experience, it causes us discomfort. An appreciation of the power of self-justification helps us understand, therefore, why people who have low self-esteem, or who simply believe that they are incompetent in some domain, are not totally overjoyed when they do something well; why, on the contrary, they often feel like frauds. If the woman who believes she is unlovable meets a terrified guy who starts pursuing her seriously, she will feel momentarily pleased, but that pleasure is likely to be tarnished by a rush of dissonance: ""What does he see in me?"" Her resolution is unlikely to be ""How nice; I must be more appealing than I thought I was."" More likely, it will be ""As soon as he discovers the real me, he'll dump me."" She will pay a high psychological price to have that consonance restored.""""The Milgram experiment shows us how ordinary people can end up doing immoral and harmful things through a chain reaction of behavior and subsequent self-justification. When we, as observers, look at them in puzzlement or dismay, we fail to realize that we are often looking at the end of a long, slow process down that pyramid. At his sentencing, Magruder said to Judge John Sirica: ""I know what I have done, and Your Honor knows what I have done. Somewhere between my ambition and my ideals, I lost my ethical compass."" How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self-justification will do the rest.""""The brain is designed with blind spots, optical and psychological, and one of its cleverest tricks is to confer on us the comforting delusion that we, personally, do not have any. In a sense, dissonance theory is a theory of blind spots - of how and why people unintentionally blind themselves so that they fail to notice vital events and information that might make them question their behavior or their convictions. Along with the confirmation bias, the brain comes packaged with other self-serving habits that allow us to justify our own perceptions and beliefs as being accurate, realistic, and unbiased. Social psychologist Lee Ross calls this phenomenon ""naïve realism,"" the inescapable conviction that we perceive objects and events clearly, ""as they really are."" We assume that other reasonable people see things the same way we do. If they disagree with us, they obviously aren't seeing clearly. Naïve realism creates a logical labyrinth because it presupposes two things. One, people who are open-minded and fair ought to agree with a reasonable opinion. And two, any opinion I hold must be reasonable; if it weren't, I wouldn't hold it. Therefore, if I can just get my opponents to sit down here and listen to me, so I can tell them how things really are, they will agree with me. And if they don't, it must be because they are biased.""""As fallible human beings, all of us share the impulse to justify ourselves and avoid taking responsibility for any actions that turn out to be harmful, immoral, or stupid. ... Most people when directly confronted with proof that they are wrong, do not change their point of view or course of action but justify it even more tenaciously.""""Just as we can identify hypocrisy in everyone but ourselves, just as it's obvious that others can be influenced by money but not ourselves, so we can see prejudices in everyone else but ourselves. Thanks to our ego-preserving blind spots, we cannot possibly have a prejudice, which is an irrational or mean-spirited feeling about all members of another group. Because are are not irrational or mean-spirited, any negative feelings we have about another group are justified; our dislikes are rational and well founded. It's theirs we need to suppress. Like the Hasids pounding on the Unprejudiced door at the Museum of Tolerance, we are blind to our own prejudices.""""When two people produce entirely different memories of the same event, observers usually assume that one of them is lying. Of course, some people do invent or embellish stories to manipulate or deceive their audiences, as James Frey notably did with his bestseller A Million Little Pieces. But most of us, most of the time, are neither telling the whole truth nor intentionally deceiving. We aren't lying; we are self-justifying. All of us, as we tell our stories, add details and omit inconvenient facts; we give the tale a small, self-enhancing spin; that spin goes over so well that the next time we add a slightly more dramatic embellishment; we justify that little white lie as making the story better and clearer - until what we remember may not have happened that way, or even may not have happened at all.""""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives. An appreciation of the distortions of memory, a realization that even deeply  felt memories might be wrong, might encourage people to hold their memories more lightly, to drop the certainty that their memories are always accurate, and to let go of the appealing impulse to use the past to justify problems of the present. If we are to be careful about what we wish for because it might come true, we must also be careful which memories we select to justify our lives, because than we will have to live by them.""""For any theory to be scientific, it must be stated in such a way that it can be shown to be false as well as true. If every outcome confirms your hypotheses that all men unconsciously suffer from castration anxiety; or that intelligent design, rather than evolution, accounts for the diversity of species; or that your favourite psychic would accurately have predicted 9/11 if only she hadn't been taking a shower that morning; or that all dolphins are kind to humans, your beliefs are a matter of faith, not science.""""Our implicit theories of why we and other people behave as we do come in one of two versions. We can say it's because of something in the situation or environment: ""The bank teller snapped at me because she is overworked today; there aren't enough tellers to handle these lines."" Or we can say it's because something is wrong with the person: ""That teller snapped at me because she is plain rude."" When we explain our own behavior, self-justification allows us to flatter ourselves: We give ourselves credit for our good actions but let the situation excuse the bad ones. When we do something that hurts another, for example, we rarely say, ""I behaved this way because I am a cruel and heartless human being."" We say, ""I was provoked; anyone would do what I did""; or ""I had no choice""; or ""Yes, I said some awful things, but that wasn't me - it's because I was drunk."" Yet when we do something generous, helpful, or brave, we don't say we did it because we were provoked or drunk or had no choice, or because the guy on the phone guilt-induced us into donating to charity. We did it because we are generous and open-hearted.""""Did Charles Graner and Lynndie England know what they were doing, let alone believe they were ""doing evil"" while they were deliberately inflicting pain and humiliation on their Iraqi prisoners and then laughing at them? No, they didn't, and that is why Amos Oz is wrong. Oz didn't reckon with the power of self-justification: We are good people. Therefore, if we deliberately inflict pain on another, the other must have deserved it. Therefore, we are not doing evil, quite the contrary. We are doing good. The relatively small percentage of people who cannot or will not reduce dissonance this way pay a large psychological price in guilt, anguish, anxiety, nightmares, and sleepless nights. The pain of living with horrors they have committed, but cannot morally accept, would be searing, which is why most people will reach for any justification available to assuage the dissonance. In the previous chapter, we saw on a smaller scale why many divorcing couples justify the hurt they inflict on each other. In the horrifying calculus of self-deception, the greater the pain we inflict on others, the greater the need to justify it to maintain our feelings of decency and self-worth. Because our victims deserved what they got, we hate them even more than we did before we harmed them, which in turn makes us inflict even more pain on them.""""But what are we supposed to do in our everyday lives? Call an external review board of cousins and in-laws to adjudicate every family quarrel? Videotape all parental interrogations of their teenagers? In our private relationships, we are on our own, and that calls for some self-awareness. Once we understand how and when we need to reduce dissonance, we can become more vigilant about the process and often nip it in the bud; like Oprah, we can catch ourselves before we slide too far down the pyramid. By looking at our actions critically and dispassionately, as if we were observing someone else, we stand a chance of bring out of the cycle of action followed by self-justification, followed by more committed action. We can learn to put a little space between what we feel and how we respond, insert a moment of reflection, and think about whether we really want to buy that canoe in January, really want to send good money after bad, really want to hold on to a belief that is unfettered by facts. We might even change our minds before our brains freeze our thoughts into consistent patterns.""""Humbling yes, but ultimately that's the point. Understanding how the mind yearns for consonance, and rejects information that questions our beliefs, decisions, or preferences, teaches us to be open to the possibility of error. It also helps us let go of the need to be right. Confidence is a fine and useful quality; none of us would want a physician who was forever wallowing in uncertainty and couldn't decide how to treat our illness, but we do want one who is open-minded and willing to learn. Nor would most of us wish to live without passions or convictions, which give our lives meaning and color, energy and hope. When confidence and convictions are unleavened by humility, by an acceptance of fallibility, people can easily cross the line from healthy self-assurance to arrogance. In this book, we have met many who crossed that line: the psychiatrists who are certain that they can tell if a recovered memory is valid; the physicians and judges who are certain that they are above conflicts of interest; the police officers who are certain that they can tell if a suspect is lying; the prosecutors who are certain that they convicted the guilty party; the husbands and wives who are certain that their interpretation of events is the right one; the nations who are certain that their version of history is the only one.""""Most Americans know they are supposed to say ""we learn from our mistakes,"" but deep down, they don't believe it for a minute. They think that mistakes mean you are stupid. Combined with the culture's famous amnesia for anything that happened more than a month ago, this attitude means that people treat mistakes like hot potatoes, eager to get rid of them as fast as possible, even if they have to toss them in someone else's lap."""
55,0151010986,http://goodreads.com/user/show/8435102-joan,3,"Why is it so hard for us to admit we have made a mistake? Why do we justify our actions? Why is it so hard to change our minds when we think we are right?The authors wrote this book with a goal of understanding those behaviors. I learned tons about why we say what we do to ourselves. Self-justification, for example. We convince ourselves we made the best choice possible. Unfortunately, that blocks us from seeing our errors and learning from them.I read about cognitive dissonance and how it changes our perception. When we see disconfirming evidence, we will criticize the source (fake news), distort or outright dismiss it. Maintaining the belief is more important than truth. And we have confirmation bias, the reason it is so hard to change our minds when we have made a firm decision. I also learned much about blind spots, how our memories change (or we change them purposely), and false memories. The authors give many examples of interrogators (such as child psychologists) manipulating people to confess to crimes or report non-existing events. They give examples of law enforcement officials and prosecutors refusing to admit mistakes even when DNA evidence finally proves them wrong.Rounding out this informative book are thoughts on the price paid for for justifying decisions that cause pain to others. For example, international acts are justified by saying our deeds were bad but not nearly as bad as theirs.The authors end the book reminding us of the benefits of admitting mistakes. There is a positive effect. For politicians, admitting a mistake results in constituents admiring the person is big enough to admit wrong and desire to learn from mistakes.This is an interesting book that is very informative and easy to read. I really found it enlightening in explaining much of the rhetoric we hear today."
56,0151010986,http://goodreads.com/user/show/28157679-susan-s-frederick,5,"Really opened my eyes to bias and lenses that are different for each of us, but have profound effect on how we see things, remember things, feel things. Fascinating."
57,0151010986,http://goodreads.com/user/show/4134989-chuck,4,"A well written exposure of dissonance avoidance, self-justification, confirmation bias and other forces that effect us all. The examples and insights here are especially helpful in understanding why ourself and others make mistakes, defend actions, and choose self-preserving narratives. A revelation into neural, natural wiring. A brave look into the mirror as well as the boundaries of tolerance we construct for others. Keen, practical eye-opening read. "
58,0151010986,http://goodreads.com/user/show/32598115-becky,5,This was an interesting look at how our minds work to dissociate with problems and errors in judgement.
59,0151010986,http://goodreads.com/user/show/2251009-esteban-del-mal,4,"Cognitive dissonance: The mental discomfort experienced by a person who holds two or more contradictory beliefs, ideas, or values. This discomfort is triggered by a situation in which a person's belief clashes with new evidence perceived by the person. When confronted with facts that contradict beliefs, ideals, and/or values, people will try to find a way to resolve the contradiction to reduce their discomfort (~squaring a circle).Cognitive bias: A systematic pattern of deviation from norm or rationality in judgment. Individuals create their own subjective social reality from their perception of the input. An individual's construction of social reality, not the objective input, may dictate his or her behavior in the social world; thus, cognitive biases may sometimes lead to perceptual distortion, inaccurate judgment, illogical interpretation, or what is broadly called irrationality. Catharsis: The psychodynamic principle of emotional release. It's a bullshit theory leftover from Freud. Self-justification: How, when a person encounters cognitive dissonance or a situation in which a person's behavior is inconsistent with his/her beliefs, that person tends to justify the behavior and deny any negative feedback associated with the behavior. Naive realism: The human tendency to believe that we see the world around us objectively and that people who disagree with us must be uninformed, irrational, or biased.Totalitaian ego: a) The ego/self is an organization of knowledge; b) ego/self is characterized by cognitive biases analogous to totalitarian information-control strategies, and; c) these totalitarian-ego biases function to preserve organization in cognitive structures.Reconstructive memory: A theory of memory recall in which the act of remembering is influenced by various other cognitive processes including perception, imagination, semantic memory, and beliefs. People view their memories as being a coherent and truthful account of episodic memory and believe their perspective is free from error during recall; however, the reconstructive process of memory recall is subject to distortion by other intervening cognitive functions such as individual perceptions, social influences, and world knowledge, all of which can lead to errors during reconstruction. [REPRESSED MEMORIES DO NOT EXIST]Source confusion: An attribute seen in different people's accounts of the same event after hearing people speak about the situation (for example, a witness who heard a police officer say someone had a gun who then states he/she saw the gun).Anomie: A condition in which society provides little moral guidance to individuals. This state evolves from conflict of belief systems and causes a breakdown of social bonds between an individual and the community. In a person, this condition can progress into a dysfunctional ability to integrate within the normative situations of his/her social world (for example, an unruly personal scenario that results in fragmentation of social identity and rejection of values). The term is commonly understood to mean normlessness.Imagination inflation: The finding that imagining an event which never happened can increase confidence that it actually occurred.Confidence-accuracy relationship: As one's confidence increases, so does one's level of accuracy (or belief therein).Benevolent dolphin problem: Every once in a while, a news story appears about a shipwrecked sailor who, on the verge of drowning, is nudged to safety by a dolphin. It is tempting to conclude that dolphins must really like human beings, enough to save us from drowning. But wait—are dolphins aware that humans don’t swim as well as they do? Are they actually intending to be helpful? To answer that question, we would need to know how many shipwrecked sailors have been gently nudged further out to sea by dolphins, there to drown and never be heard from again. We don’t know about those cases because the swimmers don’t live to tell us about their evil-dolphin experiences. If we had that information, we might conclude that dolphins are neither benevolent nor evil; they are just being playful.Effort justification: A person's tendency to attribute a value to an outcome which he/she had to put effort into achieving which is greater than the objective value of the outcome (i.e., the more effort put into something, the more it is valued).Implicit personality theory: The specific patterns and biases an individual uses when forming impressions based on a limited amount of initial information about an individual or situation."
60,0151010986,http://goodreads.com/user/show/11966043-lia,5,"4.5 starsI think this is one of the best non-fiction books I've ever read. It is so fascinating and it is so well-written. I've learned so much, about others and about myself. I honestly think that reading this book makes you a better person. I couldn't recommend it more."
61,0151010986,http://goodreads.com/user/show/23790728-amani,5,This was a very interesting and informative read. 
62,0151010986,http://goodreads.com/user/show/522647-kathy,4,"I'm so depressed. Humans, grrr. If you've ever wondered why people won't admit mistakes even in the face of verifiable truth contradicting their actions or beliefs, this book explains why. With sections on cognitive dissonance, why we think we're above outside influence, memory (yes, we make up our own ""memories""), scientific research fallacies, law enforcement/prosecution proceedings and relationship killers the gamut is pretty much covered. And, it's depressing. Did I mention that already? Well, it bears mentioning twice. We humans are geared to stick to our figurative guns no matter what. I have no hope for our current political unrest in the USA to get better any time soon. Sigh."
63,0151010986,http://goodreads.com/user/show/64733542-nafisa,5,"""A nation's character, and an individual's integrity, do not depend on being error-free. It depends on what we do after making an error.""Once in a while, I come across a book that makes me question my self-concept; this book is one of them. Broadly, it is about cognitive dissonance -- the psychological stress we face when our actions contradict our beliefs and ideals. Since we don't like to think of ourselves as incompetent or ill-intentioned, our natural tendency is to convince ourselves that we did the right thing. Mindless self-justification in the face of cognitive dissonance can have far-reaching (and often devastating) consequences, and the authors do a commendable job of documenting such examples from numerous distinct domains ranging from the criminal justice system, politics, medicine, and even marriage and relationships. A fresh set of ideas, quite compelling, and sometimes challenging to read as they force you to constantly self-reflect. I highly recommend it to anyone with an interest in psychology. The book is not intended to be self-help but offers a lot of scope for personal growth."
64,0151010986,http://goodreads.com/user/show/3669193-mah-ebr,5,i think everyone should read this one! 
65,0151010986,http://goodreads.com/user/show/901342-jacob,4,"This covers ground related to Evil Genes: Why Rome Fell, Hitler Rose, Enron Failed, and My Sister Stole My Mother's Boyfriend and The Honest Truth About Dishonesty: How We Lie to Everyone--Especially Ourselves, but it's specifically about self-justification. It's attempting to answer the question ""Why do people self-justify obvious mistakes?"" and look at the impact of doing so. It's pretty straightforward and quite readable.Self-justification is a useful and even essential way for humans to protect their ego and mental health, but it can get pretty out of whack. Self-justification is not only sad when it helps us decide to do things we shouldn't, it's extra sad when people do things they shouldn't only because they are trying to support an existing self-justification for a previous bad decision. One of the elaborated examples is when innocent people go to jail: it's bad enough when police and attorneys justify acting unethically in order to convict someone they ""know"" is guilty. Where it becomes absolutely unconscionable is where they work hard to prevent people from being proven innocent after the fact so they don't have to admit screwing up.On a lighter note, with books about human fallibility you have to chuckle when the authors display the very fallibility they're decrying. In one case, they claim to be certain about someone's motivation for making poor remarks without allowing for those remarks to be caused by that person looking for any excuse to self-justify behavior. In another case, they berate therapists for not thinking scientifically and not examining the disconfirming cases, then talk about the Gottmans' work on predicting divorce without examining the disconfirming cases (where the Gottmans predicted divorce and were wrong). They mention a case where of 10 of 47 couples were predicted to divorce, all 7 who did divorce were predicted ones. Of the remaining 40, all they say is that the 90% accuracy is impressive. But they don't address that 30% of the predicted divorces didn't happen, which pokes a hole in their nice theory about self-justification causing divorce. That wouldn't be a problem if they hadn't already spent a chapter bagging on therapists for having pet theories without looking at evidence that would contradict the theory.One of the reasons you chuckle over those kinds of mistakes instead of criticizing is because we ALL do those things. I'm not immune from doing those very same things, and neither is anyone else. But we might become less that way if we are aware of the phenomenon and try to identify when we are justifying ourselves."
66,0151010986,http://goodreads.com/user/show/7399266-camie,4,"I should start by saying I find social psychology fascinating! This book is about cognitive dissonance , which basically means having two conflicting beliefs and the measures we will resort to in order to defend and justify our beliefs , decisions, and actions. Backed by much research, this very insightful book explains how we all are capable of self deception, why we do it, why it is harmful, and how to overcome the very human mechanism of justifying our foolish beliefs, improper actions, poor decisions, and hurtful acts, and more importantly how to keep small things from escalating to disastrous proportions. Looking at everything from political situations, criminal acts, war, marriage, and personal levels it offers answers to how impossible atrocities come about , one justification at a time. ""How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self justification will do the rest."" From the politician who can't publically admit his actions, the torturer who feels no guilt, to the person who will say anything to win an argument, this book explains why it is so easy to see the hypocrisy of others while being totally blind to our own. Co-written by Elliot Aronson, author of The Social Animal , a great textbook, this is a very readable informative book. The introduction is called Knaves, Fools, Villains, and Hypocrites: How Do They Live With Themselves.... lol how do we ?? 4 stars"
67,0151010986,http://goodreads.com/user/show/51519663-diana-nahirna,5,"Well, that explains a lot of my recent purchases, Iraq, and why marriages fail. "
68,0151010986,http://goodreads.com/user/show/1974052-milan,5,"Mistakes Were Made (But Not by Me) is quite an enlightening book by Carol Tavris and Elliot Aronson. The authors examine our deep-rooted tendencies to underplay our faults and errors and to exaggerate the mistakes of others, especially when they go against us. ""Cognitive dissonance occurs when a person holds two or more contradictory beliefs, ideas, or values, or participates in an action that goes against one of these three, and experiences psychological stress because of that."" Two lessons from this theory: “First, the ability to reduce dissonance helps us in countless ways, preserving our beliefs, confidence, decisions, self-esteem, and well-being. Second, this ability can get us into big trouble.”The self-justification mechanisms like cognitive dissonance, confirmation bias, and fabricated memory play such an important role in our lives that they are hard to ignore. The authors provide very vivid examples from politics, therapy, conflict, wars, marriage, police and court procedures to show how these biases work. A few important lessons: •	 “Most human beings and institutions are going to do everything in their power to reduce dissonance in ways that are favorable to them, that allow them to justify their mistakes and maintain business as usual.” •	“Most people, when directly confronted by evidence that they are wrong, do not change their point of view or course of action but justify it even more tenaciously. Even irrefutable evidence is rarely enough to pierce the mental armor of self-justification.”•	Our ‘mistake-phobic’ culture causes people not to learn from their mistakes.•	Naive realism: the believe that everyone else sees the world as we do•	We all self-justify as a way to protect against cognitive dissonance, whether positively or negatively.•	Memories are easily modified to fit a narrative to reduce cognitive dissonance.•	We must be careful to not allow memory distortion to justify previous decisions.•	Therapists should be very concerned about confirmation bias, their expert assessments and also in their evaluations of people.•	Confessions can be elicited from accused legally by using deceit, trickery, etc.•	Successful couples will give the benefit of the doubt to their partners, just as they would to themselves. Unsuccessful couples do the opposite.•	We must strive to take self-justification into account in our lives and relationships to prevent incorrect decisions making.Two things to keep in mind – our personal life will suffer if we don’t admit our mistakes and society will work better if people admitted when they’re wrong."
69,0151010986,http://goodreads.com/user/show/28602450-vladyslav-sitalo,4,"You think about yourself as a reasonably nice person, with not perfect but good enough memory. Maybe you've done some things in your life, that you don't particularly like, but you think that in most cases, given the situation you were in, most of the people would've done the same.So you ain't perfect but better than the most, right?Well, this book would get you to at least question, how accurate is the description above. And it will also tell you how come you (and most of the people, even most morally flawed, from your perspective, people) think of themselves in this way.The book will tell you how your mind is desperately trying to maintain the self-image, you have about yourself and protect beliefs your hold. How it change your perceptions of things around you to fit this image/beliefs. And here comes more fun: it also employs your memory to justify your current self-perception/beliefs. So your memory is gradually, with each recall, become more compliant with this image. And eventually, all you left with is the nice, coherent story of your life that corresponds to your current view of yourself and your beliefs. But this story often has little or nothing to do with reality.As authors call it: Memory is your self-justifying historian (I would also highly recommend a novelette by Ted Chiang - ""The Truth of Fact, the Truth of Feeling"" as an exploration of this aspect of our memory: https://www.goodreads.com/book/show/1...).And the thing is that this process influences pretty much every aspect of your life regardless of your age/education or other things, you might think would influence the situation.So the process kicks in:When you're a nice, kind boy, who find himself in a company that is bullying a weaker guy. You don't particularly like the process but, as you want to be a part of this social group - you continue to participate in it. But there is dissonance here: how come you, as a nice, kind boy become a bully? So here the self-justification comes to your help: ""It's totally the guy's responsibility that he got bullied. Let's modify our image of the guy to leave our self-image preserved and justify what've done. Yay! And hey we're justified to continue to bully him as he is such a ....""Or let's say you're a student who don't have any strong position on cheating. You know it's generally considered a ""bad thing"" but you don't have any personal conviction either way. You haven't done it earlier because you didn't need to. But now you're in the situation when you need either cheat or fail this particular course. So situation can go in two ways from here:World 1: You've decided to cheat. ""Self-justification process: Ok we've cheated, as we know we're a generally good person, so we could not have possibly done a bad thing, so we may conclude that cheating is not a big deal"".World 2: You've decided not to cheat. ""Self-justification process: Ok we've failed the course. That's unfortunate but, well we didn't have any other option, right? We wouldn't even consider doing such a terrible thing as cheating"".Or you're a detective and you've interrogated your suspect to the point that he have given you a confession. But here comes the strong evidence (like DNA test or videotape) that he is innocent. So here it goes: ""I'm an honest infallible detective and my interrogation methods are great, and, after all, the guy has given confession after only 36 consecutive hours of interrogation. The evidence must be wrong""And let's upgrade a bit more. You're an honest politician, who is right now flying with a lobbyist on a luxury private plane to spend a nice weekend in some luxury resort. ""As we're an honest, good man, this situation can't possibly influence our political judgment in any way, right?"" (To understand how you got in this situation in a first place and for a lot of other good examples - read the book ;)The more deeply held self-belief that is contradicting to what you did the more actively you would justify the deed as the kind of deed that don't contradict this self-belief.You probably think to yourself: ""Ok maybe some of the cases described in this book can be true about me, but in most of them I would not have employed this level of self-justification""Well, the problem is that self-justification is largely unconscious process so when you do something that don't correspond to your self-image or see information that contradicts your belief - the justification process kicks in automatically in the background.So usually, you don't even notice on the conscious level that you've maybe done something wrong or that you hold a questionable belief. And correspondingly you don't have a chance to fix the situation before you internalize it as the normal state of things.That's why it's often said ""Hypocrite is obvious to all but himself""So you would probably at this point like to know - are we doomed? Can we do better? And the answer is yes we can! The book advises us to institute impartial external overview committees wherever possible (if necessary even against the will of involved people/institutions) because the external observer can usually notice an error much easier than somebody who have committed it. As he is not emotionally/financially/in other way invested in this decision.In the situations where setting up such an institutions is not feasible or reasonable (For example in the case of personal relationships), make sure that you and people around are aware and conscious about the magic of self-justification. You also can, to some level, train yourself to recognize the typical situations where the process may kick in and be especially careful when facing them. Also, be aware of the fact that this magic works on other people, so when you try to point out his/her error to somebody, be careful to do it in a way that will not make them self-defensive and more likely to justify this error.And don't be afraid to admit your errors, because as you relinquish wrong beliefs you become wiser, as you own up to your errors you gain more respect from people and you're less likely to make the same error in the future. Everybody makes mistakes, but you only can learn from yours, when you admit them."
70,0151010986,http://goodreads.com/user/show/21170365-amy-anderson,5,"I loved this book and found it so applicable to everyone. While we need justification to move forward in life and not second guess our every decision, we also need to be aware that justification can lead us to be blind sighted to truth. Its a fine line to walk. I could quote this whole book, but here are my favorites:""Self-justification is more powerful and dangerous than the explicit lie. It allows people to convince themselves that what they did was the best thing they could have done. In fact, come to think of it, it was the right thing."" p.4""Self-justification not only minimizes our mistakes and bad decision, it is also the reason that everyone can see a hypocrite in action except the hypocrite."" p.4""How in the world can they live with themselves? The answer is exactly the way the rest of us do."" p.9""Yet mindless self-justification, like quicksand, can draw us deeper into disaster. It blocks our ability to even see our errors, let alone correct them. It distorts reality, keeping us from getting all the information we need and assessing the issues clearly. It prolongs and widens rifts between lovers, friends, and nations. It keeps us from letting go of unhealthy habits. IT permits the guilty to avoid taking responsibility for their deeds."" p.9""I will look at any additional evidence to confirm the opinion to which I have already come."" Lord Molson p.17""These mechanisms provide a neurological basis for the observation that once our minds are made up, it is hard to change them."" p.19""People become more certain they are right about something they just did if they can't undo it."" p.22""Decades of experimental research have found exactly the opposite: that when people vent their feelings aggressively they often feel worse, pump up their blood pressure and make themselves angrier."" p.26""Aggression begets self-justification, which begets more aggression."" p.27""How do you get an honest man to lose his ethical compass? You get hi to take one step at a time, and self-justification will do the rest."" p.37""Parent blaming is a popular and convenient form of self-justification because it allows people to live less uncomfortably with their regrets and imperfections."" p.76""...current self-concepts blurred their memories, bringing their past selves into harmony with their present ones."" p.79""If a memory is a central part of your identity, a self-serving distortion is even more likely."" p.79""For those who are trying to remember something that never happened, writing analyzing dreams, and drawing pictures- techniques that are the staples of many psychotherapists- are all methods that quickly conflate imagination with reality."" p.86""Once the seed of belief was planted [they] began to search for confirming evidence."" p.90""...the story fits the needs of the experiences."" p.91"",,,experiences have internalized their new false memories and cannot now distinguish them from true ones. They have come to believe their own stories."" p.93""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives."" p.93""Successful partners extend to each other the same self-forgiving ways of thinking we extend to ourselves: They forgive each other's missteps as being due to the situation, but give each other credit for the thoughtful and loving things they do."" p.169""It may sometimes be hard to define good, but evil has its unmistakable odor: Every child knows what pain is. Therefore, each time we deliberately inflict pain on another, we know what we are doing. We are doing evil."" Amoz p.198""Would you rather admit you're wrong now or wait until someone else proves it?"" p.221""People will pursue self-destructive courses of action to protect the wisdom of their initial decisions."" p.222""They will treat people they have hurt even more harshly, because they convince themselves that their victims deserve it."" p.222""People who are insecure in their religious beliefs may feel the impulse to silence and harass those who disagree with them, because their mere existence arouses the painful dissonance of doubt."" p.222"
71,0151010986,http://goodreads.com/user/show/5301457-sergei-moska,4,"Although this book didn't actually teach me anything new in terms of theory (but did provide me with many details of practical cases), it nonetheless surprised me. First, I decided to read this book at this time because I've been a bit burned out from dense reading and wanted something useful but light. It was in fact both these things, but it was also far, far more depressing than I had expected. I expected this to be a “Ha ha, let's look at our foibles!” type of read. No, it's more of a “your identity is a joke and the world systematically does evil things. And so do you.” kind of experience. Structurally speaking, the book is very simple. The first part posits a simplified theory, and the rest of the book demonstrates the theory in action, in a few select areas of life. The theory is that we need to overcome the cognitive dissonance that emerges when our actions conflict with our self-image or beliefs. At such a moment, we are said to be at the top of a “pyramid” (a 2-dimensional triangle would be a better image), and the authors believe that whether or not we choose to justify ourselves to ourselves in such moments will lead us down one side of the pyramid or the other, with drastically different outcomes once we hit either side of the base of the pyramid. I may give up the idea that I'm such a great guy, or I can decide that the other person deserved the treatment, that it really wasn't a big deal, etc. The authors believe that whatever choice we make will cause us – in order to avoid further cognitive dissonance – to more extreme positions in order to justify our initial choice. A number of surprising findings come about as a result. For instance, the more helpless the victim, the more we will tend to denigrate him in order to justify our initial mistreatment of him. Beating up an angry drunk at a bar doesn't necessarily require much justification (“He was being threatening, and it's fine to beat up people that are threatening”), but participating in bullying usually does (“I'm a nice guy and beating him up, so it must be because he's a weenie who deserves to be humiliated. Plus he'd do it if he had the chance”.)A fun book to read, although it was too simplified for my taste in at least two ways. First, the authors' theory is *very* simple, and at times their application of the theory seems too universal. For instance, why do innocent people confess to crimes? The authors only seem to entertain the notion that it's in order to reduce cognitive dissonance: “I didn't do anything, but all the cops say that they have proof. The cops are honest and good people, so I must be the problem.” Yet at times this just seems dubious. The explanation is far more convincing when they apply it to the decision by the police to continue interrogation even in the absence of evidence. The second way that the book was too simplified for my taste is in its structure. After a very good exposition of their theory, I was hoping that the subsequent material would help develop the theory further. But what it turned out to be was “Here's a theory, and now we're going to show you the theory in X, Y, and Z.” This is a matter of taste, but I really don't like that format. What's more, I do think it hurts the authors, since it implies that the answer to the subtitle of the book is monolithic. I don't think that to be the case, and I suspect the authors don't either. In fairness, they do incidentally go through a number of additional mechanisms that are attached to the problem of cognitive dissonance, including a wonderful treatment on the foibles of memory, but it would have been really nice to make their answer more complex and complete, even at the risk of making it less parsimonious. Normally that kind of issue would be a big turn-off for me, but the book really is saved (for me) by their incredibly chilling accounts, especially in chapters 3-6. The writing is very clear and engaging, and the book is also thoroughly annotated, all of which makes me fall a little bit in love with the authors."
72,0151010986,http://goodreads.com/user/show/1677868-steven-peterson,4,"This is a well written, snappy book that addresses an important issue, best described by the book's title and subtitle: ""Mistakes Were Made (but not by me): Why we justify foolish beliefs, bad decisions, and hurtful acts."" The two authors, both well reputed psychologists, use the theory of cognitive dissonance as their starting point. Leon Festinger was one of the major theorists of this approach. The authors of this book simply define the perspective thus (page 13): ""Cognitive dissonance is a state of tension that occurs whenever a person holds two cognitions (ideas, attitudes, beliefs, opinions) that are psychologically inconsistent, such as 'Smoking is a dumb thing to do because it could kill me' and 'I smoke two packs a day.'"" How does one deal with this? By adopting one of the positions and then downgrading or rejecting the other. The end result is self-justification, self-deception, seeking out evidence to support the choice that we have made while rejecting evidence that does not fit with our choice. The brain itself shows evidence of the operation of cognitive dissonance. The example on page 19 of functional Magnetic Resonance Imaging (fMRI) and processing information about presidential candidates is telling. The end result is ""blind spots,"" in which people (page 42) ""fail to notice vital events and information that might make them question their behavior or their convictions."" As such, the authors note that cognitive dissonance makes mincemeat of such theoretical views as rational actor theory and psychoanalytic theory. One result of cognitive dissonance is what is called ""confirmation bias,"" the attending to evidence that supports our views and the rejection/suppression of evidence that does not support our views. Many examples are advanced to illustrate the case that the authors make. Issues include: moral lapses (e.g., Watergate participants), ""made up"" memories (raising serious questions about the whole idea of repressed memories), criminal justice system decisions on guilt or innocence, and so on. Much is at stake with cognitive dissonance as it operates. In the closing chapter, the authors try to indicate how understanding cognitive dissonance might help us to limit the damage that may occur as a result of its operation. Convincing? I'm not so sure, but this discussion does get one thinking about how we might address the harmful side effects of cognitive dissonance. A readable book that raises important issues. I think that more use of neuroscientific research could have strengthened this book that much more. Also, the work by cognitive psychologists like Kahneman and Tversky could have spoken to key points as well. This book might also profitably be read in tandem with another recent book on a similar subject, Cordelia Fine, ""A Mind of Its Own."" In addition, Linden's ""accidental Mind"" provides a perspective on related issues from a neuroscience viewpoint. "
73,0151010986,http://goodreads.com/user/show/9281934-louise,5,"Prior to reading this, I had only considered the theory of cognitive dissonance as it applied to holding two contrary opinions, the classic example being that of the racist with friends who are members of the race s/he denigrates. Tavris and Aronson demonstrate further applications of this theory and how destructive the behavior it spawns continues to be.The 1980's/90's day care scandals pre-dated the 24 hour cable cycle (imagine this being covered today by Fox) so it blipped in and out of my attention. I remember thinking how it didn't add up, but I wasn't really following it. Today, somewhere below my radar screen are the DNA absolved prisoners, and their continued incarceration doesn't add up either. Tavris and Aronson show how the professionals involved continued and continue to stick to their long fought for opinion, even as evidence pours in against it. As the dissonance theory predicts, the greater the commitment to the opinion the more the mind works to re-enforce it.The book is most convincing on the personal level such as the damage caused by the dynamics in divorce or accusations such as those made by those in the recovered memory therapies.While cognitive dissonance is undoubtedly operative, it is not the only culprit in the inability to admit mistakes. For commercial and public policy issues there is liability to be paid either through job loss, litigation, an election, or even everyday office politics. If the culprit is a principal player on a big stage, it could be a career ender for not only the decider, but his/her staff. It is not just the mind that keeps out contrary information, there is undoubtedly social support for the bad decision by those who also made the mistake or assisted in its execution. There are also families to consider, you admit the mistake, you could lose your job and there will be no college education for your kids. The books speaks of these barriers, but sticks to its purpose of illustrating the theory.For barriers beyond cognitive dissonance, I think of George Bush and the Iraq war. If he could bring himself to admit the mistake, he would face huge institutional and social acrimony from the policy makers who assisted him, the party who supported him, the military as an institution and the families who lost their loved ones. Ultimate decision makers on the Iraq War will wait, like Robert McNamara did, until the mistake is universally recognized.This is an excellent book. The authors develop their theory for the lay person with good examples from both everyday life and the world of public policy. I highly recommend it. "
74,0151010986,http://goodreads.com/user/show/2414293-adelle,3,"The authors' political biases came through as they used the beginning and the ending of the book to castigate then (2007) President George W. Bush, and to call Newt Gingrich a “hypocrite” for criticizing (now former) President Bill Clinton’s sexual affair…WITHOUT any allusion to Clinton’s defensive “I did not have sex with that woman…Miss Lewinski” statement. But most of the center sections of the book--which thankfully were relatively free of politics--- I found endlessly fascinating. Oh, how tenaciously we cling to “our version” of the story, filtering the facts so that what WE did/or didn’t do is seen to be of negligible consequence or perhaps even honorable, and what THE OTHER GUY did/or didn’t do is seen to be righteously reprehensible, obviously beyond the pale. I loved, too, the authors’ many demonstrations that the act that alienates one party or the other is not a stand-alone event. To reference Aesop, it is much more likely to be the straw that broke the camel’s back. Hurts and grievances in both parties have probably been building for some time. “Who were the victims? It depends on how many years, decades, and centuries you take into account” (206). Consider Kosovo. Consider the Crusades. As the authors describe these tragic events, IF one is not emotionally involved with one side or the other, one can see BOTH points of view. Likewise in personal relationships. “Of all the stories that people construct to justify their lives, loves, and losses, the ones they weave to account for being the instigator or the recipient of injustice or harm are the most compelling and have the most far-reaching consequences” (191). Tavris and Aronson continue, “We have all done something that made others angry at us, and we have all been spurred to anger by what others have done to us. We all have, intentionally or unintentionally, hurt another person who will forever regard us as the villain, the betrayer, the scoundrel. And we have all … [been:] on the receiving end” (191). It would seem it is seldom the absolute fault of “the other guy.” But…that would mean…and humans on the whole have SUCH a vested interest in protecting their own self-image.A interesting, engaging read."
75,0151010986,http://goodreads.com/user/show/25763919-mimi,4," This is phenomenal! .......it made me love Psychology even more.This book has a protagonist , well ,i think it's more of an antagonist (to us) named : cognitive dissonance (i am so in love with this character hhhhh) ""Mistakes Were Made But Not By Me"" discusses all SORTS of lengths human being may go in order to reduce cognitive dissonance.Acting in contradiction to what u believe (cognitive dissonance) is 'painful' 'uncomfortable' so what we do? the remedy is employed extensively by all yet little know about it : it's self justification.How it works: you hate cheating (this is your belief), it happened and you cheated once voluntarily (contradicting behavior) ====== results is cognitive dissonance ( your self image is shaken ,because your belief about 'cheating' has being shaken)Huh! now comes the remedy time : cheating isn't that bad. the exam was unfairly difficult that's why i cheated these are some of the thoughts we may have once we start justifying our actions (cheating) to reduce cognitive dissonance.OK , now let me introduce you other cognitive biases that leads u to screwing up immensely:Confirmation bias : this dude screws rational healthy discussions... for it blinds you for one side of an argument completely. You believe in one side, you keep looking for info to prove it without EVER checking the arguments and evidence the opposite view might present ( this is what makes some peoples' craniums rock-hard , never allowing the penetration of any of your ideas or arguments ) Snap decisions/judgements : this guys are super bad , if you could just turn them off when you are presented with anything which needs you opinion ....when you take a snap decision you are done for , it becomes harder to see the other angles of a person , an idea ...unless you knew how dangerous these guys are for your objectivity and try harder to make a balanced judgment. Sadly humans are hardwired with many biases that makes them fallible creatures....and without knowing them they will be extra fallible."
76,0151010986,http://goodreads.com/user/show/17485839-zena-ryder,4,"If you don't know what cognitive dissonance is, this is a great introduction. If you do know what it is, this is an easy, enjoyable read, with interesting stories and experiments that illustrate dissonance and the resulting self-justification, which will likely deepen your understanding of this all too human phenomenon. The authors also talk about the fascinating and related phenomenon of false memories — our memories tend to get distorted (or even created!) to be self-serving. I found the section on how easily children can be persuaded to have memories of things that didn't really happen both fascinating and disturbing. The authors also talk about the how police officers' confirmation bias and the need to avoid dissonance by those involved at the various stages of the justice system can and does lead to terrible miscarriages of justice.I guess the biggest thing that was missing, for me, was more detail of when we don't give in to self-justification in order to avoid dissonance. The authors do talk about this, but I would have liked more detail. I would also like more detail on people with low self esteem, who don't tend to resolve their dissonance in self-serving ways, but rather in ways that fit their self image of being incompetent, unlovable etc.While knowing about cognitive biases and flaws isn't enough to make them magically go away, the authors suggest that being aware of them should make us less confident in our own convictions and memories, especially when they are self-serving. I think that is an important lesson for anyone."
77,0151010986,http://goodreads.com/user/show/4532156-alaa-a,5,"This year I started to be more interested in social psychology books in my hope to change my default sitting to the world and understand it better, and what better way than saying I was wrong to your self and owning the mistakes to your self...Its a very challenging book to read its started to with an eases of pointing the mistakes of politics and countries and introducing the conformation biases then going to personal stories that we are confined that happened when all evidenced are against.One of the psychological insights that has been messing around with my mind is the selective memory and that even if you feel strongly sure and emotionally attached to it can be wrong or even planted made me question my memories and if I am a hypocrite the explanation for people's unwillingness to admit mistakes, even to themselves, in a variety of realms. This far-reaching BOOK tackles irrational prejudices, false memories, misjudgement as a psychotherapist, prosecuting the wrong individual, blaming one's spousethe part of repressed memory therapy of rape victimise was eye opening for me as how easy for as to follow :Cognitive dissonanceConfirmation biasI read in the book ""thinking fast and slow "" that knowing this biases dose not stop you form doing it even for the experts in this felid but it can make you stop your self and question why you think or act this way, and that is about it what you can do!! "
78,0151010986,http://goodreads.com/user/show/5856337-mark,5,"Having been put off by several popular books by social psychologists I read in recent years which I felt failed to deliver on the promised goods (""Emotional Intelligence"" and ""Social Intelligence,"" both by Daniel Goldman come quickly to mind), I was both relieved and impressed as I listened to the audiobook version of ""Mistakes Were Made.""The authors not only convincingly support and develop their thesis from start to finish, they do so in an entertaining fashion. Furthermore, the book offers plenty of opportunity for practical application for any casual reader who dares to pause to consider how his or her own pride, cognitive dissonance, confirmation biases, etc. may cause him/her to re-write history, justify themselves and their experiences, blind themselves from seeing the truth, etc. I will mention one area where the authors may possibly be a little ""off."" Toward the end of the book, they share an example of Japanese encouraging mistakes in the classroom and seem to generalize this example for Asian culture. However, across mainland China, Japan, Taiwan, and Korea, societies seems to be somewhat intolerant of mistakes. Having said all that, this is still a great book. Read it!"
79,0151010986,http://goodreads.com/user/show/2050800-kathy,1,"Although the authors have some good points about self-justification in a few sections of the book, they clearly spend way too much time on the ""problem"" and their political biases than a plausible solution to overcoming self-justification. I read the last page of the book in complete disgust as to the topic they chose to end with and completely irritated that very few solutions were offered to help minimize self-justification in ourselves as well as others. I guess I should have read the title a little closer: It states ""Why we..."" and not ""How to overcome why we..."" Also found it very fitting based on the severe bias that shone through the entire book that there was not one mention of the infamous ""I did not have sexual relations with that woman"" by Bill Clinton. Now that's a perfect example of self-justification if I've ever seen one!There is nothing more irritating to me than reading 200 pages about a problem and then getting to the end and realizing the author offered no real solutions but a ton of biased opinions. What a waste!"
80,0151010986,http://goodreads.com/user/show/1347209-jacob,5,"As much as I read, there are few books that are enlightening, educational, and entertaining enough for me to rate them so highly. This is one of those books that every time you put it down you have to run and find someone to tell what you just read. You find the content so interesting that you can't help but share it with others.The authors do a great job at explaining cognitive dissonance and how it leads to self-justification. They also apply the concepts well by focusing a chapter on a specific realm of how this impacts our world (legal interrogation, false memory recovery, etc).If you have ever read ""Leadership and Self Deception"" I think you would enjoy this book also. More of the science behind the story.Read this and then apply the information in your life. It is blessing me and those around me and I'm sure it will you."
81,0151010986,http://goodreads.com/user/show/1984886-tim-kadlec,3,"The book was full of good information, and good discussions around cognitive dissonance. It's fault, however, was that the anecdotes tended to be very politically charged, and very biased.Unfortunately, the authors bias came through very strongly in several of the examples used, and this distracts from the points the authors are attempting to make. In addition, a few of the examples felt like they didn't really fit in with the subject matter, and were instead used to continue to justify the authors biases (ironic I know)."
82,0151010986,http://goodreads.com/user/show/26434622-sophiacoming,5,"One of my favorite books! make me more aware of my silly impulses. I think understanding these limitation is the basis for having a crucial conversation, and making peace with yourself and people around you."
83,0151010986,http://goodreads.com/user/show/58909202-edu,2,"The concept is very interesting, even necessary to know, and mindblowing, wich I liked a lot. But there were many many examples and much of them from USA politics, which I don't care so much about. "
84,0151010986,http://goodreads.com/user/show/8778400-rebekka-steg,5,"This week I've been reading Mistakes Were Made (But Not by Me): Why We Justify Foolish Beliefs, Bad Decisions, and Hurtful Acts by Carol Tavris and Elliot Aronson, an absolutely amazing book, which everyone should be acquired to read.The book deals with the issue of self-justification, and the role it plays in all of our lives, from such ""minor"" issues as arguments within a relationship, to bullying, prejudicialness, torture, fraud etc.Written by two psychologist, the book is backed by research as well as real life cases and examples. It's easy to read, incredibly thought-provoking and it deals with such an important topic, which affects us all.

 Quotes ""We are all capable of believing things which we know to be untrue, and then, when we are finally proved wrong, impudently twisting the facts so as to show that we were right. Intellectually, it is possible to carry on this process for an indefinite time: the only check on it is that sooner or later a false belief bumps up against solid reality, usually on a battlefield.""- George Orwell (1946)""For example, Elliot predicted that if people go through a great deal of pain, discomfort, effort, or embarrassment to get something, they will be happier with that ""something"" than if it came to them easily. For behaviorists this was a preposterous prediction. Why would people like anything associated with pain? But for Elliot, the answer was obvious: self-justification. The cognition that I am a sensible, competent person is dissonant with the cognition that I went through a painful procedure to achieve something - say, joining a group that turned out to be boring and worthless. Therefore, I would distort my perceptions of the group in a positive direction, trying to find good things about them and ignoring the downside.""""Venting is especially likely to backfire if a person commits an aggressive act against another person directly, which is exactly what cognitive dissonance theory would predict. When you do anything that harms someone else - get them in trouble, verbally abuse them or punch them out - a powerful new factor comes into play: the need to justify what you did. Take a boy who goes along with a group of his fellow seventh graders who are taunting and bullying a weaker kid who did them no harm. The boy likes being part of the gang but his heart really isn't in the bullying. Later, he feels some dissonance about what he did. ""How can a decent kid like me,"" he wonders, ""have done such a cruel thing to a nice, innocent little kid like him?"" To reduce dissonance, he will try to convince himself that the victim is neither nice nor innocent: ""He is such a nerd and cry-baby. Besides, he would have done the same to me if he had the chance."" Once the boy starts down the path of blaming the victim, he becomes more likely to beat up on the victim with even greater ferocity the next chance he gets. Justifying his first hurtful act sets the stage for more aggression. That's why the catharsis hypothesis is wrong.""""Our convictions about who we are carry us through the day, and we are constantly interpreting the things that happen to us through the filter of those core beliefs. When they are violated, even by a good experience, it causes us discomfort. An appreciation of the power of self-justification helps us understand, therefore, why people who have low self-esteem, or who simply believe that they are incompetent in some domain, are not totally overjoyed when they do something well; why, on the contrary, they often feel like frauds. If the woman who believes she is unlovable meets a terrified guy who starts pursuing her seriously, she will feel momentarily pleased, but that pleasure is likely to be tarnished by a rush of dissonance: ""What does he see in me?"" Her resolution is unlikely to be ""How nice; I must be more appealing than I thought I was."" More likely, it will be ""As soon as he discovers the real me, he'll dump me."" She will pay a high psychological price to have that consonance restored.""""The Milgram experiment shows us how ordinary people can end up doing immoral and harmful things through a chain reaction of behavior and subsequent self-justification. When we, as observers, look at them in puzzlement or dismay, we fail to realize that we are often looking at the end of a long, slow process down that pyramid. At his sentencing, Magruder said to Judge John Sirica: ""I know what I have done, and Your Honor knows what I have done. Somewhere between my ambition and my ideals, I lost my ethical compass."" How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self-justification will do the rest.""""The brain is designed with blind spots, optical and psychological, and one of its cleverest tricks is to confer on us the comforting delusion that we, personally, do not have any. In a sense, dissonance theory is a theory of blind spots - of how and why people unintentionally blind themselves so that they fail to notice vital events and information that might make them question their behavior or their convictions. Along with the confirmation bias, the brain comes packaged with other self-serving habits that allow us to justify our own perceptions and beliefs as being accurate, realistic, and unbiased. Social psychologist Lee Ross calls this phenomenon ""naïve realism,"" the inescapable conviction that we perceive objects and events clearly, ""as they really are."" We assume that other reasonable people see things the same way we do. If they disagree with us, they obviously aren't seeing clearly. Naïve realism creates a logical labyrinth because it presupposes two things. One, people who are open-minded and fair ought to agree with a reasonable opinion. And two, any opinion I hold must be reasonable; if it weren't, I wouldn't hold it. Therefore, if I can just get my opponents to sit down here and listen to me, so I can tell them how things really are, they will agree with me. And if they don't, it must be because they are biased.""""As fallible human beings, all of us share the impulse to justify ourselves and avoid taking responsibility for any actions that turn out to be harmful, immoral, or stupid. ... Most people when directly confronted with proof that they are wrong, do not change their point of view or course of action but justify it even more tenaciously.""""Just as we can identify hypocrisy in everyone but ourselves, just as it's obvious that others can be influenced by money but not ourselves, so we can see prejudices in everyone else but ourselves. Thanks to our ego-preserving blind spots, we cannot possibly have a prejudice, which is an irrational or mean-spirited feeling about all members of another group. Because are are not irrational or mean-spirited, any negative feelings we have about another group are justified; our dislikes are rational and well founded. It's theirs we need to suppress. Like the Hasids pounding on the Unprejudiced door at the Museum of Tolerance, we are blind to our own prejudices.""""When two people produce entirely different memories of the same event, observers usually assume that one of them is lying. Of course, some people do invent or embellish stories to manipulate or deceive their audiences, as James Frey notably did with his bestseller A Million Little Pieces. But most of us, most of the time, are neither telling the whole truth nor intentionally deceiving. We aren't lying; we are self-justifying. All of us, as we tell our stories, add details and omit inconvenient facts; we give the tale a small, self-enhancing spin; that spin goes over so well that the next time we add a slightly more dramatic embellishment; we justify that little white lie as making the story better and clearer - until what we remember may not have happened that way, or even may not have happened at all.""""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives. An appreciation of the distortions of memory, a realization that even deeply  felt memories might be wrong, might encourage people to hold their memories more lightly, to drop the certainty that their memories are always accurate, and to let go of the appealing impulse to use the past to justify problems of the present. If we are to be careful about what we wish for because it might come true, we must also be careful which memories we select to justify our lives, because than we will have to live by them.""""For any theory to be scientific, it must be stated in such a way that it can be shown to be false as well as true. If every outcome confirms your hypotheses that all men unconsciously suffer from castration anxiety; or that intelligent design, rather than evolution, accounts for the diversity of species; or that your favourite psychic would accurately have predicted 9/11 if only she hadn't been taking a shower that morning; or that all dolphins are kind to humans, your beliefs are a matter of faith, not science.""""Our implicit theories of why we and other people behave as we do come in one of two versions. We can say it's because of something in the situation or environment: ""The bank teller snapped at me because she is overworked today; there aren't enough tellers to handle these lines."" Or we can say it's because something is wrong with the person: ""That teller snapped at me because she is plain rude."" When we explain our own behavior, self-justification allows us to flatter ourselves: We give ourselves credit for our good actions but let the situation excuse the bad ones. When we do something that hurts another, for example, we rarely say, ""I behaved this way because I am a cruel and heartless human being."" We say, ""I was provoked; anyone would do what I did""; or ""I had no choice""; or ""Yes, I said some awful things, but that wasn't me - it's because I was drunk."" Yet when we do something generous, helpful, or brave, we don't say we did it because we were provoked or drunk or had no choice, or because the guy on the phone guilt-induced us into donating to charity. We did it because we are generous and open-hearted.""""Did Charles Graner and Lynndie England know what they were doing, let alone believe they were ""doing evil"" while they were deliberately inflicting pain and humiliation on their Iraqi prisoners and then laughing at them? No, they didn't, and that is why Amos Oz is wrong. Oz didn't reckon with the power of self-justification: We are good people. Therefore, if we deliberately inflict pain on another, the other must have deserved it. Therefore, we are not doing evil, quite the contrary. We are doing good. The relatively small percentage of people who cannot or will not reduce dissonance this way pay a large psychological price in guilt, anguish, anxiety, nightmares, and sleepless nights. The pain of living with horrors they have committed, but cannot morally accept, would be searing, which is why most people will reach for any justification available to assuage the dissonance. In the previous chapter, we saw on a smaller scale why many divorcing couples justify the hurt they inflict on each other. In the horrifying calculus of self-deception, the greater the pain we inflict on others, the greater the need to justify it to maintain our feelings of decency and self-worth. Because our victims deserved what they got, we hate them even more than we did before we harmed them, which in turn makes us inflict even more pain on them.""""But what are we supposed to do in our everyday lives? Call an external review board of cousins and in-laws to adjudicate every family quarrel? Videotape all parental interrogations of their teenagers? In our private relationships, we are on our own, and that calls for some self-awareness. Once we understand how and when we need to reduce dissonance, we can become more vigilant about the process and often nip it in the bud; like Oprah, we can catch ourselves before we slide too far down the pyramid. By looking at our actions critically and dispassionately, as if we were observing someone else, we stand a chance of bring out of the cycle of action followed by self-justification, followed by more committed action. We can learn to put a little space between what we feel and how we respond, insert a moment of reflection, and think about whether we really want to buy that canoe in January, really want to send good money after bad, really want to hold on to a belief that is unfettered by facts. We might even change our minds before our brains freeze our thoughts into consistent patterns.""""Humbling yes, but ultimately that's the point. Understanding how the mind yearns for consonance, and rejects information that questions our beliefs, decisions, or preferences, teaches us to be open to the possibility of error. It also helps us let go of the need to be right. Confidence is a fine and useful quality; none of us would want a physician who was forever wallowing in uncertainty and couldn't decide how to treat our illness, but we do want one who is open-minded and willing to learn. Nor would most of us wish to live without passions or convictions, which give our lives meaning and color, energy and hope. When confidence and convictions are unleavened by humility, by an acceptance of fallibility, people can easily cross the line from healthy self-assurance to arrogance. In this book, we have met many who crossed that line: the psychiatrists who are certain that they can tell if a recovered memory is valid; the physicians and judges who are certain that they are above conflicts of interest; the police officers who are certain that they can tell if a suspect is lying; the prosecutors who are certain that they convicted the guilty party; the husbands and wives who are certain that their interpretation of events is the right one; the nations who are certain that their version of history is the only one.""""Most Americans know they are supposed to say ""we learn from our mistakes,"" but deep down, they don't believe it for a minute. They think that mistakes mean you are stupid. Combined with the culture's famous amnesia for anything that happened more than a month ago, this attitude means that people treat mistakes like hot potatoes, eager to get rid of them as fast as possible, even if they have to toss them in someone else's lap."""
85,0151010986,http://goodreads.com/user/show/8435102-joan,3,"Why is it so hard for us to admit we have made a mistake? Why do we justify our actions? Why is it so hard to change our minds when we think we are right?The authors wrote this book with a goal of understanding those behaviors. I learned tons about why we say what we do to ourselves. Self-justification, for example. We convince ourselves we made the best choice possible. Unfortunately, that blocks us from seeing our errors and learning from them.I read about cognitive dissonance and how it changes our perception. When we see disconfirming evidence, we will criticize the source (fake news), distort or outright dismiss it. Maintaining the belief is more important than truth. And we have confirmation bias, the reason it is so hard to change our minds when we have made a firm decision. I also learned much about blind spots, how our memories change (or we change them purposely), and false memories. The authors give many examples of interrogators (such as child psychologists) manipulating people to confess to crimes or report non-existing events. They give examples of law enforcement officials and prosecutors refusing to admit mistakes even when DNA evidence finally proves them wrong.Rounding out this informative book are thoughts on the price paid for for justifying decisions that cause pain to others. For example, international acts are justified by saying our deeds were bad but not nearly as bad as theirs.The authors end the book reminding us of the benefits of admitting mistakes. There is a positive effect. For politicians, admitting a mistake results in constituents admiring the person is big enough to admit wrong and desire to learn from mistakes.This is an interesting book that is very informative and easy to read. I really found it enlightening in explaining much of the rhetoric we hear today."
86,0151010986,http://goodreads.com/user/show/28157679-susan-s-frederick,5,"Really opened my eyes to bias and lenses that are different for each of us, but have profound effect on how we see things, remember things, feel things. Fascinating."
87,0151010986,http://goodreads.com/user/show/4134989-chuck,4,"A well written exposure of dissonance avoidance, self-justification, confirmation bias and other forces that effect us all. The examples and insights here are especially helpful in understanding why ourself and others make mistakes, defend actions, and choose self-preserving narratives. A revelation into neural, natural wiring. A brave look into the mirror as well as the boundaries of tolerance we construct for others. Keen, practical eye-opening read. "
88,0151010986,http://goodreads.com/user/show/32598115-becky,5,This was an interesting look at how our minds work to dissociate with problems and errors in judgement.
89,0151010986,http://goodreads.com/user/show/2251009-esteban-del-mal,4,"Cognitive dissonance: The mental discomfort experienced by a person who holds two or more contradictory beliefs, ideas, or values. This discomfort is triggered by a situation in which a person's belief clashes with new evidence perceived by the person. When confronted with facts that contradict beliefs, ideals, and/or values, people will try to find a way to resolve the contradiction to reduce their discomfort (~squaring a circle).Cognitive bias: A systematic pattern of deviation from norm or rationality in judgment. Individuals create their own subjective social reality from their perception of the input. An individual's construction of social reality, not the objective input, may dictate his or her behavior in the social world; thus, cognitive biases may sometimes lead to perceptual distortion, inaccurate judgment, illogical interpretation, or what is broadly called irrationality. Catharsis: The psychodynamic principle of emotional release. It's a bullshit theory leftover from Freud. Self-justification: How, when a person encounters cognitive dissonance or a situation in which a person's behavior is inconsistent with his/her beliefs, that person tends to justify the behavior and deny any negative feedback associated with the behavior. Naive realism: The human tendency to believe that we see the world around us objectively and that people who disagree with us must be uninformed, irrational, or biased.Totalitaian ego: a) The ego/self is an organization of knowledge; b) ego/self is characterized by cognitive biases analogous to totalitarian information-control strategies, and; c) these totalitarian-ego biases function to preserve organization in cognitive structures.Reconstructive memory: A theory of memory recall in which the act of remembering is influenced by various other cognitive processes including perception, imagination, semantic memory, and beliefs. People view their memories as being a coherent and truthful account of episodic memory and believe their perspective is free from error during recall; however, the reconstructive process of memory recall is subject to distortion by other intervening cognitive functions such as individual perceptions, social influences, and world knowledge, all of which can lead to errors during reconstruction. [REPRESSED MEMORIES DO NOT EXIST]Source confusion: An attribute seen in different people's accounts of the same event after hearing people speak about the situation (for example, a witness who heard a police officer say someone had a gun who then states he/she saw the gun).Anomie: A condition in which society provides little moral guidance to individuals. This state evolves from conflict of belief systems and causes a breakdown of social bonds between an individual and the community. In a person, this condition can progress into a dysfunctional ability to integrate within the normative situations of his/her social world (for example, an unruly personal scenario that results in fragmentation of social identity and rejection of values). The term is commonly understood to mean normlessness.Imagination inflation: The finding that imagining an event which never happened can increase confidence that it actually occurred.Confidence-accuracy relationship: As one's confidence increases, so does one's level of accuracy (or belief therein).Benevolent dolphin problem: Every once in a while, a news story appears about a shipwrecked sailor who, on the verge of drowning, is nudged to safety by a dolphin. It is tempting to conclude that dolphins must really like human beings, enough to save us from drowning. But wait—are dolphins aware that humans don’t swim as well as they do? Are they actually intending to be helpful? To answer that question, we would need to know how many shipwrecked sailors have been gently nudged further out to sea by dolphins, there to drown and never be heard from again. We don’t know about those cases because the swimmers don’t live to tell us about their evil-dolphin experiences. If we had that information, we might conclude that dolphins are neither benevolent nor evil; they are just being playful.Effort justification: A person's tendency to attribute a value to an outcome which he/she had to put effort into achieving which is greater than the objective value of the outcome (i.e., the more effort put into something, the more it is valued).Implicit personality theory: The specific patterns and biases an individual uses when forming impressions based on a limited amount of initial information about an individual or situation."
90,0151010986,http://goodreads.com/user/show/11966043-lia,5,"4.5 starsI think this is one of the best non-fiction books I've ever read. It is so fascinating and it is so well-written. I've learned so much, about others and about myself. I honestly think that reading this book makes you a better person. I couldn't recommend it more."
91,0151010986,http://goodreads.com/user/show/23790728-amani,5,This was a very interesting and informative read. 
92,0151010986,http://goodreads.com/user/show/522647-kathy,4,"I'm so depressed. Humans, grrr. If you've ever wondered why people won't admit mistakes even in the face of verifiable truth contradicting their actions or beliefs, this book explains why. With sections on cognitive dissonance, why we think we're above outside influence, memory (yes, we make up our own ""memories""), scientific research fallacies, law enforcement/prosecution proceedings and relationship killers the gamut is pretty much covered. And, it's depressing. Did I mention that already? Well, it bears mentioning twice. We humans are geared to stick to our figurative guns no matter what. I have no hope for our current political unrest in the USA to get better any time soon. Sigh."
93,0151010986,http://goodreads.com/user/show/64733542-nafisa,5,"""A nation's character, and an individual's integrity, do not depend on being error-free. It depends on what we do after making an error.""Once in a while, I come across a book that makes me question my self-concept; this book is one of them. Broadly, it is about cognitive dissonance -- the psychological stress we face when our actions contradict our beliefs and ideals. Since we don't like to think of ourselves as incompetent or ill-intentioned, our natural tendency is to convince ourselves that we did the right thing. Mindless self-justification in the face of cognitive dissonance can have far-reaching (and often devastating) consequences, and the authors do a commendable job of documenting such examples from numerous distinct domains ranging from the criminal justice system, politics, medicine, and even marriage and relationships. A fresh set of ideas, quite compelling, and sometimes challenging to read as they force you to constantly self-reflect. I highly recommend it to anyone with an interest in psychology. The book is not intended to be self-help but offers a lot of scope for personal growth."
94,0151010986,http://goodreads.com/user/show/3669193-mah-ebr,5,i think everyone should read this one! 
95,0151010986,http://goodreads.com/user/show/901342-jacob,4,"This covers ground related to Evil Genes: Why Rome Fell, Hitler Rose, Enron Failed, and My Sister Stole My Mother's Boyfriend and The Honest Truth About Dishonesty: How We Lie to Everyone--Especially Ourselves, but it's specifically about self-justification. It's attempting to answer the question ""Why do people self-justify obvious mistakes?"" and look at the impact of doing so. It's pretty straightforward and quite readable.Self-justification is a useful and even essential way for humans to protect their ego and mental health, but it can get pretty out of whack. Self-justification is not only sad when it helps us decide to do things we shouldn't, it's extra sad when people do things they shouldn't only because they are trying to support an existing self-justification for a previous bad decision. One of the elaborated examples is when innocent people go to jail: it's bad enough when police and attorneys justify acting unethically in order to convict someone they ""know"" is guilty. Where it becomes absolutely unconscionable is where they work hard to prevent people from being proven innocent after the fact so they don't have to admit screwing up.On a lighter note, with books about human fallibility you have to chuckle when the authors display the very fallibility they're decrying. In one case, they claim to be certain about someone's motivation for making poor remarks without allowing for those remarks to be caused by that person looking for any excuse to self-justify behavior. In another case, they berate therapists for not thinking scientifically and not examining the disconfirming cases, then talk about the Gottmans' work on predicting divorce without examining the disconfirming cases (where the Gottmans predicted divorce and were wrong). They mention a case where of 10 of 47 couples were predicted to divorce, all 7 who did divorce were predicted ones. Of the remaining 40, all they say is that the 90% accuracy is impressive. But they don't address that 30% of the predicted divorces didn't happen, which pokes a hole in their nice theory about self-justification causing divorce. That wouldn't be a problem if they hadn't already spent a chapter bagging on therapists for having pet theories without looking at evidence that would contradict the theory.One of the reasons you chuckle over those kinds of mistakes instead of criticizing is because we ALL do those things. I'm not immune from doing those very same things, and neither is anyone else. But we might become less that way if we are aware of the phenomenon and try to identify when we are justifying ourselves."
96,0151010986,http://goodreads.com/user/show/7399266-camie,4,"I should start by saying I find social psychology fascinating! This book is about cognitive dissonance , which basically means having two conflicting beliefs and the measures we will resort to in order to defend and justify our beliefs , decisions, and actions. Backed by much research, this very insightful book explains how we all are capable of self deception, why we do it, why it is harmful, and how to overcome the very human mechanism of justifying our foolish beliefs, improper actions, poor decisions, and hurtful acts, and more importantly how to keep small things from escalating to disastrous proportions. Looking at everything from political situations, criminal acts, war, marriage, and personal levels it offers answers to how impossible atrocities come about , one justification at a time. ""How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self justification will do the rest."" From the politician who can't publically admit his actions, the torturer who feels no guilt, to the person who will say anything to win an argument, this book explains why it is so easy to see the hypocrisy of others while being totally blind to our own. Co-written by Elliot Aronson, author of The Social Animal , a great textbook, this is a very readable informative book. The introduction is called Knaves, Fools, Villains, and Hypocrites: How Do They Live With Themselves.... lol how do we ?? 4 stars"
97,0151010986,http://goodreads.com/user/show/51519663-diana-nahirna,5,"Well, that explains a lot of my recent purchases, Iraq, and why marriages fail. "
98,0151010986,http://goodreads.com/user/show/1974052-milan,5,"Mistakes Were Made (But Not by Me) is quite an enlightening book by Carol Tavris and Elliot Aronson. The authors examine our deep-rooted tendencies to underplay our faults and errors and to exaggerate the mistakes of others, especially when they go against us. ""Cognitive dissonance occurs when a person holds two or more contradictory beliefs, ideas, or values, or participates in an action that goes against one of these three, and experiences psychological stress because of that."" Two lessons from this theory: “First, the ability to reduce dissonance helps us in countless ways, preserving our beliefs, confidence, decisions, self-esteem, and well-being. Second, this ability can get us into big trouble.”The self-justification mechanisms like cognitive dissonance, confirmation bias, and fabricated memory play such an important role in our lives that they are hard to ignore. The authors provide very vivid examples from politics, therapy, conflict, wars, marriage, police and court procedures to show how these biases work. A few important lessons: •	 “Most human beings and institutions are going to do everything in their power to reduce dissonance in ways that are favorable to them, that allow them to justify their mistakes and maintain business as usual.” •	“Most people, when directly confronted by evidence that they are wrong, do not change their point of view or course of action but justify it even more tenaciously. Even irrefutable evidence is rarely enough to pierce the mental armor of self-justification.”•	Our ‘mistake-phobic’ culture causes people not to learn from their mistakes.•	Naive realism: the believe that everyone else sees the world as we do•	We all self-justify as a way to protect against cognitive dissonance, whether positively or negatively.•	Memories are easily modified to fit a narrative to reduce cognitive dissonance.•	We must be careful to not allow memory distortion to justify previous decisions.•	Therapists should be very concerned about confirmation bias, their expert assessments and also in their evaluations of people.•	Confessions can be elicited from accused legally by using deceit, trickery, etc.•	Successful couples will give the benefit of the doubt to their partners, just as they would to themselves. Unsuccessful couples do the opposite.•	We must strive to take self-justification into account in our lives and relationships to prevent incorrect decisions making.Two things to keep in mind – our personal life will suffer if we don’t admit our mistakes and society will work better if people admitted when they’re wrong."
99,0151010986,http://goodreads.com/user/show/28602450-vladyslav-sitalo,4,"You think about yourself as a reasonably nice person, with not perfect but good enough memory. Maybe you've done some things in your life, that you don't particularly like, but you think that in most cases, given the situation you were in, most of the people would've done the same.So you ain't perfect but better than the most, right?Well, this book would get you to at least question, how accurate is the description above. And it will also tell you how come you (and most of the people, even most morally flawed, from your perspective, people) think of themselves in this way.The book will tell you how your mind is desperately trying to maintain the self-image, you have about yourself and protect beliefs your hold. How it change your perceptions of things around you to fit this image/beliefs. And here comes more fun: it also employs your memory to justify your current self-perception/beliefs. So your memory is gradually, with each recall, become more compliant with this image. And eventually, all you left with is the nice, coherent story of your life that corresponds to your current view of yourself and your beliefs. But this story often has little or nothing to do with reality.As authors call it: Memory is your self-justifying historian (I would also highly recommend a novelette by Ted Chiang - ""The Truth of Fact, the Truth of Feeling"" as an exploration of this aspect of our memory: https://www.goodreads.com/book/show/1...).And the thing is that this process influences pretty much every aspect of your life regardless of your age/education or other things, you might think would influence the situation.So the process kicks in:When you're a nice, kind boy, who find himself in a company that is bullying a weaker guy. You don't particularly like the process but, as you want to be a part of this social group - you continue to participate in it. But there is dissonance here: how come you, as a nice, kind boy become a bully? So here the self-justification comes to your help: ""It's totally the guy's responsibility that he got bullied. Let's modify our image of the guy to leave our self-image preserved and justify what've done. Yay! And hey we're justified to continue to bully him as he is such a ....""Or let's say you're a student who don't have any strong position on cheating. You know it's generally considered a ""bad thing"" but you don't have any personal conviction either way. You haven't done it earlier because you didn't need to. But now you're in the situation when you need either cheat or fail this particular course. So situation can go in two ways from here:World 1: You've decided to cheat. ""Self-justification process: Ok we've cheated, as we know we're a generally good person, so we could not have possibly done a bad thing, so we may conclude that cheating is not a big deal"".World 2: You've decided not to cheat. ""Self-justification process: Ok we've failed the course. That's unfortunate but, well we didn't have any other option, right? We wouldn't even consider doing such a terrible thing as cheating"".Or you're a detective and you've interrogated your suspect to the point that he have given you a confession. But here comes the strong evidence (like DNA test or videotape) that he is innocent. So here it goes: ""I'm an honest infallible detective and my interrogation methods are great, and, after all, the guy has given confession after only 36 consecutive hours of interrogation. The evidence must be wrong""And let's upgrade a bit more. You're an honest politician, who is right now flying with a lobbyist on a luxury private plane to spend a nice weekend in some luxury resort. ""As we're an honest, good man, this situation can't possibly influence our political judgment in any way, right?"" (To understand how you got in this situation in a first place and for a lot of other good examples - read the book ;)The more deeply held self-belief that is contradicting to what you did the more actively you would justify the deed as the kind of deed that don't contradict this self-belief.You probably think to yourself: ""Ok maybe some of the cases described in this book can be true about me, but in most of them I would not have employed this level of self-justification""Well, the problem is that self-justification is largely unconscious process so when you do something that don't correspond to your self-image or see information that contradicts your belief - the justification process kicks in automatically in the background.So usually, you don't even notice on the conscious level that you've maybe done something wrong or that you hold a questionable belief. And correspondingly you don't have a chance to fix the situation before you internalize it as the normal state of things.That's why it's often said ""Hypocrite is obvious to all but himself""So you would probably at this point like to know - are we doomed? Can we do better? And the answer is yes we can! The book advises us to institute impartial external overview committees wherever possible (if necessary even against the will of involved people/institutions) because the external observer can usually notice an error much easier than somebody who have committed it. As he is not emotionally/financially/in other way invested in this decision.In the situations where setting up such an institutions is not feasible or reasonable (For example in the case of personal relationships), make sure that you and people around are aware and conscious about the magic of self-justification. You also can, to some level, train yourself to recognize the typical situations where the process may kick in and be especially careful when facing them. Also, be aware of the fact that this magic works on other people, so when you try to point out his/her error to somebody, be careful to do it in a way that will not make them self-defensive and more likely to justify this error.And don't be afraid to admit your errors, because as you relinquish wrong beliefs you become wiser, as you own up to your errors you gain more respect from people and you're less likely to make the same error in the future. Everybody makes mistakes, but you only can learn from yours, when you admit them."
100,0151010986,http://goodreads.com/user/show/21170365-amy-anderson,5,"I loved this book and found it so applicable to everyone. While we need justification to move forward in life and not second guess our every decision, we also need to be aware that justification can lead us to be blind sighted to truth. Its a fine line to walk. I could quote this whole book, but here are my favorites:""Self-justification is more powerful and dangerous than the explicit lie. It allows people to convince themselves that what they did was the best thing they could have done. In fact, come to think of it, it was the right thing."" p.4""Self-justification not only minimizes our mistakes and bad decision, it is also the reason that everyone can see a hypocrite in action except the hypocrite."" p.4""How in the world can they live with themselves? The answer is exactly the way the rest of us do."" p.9""Yet mindless self-justification, like quicksand, can draw us deeper into disaster. It blocks our ability to even see our errors, let alone correct them. It distorts reality, keeping us from getting all the information we need and assessing the issues clearly. It prolongs and widens rifts between lovers, friends, and nations. It keeps us from letting go of unhealthy habits. IT permits the guilty to avoid taking responsibility for their deeds."" p.9""I will look at any additional evidence to confirm the opinion to which I have already come."" Lord Molson p.17""These mechanisms provide a neurological basis for the observation that once our minds are made up, it is hard to change them."" p.19""People become more certain they are right about something they just did if they can't undo it."" p.22""Decades of experimental research have found exactly the opposite: that when people vent their feelings aggressively they often feel worse, pump up their blood pressure and make themselves angrier."" p.26""Aggression begets self-justification, which begets more aggression."" p.27""How do you get an honest man to lose his ethical compass? You get hi to take one step at a time, and self-justification will do the rest."" p.37""Parent blaming is a popular and convenient form of self-justification because it allows people to live less uncomfortably with their regrets and imperfections."" p.76""...current self-concepts blurred their memories, bringing their past selves into harmony with their present ones."" p.79""If a memory is a central part of your identity, a self-serving distortion is even more likely."" p.79""For those who are trying to remember something that never happened, writing analyzing dreams, and drawing pictures- techniques that are the staples of many psychotherapists- are all methods that quickly conflate imagination with reality."" p.86""Once the seed of belief was planted [they] began to search for confirming evidence."" p.90""...the story fits the needs of the experiences."" p.91"",,,experiences have internalized their new false memories and cannot now distinguish them from true ones. They have come to believe their own stories."" p.93""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives."" p.93""Successful partners extend to each other the same self-forgiving ways of thinking we extend to ourselves: They forgive each other's missteps as being due to the situation, but give each other credit for the thoughtful and loving things they do."" p.169""It may sometimes be hard to define good, but evil has its unmistakable odor: Every child knows what pain is. Therefore, each time we deliberately inflict pain on another, we know what we are doing. We are doing evil."" Amoz p.198""Would you rather admit you're wrong now or wait until someone else proves it?"" p.221""People will pursue self-destructive courses of action to protect the wisdom of their initial decisions."" p.222""They will treat people they have hurt even more harshly, because they convince themselves that their victims deserve it."" p.222""People who are insecure in their religious beliefs may feel the impulse to silence and harass those who disagree with them, because their mere existence arouses the painful dissonance of doubt."" p.222"
101,0151010986,http://goodreads.com/user/show/5301457-sergei-moska,4,"Although this book didn't actually teach me anything new in terms of theory (but did provide me with many details of practical cases), it nonetheless surprised me. First, I decided to read this book at this time because I've been a bit burned out from dense reading and wanted something useful but light. It was in fact both these things, but it was also far, far more depressing than I had expected. I expected this to be a “Ha ha, let's look at our foibles!” type of read. No, it's more of a “your identity is a joke and the world systematically does evil things. And so do you.” kind of experience. Structurally speaking, the book is very simple. The first part posits a simplified theory, and the rest of the book demonstrates the theory in action, in a few select areas of life. The theory is that we need to overcome the cognitive dissonance that emerges when our actions conflict with our self-image or beliefs. At such a moment, we are said to be at the top of a “pyramid” (a 2-dimensional triangle would be a better image), and the authors believe that whether or not we choose to justify ourselves to ourselves in such moments will lead us down one side of the pyramid or the other, with drastically different outcomes once we hit either side of the base of the pyramid. I may give up the idea that I'm such a great guy, or I can decide that the other person deserved the treatment, that it really wasn't a big deal, etc. The authors believe that whatever choice we make will cause us – in order to avoid further cognitive dissonance – to more extreme positions in order to justify our initial choice. A number of surprising findings come about as a result. For instance, the more helpless the victim, the more we will tend to denigrate him in order to justify our initial mistreatment of him. Beating up an angry drunk at a bar doesn't necessarily require much justification (“He was being threatening, and it's fine to beat up people that are threatening”), but participating in bullying usually does (“I'm a nice guy and beating him up, so it must be because he's a weenie who deserves to be humiliated. Plus he'd do it if he had the chance”.)A fun book to read, although it was too simplified for my taste in at least two ways. First, the authors' theory is *very* simple, and at times their application of the theory seems too universal. For instance, why do innocent people confess to crimes? The authors only seem to entertain the notion that it's in order to reduce cognitive dissonance: “I didn't do anything, but all the cops say that they have proof. The cops are honest and good people, so I must be the problem.” Yet at times this just seems dubious. The explanation is far more convincing when they apply it to the decision by the police to continue interrogation even in the absence of evidence. The second way that the book was too simplified for my taste is in its structure. After a very good exposition of their theory, I was hoping that the subsequent material would help develop the theory further. But what it turned out to be was “Here's a theory, and now we're going to show you the theory in X, Y, and Z.” This is a matter of taste, but I really don't like that format. What's more, I do think it hurts the authors, since it implies that the answer to the subtitle of the book is monolithic. I don't think that to be the case, and I suspect the authors don't either. In fairness, they do incidentally go through a number of additional mechanisms that are attached to the problem of cognitive dissonance, including a wonderful treatment on the foibles of memory, but it would have been really nice to make their answer more complex and complete, even at the risk of making it less parsimonious. Normally that kind of issue would be a big turn-off for me, but the book really is saved (for me) by their incredibly chilling accounts, especially in chapters 3-6. The writing is very clear and engaging, and the book is also thoroughly annotated, all of which makes me fall a little bit in love with the authors."
102,0151010986,http://goodreads.com/user/show/1677868-steven-peterson,4,"This is a well written, snappy book that addresses an important issue, best described by the book's title and subtitle: ""Mistakes Were Made (but not by me): Why we justify foolish beliefs, bad decisions, and hurtful acts."" The two authors, both well reputed psychologists, use the theory of cognitive dissonance as their starting point. Leon Festinger was one of the major theorists of this approach. The authors of this book simply define the perspective thus (page 13): ""Cognitive dissonance is a state of tension that occurs whenever a person holds two cognitions (ideas, attitudes, beliefs, opinions) that are psychologically inconsistent, such as 'Smoking is a dumb thing to do because it could kill me' and 'I smoke two packs a day.'"" How does one deal with this? By adopting one of the positions and then downgrading or rejecting the other. The end result is self-justification, self-deception, seeking out evidence to support the choice that we have made while rejecting evidence that does not fit with our choice. The brain itself shows evidence of the operation of cognitive dissonance. The example on page 19 of functional Magnetic Resonance Imaging (fMRI) and processing information about presidential candidates is telling. The end result is ""blind spots,"" in which people (page 42) ""fail to notice vital events and information that might make them question their behavior or their convictions."" As such, the authors note that cognitive dissonance makes mincemeat of such theoretical views as rational actor theory and psychoanalytic theory. One result of cognitive dissonance is what is called ""confirmation bias,"" the attending to evidence that supports our views and the rejection/suppression of evidence that does not support our views. Many examples are advanced to illustrate the case that the authors make. Issues include: moral lapses (e.g., Watergate participants), ""made up"" memories (raising serious questions about the whole idea of repressed memories), criminal justice system decisions on guilt or innocence, and so on. Much is at stake with cognitive dissonance as it operates. In the closing chapter, the authors try to indicate how understanding cognitive dissonance might help us to limit the damage that may occur as a result of its operation. Convincing? I'm not so sure, but this discussion does get one thinking about how we might address the harmful side effects of cognitive dissonance. A readable book that raises important issues. I think that more use of neuroscientific research could have strengthened this book that much more. Also, the work by cognitive psychologists like Kahneman and Tversky could have spoken to key points as well. This book might also profitably be read in tandem with another recent book on a similar subject, Cordelia Fine, ""A Mind of Its Own."" In addition, Linden's ""accidental Mind"" provides a perspective on related issues from a neuroscience viewpoint. "
103,0151010986,http://goodreads.com/user/show/9281934-louise,5,"Prior to reading this, I had only considered the theory of cognitive dissonance as it applied to holding two contrary opinions, the classic example being that of the racist with friends who are members of the race s/he denigrates. Tavris and Aronson demonstrate further applications of this theory and how destructive the behavior it spawns continues to be.The 1980's/90's day care scandals pre-dated the 24 hour cable cycle (imagine this being covered today by Fox) so it blipped in and out of my attention. I remember thinking how it didn't add up, but I wasn't really following it. Today, somewhere below my radar screen are the DNA absolved prisoners, and their continued incarceration doesn't add up either. Tavris and Aronson show how the professionals involved continued and continue to stick to their long fought for opinion, even as evidence pours in against it. As the dissonance theory predicts, the greater the commitment to the opinion the more the mind works to re-enforce it.The book is most convincing on the personal level such as the damage caused by the dynamics in divorce or accusations such as those made by those in the recovered memory therapies.While cognitive dissonance is undoubtedly operative, it is not the only culprit in the inability to admit mistakes. For commercial and public policy issues there is liability to be paid either through job loss, litigation, an election, or even everyday office politics. If the culprit is a principal player on a big stage, it could be a career ender for not only the decider, but his/her staff. It is not just the mind that keeps out contrary information, there is undoubtedly social support for the bad decision by those who also made the mistake or assisted in its execution. There are also families to consider, you admit the mistake, you could lose your job and there will be no college education for your kids. The books speaks of these barriers, but sticks to its purpose of illustrating the theory.For barriers beyond cognitive dissonance, I think of George Bush and the Iraq war. If he could bring himself to admit the mistake, he would face huge institutional and social acrimony from the policy makers who assisted him, the party who supported him, the military as an institution and the families who lost their loved ones. Ultimate decision makers on the Iraq War will wait, like Robert McNamara did, until the mistake is universally recognized.This is an excellent book. The authors develop their theory for the lay person with good examples from both everyday life and the world of public policy. I highly recommend it. "
104,0151010986,http://goodreads.com/user/show/2414293-adelle,3,"The authors' political biases came through as they used the beginning and the ending of the book to castigate then (2007) President George W. Bush, and to call Newt Gingrich a “hypocrite” for criticizing (now former) President Bill Clinton’s sexual affair…WITHOUT any allusion to Clinton’s defensive “I did not have sex with that woman…Miss Lewinski” statement. But most of the center sections of the book--which thankfully were relatively free of politics--- I found endlessly fascinating. Oh, how tenaciously we cling to “our version” of the story, filtering the facts so that what WE did/or didn’t do is seen to be of negligible consequence or perhaps even honorable, and what THE OTHER GUY did/or didn’t do is seen to be righteously reprehensible, obviously beyond the pale. I loved, too, the authors’ many demonstrations that the act that alienates one party or the other is not a stand-alone event. To reference Aesop, it is much more likely to be the straw that broke the camel’s back. Hurts and grievances in both parties have probably been building for some time. “Who were the victims? It depends on how many years, decades, and centuries you take into account” (206). Consider Kosovo. Consider the Crusades. As the authors describe these tragic events, IF one is not emotionally involved with one side or the other, one can see BOTH points of view. Likewise in personal relationships. “Of all the stories that people construct to justify their lives, loves, and losses, the ones they weave to account for being the instigator or the recipient of injustice or harm are the most compelling and have the most far-reaching consequences” (191). Tavris and Aronson continue, “We have all done something that made others angry at us, and we have all been spurred to anger by what others have done to us. We all have, intentionally or unintentionally, hurt another person who will forever regard us as the villain, the betrayer, the scoundrel. And we have all … [been:] on the receiving end” (191). It would seem it is seldom the absolute fault of “the other guy.” But…that would mean…and humans on the whole have SUCH a vested interest in protecting their own self-image.A interesting, engaging read."
105,0151010986,http://goodreads.com/user/show/25763919-mimi,4," This is phenomenal! .......it made me love Psychology even more.This book has a protagonist , well ,i think it's more of an antagonist (to us) named : cognitive dissonance (i am so in love with this character hhhhh) ""Mistakes Were Made But Not By Me"" discusses all SORTS of lengths human being may go in order to reduce cognitive dissonance.Acting in contradiction to what u believe (cognitive dissonance) is 'painful' 'uncomfortable' so what we do? the remedy is employed extensively by all yet little know about it : it's self justification.How it works: you hate cheating (this is your belief), it happened and you cheated once voluntarily (contradicting behavior) ====== results is cognitive dissonance ( your self image is shaken ,because your belief about 'cheating' has being shaken)Huh! now comes the remedy time : cheating isn't that bad. the exam was unfairly difficult that's why i cheated these are some of the thoughts we may have once we start justifying our actions (cheating) to reduce cognitive dissonance.OK , now let me introduce you other cognitive biases that leads u to screwing up immensely:Confirmation bias : this dude screws rational healthy discussions... for it blinds you for one side of an argument completely. You believe in one side, you keep looking for info to prove it without EVER checking the arguments and evidence the opposite view might present ( this is what makes some peoples' craniums rock-hard , never allowing the penetration of any of your ideas or arguments ) Snap decisions/judgements : this guys are super bad , if you could just turn them off when you are presented with anything which needs you opinion ....when you take a snap decision you are done for , it becomes harder to see the other angles of a person , an idea ...unless you knew how dangerous these guys are for your objectivity and try harder to make a balanced judgment. Sadly humans are hardwired with many biases that makes them fallible creatures....and without knowing them they will be extra fallible."
106,0151010986,http://goodreads.com/user/show/17485839-zena-ryder,4,"If you don't know what cognitive dissonance is, this is a great introduction. If you do know what it is, this is an easy, enjoyable read, with interesting stories and experiments that illustrate dissonance and the resulting self-justification, which will likely deepen your understanding of this all too human phenomenon. The authors also talk about the fascinating and related phenomenon of false memories — our memories tend to get distorted (or even created!) to be self-serving. I found the section on how easily children can be persuaded to have memories of things that didn't really happen both fascinating and disturbing. The authors also talk about the how police officers' confirmation bias and the need to avoid dissonance by those involved at the various stages of the justice system can and does lead to terrible miscarriages of justice.I guess the biggest thing that was missing, for me, was more detail of when we don't give in to self-justification in order to avoid dissonance. The authors do talk about this, but I would have liked more detail. I would also like more detail on people with low self esteem, who don't tend to resolve their dissonance in self-serving ways, but rather in ways that fit their self image of being incompetent, unlovable etc.While knowing about cognitive biases and flaws isn't enough to make them magically go away, the authors suggest that being aware of them should make us less confident in our own convictions and memories, especially when they are self-serving. I think that is an important lesson for anyone."
107,0151010986,http://goodreads.com/user/show/4532156-alaa-a,5,"This year I started to be more interested in social psychology books in my hope to change my default sitting to the world and understand it better, and what better way than saying I was wrong to your self and owning the mistakes to your self...Its a very challenging book to read its started to with an eases of pointing the mistakes of politics and countries and introducing the conformation biases then going to personal stories that we are confined that happened when all evidenced are against.One of the psychological insights that has been messing around with my mind is the selective memory and that even if you feel strongly sure and emotionally attached to it can be wrong or even planted made me question my memories and if I am a hypocrite the explanation for people's unwillingness to admit mistakes, even to themselves, in a variety of realms. This far-reaching BOOK tackles irrational prejudices, false memories, misjudgement as a psychotherapist, prosecuting the wrong individual, blaming one's spousethe part of repressed memory therapy of rape victimise was eye opening for me as how easy for as to follow :Cognitive dissonanceConfirmation biasI read in the book ""thinking fast and slow "" that knowing this biases dose not stop you form doing it even for the experts in this felid but it can make you stop your self and question why you think or act this way, and that is about it what you can do!! "
108,0151010986,http://goodreads.com/user/show/5856337-mark,5,"Having been put off by several popular books by social psychologists I read in recent years which I felt failed to deliver on the promised goods (""Emotional Intelligence"" and ""Social Intelligence,"" both by Daniel Goldman come quickly to mind), I was both relieved and impressed as I listened to the audiobook version of ""Mistakes Were Made.""The authors not only convincingly support and develop their thesis from start to finish, they do so in an entertaining fashion. Furthermore, the book offers plenty of opportunity for practical application for any casual reader who dares to pause to consider how his or her own pride, cognitive dissonance, confirmation biases, etc. may cause him/her to re-write history, justify themselves and their experiences, blind themselves from seeing the truth, etc. I will mention one area where the authors may possibly be a little ""off."" Toward the end of the book, they share an example of Japanese encouraging mistakes in the classroom and seem to generalize this example for Asian culture. However, across mainland China, Japan, Taiwan, and Korea, societies seems to be somewhat intolerant of mistakes. Having said all that, this is still a great book. Read it!"
109,0151010986,http://goodreads.com/user/show/2050800-kathy,1,"Although the authors have some good points about self-justification in a few sections of the book, they clearly spend way too much time on the ""problem"" and their political biases than a plausible solution to overcoming self-justification. I read the last page of the book in complete disgust as to the topic they chose to end with and completely irritated that very few solutions were offered to help minimize self-justification in ourselves as well as others. I guess I should have read the title a little closer: It states ""Why we..."" and not ""How to overcome why we..."" Also found it very fitting based on the severe bias that shone through the entire book that there was not one mention of the infamous ""I did not have sexual relations with that woman"" by Bill Clinton. Now that's a perfect example of self-justification if I've ever seen one!There is nothing more irritating to me than reading 200 pages about a problem and then getting to the end and realizing the author offered no real solutions but a ton of biased opinions. What a waste!"
110,0151010986,http://goodreads.com/user/show/1347209-jacob,5,"As much as I read, there are few books that are enlightening, educational, and entertaining enough for me to rate them so highly. This is one of those books that every time you put it down you have to run and find someone to tell what you just read. You find the content so interesting that you can't help but share it with others.The authors do a great job at explaining cognitive dissonance and how it leads to self-justification. They also apply the concepts well by focusing a chapter on a specific realm of how this impacts our world (legal interrogation, false memory recovery, etc).If you have ever read ""Leadership and Self Deception"" I think you would enjoy this book also. More of the science behind the story.Read this and then apply the information in your life. It is blessing me and those around me and I'm sure it will you."
111,0151010986,http://goodreads.com/user/show/1984886-tim-kadlec,3,"The book was full of good information, and good discussions around cognitive dissonance. It's fault, however, was that the anecdotes tended to be very politically charged, and very biased.Unfortunately, the authors bias came through very strongly in several of the examples used, and this distracts from the points the authors are attempting to make. In addition, a few of the examples felt like they didn't really fit in with the subject matter, and were instead used to continue to justify the authors biases (ironic I know)."
112,0151010986,http://goodreads.com/user/show/26434622-sophiacoming,5,"One of my favorite books! make me more aware of my silly impulses. I think understanding these limitation is the basis for having a crucial conversation, and making peace with yourself and people around you."
113,0151010986,http://goodreads.com/user/show/58909202-edu,2,"The concept is very interesting, even necessary to know, and mindblowing, wich I liked a lot. But there were many many examples and much of them from USA politics, which I don't care so much about. "
114,0151010986,http://goodreads.com/user/show/8778400-rebekka-steg,5,"This week I've been reading Mistakes Were Made (But Not by Me): Why We Justify Foolish Beliefs, Bad Decisions, and Hurtful Acts by Carol Tavris and Elliot Aronson, an absolutely amazing book, which everyone should be acquired to read.The book deals with the issue of self-justification, and the role it plays in all of our lives, from such ""minor"" issues as arguments within a relationship, to bullying, prejudicialness, torture, fraud etc.Written by two psychologist, the book is backed by research as well as real life cases and examples. It's easy to read, incredibly thought-provoking and it deals with such an important topic, which affects us all.

 Quotes ""We are all capable of believing things which we know to be untrue, and then, when we are finally proved wrong, impudently twisting the facts so as to show that we were right. Intellectually, it is possible to carry on this process for an indefinite time: the only check on it is that sooner or later a false belief bumps up against solid reality, usually on a battlefield.""- George Orwell (1946)""For example, Elliot predicted that if people go through a great deal of pain, discomfort, effort, or embarrassment to get something, they will be happier with that ""something"" than if it came to them easily. For behaviorists this was a preposterous prediction. Why would people like anything associated with pain? But for Elliot, the answer was obvious: self-justification. The cognition that I am a sensible, competent person is dissonant with the cognition that I went through a painful procedure to achieve something - say, joining a group that turned out to be boring and worthless. Therefore, I would distort my perceptions of the group in a positive direction, trying to find good things about them and ignoring the downside.""""Venting is especially likely to backfire if a person commits an aggressive act against another person directly, which is exactly what cognitive dissonance theory would predict. When you do anything that harms someone else - get them in trouble, verbally abuse them or punch them out - a powerful new factor comes into play: the need to justify what you did. Take a boy who goes along with a group of his fellow seventh graders who are taunting and bullying a weaker kid who did them no harm. The boy likes being part of the gang but his heart really isn't in the bullying. Later, he feels some dissonance about what he did. ""How can a decent kid like me,"" he wonders, ""have done such a cruel thing to a nice, innocent little kid like him?"" To reduce dissonance, he will try to convince himself that the victim is neither nice nor innocent: ""He is such a nerd and cry-baby. Besides, he would have done the same to me if he had the chance."" Once the boy starts down the path of blaming the victim, he becomes more likely to beat up on the victim with even greater ferocity the next chance he gets. Justifying his first hurtful act sets the stage for more aggression. That's why the catharsis hypothesis is wrong.""""Our convictions about who we are carry us through the day, and we are constantly interpreting the things that happen to us through the filter of those core beliefs. When they are violated, even by a good experience, it causes us discomfort. An appreciation of the power of self-justification helps us understand, therefore, why people who have low self-esteem, or who simply believe that they are incompetent in some domain, are not totally overjoyed when they do something well; why, on the contrary, they often feel like frauds. If the woman who believes she is unlovable meets a terrified guy who starts pursuing her seriously, she will feel momentarily pleased, but that pleasure is likely to be tarnished by a rush of dissonance: ""What does he see in me?"" Her resolution is unlikely to be ""How nice; I must be more appealing than I thought I was."" More likely, it will be ""As soon as he discovers the real me, he'll dump me."" She will pay a high psychological price to have that consonance restored.""""The Milgram experiment shows us how ordinary people can end up doing immoral and harmful things through a chain reaction of behavior and subsequent self-justification. When we, as observers, look at them in puzzlement or dismay, we fail to realize that we are often looking at the end of a long, slow process down that pyramid. At his sentencing, Magruder said to Judge John Sirica: ""I know what I have done, and Your Honor knows what I have done. Somewhere between my ambition and my ideals, I lost my ethical compass."" How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self-justification will do the rest.""""The brain is designed with blind spots, optical and psychological, and one of its cleverest tricks is to confer on us the comforting delusion that we, personally, do not have any. In a sense, dissonance theory is a theory of blind spots - of how and why people unintentionally blind themselves so that they fail to notice vital events and information that might make them question their behavior or their convictions. Along with the confirmation bias, the brain comes packaged with other self-serving habits that allow us to justify our own perceptions and beliefs as being accurate, realistic, and unbiased. Social psychologist Lee Ross calls this phenomenon ""naïve realism,"" the inescapable conviction that we perceive objects and events clearly, ""as they really are."" We assume that other reasonable people see things the same way we do. If they disagree with us, they obviously aren't seeing clearly. Naïve realism creates a logical labyrinth because it presupposes two things. One, people who are open-minded and fair ought to agree with a reasonable opinion. And two, any opinion I hold must be reasonable; if it weren't, I wouldn't hold it. Therefore, if I can just get my opponents to sit down here and listen to me, so I can tell them how things really are, they will agree with me. And if they don't, it must be because they are biased.""""As fallible human beings, all of us share the impulse to justify ourselves and avoid taking responsibility for any actions that turn out to be harmful, immoral, or stupid. ... Most people when directly confronted with proof that they are wrong, do not change their point of view or course of action but justify it even more tenaciously.""""Just as we can identify hypocrisy in everyone but ourselves, just as it's obvious that others can be influenced by money but not ourselves, so we can see prejudices in everyone else but ourselves. Thanks to our ego-preserving blind spots, we cannot possibly have a prejudice, which is an irrational or mean-spirited feeling about all members of another group. Because are are not irrational or mean-spirited, any negative feelings we have about another group are justified; our dislikes are rational and well founded. It's theirs we need to suppress. Like the Hasids pounding on the Unprejudiced door at the Museum of Tolerance, we are blind to our own prejudices.""""When two people produce entirely different memories of the same event, observers usually assume that one of them is lying. Of course, some people do invent or embellish stories to manipulate or deceive their audiences, as James Frey notably did with his bestseller A Million Little Pieces. But most of us, most of the time, are neither telling the whole truth nor intentionally deceiving. We aren't lying; we are self-justifying. All of us, as we tell our stories, add details and omit inconvenient facts; we give the tale a small, self-enhancing spin; that spin goes over so well that the next time we add a slightly more dramatic embellishment; we justify that little white lie as making the story better and clearer - until what we remember may not have happened that way, or even may not have happened at all.""""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives. An appreciation of the distortions of memory, a realization that even deeply  felt memories might be wrong, might encourage people to hold their memories more lightly, to drop the certainty that their memories are always accurate, and to let go of the appealing impulse to use the past to justify problems of the present. If we are to be careful about what we wish for because it might come true, we must also be careful which memories we select to justify our lives, because than we will have to live by them.""""For any theory to be scientific, it must be stated in such a way that it can be shown to be false as well as true. If every outcome confirms your hypotheses that all men unconsciously suffer from castration anxiety; or that intelligent design, rather than evolution, accounts for the diversity of species; or that your favourite psychic would accurately have predicted 9/11 if only she hadn't been taking a shower that morning; or that all dolphins are kind to humans, your beliefs are a matter of faith, not science.""""Our implicit theories of why we and other people behave as we do come in one of two versions. We can say it's because of something in the situation or environment: ""The bank teller snapped at me because she is overworked today; there aren't enough tellers to handle these lines."" Or we can say it's because something is wrong with the person: ""That teller snapped at me because she is plain rude."" When we explain our own behavior, self-justification allows us to flatter ourselves: We give ourselves credit for our good actions but let the situation excuse the bad ones. When we do something that hurts another, for example, we rarely say, ""I behaved this way because I am a cruel and heartless human being."" We say, ""I was provoked; anyone would do what I did""; or ""I had no choice""; or ""Yes, I said some awful things, but that wasn't me - it's because I was drunk."" Yet when we do something generous, helpful, or brave, we don't say we did it because we were provoked or drunk or had no choice, or because the guy on the phone guilt-induced us into donating to charity. We did it because we are generous and open-hearted.""""Did Charles Graner and Lynndie England know what they were doing, let alone believe they were ""doing evil"" while they were deliberately inflicting pain and humiliation on their Iraqi prisoners and then laughing at them? No, they didn't, and that is why Amos Oz is wrong. Oz didn't reckon with the power of self-justification: We are good people. Therefore, if we deliberately inflict pain on another, the other must have deserved it. Therefore, we are not doing evil, quite the contrary. We are doing good. The relatively small percentage of people who cannot or will not reduce dissonance this way pay a large psychological price in guilt, anguish, anxiety, nightmares, and sleepless nights. The pain of living with horrors they have committed, but cannot morally accept, would be searing, which is why most people will reach for any justification available to assuage the dissonance. In the previous chapter, we saw on a smaller scale why many divorcing couples justify the hurt they inflict on each other. In the horrifying calculus of self-deception, the greater the pain we inflict on others, the greater the need to justify it to maintain our feelings of decency and self-worth. Because our victims deserved what they got, we hate them even more than we did before we harmed them, which in turn makes us inflict even more pain on them.""""But what are we supposed to do in our everyday lives? Call an external review board of cousins and in-laws to adjudicate every family quarrel? Videotape all parental interrogations of their teenagers? In our private relationships, we are on our own, and that calls for some self-awareness. Once we understand how and when we need to reduce dissonance, we can become more vigilant about the process and often nip it in the bud; like Oprah, we can catch ourselves before we slide too far down the pyramid. By looking at our actions critically and dispassionately, as if we were observing someone else, we stand a chance of bring out of the cycle of action followed by self-justification, followed by more committed action. We can learn to put a little space between what we feel and how we respond, insert a moment of reflection, and think about whether we really want to buy that canoe in January, really want to send good money after bad, really want to hold on to a belief that is unfettered by facts. We might even change our minds before our brains freeze our thoughts into consistent patterns.""""Humbling yes, but ultimately that's the point. Understanding how the mind yearns for consonance, and rejects information that questions our beliefs, decisions, or preferences, teaches us to be open to the possibility of error. It also helps us let go of the need to be right. Confidence is a fine and useful quality; none of us would want a physician who was forever wallowing in uncertainty and couldn't decide how to treat our illness, but we do want one who is open-minded and willing to learn. Nor would most of us wish to live without passions or convictions, which give our lives meaning and color, energy and hope. When confidence and convictions are unleavened by humility, by an acceptance of fallibility, people can easily cross the line from healthy self-assurance to arrogance. In this book, we have met many who crossed that line: the psychiatrists who are certain that they can tell if a recovered memory is valid; the physicians and judges who are certain that they are above conflicts of interest; the police officers who are certain that they can tell if a suspect is lying; the prosecutors who are certain that they convicted the guilty party; the husbands and wives who are certain that their interpretation of events is the right one; the nations who are certain that their version of history is the only one.""""Most Americans know they are supposed to say ""we learn from our mistakes,"" but deep down, they don't believe it for a minute. They think that mistakes mean you are stupid. Combined with the culture's famous amnesia for anything that happened more than a month ago, this attitude means that people treat mistakes like hot potatoes, eager to get rid of them as fast as possible, even if they have to toss them in someone else's lap."""
115,0151010986,http://goodreads.com/user/show/8435102-joan,3,"Why is it so hard for us to admit we have made a mistake? Why do we justify our actions? Why is it so hard to change our minds when we think we are right?The authors wrote this book with a goal of understanding those behaviors. I learned tons about why we say what we do to ourselves. Self-justification, for example. We convince ourselves we made the best choice possible. Unfortunately, that blocks us from seeing our errors and learning from them.I read about cognitive dissonance and how it changes our perception. When we see disconfirming evidence, we will criticize the source (fake news), distort or outright dismiss it. Maintaining the belief is more important than truth. And we have confirmation bias, the reason it is so hard to change our minds when we have made a firm decision. I also learned much about blind spots, how our memories change (or we change them purposely), and false memories. The authors give many examples of interrogators (such as child psychologists) manipulating people to confess to crimes or report non-existing events. They give examples of law enforcement officials and prosecutors refusing to admit mistakes even when DNA evidence finally proves them wrong.Rounding out this informative book are thoughts on the price paid for for justifying decisions that cause pain to others. For example, international acts are justified by saying our deeds were bad but not nearly as bad as theirs.The authors end the book reminding us of the benefits of admitting mistakes. There is a positive effect. For politicians, admitting a mistake results in constituents admiring the person is big enough to admit wrong and desire to learn from mistakes.This is an interesting book that is very informative and easy to read. I really found it enlightening in explaining much of the rhetoric we hear today."
116,0151010986,http://goodreads.com/user/show/28157679-susan-s-frederick,5,"Really opened my eyes to bias and lenses that are different for each of us, but have profound effect on how we see things, remember things, feel things. Fascinating."
117,0151010986,http://goodreads.com/user/show/4134989-chuck,4,"A well written exposure of dissonance avoidance, self-justification, confirmation bias and other forces that effect us all. The examples and insights here are especially helpful in understanding why ourself and others make mistakes, defend actions, and choose self-preserving narratives. A revelation into neural, natural wiring. A brave look into the mirror as well as the boundaries of tolerance we construct for others. Keen, practical eye-opening read. "
118,0151010986,http://goodreads.com/user/show/32598115-becky,5,This was an interesting look at how our minds work to dissociate with problems and errors in judgement.
119,0151010986,http://goodreads.com/user/show/2251009-esteban-del-mal,4,"Cognitive dissonance: The mental discomfort experienced by a person who holds two or more contradictory beliefs, ideas, or values. This discomfort is triggered by a situation in which a person's belief clashes with new evidence perceived by the person. When confronted with facts that contradict beliefs, ideals, and/or values, people will try to find a way to resolve the contradiction to reduce their discomfort (~squaring a circle).Cognitive bias: A systematic pattern of deviation from norm or rationality in judgment. Individuals create their own subjective social reality from their perception of the input. An individual's construction of social reality, not the objective input, may dictate his or her behavior in the social world; thus, cognitive biases may sometimes lead to perceptual distortion, inaccurate judgment, illogical interpretation, or what is broadly called irrationality. Catharsis: The psychodynamic principle of emotional release. It's a bullshit theory leftover from Freud. Self-justification: How, when a person encounters cognitive dissonance or a situation in which a person's behavior is inconsistent with his/her beliefs, that person tends to justify the behavior and deny any negative feedback associated with the behavior. Naive realism: The human tendency to believe that we see the world around us objectively and that people who disagree with us must be uninformed, irrational, or biased.Totalitaian ego: a) The ego/self is an organization of knowledge; b) ego/self is characterized by cognitive biases analogous to totalitarian information-control strategies, and; c) these totalitarian-ego biases function to preserve organization in cognitive structures.Reconstructive memory: A theory of memory recall in which the act of remembering is influenced by various other cognitive processes including perception, imagination, semantic memory, and beliefs. People view their memories as being a coherent and truthful account of episodic memory and believe their perspective is free from error during recall; however, the reconstructive process of memory recall is subject to distortion by other intervening cognitive functions such as individual perceptions, social influences, and world knowledge, all of which can lead to errors during reconstruction. [REPRESSED MEMORIES DO NOT EXIST]Source confusion: An attribute seen in different people's accounts of the same event after hearing people speak about the situation (for example, a witness who heard a police officer say someone had a gun who then states he/she saw the gun).Anomie: A condition in which society provides little moral guidance to individuals. This state evolves from conflict of belief systems and causes a breakdown of social bonds between an individual and the community. In a person, this condition can progress into a dysfunctional ability to integrate within the normative situations of his/her social world (for example, an unruly personal scenario that results in fragmentation of social identity and rejection of values). The term is commonly understood to mean normlessness.Imagination inflation: The finding that imagining an event which never happened can increase confidence that it actually occurred.Confidence-accuracy relationship: As one's confidence increases, so does one's level of accuracy (or belief therein).Benevolent dolphin problem: Every once in a while, a news story appears about a shipwrecked sailor who, on the verge of drowning, is nudged to safety by a dolphin. It is tempting to conclude that dolphins must really like human beings, enough to save us from drowning. But wait—are dolphins aware that humans don’t swim as well as they do? Are they actually intending to be helpful? To answer that question, we would need to know how many shipwrecked sailors have been gently nudged further out to sea by dolphins, there to drown and never be heard from again. We don’t know about those cases because the swimmers don’t live to tell us about their evil-dolphin experiences. If we had that information, we might conclude that dolphins are neither benevolent nor evil; they are just being playful.Effort justification: A person's tendency to attribute a value to an outcome which he/she had to put effort into achieving which is greater than the objective value of the outcome (i.e., the more effort put into something, the more it is valued).Implicit personality theory: The specific patterns and biases an individual uses when forming impressions based on a limited amount of initial information about an individual or situation."
120,0151010986,http://goodreads.com/user/show/11966043-lia,5,"4.5 starsI think this is one of the best non-fiction books I've ever read. It is so fascinating and it is so well-written. I've learned so much, about others and about myself. I honestly think that reading this book makes you a better person. I couldn't recommend it more."
121,0151010986,http://goodreads.com/user/show/23790728-amani,5,This was a very interesting and informative read. 
122,0151010986,http://goodreads.com/user/show/522647-kathy,4,"I'm so depressed. Humans, grrr. If you've ever wondered why people won't admit mistakes even in the face of verifiable truth contradicting their actions or beliefs, this book explains why. With sections on cognitive dissonance, why we think we're above outside influence, memory (yes, we make up our own ""memories""), scientific research fallacies, law enforcement/prosecution proceedings and relationship killers the gamut is pretty much covered. And, it's depressing. Did I mention that already? Well, it bears mentioning twice. We humans are geared to stick to our figurative guns no matter what. I have no hope for our current political unrest in the USA to get better any time soon. Sigh."
123,0151010986,http://goodreads.com/user/show/64733542-nafisa,5,"""A nation's character, and an individual's integrity, do not depend on being error-free. It depends on what we do after making an error.""Once in a while, I come across a book that makes me question my self-concept; this book is one of them. Broadly, it is about cognitive dissonance -- the psychological stress we face when our actions contradict our beliefs and ideals. Since we don't like to think of ourselves as incompetent or ill-intentioned, our natural tendency is to convince ourselves that we did the right thing. Mindless self-justification in the face of cognitive dissonance can have far-reaching (and often devastating) consequences, and the authors do a commendable job of documenting such examples from numerous distinct domains ranging from the criminal justice system, politics, medicine, and even marriage and relationships. A fresh set of ideas, quite compelling, and sometimes challenging to read as they force you to constantly self-reflect. I highly recommend it to anyone with an interest in psychology. The book is not intended to be self-help but offers a lot of scope for personal growth."
124,0151010986,http://goodreads.com/user/show/3669193-mah-ebr,5,i think everyone should read this one! 
125,0151010986,http://goodreads.com/user/show/901342-jacob,4,"This covers ground related to Evil Genes: Why Rome Fell, Hitler Rose, Enron Failed, and My Sister Stole My Mother's Boyfriend and The Honest Truth About Dishonesty: How We Lie to Everyone--Especially Ourselves, but it's specifically about self-justification. It's attempting to answer the question ""Why do people self-justify obvious mistakes?"" and look at the impact of doing so. It's pretty straightforward and quite readable.Self-justification is a useful and even essential way for humans to protect their ego and mental health, but it can get pretty out of whack. Self-justification is not only sad when it helps us decide to do things we shouldn't, it's extra sad when people do things they shouldn't only because they are trying to support an existing self-justification for a previous bad decision. One of the elaborated examples is when innocent people go to jail: it's bad enough when police and attorneys justify acting unethically in order to convict someone they ""know"" is guilty. Where it becomes absolutely unconscionable is where they work hard to prevent people from being proven innocent after the fact so they don't have to admit screwing up.On a lighter note, with books about human fallibility you have to chuckle when the authors display the very fallibility they're decrying. In one case, they claim to be certain about someone's motivation for making poor remarks without allowing for those remarks to be caused by that person looking for any excuse to self-justify behavior. In another case, they berate therapists for not thinking scientifically and not examining the disconfirming cases, then talk about the Gottmans' work on predicting divorce without examining the disconfirming cases (where the Gottmans predicted divorce and were wrong). They mention a case where of 10 of 47 couples were predicted to divorce, all 7 who did divorce were predicted ones. Of the remaining 40, all they say is that the 90% accuracy is impressive. But they don't address that 30% of the predicted divorces didn't happen, which pokes a hole in their nice theory about self-justification causing divorce. That wouldn't be a problem if they hadn't already spent a chapter bagging on therapists for having pet theories without looking at evidence that would contradict the theory.One of the reasons you chuckle over those kinds of mistakes instead of criticizing is because we ALL do those things. I'm not immune from doing those very same things, and neither is anyone else. But we might become less that way if we are aware of the phenomenon and try to identify when we are justifying ourselves."
126,0151010986,http://goodreads.com/user/show/7399266-camie,4,"I should start by saying I find social psychology fascinating! This book is about cognitive dissonance , which basically means having two conflicting beliefs and the measures we will resort to in order to defend and justify our beliefs , decisions, and actions. Backed by much research, this very insightful book explains how we all are capable of self deception, why we do it, why it is harmful, and how to overcome the very human mechanism of justifying our foolish beliefs, improper actions, poor decisions, and hurtful acts, and more importantly how to keep small things from escalating to disastrous proportions. Looking at everything from political situations, criminal acts, war, marriage, and personal levels it offers answers to how impossible atrocities come about , one justification at a time. ""How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self justification will do the rest."" From the politician who can't publically admit his actions, the torturer who feels no guilt, to the person who will say anything to win an argument, this book explains why it is so easy to see the hypocrisy of others while being totally blind to our own. Co-written by Elliot Aronson, author of The Social Animal , a great textbook, this is a very readable informative book. The introduction is called Knaves, Fools, Villains, and Hypocrites: How Do They Live With Themselves.... lol how do we ?? 4 stars"
127,0151010986,http://goodreads.com/user/show/51519663-diana-nahirna,5,"Well, that explains a lot of my recent purchases, Iraq, and why marriages fail. "
128,0151010986,http://goodreads.com/user/show/1974052-milan,5,"Mistakes Were Made (But Not by Me) is quite an enlightening book by Carol Tavris and Elliot Aronson. The authors examine our deep-rooted tendencies to underplay our faults and errors and to exaggerate the mistakes of others, especially when they go against us. ""Cognitive dissonance occurs when a person holds two or more contradictory beliefs, ideas, or values, or participates in an action that goes against one of these three, and experiences psychological stress because of that."" Two lessons from this theory: “First, the ability to reduce dissonance helps us in countless ways, preserving our beliefs, confidence, decisions, self-esteem, and well-being. Second, this ability can get us into big trouble.”The self-justification mechanisms like cognitive dissonance, confirmation bias, and fabricated memory play such an important role in our lives that they are hard to ignore. The authors provide very vivid examples from politics, therapy, conflict, wars, marriage, police and court procedures to show how these biases work. A few important lessons: •	 “Most human beings and institutions are going to do everything in their power to reduce dissonance in ways that are favorable to them, that allow them to justify their mistakes and maintain business as usual.” •	“Most people, when directly confronted by evidence that they are wrong, do not change their point of view or course of action but justify it even more tenaciously. Even irrefutable evidence is rarely enough to pierce the mental armor of self-justification.”•	Our ‘mistake-phobic’ culture causes people not to learn from their mistakes.•	Naive realism: the believe that everyone else sees the world as we do•	We all self-justify as a way to protect against cognitive dissonance, whether positively or negatively.•	Memories are easily modified to fit a narrative to reduce cognitive dissonance.•	We must be careful to not allow memory distortion to justify previous decisions.•	Therapists should be very concerned about confirmation bias, their expert assessments and also in their evaluations of people.•	Confessions can be elicited from accused legally by using deceit, trickery, etc.•	Successful couples will give the benefit of the doubt to their partners, just as they would to themselves. Unsuccessful couples do the opposite.•	We must strive to take self-justification into account in our lives and relationships to prevent incorrect decisions making.Two things to keep in mind – our personal life will suffer if we don’t admit our mistakes and society will work better if people admitted when they’re wrong."
129,0151010986,http://goodreads.com/user/show/28602450-vladyslav-sitalo,4,"You think about yourself as a reasonably nice person, with not perfect but good enough memory. Maybe you've done some things in your life, that you don't particularly like, but you think that in most cases, given the situation you were in, most of the people would've done the same.So you ain't perfect but better than the most, right?Well, this book would get you to at least question, how accurate is the description above. And it will also tell you how come you (and most of the people, even most morally flawed, from your perspective, people) think of themselves in this way.The book will tell you how your mind is desperately trying to maintain the self-image, you have about yourself and protect beliefs your hold. How it change your perceptions of things around you to fit this image/beliefs. And here comes more fun: it also employs your memory to justify your current self-perception/beliefs. So your memory is gradually, with each recall, become more compliant with this image. And eventually, all you left with is the nice, coherent story of your life that corresponds to your current view of yourself and your beliefs. But this story often has little or nothing to do with reality.As authors call it: Memory is your self-justifying historian (I would also highly recommend a novelette by Ted Chiang - ""The Truth of Fact, the Truth of Feeling"" as an exploration of this aspect of our memory: https://www.goodreads.com/book/show/1...).And the thing is that this process influences pretty much every aspect of your life regardless of your age/education or other things, you might think would influence the situation.So the process kicks in:When you're a nice, kind boy, who find himself in a company that is bullying a weaker guy. You don't particularly like the process but, as you want to be a part of this social group - you continue to participate in it. But there is dissonance here: how come you, as a nice, kind boy become a bully? So here the self-justification comes to your help: ""It's totally the guy's responsibility that he got bullied. Let's modify our image of the guy to leave our self-image preserved and justify what've done. Yay! And hey we're justified to continue to bully him as he is such a ....""Or let's say you're a student who don't have any strong position on cheating. You know it's generally considered a ""bad thing"" but you don't have any personal conviction either way. You haven't done it earlier because you didn't need to. But now you're in the situation when you need either cheat or fail this particular course. So situation can go in two ways from here:World 1: You've decided to cheat. ""Self-justification process: Ok we've cheated, as we know we're a generally good person, so we could not have possibly done a bad thing, so we may conclude that cheating is not a big deal"".World 2: You've decided not to cheat. ""Self-justification process: Ok we've failed the course. That's unfortunate but, well we didn't have any other option, right? We wouldn't even consider doing such a terrible thing as cheating"".Or you're a detective and you've interrogated your suspect to the point that he have given you a confession. But here comes the strong evidence (like DNA test or videotape) that he is innocent. So here it goes: ""I'm an honest infallible detective and my interrogation methods are great, and, after all, the guy has given confession after only 36 consecutive hours of interrogation. The evidence must be wrong""And let's upgrade a bit more. You're an honest politician, who is right now flying with a lobbyist on a luxury private plane to spend a nice weekend in some luxury resort. ""As we're an honest, good man, this situation can't possibly influence our political judgment in any way, right?"" (To understand how you got in this situation in a first place and for a lot of other good examples - read the book ;)The more deeply held self-belief that is contradicting to what you did the more actively you would justify the deed as the kind of deed that don't contradict this self-belief.You probably think to yourself: ""Ok maybe some of the cases described in this book can be true about me, but in most of them I would not have employed this level of self-justification""Well, the problem is that self-justification is largely unconscious process so when you do something that don't correspond to your self-image or see information that contradicts your belief - the justification process kicks in automatically in the background.So usually, you don't even notice on the conscious level that you've maybe done something wrong or that you hold a questionable belief. And correspondingly you don't have a chance to fix the situation before you internalize it as the normal state of things.That's why it's often said ""Hypocrite is obvious to all but himself""So you would probably at this point like to know - are we doomed? Can we do better? And the answer is yes we can! The book advises us to institute impartial external overview committees wherever possible (if necessary even against the will of involved people/institutions) because the external observer can usually notice an error much easier than somebody who have committed it. As he is not emotionally/financially/in other way invested in this decision.In the situations where setting up such an institutions is not feasible or reasonable (For example in the case of personal relationships), make sure that you and people around are aware and conscious about the magic of self-justification. You also can, to some level, train yourself to recognize the typical situations where the process may kick in and be especially careful when facing them. Also, be aware of the fact that this magic works on other people, so when you try to point out his/her error to somebody, be careful to do it in a way that will not make them self-defensive and more likely to justify this error.And don't be afraid to admit your errors, because as you relinquish wrong beliefs you become wiser, as you own up to your errors you gain more respect from people and you're less likely to make the same error in the future. Everybody makes mistakes, but you only can learn from yours, when you admit them."
130,0151010986,http://goodreads.com/user/show/21170365-amy-anderson,5,"I loved this book and found it so applicable to everyone. While we need justification to move forward in life and not second guess our every decision, we also need to be aware that justification can lead us to be blind sighted to truth. Its a fine line to walk. I could quote this whole book, but here are my favorites:""Self-justification is more powerful and dangerous than the explicit lie. It allows people to convince themselves that what they did was the best thing they could have done. In fact, come to think of it, it was the right thing."" p.4""Self-justification not only minimizes our mistakes and bad decision, it is also the reason that everyone can see a hypocrite in action except the hypocrite."" p.4""How in the world can they live with themselves? The answer is exactly the way the rest of us do."" p.9""Yet mindless self-justification, like quicksand, can draw us deeper into disaster. It blocks our ability to even see our errors, let alone correct them. It distorts reality, keeping us from getting all the information we need and assessing the issues clearly. It prolongs and widens rifts between lovers, friends, and nations. It keeps us from letting go of unhealthy habits. IT permits the guilty to avoid taking responsibility for their deeds."" p.9""I will look at any additional evidence to confirm the opinion to which I have already come."" Lord Molson p.17""These mechanisms provide a neurological basis for the observation that once our minds are made up, it is hard to change them."" p.19""People become more certain they are right about something they just did if they can't undo it."" p.22""Decades of experimental research have found exactly the opposite: that when people vent their feelings aggressively they often feel worse, pump up their blood pressure and make themselves angrier."" p.26""Aggression begets self-justification, which begets more aggression."" p.27""How do you get an honest man to lose his ethical compass? You get hi to take one step at a time, and self-justification will do the rest."" p.37""Parent blaming is a popular and convenient form of self-justification because it allows people to live less uncomfortably with their regrets and imperfections."" p.76""...current self-concepts blurred their memories, bringing their past selves into harmony with their present ones."" p.79""If a memory is a central part of your identity, a self-serving distortion is even more likely."" p.79""For those who are trying to remember something that never happened, writing analyzing dreams, and drawing pictures- techniques that are the staples of many psychotherapists- are all methods that quickly conflate imagination with reality."" p.86""Once the seed of belief was planted [they] began to search for confirming evidence."" p.90""...the story fits the needs of the experiences."" p.91"",,,experiences have internalized their new false memories and cannot now distinguish them from true ones. They have come to believe their own stories."" p.93""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives."" p.93""Successful partners extend to each other the same self-forgiving ways of thinking we extend to ourselves: They forgive each other's missteps as being due to the situation, but give each other credit for the thoughtful and loving things they do."" p.169""It may sometimes be hard to define good, but evil has its unmistakable odor: Every child knows what pain is. Therefore, each time we deliberately inflict pain on another, we know what we are doing. We are doing evil."" Amoz p.198""Would you rather admit you're wrong now or wait until someone else proves it?"" p.221""People will pursue self-destructive courses of action to protect the wisdom of their initial decisions."" p.222""They will treat people they have hurt even more harshly, because they convince themselves that their victims deserve it."" p.222""People who are insecure in their religious beliefs may feel the impulse to silence and harass those who disagree with them, because their mere existence arouses the painful dissonance of doubt."" p.222"
131,0151010986,http://goodreads.com/user/show/5301457-sergei-moska,4,"Although this book didn't actually teach me anything new in terms of theory (but did provide me with many details of practical cases), it nonetheless surprised me. First, I decided to read this book at this time because I've been a bit burned out from dense reading and wanted something useful but light. It was in fact both these things, but it was also far, far more depressing than I had expected. I expected this to be a “Ha ha, let's look at our foibles!” type of read. No, it's more of a “your identity is a joke and the world systematically does evil things. And so do you.” kind of experience. Structurally speaking, the book is very simple. The first part posits a simplified theory, and the rest of the book demonstrates the theory in action, in a few select areas of life. The theory is that we need to overcome the cognitive dissonance that emerges when our actions conflict with our self-image or beliefs. At such a moment, we are said to be at the top of a “pyramid” (a 2-dimensional triangle would be a better image), and the authors believe that whether or not we choose to justify ourselves to ourselves in such moments will lead us down one side of the pyramid or the other, with drastically different outcomes once we hit either side of the base of the pyramid. I may give up the idea that I'm such a great guy, or I can decide that the other person deserved the treatment, that it really wasn't a big deal, etc. The authors believe that whatever choice we make will cause us – in order to avoid further cognitive dissonance – to more extreme positions in order to justify our initial choice. A number of surprising findings come about as a result. For instance, the more helpless the victim, the more we will tend to denigrate him in order to justify our initial mistreatment of him. Beating up an angry drunk at a bar doesn't necessarily require much justification (“He was being threatening, and it's fine to beat up people that are threatening”), but participating in bullying usually does (“I'm a nice guy and beating him up, so it must be because he's a weenie who deserves to be humiliated. Plus he'd do it if he had the chance”.)A fun book to read, although it was too simplified for my taste in at least two ways. First, the authors' theory is *very* simple, and at times their application of the theory seems too universal. For instance, why do innocent people confess to crimes? The authors only seem to entertain the notion that it's in order to reduce cognitive dissonance: “I didn't do anything, but all the cops say that they have proof. The cops are honest and good people, so I must be the problem.” Yet at times this just seems dubious. The explanation is far more convincing when they apply it to the decision by the police to continue interrogation even in the absence of evidence. The second way that the book was too simplified for my taste is in its structure. After a very good exposition of their theory, I was hoping that the subsequent material would help develop the theory further. But what it turned out to be was “Here's a theory, and now we're going to show you the theory in X, Y, and Z.” This is a matter of taste, but I really don't like that format. What's more, I do think it hurts the authors, since it implies that the answer to the subtitle of the book is monolithic. I don't think that to be the case, and I suspect the authors don't either. In fairness, they do incidentally go through a number of additional mechanisms that are attached to the problem of cognitive dissonance, including a wonderful treatment on the foibles of memory, but it would have been really nice to make their answer more complex and complete, even at the risk of making it less parsimonious. Normally that kind of issue would be a big turn-off for me, but the book really is saved (for me) by their incredibly chilling accounts, especially in chapters 3-6. The writing is very clear and engaging, and the book is also thoroughly annotated, all of which makes me fall a little bit in love with the authors."
132,0151010986,http://goodreads.com/user/show/1677868-steven-peterson,4,"This is a well written, snappy book that addresses an important issue, best described by the book's title and subtitle: ""Mistakes Were Made (but not by me): Why we justify foolish beliefs, bad decisions, and hurtful acts."" The two authors, both well reputed psychologists, use the theory of cognitive dissonance as their starting point. Leon Festinger was one of the major theorists of this approach. The authors of this book simply define the perspective thus (page 13): ""Cognitive dissonance is a state of tension that occurs whenever a person holds two cognitions (ideas, attitudes, beliefs, opinions) that are psychologically inconsistent, such as 'Smoking is a dumb thing to do because it could kill me' and 'I smoke two packs a day.'"" How does one deal with this? By adopting one of the positions and then downgrading or rejecting the other. The end result is self-justification, self-deception, seeking out evidence to support the choice that we have made while rejecting evidence that does not fit with our choice. The brain itself shows evidence of the operation of cognitive dissonance. The example on page 19 of functional Magnetic Resonance Imaging (fMRI) and processing information about presidential candidates is telling. The end result is ""blind spots,"" in which people (page 42) ""fail to notice vital events and information that might make them question their behavior or their convictions."" As such, the authors note that cognitive dissonance makes mincemeat of such theoretical views as rational actor theory and psychoanalytic theory. One result of cognitive dissonance is what is called ""confirmation bias,"" the attending to evidence that supports our views and the rejection/suppression of evidence that does not support our views. Many examples are advanced to illustrate the case that the authors make. Issues include: moral lapses (e.g., Watergate participants), ""made up"" memories (raising serious questions about the whole idea of repressed memories), criminal justice system decisions on guilt or innocence, and so on. Much is at stake with cognitive dissonance as it operates. In the closing chapter, the authors try to indicate how understanding cognitive dissonance might help us to limit the damage that may occur as a result of its operation. Convincing? I'm not so sure, but this discussion does get one thinking about how we might address the harmful side effects of cognitive dissonance. A readable book that raises important issues. I think that more use of neuroscientific research could have strengthened this book that much more. Also, the work by cognitive psychologists like Kahneman and Tversky could have spoken to key points as well. This book might also profitably be read in tandem with another recent book on a similar subject, Cordelia Fine, ""A Mind of Its Own."" In addition, Linden's ""accidental Mind"" provides a perspective on related issues from a neuroscience viewpoint. "
133,0151010986,http://goodreads.com/user/show/9281934-louise,5,"Prior to reading this, I had only considered the theory of cognitive dissonance as it applied to holding two contrary opinions, the classic example being that of the racist with friends who are members of the race s/he denigrates. Tavris and Aronson demonstrate further applications of this theory and how destructive the behavior it spawns continues to be.The 1980's/90's day care scandals pre-dated the 24 hour cable cycle (imagine this being covered today by Fox) so it blipped in and out of my attention. I remember thinking how it didn't add up, but I wasn't really following it. Today, somewhere below my radar screen are the DNA absolved prisoners, and their continued incarceration doesn't add up either. Tavris and Aronson show how the professionals involved continued and continue to stick to their long fought for opinion, even as evidence pours in against it. As the dissonance theory predicts, the greater the commitment to the opinion the more the mind works to re-enforce it.The book is most convincing on the personal level such as the damage caused by the dynamics in divorce or accusations such as those made by those in the recovered memory therapies.While cognitive dissonance is undoubtedly operative, it is not the only culprit in the inability to admit mistakes. For commercial and public policy issues there is liability to be paid either through job loss, litigation, an election, or even everyday office politics. If the culprit is a principal player on a big stage, it could be a career ender for not only the decider, but his/her staff. It is not just the mind that keeps out contrary information, there is undoubtedly social support for the bad decision by those who also made the mistake or assisted in its execution. There are also families to consider, you admit the mistake, you could lose your job and there will be no college education for your kids. The books speaks of these barriers, but sticks to its purpose of illustrating the theory.For barriers beyond cognitive dissonance, I think of George Bush and the Iraq war. If he could bring himself to admit the mistake, he would face huge institutional and social acrimony from the policy makers who assisted him, the party who supported him, the military as an institution and the families who lost their loved ones. Ultimate decision makers on the Iraq War will wait, like Robert McNamara did, until the mistake is universally recognized.This is an excellent book. The authors develop their theory for the lay person with good examples from both everyday life and the world of public policy. I highly recommend it. "
134,0151010986,http://goodreads.com/user/show/2414293-adelle,3,"The authors' political biases came through as they used the beginning and the ending of the book to castigate then (2007) President George W. Bush, and to call Newt Gingrich a “hypocrite” for criticizing (now former) President Bill Clinton’s sexual affair…WITHOUT any allusion to Clinton’s defensive “I did not have sex with that woman…Miss Lewinski” statement. But most of the center sections of the book--which thankfully were relatively free of politics--- I found endlessly fascinating. Oh, how tenaciously we cling to “our version” of the story, filtering the facts so that what WE did/or didn’t do is seen to be of negligible consequence or perhaps even honorable, and what THE OTHER GUY did/or didn’t do is seen to be righteously reprehensible, obviously beyond the pale. I loved, too, the authors’ many demonstrations that the act that alienates one party or the other is not a stand-alone event. To reference Aesop, it is much more likely to be the straw that broke the camel’s back. Hurts and grievances in both parties have probably been building for some time. “Who were the victims? It depends on how many years, decades, and centuries you take into account” (206). Consider Kosovo. Consider the Crusades. As the authors describe these tragic events, IF one is not emotionally involved with one side or the other, one can see BOTH points of view. Likewise in personal relationships. “Of all the stories that people construct to justify their lives, loves, and losses, the ones they weave to account for being the instigator or the recipient of injustice or harm are the most compelling and have the most far-reaching consequences” (191). Tavris and Aronson continue, “We have all done something that made others angry at us, and we have all been spurred to anger by what others have done to us. We all have, intentionally or unintentionally, hurt another person who will forever regard us as the villain, the betrayer, the scoundrel. And we have all … [been:] on the receiving end” (191). It would seem it is seldom the absolute fault of “the other guy.” But…that would mean…and humans on the whole have SUCH a vested interest in protecting their own self-image.A interesting, engaging read."
135,0151010986,http://goodreads.com/user/show/25763919-mimi,4," This is phenomenal! .......it made me love Psychology even more.This book has a protagonist , well ,i think it's more of an antagonist (to us) named : cognitive dissonance (i am so in love with this character hhhhh) ""Mistakes Were Made But Not By Me"" discusses all SORTS of lengths human being may go in order to reduce cognitive dissonance.Acting in contradiction to what u believe (cognitive dissonance) is 'painful' 'uncomfortable' so what we do? the remedy is employed extensively by all yet little know about it : it's self justification.How it works: you hate cheating (this is your belief), it happened and you cheated once voluntarily (contradicting behavior) ====== results is cognitive dissonance ( your self image is shaken ,because your belief about 'cheating' has being shaken)Huh! now comes the remedy time : cheating isn't that bad. the exam was unfairly difficult that's why i cheated these are some of the thoughts we may have once we start justifying our actions (cheating) to reduce cognitive dissonance.OK , now let me introduce you other cognitive biases that leads u to screwing up immensely:Confirmation bias : this dude screws rational healthy discussions... for it blinds you for one side of an argument completely. You believe in one side, you keep looking for info to prove it without EVER checking the arguments and evidence the opposite view might present ( this is what makes some peoples' craniums rock-hard , never allowing the penetration of any of your ideas or arguments ) Snap decisions/judgements : this guys are super bad , if you could just turn them off when you are presented with anything which needs you opinion ....when you take a snap decision you are done for , it becomes harder to see the other angles of a person , an idea ...unless you knew how dangerous these guys are for your objectivity and try harder to make a balanced judgment. Sadly humans are hardwired with many biases that makes them fallible creatures....and without knowing them they will be extra fallible."
136,0151010986,http://goodreads.com/user/show/17485839-zena-ryder,4,"If you don't know what cognitive dissonance is, this is a great introduction. If you do know what it is, this is an easy, enjoyable read, with interesting stories and experiments that illustrate dissonance and the resulting self-justification, which will likely deepen your understanding of this all too human phenomenon. The authors also talk about the fascinating and related phenomenon of false memories — our memories tend to get distorted (or even created!) to be self-serving. I found the section on how easily children can be persuaded to have memories of things that didn't really happen both fascinating and disturbing. The authors also talk about the how police officers' confirmation bias and the need to avoid dissonance by those involved at the various stages of the justice system can and does lead to terrible miscarriages of justice.I guess the biggest thing that was missing, for me, was more detail of when we don't give in to self-justification in order to avoid dissonance. The authors do talk about this, but I would have liked more detail. I would also like more detail on people with low self esteem, who don't tend to resolve their dissonance in self-serving ways, but rather in ways that fit their self image of being incompetent, unlovable etc.While knowing about cognitive biases and flaws isn't enough to make them magically go away, the authors suggest that being aware of them should make us less confident in our own convictions and memories, especially when they are self-serving. I think that is an important lesson for anyone."
137,0151010986,http://goodreads.com/user/show/4532156-alaa-a,5,"This year I started to be more interested in social psychology books in my hope to change my default sitting to the world and understand it better, and what better way than saying I was wrong to your self and owning the mistakes to your self...Its a very challenging book to read its started to with an eases of pointing the mistakes of politics and countries and introducing the conformation biases then going to personal stories that we are confined that happened when all evidenced are against.One of the psychological insights that has been messing around with my mind is the selective memory and that even if you feel strongly sure and emotionally attached to it can be wrong or even planted made me question my memories and if I am a hypocrite the explanation for people's unwillingness to admit mistakes, even to themselves, in a variety of realms. This far-reaching BOOK tackles irrational prejudices, false memories, misjudgement as a psychotherapist, prosecuting the wrong individual, blaming one's spousethe part of repressed memory therapy of rape victimise was eye opening for me as how easy for as to follow :Cognitive dissonanceConfirmation biasI read in the book ""thinking fast and slow "" that knowing this biases dose not stop you form doing it even for the experts in this felid but it can make you stop your self and question why you think or act this way, and that is about it what you can do!! "
138,0151010986,http://goodreads.com/user/show/5856337-mark,5,"Having been put off by several popular books by social psychologists I read in recent years which I felt failed to deliver on the promised goods (""Emotional Intelligence"" and ""Social Intelligence,"" both by Daniel Goldman come quickly to mind), I was both relieved and impressed as I listened to the audiobook version of ""Mistakes Were Made.""The authors not only convincingly support and develop their thesis from start to finish, they do so in an entertaining fashion. Furthermore, the book offers plenty of opportunity for practical application for any casual reader who dares to pause to consider how his or her own pride, cognitive dissonance, confirmation biases, etc. may cause him/her to re-write history, justify themselves and their experiences, blind themselves from seeing the truth, etc. I will mention one area where the authors may possibly be a little ""off."" Toward the end of the book, they share an example of Japanese encouraging mistakes in the classroom and seem to generalize this example for Asian culture. However, across mainland China, Japan, Taiwan, and Korea, societies seems to be somewhat intolerant of mistakes. Having said all that, this is still a great book. Read it!"
139,0151010986,http://goodreads.com/user/show/2050800-kathy,1,"Although the authors have some good points about self-justification in a few sections of the book, they clearly spend way too much time on the ""problem"" and their political biases than a plausible solution to overcoming self-justification. I read the last page of the book in complete disgust as to the topic they chose to end with and completely irritated that very few solutions were offered to help minimize self-justification in ourselves as well as others. I guess I should have read the title a little closer: It states ""Why we..."" and not ""How to overcome why we..."" Also found it very fitting based on the severe bias that shone through the entire book that there was not one mention of the infamous ""I did not have sexual relations with that woman"" by Bill Clinton. Now that's a perfect example of self-justification if I've ever seen one!There is nothing more irritating to me than reading 200 pages about a problem and then getting to the end and realizing the author offered no real solutions but a ton of biased opinions. What a waste!"
140,0151010986,http://goodreads.com/user/show/1347209-jacob,5,"As much as I read, there are few books that are enlightening, educational, and entertaining enough for me to rate them so highly. This is one of those books that every time you put it down you have to run and find someone to tell what you just read. You find the content so interesting that you can't help but share it with others.The authors do a great job at explaining cognitive dissonance and how it leads to self-justification. They also apply the concepts well by focusing a chapter on a specific realm of how this impacts our world (legal interrogation, false memory recovery, etc).If you have ever read ""Leadership and Self Deception"" I think you would enjoy this book also. More of the science behind the story.Read this and then apply the information in your life. It is blessing me and those around me and I'm sure it will you."
141,0151010986,http://goodreads.com/user/show/1984886-tim-kadlec,3,"The book was full of good information, and good discussions around cognitive dissonance. It's fault, however, was that the anecdotes tended to be very politically charged, and very biased.Unfortunately, the authors bias came through very strongly in several of the examples used, and this distracts from the points the authors are attempting to make. In addition, a few of the examples felt like they didn't really fit in with the subject matter, and were instead used to continue to justify the authors biases (ironic I know)."
142,0151010986,http://goodreads.com/user/show/26434622-sophiacoming,5,"One of my favorite books! make me more aware of my silly impulses. I think understanding these limitation is the basis for having a crucial conversation, and making peace with yourself and people around you."
143,0151010986,http://goodreads.com/user/show/58909202-edu,2,"The concept is very interesting, even necessary to know, and mindblowing, wich I liked a lot. But there were many many examples and much of them from USA politics, which I don't care so much about. "
144,0151010986,http://goodreads.com/user/show/8778400-rebekka-steg,5,"This week I've been reading Mistakes Were Made (But Not by Me): Why We Justify Foolish Beliefs, Bad Decisions, and Hurtful Acts by Carol Tavris and Elliot Aronson, an absolutely amazing book, which everyone should be acquired to read.The book deals with the issue of self-justification, and the role it plays in all of our lives, from such ""minor"" issues as arguments within a relationship, to bullying, prejudicialness, torture, fraud etc.Written by two psychologist, the book is backed by research as well as real life cases and examples. It's easy to read, incredibly thought-provoking and it deals with such an important topic, which affects us all.

 Quotes ""We are all capable of believing things which we know to be untrue, and then, when we are finally proved wrong, impudently twisting the facts so as to show that we were right. Intellectually, it is possible to carry on this process for an indefinite time: the only check on it is that sooner or later a false belief bumps up against solid reality, usually on a battlefield.""- George Orwell (1946)""For example, Elliot predicted that if people go through a great deal of pain, discomfort, effort, or embarrassment to get something, they will be happier with that ""something"" than if it came to them easily. For behaviorists this was a preposterous prediction. Why would people like anything associated with pain? But for Elliot, the answer was obvious: self-justification. The cognition that I am a sensible, competent person is dissonant with the cognition that I went through a painful procedure to achieve something - say, joining a group that turned out to be boring and worthless. Therefore, I would distort my perceptions of the group in a positive direction, trying to find good things about them and ignoring the downside.""""Venting is especially likely to backfire if a person commits an aggressive act against another person directly, which is exactly what cognitive dissonance theory would predict. When you do anything that harms someone else - get them in trouble, verbally abuse them or punch them out - a powerful new factor comes into play: the need to justify what you did. Take a boy who goes along with a group of his fellow seventh graders who are taunting and bullying a weaker kid who did them no harm. The boy likes being part of the gang but his heart really isn't in the bullying. Later, he feels some dissonance about what he did. ""How can a decent kid like me,"" he wonders, ""have done such a cruel thing to a nice, innocent little kid like him?"" To reduce dissonance, he will try to convince himself that the victim is neither nice nor innocent: ""He is such a nerd and cry-baby. Besides, he would have done the same to me if he had the chance."" Once the boy starts down the path of blaming the victim, he becomes more likely to beat up on the victim with even greater ferocity the next chance he gets. Justifying his first hurtful act sets the stage for more aggression. That's why the catharsis hypothesis is wrong.""""Our convictions about who we are carry us through the day, and we are constantly interpreting the things that happen to us through the filter of those core beliefs. When they are violated, even by a good experience, it causes us discomfort. An appreciation of the power of self-justification helps us understand, therefore, why people who have low self-esteem, or who simply believe that they are incompetent in some domain, are not totally overjoyed when they do something well; why, on the contrary, they often feel like frauds. If the woman who believes she is unlovable meets a terrified guy who starts pursuing her seriously, she will feel momentarily pleased, but that pleasure is likely to be tarnished by a rush of dissonance: ""What does he see in me?"" Her resolution is unlikely to be ""How nice; I must be more appealing than I thought I was."" More likely, it will be ""As soon as he discovers the real me, he'll dump me."" She will pay a high psychological price to have that consonance restored.""""The Milgram experiment shows us how ordinary people can end up doing immoral and harmful things through a chain reaction of behavior and subsequent self-justification. When we, as observers, look at them in puzzlement or dismay, we fail to realize that we are often looking at the end of a long, slow process down that pyramid. At his sentencing, Magruder said to Judge John Sirica: ""I know what I have done, and Your Honor knows what I have done. Somewhere between my ambition and my ideals, I lost my ethical compass."" How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self-justification will do the rest.""""The brain is designed with blind spots, optical and psychological, and one of its cleverest tricks is to confer on us the comforting delusion that we, personally, do not have any. In a sense, dissonance theory is a theory of blind spots - of how and why people unintentionally blind themselves so that they fail to notice vital events and information that might make them question their behavior or their convictions. Along with the confirmation bias, the brain comes packaged with other self-serving habits that allow us to justify our own perceptions and beliefs as being accurate, realistic, and unbiased. Social psychologist Lee Ross calls this phenomenon ""naïve realism,"" the inescapable conviction that we perceive objects and events clearly, ""as they really are."" We assume that other reasonable people see things the same way we do. If they disagree with us, they obviously aren't seeing clearly. Naïve realism creates a logical labyrinth because it presupposes two things. One, people who are open-minded and fair ought to agree with a reasonable opinion. And two, any opinion I hold must be reasonable; if it weren't, I wouldn't hold it. Therefore, if I can just get my opponents to sit down here and listen to me, so I can tell them how things really are, they will agree with me. And if they don't, it must be because they are biased.""""As fallible human beings, all of us share the impulse to justify ourselves and avoid taking responsibility for any actions that turn out to be harmful, immoral, or stupid. ... Most people when directly confronted with proof that they are wrong, do not change their point of view or course of action but justify it even more tenaciously.""""Just as we can identify hypocrisy in everyone but ourselves, just as it's obvious that others can be influenced by money but not ourselves, so we can see prejudices in everyone else but ourselves. Thanks to our ego-preserving blind spots, we cannot possibly have a prejudice, which is an irrational or mean-spirited feeling about all members of another group. Because are are not irrational or mean-spirited, any negative feelings we have about another group are justified; our dislikes are rational and well founded. It's theirs we need to suppress. Like the Hasids pounding on the Unprejudiced door at the Museum of Tolerance, we are blind to our own prejudices.""""When two people produce entirely different memories of the same event, observers usually assume that one of them is lying. Of course, some people do invent or embellish stories to manipulate or deceive their audiences, as James Frey notably did with his bestseller A Million Little Pieces. But most of us, most of the time, are neither telling the whole truth nor intentionally deceiving. We aren't lying; we are self-justifying. All of us, as we tell our stories, add details and omit inconvenient facts; we give the tale a small, self-enhancing spin; that spin goes over so well that the next time we add a slightly more dramatic embellishment; we justify that little white lie as making the story better and clearer - until what we remember may not have happened that way, or even may not have happened at all.""""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives. An appreciation of the distortions of memory, a realization that even deeply  felt memories might be wrong, might encourage people to hold their memories more lightly, to drop the certainty that their memories are always accurate, and to let go of the appealing impulse to use the past to justify problems of the present. If we are to be careful about what we wish for because it might come true, we must also be careful which memories we select to justify our lives, because than we will have to live by them.""""For any theory to be scientific, it must be stated in such a way that it can be shown to be false as well as true. If every outcome confirms your hypotheses that all men unconsciously suffer from castration anxiety; or that intelligent design, rather than evolution, accounts for the diversity of species; or that your favourite psychic would accurately have predicted 9/11 if only she hadn't been taking a shower that morning; or that all dolphins are kind to humans, your beliefs are a matter of faith, not science.""""Our implicit theories of why we and other people behave as we do come in one of two versions. We can say it's because of something in the situation or environment: ""The bank teller snapped at me because she is overworked today; there aren't enough tellers to handle these lines."" Or we can say it's because something is wrong with the person: ""That teller snapped at me because she is plain rude."" When we explain our own behavior, self-justification allows us to flatter ourselves: We give ourselves credit for our good actions but let the situation excuse the bad ones. When we do something that hurts another, for example, we rarely say, ""I behaved this way because I am a cruel and heartless human being."" We say, ""I was provoked; anyone would do what I did""; or ""I had no choice""; or ""Yes, I said some awful things, but that wasn't me - it's because I was drunk."" Yet when we do something generous, helpful, or brave, we don't say we did it because we were provoked or drunk or had no choice, or because the guy on the phone guilt-induced us into donating to charity. We did it because we are generous and open-hearted.""""Did Charles Graner and Lynndie England know what they were doing, let alone believe they were ""doing evil"" while they were deliberately inflicting pain and humiliation on their Iraqi prisoners and then laughing at them? No, they didn't, and that is why Amos Oz is wrong. Oz didn't reckon with the power of self-justification: We are good people. Therefore, if we deliberately inflict pain on another, the other must have deserved it. Therefore, we are not doing evil, quite the contrary. We are doing good. The relatively small percentage of people who cannot or will not reduce dissonance this way pay a large psychological price in guilt, anguish, anxiety, nightmares, and sleepless nights. The pain of living with horrors they have committed, but cannot morally accept, would be searing, which is why most people will reach for any justification available to assuage the dissonance. In the previous chapter, we saw on a smaller scale why many divorcing couples justify the hurt they inflict on each other. In the horrifying calculus of self-deception, the greater the pain we inflict on others, the greater the need to justify it to maintain our feelings of decency and self-worth. Because our victims deserved what they got, we hate them even more than we did before we harmed them, which in turn makes us inflict even more pain on them.""""But what are we supposed to do in our everyday lives? Call an external review board of cousins and in-laws to adjudicate every family quarrel? Videotape all parental interrogations of their teenagers? In our private relationships, we are on our own, and that calls for some self-awareness. Once we understand how and when we need to reduce dissonance, we can become more vigilant about the process and often nip it in the bud; like Oprah, we can catch ourselves before we slide too far down the pyramid. By looking at our actions critically and dispassionately, as if we were observing someone else, we stand a chance of bring out of the cycle of action followed by self-justification, followed by more committed action. We can learn to put a little space between what we feel and how we respond, insert a moment of reflection, and think about whether we really want to buy that canoe in January, really want to send good money after bad, really want to hold on to a belief that is unfettered by facts. We might even change our minds before our brains freeze our thoughts into consistent patterns.""""Humbling yes, but ultimately that's the point. Understanding how the mind yearns for consonance, and rejects information that questions our beliefs, decisions, or preferences, teaches us to be open to the possibility of error. It also helps us let go of the need to be right. Confidence is a fine and useful quality; none of us would want a physician who was forever wallowing in uncertainty and couldn't decide how to treat our illness, but we do want one who is open-minded and willing to learn. Nor would most of us wish to live without passions or convictions, which give our lives meaning and color, energy and hope. When confidence and convictions are unleavened by humility, by an acceptance of fallibility, people can easily cross the line from healthy self-assurance to arrogance. In this book, we have met many who crossed that line: the psychiatrists who are certain that they can tell if a recovered memory is valid; the physicians and judges who are certain that they are above conflicts of interest; the police officers who are certain that they can tell if a suspect is lying; the prosecutors who are certain that they convicted the guilty party; the husbands and wives who are certain that their interpretation of events is the right one; the nations who are certain that their version of history is the only one.""""Most Americans know they are supposed to say ""we learn from our mistakes,"" but deep down, they don't believe it for a minute. They think that mistakes mean you are stupid. Combined with the culture's famous amnesia for anything that happened more than a month ago, this attitude means that people treat mistakes like hot potatoes, eager to get rid of them as fast as possible, even if they have to toss them in someone else's lap."""
145,0151010986,http://goodreads.com/user/show/8435102-joan,3,"Why is it so hard for us to admit we have made a mistake? Why do we justify our actions? Why is it so hard to change our minds when we think we are right?The authors wrote this book with a goal of understanding those behaviors. I learned tons about why we say what we do to ourselves. Self-justification, for example. We convince ourselves we made the best choice possible. Unfortunately, that blocks us from seeing our errors and learning from them.I read about cognitive dissonance and how it changes our perception. When we see disconfirming evidence, we will criticize the source (fake news), distort or outright dismiss it. Maintaining the belief is more important than truth. And we have confirmation bias, the reason it is so hard to change our minds when we have made a firm decision. I also learned much about blind spots, how our memories change (or we change them purposely), and false memories. The authors give many examples of interrogators (such as child psychologists) manipulating people to confess to crimes or report non-existing events. They give examples of law enforcement officials and prosecutors refusing to admit mistakes even when DNA evidence finally proves them wrong.Rounding out this informative book are thoughts on the price paid for for justifying decisions that cause pain to others. For example, international acts are justified by saying our deeds were bad but not nearly as bad as theirs.The authors end the book reminding us of the benefits of admitting mistakes. There is a positive effect. For politicians, admitting a mistake results in constituents admiring the person is big enough to admit wrong and desire to learn from mistakes.This is an interesting book that is very informative and easy to read. I really found it enlightening in explaining much of the rhetoric we hear today."
146,0151010986,http://goodreads.com/user/show/28157679-susan-s-frederick,5,"Really opened my eyes to bias and lenses that are different for each of us, but have profound effect on how we see things, remember things, feel things. Fascinating."
147,0151010986,http://goodreads.com/user/show/4134989-chuck,4,"A well written exposure of dissonance avoidance, self-justification, confirmation bias and other forces that effect us all. The examples and insights here are especially helpful in understanding why ourself and others make mistakes, defend actions, and choose self-preserving narratives. A revelation into neural, natural wiring. A brave look into the mirror as well as the boundaries of tolerance we construct for others. Keen, practical eye-opening read. "
148,0151010986,http://goodreads.com/user/show/32598115-becky,5,This was an interesting look at how our minds work to dissociate with problems and errors in judgement.
149,0151010986,http://goodreads.com/user/show/2251009-esteban-del-mal,4,"Cognitive dissonance: The mental discomfort experienced by a person who holds two or more contradictory beliefs, ideas, or values. This discomfort is triggered by a situation in which a person's belief clashes with new evidence perceived by the person. When confronted with facts that contradict beliefs, ideals, and/or values, people will try to find a way to resolve the contradiction to reduce their discomfort (~squaring a circle).Cognitive bias: A systematic pattern of deviation from norm or rationality in judgment. Individuals create their own subjective social reality from their perception of the input. An individual's construction of social reality, not the objective input, may dictate his or her behavior in the social world; thus, cognitive biases may sometimes lead to perceptual distortion, inaccurate judgment, illogical interpretation, or what is broadly called irrationality. Catharsis: The psychodynamic principle of emotional release. It's a bullshit theory leftover from Freud. Self-justification: How, when a person encounters cognitive dissonance or a situation in which a person's behavior is inconsistent with his/her beliefs, that person tends to justify the behavior and deny any negative feedback associated with the behavior. Naive realism: The human tendency to believe that we see the world around us objectively and that people who disagree with us must be uninformed, irrational, or biased.Totalitaian ego: a) The ego/self is an organization of knowledge; b) ego/self is characterized by cognitive biases analogous to totalitarian information-control strategies, and; c) these totalitarian-ego biases function to preserve organization in cognitive structures.Reconstructive memory: A theory of memory recall in which the act of remembering is influenced by various other cognitive processes including perception, imagination, semantic memory, and beliefs. People view their memories as being a coherent and truthful account of episodic memory and believe their perspective is free from error during recall; however, the reconstructive process of memory recall is subject to distortion by other intervening cognitive functions such as individual perceptions, social influences, and world knowledge, all of which can lead to errors during reconstruction. [REPRESSED MEMORIES DO NOT EXIST]Source confusion: An attribute seen in different people's accounts of the same event after hearing people speak about the situation (for example, a witness who heard a police officer say someone had a gun who then states he/she saw the gun).Anomie: A condition in which society provides little moral guidance to individuals. This state evolves from conflict of belief systems and causes a breakdown of social bonds between an individual and the community. In a person, this condition can progress into a dysfunctional ability to integrate within the normative situations of his/her social world (for example, an unruly personal scenario that results in fragmentation of social identity and rejection of values). The term is commonly understood to mean normlessness.Imagination inflation: The finding that imagining an event which never happened can increase confidence that it actually occurred.Confidence-accuracy relationship: As one's confidence increases, so does one's level of accuracy (or belief therein).Benevolent dolphin problem: Every once in a while, a news story appears about a shipwrecked sailor who, on the verge of drowning, is nudged to safety by a dolphin. It is tempting to conclude that dolphins must really like human beings, enough to save us from drowning. But wait—are dolphins aware that humans don’t swim as well as they do? Are they actually intending to be helpful? To answer that question, we would need to know how many shipwrecked sailors have been gently nudged further out to sea by dolphins, there to drown and never be heard from again. We don’t know about those cases because the swimmers don’t live to tell us about their evil-dolphin experiences. If we had that information, we might conclude that dolphins are neither benevolent nor evil; they are just being playful.Effort justification: A person's tendency to attribute a value to an outcome which he/she had to put effort into achieving which is greater than the objective value of the outcome (i.e., the more effort put into something, the more it is valued).Implicit personality theory: The specific patterns and biases an individual uses when forming impressions based on a limited amount of initial information about an individual or situation."
150,0151010986,http://goodreads.com/user/show/11966043-lia,5,"4.5 starsI think this is one of the best non-fiction books I've ever read. It is so fascinating and it is so well-written. I've learned so much, about others and about myself. I honestly think that reading this book makes you a better person. I couldn't recommend it more."
151,0151010986,http://goodreads.com/user/show/23790728-amani,5,This was a very interesting and informative read. 
152,0151010986,http://goodreads.com/user/show/522647-kathy,4,"I'm so depressed. Humans, grrr. If you've ever wondered why people won't admit mistakes even in the face of verifiable truth contradicting their actions or beliefs, this book explains why. With sections on cognitive dissonance, why we think we're above outside influence, memory (yes, we make up our own ""memories""), scientific research fallacies, law enforcement/prosecution proceedings and relationship killers the gamut is pretty much covered. And, it's depressing. Did I mention that already? Well, it bears mentioning twice. We humans are geared to stick to our figurative guns no matter what. I have no hope for our current political unrest in the USA to get better any time soon. Sigh."
153,0151010986,http://goodreads.com/user/show/64733542-nafisa,5,"""A nation's character, and an individual's integrity, do not depend on being error-free. It depends on what we do after making an error.""Once in a while, I come across a book that makes me question my self-concept; this book is one of them. Broadly, it is about cognitive dissonance -- the psychological stress we face when our actions contradict our beliefs and ideals. Since we don't like to think of ourselves as incompetent or ill-intentioned, our natural tendency is to convince ourselves that we did the right thing. Mindless self-justification in the face of cognitive dissonance can have far-reaching (and often devastating) consequences, and the authors do a commendable job of documenting such examples from numerous distinct domains ranging from the criminal justice system, politics, medicine, and even marriage and relationships. A fresh set of ideas, quite compelling, and sometimes challenging to read as they force you to constantly self-reflect. I highly recommend it to anyone with an interest in psychology. The book is not intended to be self-help but offers a lot of scope for personal growth."
154,0151010986,http://goodreads.com/user/show/3669193-mah-ebr,5,i think everyone should read this one! 
155,0151010986,http://goodreads.com/user/show/901342-jacob,4,"This covers ground related to Evil Genes: Why Rome Fell, Hitler Rose, Enron Failed, and My Sister Stole My Mother's Boyfriend and The Honest Truth About Dishonesty: How We Lie to Everyone--Especially Ourselves, but it's specifically about self-justification. It's attempting to answer the question ""Why do people self-justify obvious mistakes?"" and look at the impact of doing so. It's pretty straightforward and quite readable.Self-justification is a useful and even essential way for humans to protect their ego and mental health, but it can get pretty out of whack. Self-justification is not only sad when it helps us decide to do things we shouldn't, it's extra sad when people do things they shouldn't only because they are trying to support an existing self-justification for a previous bad decision. One of the elaborated examples is when innocent people go to jail: it's bad enough when police and attorneys justify acting unethically in order to convict someone they ""know"" is guilty. Where it becomes absolutely unconscionable is where they work hard to prevent people from being proven innocent after the fact so they don't have to admit screwing up.On a lighter note, with books about human fallibility you have to chuckle when the authors display the very fallibility they're decrying. In one case, they claim to be certain about someone's motivation for making poor remarks without allowing for those remarks to be caused by that person looking for any excuse to self-justify behavior. In another case, they berate therapists for not thinking scientifically and not examining the disconfirming cases, then talk about the Gottmans' work on predicting divorce without examining the disconfirming cases (where the Gottmans predicted divorce and were wrong). They mention a case where of 10 of 47 couples were predicted to divorce, all 7 who did divorce were predicted ones. Of the remaining 40, all they say is that the 90% accuracy is impressive. But they don't address that 30% of the predicted divorces didn't happen, which pokes a hole in their nice theory about self-justification causing divorce. That wouldn't be a problem if they hadn't already spent a chapter bagging on therapists for having pet theories without looking at evidence that would contradict the theory.One of the reasons you chuckle over those kinds of mistakes instead of criticizing is because we ALL do those things. I'm not immune from doing those very same things, and neither is anyone else. But we might become less that way if we are aware of the phenomenon and try to identify when we are justifying ourselves."
156,0151010986,http://goodreads.com/user/show/7399266-camie,4,"I should start by saying I find social psychology fascinating! This book is about cognitive dissonance , which basically means having two conflicting beliefs and the measures we will resort to in order to defend and justify our beliefs , decisions, and actions. Backed by much research, this very insightful book explains how we all are capable of self deception, why we do it, why it is harmful, and how to overcome the very human mechanism of justifying our foolish beliefs, improper actions, poor decisions, and hurtful acts, and more importantly how to keep small things from escalating to disastrous proportions. Looking at everything from political situations, criminal acts, war, marriage, and personal levels it offers answers to how impossible atrocities come about , one justification at a time. ""How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self justification will do the rest."" From the politician who can't publically admit his actions, the torturer who feels no guilt, to the person who will say anything to win an argument, this book explains why it is so easy to see the hypocrisy of others while being totally blind to our own. Co-written by Elliot Aronson, author of The Social Animal , a great textbook, this is a very readable informative book. The introduction is called Knaves, Fools, Villains, and Hypocrites: How Do They Live With Themselves.... lol how do we ?? 4 stars"
157,0151010986,http://goodreads.com/user/show/51519663-diana-nahirna,5,"Well, that explains a lot of my recent purchases, Iraq, and why marriages fail. "
158,0151010986,http://goodreads.com/user/show/1974052-milan,5,"Mistakes Were Made (But Not by Me) is quite an enlightening book by Carol Tavris and Elliot Aronson. The authors examine our deep-rooted tendencies to underplay our faults and errors and to exaggerate the mistakes of others, especially when they go against us. ""Cognitive dissonance occurs when a person holds two or more contradictory beliefs, ideas, or values, or participates in an action that goes against one of these three, and experiences psychological stress because of that."" Two lessons from this theory: “First, the ability to reduce dissonance helps us in countless ways, preserving our beliefs, confidence, decisions, self-esteem, and well-being. Second, this ability can get us into big trouble.”The self-justification mechanisms like cognitive dissonance, confirmation bias, and fabricated memory play such an important role in our lives that they are hard to ignore. The authors provide very vivid examples from politics, therapy, conflict, wars, marriage, police and court procedures to show how these biases work. A few important lessons: •	 “Most human beings and institutions are going to do everything in their power to reduce dissonance in ways that are favorable to them, that allow them to justify their mistakes and maintain business as usual.” •	“Most people, when directly confronted by evidence that they are wrong, do not change their point of view or course of action but justify it even more tenaciously. Even irrefutable evidence is rarely enough to pierce the mental armor of self-justification.”•	Our ‘mistake-phobic’ culture causes people not to learn from their mistakes.•	Naive realism: the believe that everyone else sees the world as we do•	We all self-justify as a way to protect against cognitive dissonance, whether positively or negatively.•	Memories are easily modified to fit a narrative to reduce cognitive dissonance.•	We must be careful to not allow memory distortion to justify previous decisions.•	Therapists should be very concerned about confirmation bias, their expert assessments and also in their evaluations of people.•	Confessions can be elicited from accused legally by using deceit, trickery, etc.•	Successful couples will give the benefit of the doubt to their partners, just as they would to themselves. Unsuccessful couples do the opposite.•	We must strive to take self-justification into account in our lives and relationships to prevent incorrect decisions making.Two things to keep in mind – our personal life will suffer if we don’t admit our mistakes and society will work better if people admitted when they’re wrong."
159,0151010986,http://goodreads.com/user/show/28602450-vladyslav-sitalo,4,"You think about yourself as a reasonably nice person, with not perfect but good enough memory. Maybe you've done some things in your life, that you don't particularly like, but you think that in most cases, given the situation you were in, most of the people would've done the same.So you ain't perfect but better than the most, right?Well, this book would get you to at least question, how accurate is the description above. And it will also tell you how come you (and most of the people, even most morally flawed, from your perspective, people) think of themselves in this way.The book will tell you how your mind is desperately trying to maintain the self-image, you have about yourself and protect beliefs your hold. How it change your perceptions of things around you to fit this image/beliefs. And here comes more fun: it also employs your memory to justify your current self-perception/beliefs. So your memory is gradually, with each recall, become more compliant with this image. And eventually, all you left with is the nice, coherent story of your life that corresponds to your current view of yourself and your beliefs. But this story often has little or nothing to do with reality.As authors call it: Memory is your self-justifying historian (I would also highly recommend a novelette by Ted Chiang - ""The Truth of Fact, the Truth of Feeling"" as an exploration of this aspect of our memory: https://www.goodreads.com/book/show/1...).And the thing is that this process influences pretty much every aspect of your life regardless of your age/education or other things, you might think would influence the situation.So the process kicks in:When you're a nice, kind boy, who find himself in a company that is bullying a weaker guy. You don't particularly like the process but, as you want to be a part of this social group - you continue to participate in it. But there is dissonance here: how come you, as a nice, kind boy become a bully? So here the self-justification comes to your help: ""It's totally the guy's responsibility that he got bullied. Let's modify our image of the guy to leave our self-image preserved and justify what've done. Yay! And hey we're justified to continue to bully him as he is such a ....""Or let's say you're a student who don't have any strong position on cheating. You know it's generally considered a ""bad thing"" but you don't have any personal conviction either way. You haven't done it earlier because you didn't need to. But now you're in the situation when you need either cheat or fail this particular course. So situation can go in two ways from here:World 1: You've decided to cheat. ""Self-justification process: Ok we've cheated, as we know we're a generally good person, so we could not have possibly done a bad thing, so we may conclude that cheating is not a big deal"".World 2: You've decided not to cheat. ""Self-justification process: Ok we've failed the course. That's unfortunate but, well we didn't have any other option, right? We wouldn't even consider doing such a terrible thing as cheating"".Or you're a detective and you've interrogated your suspect to the point that he have given you a confession. But here comes the strong evidence (like DNA test or videotape) that he is innocent. So here it goes: ""I'm an honest infallible detective and my interrogation methods are great, and, after all, the guy has given confession after only 36 consecutive hours of interrogation. The evidence must be wrong""And let's upgrade a bit more. You're an honest politician, who is right now flying with a lobbyist on a luxury private plane to spend a nice weekend in some luxury resort. ""As we're an honest, good man, this situation can't possibly influence our political judgment in any way, right?"" (To understand how you got in this situation in a first place and for a lot of other good examples - read the book ;)The more deeply held self-belief that is contradicting to what you did the more actively you would justify the deed as the kind of deed that don't contradict this self-belief.You probably think to yourself: ""Ok maybe some of the cases described in this book can be true about me, but in most of them I would not have employed this level of self-justification""Well, the problem is that self-justification is largely unconscious process so when you do something that don't correspond to your self-image or see information that contradicts your belief - the justification process kicks in automatically in the background.So usually, you don't even notice on the conscious level that you've maybe done something wrong or that you hold a questionable belief. And correspondingly you don't have a chance to fix the situation before you internalize it as the normal state of things.That's why it's often said ""Hypocrite is obvious to all but himself""So you would probably at this point like to know - are we doomed? Can we do better? And the answer is yes we can! The book advises us to institute impartial external overview committees wherever possible (if necessary even against the will of involved people/institutions) because the external observer can usually notice an error much easier than somebody who have committed it. As he is not emotionally/financially/in other way invested in this decision.In the situations where setting up such an institutions is not feasible or reasonable (For example in the case of personal relationships), make sure that you and people around are aware and conscious about the magic of self-justification. You also can, to some level, train yourself to recognize the typical situations where the process may kick in and be especially careful when facing them. Also, be aware of the fact that this magic works on other people, so when you try to point out his/her error to somebody, be careful to do it in a way that will not make them self-defensive and more likely to justify this error.And don't be afraid to admit your errors, because as you relinquish wrong beliefs you become wiser, as you own up to your errors you gain more respect from people and you're less likely to make the same error in the future. Everybody makes mistakes, but you only can learn from yours, when you admit them."
160,0151010986,http://goodreads.com/user/show/21170365-amy-anderson,5,"I loved this book and found it so applicable to everyone. While we need justification to move forward in life and not second guess our every decision, we also need to be aware that justification can lead us to be blind sighted to truth. Its a fine line to walk. I could quote this whole book, but here are my favorites:""Self-justification is more powerful and dangerous than the explicit lie. It allows people to convince themselves that what they did was the best thing they could have done. In fact, come to think of it, it was the right thing."" p.4""Self-justification not only minimizes our mistakes and bad decision, it is also the reason that everyone can see a hypocrite in action except the hypocrite."" p.4""How in the world can they live with themselves? The answer is exactly the way the rest of us do."" p.9""Yet mindless self-justification, like quicksand, can draw us deeper into disaster. It blocks our ability to even see our errors, let alone correct them. It distorts reality, keeping us from getting all the information we need and assessing the issues clearly. It prolongs and widens rifts between lovers, friends, and nations. It keeps us from letting go of unhealthy habits. IT permits the guilty to avoid taking responsibility for their deeds."" p.9""I will look at any additional evidence to confirm the opinion to which I have already come."" Lord Molson p.17""These mechanisms provide a neurological basis for the observation that once our minds are made up, it is hard to change them."" p.19""People become more certain they are right about something they just did if they can't undo it."" p.22""Decades of experimental research have found exactly the opposite: that when people vent their feelings aggressively they often feel worse, pump up their blood pressure and make themselves angrier."" p.26""Aggression begets self-justification, which begets more aggression."" p.27""How do you get an honest man to lose his ethical compass? You get hi to take one step at a time, and self-justification will do the rest."" p.37""Parent blaming is a popular and convenient form of self-justification because it allows people to live less uncomfortably with their regrets and imperfections."" p.76""...current self-concepts blurred their memories, bringing their past selves into harmony with their present ones."" p.79""If a memory is a central part of your identity, a self-serving distortion is even more likely."" p.79""For those who are trying to remember something that never happened, writing analyzing dreams, and drawing pictures- techniques that are the staples of many psychotherapists- are all methods that quickly conflate imagination with reality."" p.86""Once the seed of belief was planted [they] began to search for confirming evidence."" p.90""...the story fits the needs of the experiences."" p.91"",,,experiences have internalized their new false memories and cannot now distinguish them from true ones. They have come to believe their own stories."" p.93""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives."" p.93""Successful partners extend to each other the same self-forgiving ways of thinking we extend to ourselves: They forgive each other's missteps as being due to the situation, but give each other credit for the thoughtful and loving things they do."" p.169""It may sometimes be hard to define good, but evil has its unmistakable odor: Every child knows what pain is. Therefore, each time we deliberately inflict pain on another, we know what we are doing. We are doing evil."" Amoz p.198""Would you rather admit you're wrong now or wait until someone else proves it?"" p.221""People will pursue self-destructive courses of action to protect the wisdom of their initial decisions."" p.222""They will treat people they have hurt even more harshly, because they convince themselves that their victims deserve it."" p.222""People who are insecure in their religious beliefs may feel the impulse to silence and harass those who disagree with them, because their mere existence arouses the painful dissonance of doubt."" p.222"
161,0151010986,http://goodreads.com/user/show/5301457-sergei-moska,4,"Although this book didn't actually teach me anything new in terms of theory (but did provide me with many details of practical cases), it nonetheless surprised me. First, I decided to read this book at this time because I've been a bit burned out from dense reading and wanted something useful but light. It was in fact both these things, but it was also far, far more depressing than I had expected. I expected this to be a “Ha ha, let's look at our foibles!” type of read. No, it's more of a “your identity is a joke and the world systematically does evil things. And so do you.” kind of experience. Structurally speaking, the book is very simple. The first part posits a simplified theory, and the rest of the book demonstrates the theory in action, in a few select areas of life. The theory is that we need to overcome the cognitive dissonance that emerges when our actions conflict with our self-image or beliefs. At such a moment, we are said to be at the top of a “pyramid” (a 2-dimensional triangle would be a better image), and the authors believe that whether or not we choose to justify ourselves to ourselves in such moments will lead us down one side of the pyramid or the other, with drastically different outcomes once we hit either side of the base of the pyramid. I may give up the idea that I'm such a great guy, or I can decide that the other person deserved the treatment, that it really wasn't a big deal, etc. The authors believe that whatever choice we make will cause us – in order to avoid further cognitive dissonance – to more extreme positions in order to justify our initial choice. A number of surprising findings come about as a result. For instance, the more helpless the victim, the more we will tend to denigrate him in order to justify our initial mistreatment of him. Beating up an angry drunk at a bar doesn't necessarily require much justification (“He was being threatening, and it's fine to beat up people that are threatening”), but participating in bullying usually does (“I'm a nice guy and beating him up, so it must be because he's a weenie who deserves to be humiliated. Plus he'd do it if he had the chance”.)A fun book to read, although it was too simplified for my taste in at least two ways. First, the authors' theory is *very* simple, and at times their application of the theory seems too universal. For instance, why do innocent people confess to crimes? The authors only seem to entertain the notion that it's in order to reduce cognitive dissonance: “I didn't do anything, but all the cops say that they have proof. The cops are honest and good people, so I must be the problem.” Yet at times this just seems dubious. The explanation is far more convincing when they apply it to the decision by the police to continue interrogation even in the absence of evidence. The second way that the book was too simplified for my taste is in its structure. After a very good exposition of their theory, I was hoping that the subsequent material would help develop the theory further. But what it turned out to be was “Here's a theory, and now we're going to show you the theory in X, Y, and Z.” This is a matter of taste, but I really don't like that format. What's more, I do think it hurts the authors, since it implies that the answer to the subtitle of the book is monolithic. I don't think that to be the case, and I suspect the authors don't either. In fairness, they do incidentally go through a number of additional mechanisms that are attached to the problem of cognitive dissonance, including a wonderful treatment on the foibles of memory, but it would have been really nice to make their answer more complex and complete, even at the risk of making it less parsimonious. Normally that kind of issue would be a big turn-off for me, but the book really is saved (for me) by their incredibly chilling accounts, especially in chapters 3-6. The writing is very clear and engaging, and the book is also thoroughly annotated, all of which makes me fall a little bit in love with the authors."
162,0151010986,http://goodreads.com/user/show/1677868-steven-peterson,4,"This is a well written, snappy book that addresses an important issue, best described by the book's title and subtitle: ""Mistakes Were Made (but not by me): Why we justify foolish beliefs, bad decisions, and hurtful acts."" The two authors, both well reputed psychologists, use the theory of cognitive dissonance as their starting point. Leon Festinger was one of the major theorists of this approach. The authors of this book simply define the perspective thus (page 13): ""Cognitive dissonance is a state of tension that occurs whenever a person holds two cognitions (ideas, attitudes, beliefs, opinions) that are psychologically inconsistent, such as 'Smoking is a dumb thing to do because it could kill me' and 'I smoke two packs a day.'"" How does one deal with this? By adopting one of the positions and then downgrading or rejecting the other. The end result is self-justification, self-deception, seeking out evidence to support the choice that we have made while rejecting evidence that does not fit with our choice. The brain itself shows evidence of the operation of cognitive dissonance. The example on page 19 of functional Magnetic Resonance Imaging (fMRI) and processing information about presidential candidates is telling. The end result is ""blind spots,"" in which people (page 42) ""fail to notice vital events and information that might make them question their behavior or their convictions."" As such, the authors note that cognitive dissonance makes mincemeat of such theoretical views as rational actor theory and psychoanalytic theory. One result of cognitive dissonance is what is called ""confirmation bias,"" the attending to evidence that supports our views and the rejection/suppression of evidence that does not support our views. Many examples are advanced to illustrate the case that the authors make. Issues include: moral lapses (e.g., Watergate participants), ""made up"" memories (raising serious questions about the whole idea of repressed memories), criminal justice system decisions on guilt or innocence, and so on. Much is at stake with cognitive dissonance as it operates. In the closing chapter, the authors try to indicate how understanding cognitive dissonance might help us to limit the damage that may occur as a result of its operation. Convincing? I'm not so sure, but this discussion does get one thinking about how we might address the harmful side effects of cognitive dissonance. A readable book that raises important issues. I think that more use of neuroscientific research could have strengthened this book that much more. Also, the work by cognitive psychologists like Kahneman and Tversky could have spoken to key points as well. This book might also profitably be read in tandem with another recent book on a similar subject, Cordelia Fine, ""A Mind of Its Own."" In addition, Linden's ""accidental Mind"" provides a perspective on related issues from a neuroscience viewpoint. "
163,0151010986,http://goodreads.com/user/show/9281934-louise,5,"Prior to reading this, I had only considered the theory of cognitive dissonance as it applied to holding two contrary opinions, the classic example being that of the racist with friends who are members of the race s/he denigrates. Tavris and Aronson demonstrate further applications of this theory and how destructive the behavior it spawns continues to be.The 1980's/90's day care scandals pre-dated the 24 hour cable cycle (imagine this being covered today by Fox) so it blipped in and out of my attention. I remember thinking how it didn't add up, but I wasn't really following it. Today, somewhere below my radar screen are the DNA absolved prisoners, and their continued incarceration doesn't add up either. Tavris and Aronson show how the professionals involved continued and continue to stick to their long fought for opinion, even as evidence pours in against it. As the dissonance theory predicts, the greater the commitment to the opinion the more the mind works to re-enforce it.The book is most convincing on the personal level such as the damage caused by the dynamics in divorce or accusations such as those made by those in the recovered memory therapies.While cognitive dissonance is undoubtedly operative, it is not the only culprit in the inability to admit mistakes. For commercial and public policy issues there is liability to be paid either through job loss, litigation, an election, or even everyday office politics. If the culprit is a principal player on a big stage, it could be a career ender for not only the decider, but his/her staff. It is not just the mind that keeps out contrary information, there is undoubtedly social support for the bad decision by those who also made the mistake or assisted in its execution. There are also families to consider, you admit the mistake, you could lose your job and there will be no college education for your kids. The books speaks of these barriers, but sticks to its purpose of illustrating the theory.For barriers beyond cognitive dissonance, I think of George Bush and the Iraq war. If he could bring himself to admit the mistake, he would face huge institutional and social acrimony from the policy makers who assisted him, the party who supported him, the military as an institution and the families who lost their loved ones. Ultimate decision makers on the Iraq War will wait, like Robert McNamara did, until the mistake is universally recognized.This is an excellent book. The authors develop their theory for the lay person with good examples from both everyday life and the world of public policy. I highly recommend it. "
164,0151010986,http://goodreads.com/user/show/2414293-adelle,3,"The authors' political biases came through as they used the beginning and the ending of the book to castigate then (2007) President George W. Bush, and to call Newt Gingrich a “hypocrite” for criticizing (now former) President Bill Clinton’s sexual affair…WITHOUT any allusion to Clinton’s defensive “I did not have sex with that woman…Miss Lewinski” statement. But most of the center sections of the book--which thankfully were relatively free of politics--- I found endlessly fascinating. Oh, how tenaciously we cling to “our version” of the story, filtering the facts so that what WE did/or didn’t do is seen to be of negligible consequence or perhaps even honorable, and what THE OTHER GUY did/or didn’t do is seen to be righteously reprehensible, obviously beyond the pale. I loved, too, the authors’ many demonstrations that the act that alienates one party or the other is not a stand-alone event. To reference Aesop, it is much more likely to be the straw that broke the camel’s back. Hurts and grievances in both parties have probably been building for some time. “Who were the victims? It depends on how many years, decades, and centuries you take into account” (206). Consider Kosovo. Consider the Crusades. As the authors describe these tragic events, IF one is not emotionally involved with one side or the other, one can see BOTH points of view. Likewise in personal relationships. “Of all the stories that people construct to justify their lives, loves, and losses, the ones they weave to account for being the instigator or the recipient of injustice or harm are the most compelling and have the most far-reaching consequences” (191). Tavris and Aronson continue, “We have all done something that made others angry at us, and we have all been spurred to anger by what others have done to us. We all have, intentionally or unintentionally, hurt another person who will forever regard us as the villain, the betrayer, the scoundrel. And we have all … [been:] on the receiving end” (191). It would seem it is seldom the absolute fault of “the other guy.” But…that would mean…and humans on the whole have SUCH a vested interest in protecting their own self-image.A interesting, engaging read."
165,0151010986,http://goodreads.com/user/show/25763919-mimi,4," This is phenomenal! .......it made me love Psychology even more.This book has a protagonist , well ,i think it's more of an antagonist (to us) named : cognitive dissonance (i am so in love with this character hhhhh) ""Mistakes Were Made But Not By Me"" discusses all SORTS of lengths human being may go in order to reduce cognitive dissonance.Acting in contradiction to what u believe (cognitive dissonance) is 'painful' 'uncomfortable' so what we do? the remedy is employed extensively by all yet little know about it : it's self justification.How it works: you hate cheating (this is your belief), it happened and you cheated once voluntarily (contradicting behavior) ====== results is cognitive dissonance ( your self image is shaken ,because your belief about 'cheating' has being shaken)Huh! now comes the remedy time : cheating isn't that bad. the exam was unfairly difficult that's why i cheated these are some of the thoughts we may have once we start justifying our actions (cheating) to reduce cognitive dissonance.OK , now let me introduce you other cognitive biases that leads u to screwing up immensely:Confirmation bias : this dude screws rational healthy discussions... for it blinds you for one side of an argument completely. You believe in one side, you keep looking for info to prove it without EVER checking the arguments and evidence the opposite view might present ( this is what makes some peoples' craniums rock-hard , never allowing the penetration of any of your ideas or arguments ) Snap decisions/judgements : this guys are super bad , if you could just turn them off when you are presented with anything which needs you opinion ....when you take a snap decision you are done for , it becomes harder to see the other angles of a person , an idea ...unless you knew how dangerous these guys are for your objectivity and try harder to make a balanced judgment. Sadly humans are hardwired with many biases that makes them fallible creatures....and without knowing them they will be extra fallible."
166,0151010986,http://goodreads.com/user/show/17485839-zena-ryder,4,"If you don't know what cognitive dissonance is, this is a great introduction. If you do know what it is, this is an easy, enjoyable read, with interesting stories and experiments that illustrate dissonance and the resulting self-justification, which will likely deepen your understanding of this all too human phenomenon. The authors also talk about the fascinating and related phenomenon of false memories — our memories tend to get distorted (or even created!) to be self-serving. I found the section on how easily children can be persuaded to have memories of things that didn't really happen both fascinating and disturbing. The authors also talk about the how police officers' confirmation bias and the need to avoid dissonance by those involved at the various stages of the justice system can and does lead to terrible miscarriages of justice.I guess the biggest thing that was missing, for me, was more detail of when we don't give in to self-justification in order to avoid dissonance. The authors do talk about this, but I would have liked more detail. I would also like more detail on people with low self esteem, who don't tend to resolve their dissonance in self-serving ways, but rather in ways that fit their self image of being incompetent, unlovable etc.While knowing about cognitive biases and flaws isn't enough to make them magically go away, the authors suggest that being aware of them should make us less confident in our own convictions and memories, especially when they are self-serving. I think that is an important lesson for anyone."
167,0151010986,http://goodreads.com/user/show/4532156-alaa-a,5,"This year I started to be more interested in social psychology books in my hope to change my default sitting to the world and understand it better, and what better way than saying I was wrong to your self and owning the mistakes to your self...Its a very challenging book to read its started to with an eases of pointing the mistakes of politics and countries and introducing the conformation biases then going to personal stories that we are confined that happened when all evidenced are against.One of the psychological insights that has been messing around with my mind is the selective memory and that even if you feel strongly sure and emotionally attached to it can be wrong or even planted made me question my memories and if I am a hypocrite the explanation for people's unwillingness to admit mistakes, even to themselves, in a variety of realms. This far-reaching BOOK tackles irrational prejudices, false memories, misjudgement as a psychotherapist, prosecuting the wrong individual, blaming one's spousethe part of repressed memory therapy of rape victimise was eye opening for me as how easy for as to follow :Cognitive dissonanceConfirmation biasI read in the book ""thinking fast and slow "" that knowing this biases dose not stop you form doing it even for the experts in this felid but it can make you stop your self and question why you think or act this way, and that is about it what you can do!! "
168,0151010986,http://goodreads.com/user/show/5856337-mark,5,"Having been put off by several popular books by social psychologists I read in recent years which I felt failed to deliver on the promised goods (""Emotional Intelligence"" and ""Social Intelligence,"" both by Daniel Goldman come quickly to mind), I was both relieved and impressed as I listened to the audiobook version of ""Mistakes Were Made.""The authors not only convincingly support and develop their thesis from start to finish, they do so in an entertaining fashion. Furthermore, the book offers plenty of opportunity for practical application for any casual reader who dares to pause to consider how his or her own pride, cognitive dissonance, confirmation biases, etc. may cause him/her to re-write history, justify themselves and their experiences, blind themselves from seeing the truth, etc. I will mention one area where the authors may possibly be a little ""off."" Toward the end of the book, they share an example of Japanese encouraging mistakes in the classroom and seem to generalize this example for Asian culture. However, across mainland China, Japan, Taiwan, and Korea, societies seems to be somewhat intolerant of mistakes. Having said all that, this is still a great book. Read it!"
169,0151010986,http://goodreads.com/user/show/2050800-kathy,1,"Although the authors have some good points about self-justification in a few sections of the book, they clearly spend way too much time on the ""problem"" and their political biases than a plausible solution to overcoming self-justification. I read the last page of the book in complete disgust as to the topic they chose to end with and completely irritated that very few solutions were offered to help minimize self-justification in ourselves as well as others. I guess I should have read the title a little closer: It states ""Why we..."" and not ""How to overcome why we..."" Also found it very fitting based on the severe bias that shone through the entire book that there was not one mention of the infamous ""I did not have sexual relations with that woman"" by Bill Clinton. Now that's a perfect example of self-justification if I've ever seen one!There is nothing more irritating to me than reading 200 pages about a problem and then getting to the end and realizing the author offered no real solutions but a ton of biased opinions. What a waste!"
170,0151010986,http://goodreads.com/user/show/1347209-jacob,5,"As much as I read, there are few books that are enlightening, educational, and entertaining enough for me to rate them so highly. This is one of those books that every time you put it down you have to run and find someone to tell what you just read. You find the content so interesting that you can't help but share it with others.The authors do a great job at explaining cognitive dissonance and how it leads to self-justification. They also apply the concepts well by focusing a chapter on a specific realm of how this impacts our world (legal interrogation, false memory recovery, etc).If you have ever read ""Leadership and Self Deception"" I think you would enjoy this book also. More of the science behind the story.Read this and then apply the information in your life. It is blessing me and those around me and I'm sure it will you."
171,0151010986,http://goodreads.com/user/show/1984886-tim-kadlec,3,"The book was full of good information, and good discussions around cognitive dissonance. It's fault, however, was that the anecdotes tended to be very politically charged, and very biased.Unfortunately, the authors bias came through very strongly in several of the examples used, and this distracts from the points the authors are attempting to make. In addition, a few of the examples felt like they didn't really fit in with the subject matter, and were instead used to continue to justify the authors biases (ironic I know)."
172,0151010986,http://goodreads.com/user/show/26434622-sophiacoming,5,"One of my favorite books! make me more aware of my silly impulses. I think understanding these limitation is the basis for having a crucial conversation, and making peace with yourself and people around you."
173,0151010986,http://goodreads.com/user/show/58909202-edu,2,"The concept is very interesting, even necessary to know, and mindblowing, wich I liked a lot. But there were many many examples and much of them from USA politics, which I don't care so much about. "
174,0151010986,http://goodreads.com/user/show/8778400-rebekka-steg,5,"This week I've been reading Mistakes Were Made (But Not by Me): Why We Justify Foolish Beliefs, Bad Decisions, and Hurtful Acts by Carol Tavris and Elliot Aronson, an absolutely amazing book, which everyone should be acquired to read.The book deals with the issue of self-justification, and the role it plays in all of our lives, from such ""minor"" issues as arguments within a relationship, to bullying, prejudicialness, torture, fraud etc.Written by two psychologist, the book is backed by research as well as real life cases and examples. It's easy to read, incredibly thought-provoking and it deals with such an important topic, which affects us all.

 Quotes ""We are all capable of believing things which we know to be untrue, and then, when we are finally proved wrong, impudently twisting the facts so as to show that we were right. Intellectually, it is possible to carry on this process for an indefinite time: the only check on it is that sooner or later a false belief bumps up against solid reality, usually on a battlefield.""- George Orwell (1946)""For example, Elliot predicted that if people go through a great deal of pain, discomfort, effort, or embarrassment to get something, they will be happier with that ""something"" than if it came to them easily. For behaviorists this was a preposterous prediction. Why would people like anything associated with pain? But for Elliot, the answer was obvious: self-justification. The cognition that I am a sensible, competent person is dissonant with the cognition that I went through a painful procedure to achieve something - say, joining a group that turned out to be boring and worthless. Therefore, I would distort my perceptions of the group in a positive direction, trying to find good things about them and ignoring the downside.""""Venting is especially likely to backfire if a person commits an aggressive act against another person directly, which is exactly what cognitive dissonance theory would predict. When you do anything that harms someone else - get them in trouble, verbally abuse them or punch them out - a powerful new factor comes into play: the need to justify what you did. Take a boy who goes along with a group of his fellow seventh graders who are taunting and bullying a weaker kid who did them no harm. The boy likes being part of the gang but his heart really isn't in the bullying. Later, he feels some dissonance about what he did. ""How can a decent kid like me,"" he wonders, ""have done such a cruel thing to a nice, innocent little kid like him?"" To reduce dissonance, he will try to convince himself that the victim is neither nice nor innocent: ""He is such a nerd and cry-baby. Besides, he would have done the same to me if he had the chance."" Once the boy starts down the path of blaming the victim, he becomes more likely to beat up on the victim with even greater ferocity the next chance he gets. Justifying his first hurtful act sets the stage for more aggression. That's why the catharsis hypothesis is wrong.""""Our convictions about who we are carry us through the day, and we are constantly interpreting the things that happen to us through the filter of those core beliefs. When they are violated, even by a good experience, it causes us discomfort. An appreciation of the power of self-justification helps us understand, therefore, why people who have low self-esteem, or who simply believe that they are incompetent in some domain, are not totally overjoyed when they do something well; why, on the contrary, they often feel like frauds. If the woman who believes she is unlovable meets a terrified guy who starts pursuing her seriously, she will feel momentarily pleased, but that pleasure is likely to be tarnished by a rush of dissonance: ""What does he see in me?"" Her resolution is unlikely to be ""How nice; I must be more appealing than I thought I was."" More likely, it will be ""As soon as he discovers the real me, he'll dump me."" She will pay a high psychological price to have that consonance restored.""""The Milgram experiment shows us how ordinary people can end up doing immoral and harmful things through a chain reaction of behavior and subsequent self-justification. When we, as observers, look at them in puzzlement or dismay, we fail to realize that we are often looking at the end of a long, slow process down that pyramid. At his sentencing, Magruder said to Judge John Sirica: ""I know what I have done, and Your Honor knows what I have done. Somewhere between my ambition and my ideals, I lost my ethical compass."" How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self-justification will do the rest.""""The brain is designed with blind spots, optical and psychological, and one of its cleverest tricks is to confer on us the comforting delusion that we, personally, do not have any. In a sense, dissonance theory is a theory of blind spots - of how and why people unintentionally blind themselves so that they fail to notice vital events and information that might make them question their behavior or their convictions. Along with the confirmation bias, the brain comes packaged with other self-serving habits that allow us to justify our own perceptions and beliefs as being accurate, realistic, and unbiased. Social psychologist Lee Ross calls this phenomenon ""naïve realism,"" the inescapable conviction that we perceive objects and events clearly, ""as they really are."" We assume that other reasonable people see things the same way we do. If they disagree with us, they obviously aren't seeing clearly. Naïve realism creates a logical labyrinth because it presupposes two things. One, people who are open-minded and fair ought to agree with a reasonable opinion. And two, any opinion I hold must be reasonable; if it weren't, I wouldn't hold it. Therefore, if I can just get my opponents to sit down here and listen to me, so I can tell them how things really are, they will agree with me. And if they don't, it must be because they are biased.""""As fallible human beings, all of us share the impulse to justify ourselves and avoid taking responsibility for any actions that turn out to be harmful, immoral, or stupid. ... Most people when directly confronted with proof that they are wrong, do not change their point of view or course of action but justify it even more tenaciously.""""Just as we can identify hypocrisy in everyone but ourselves, just as it's obvious that others can be influenced by money but not ourselves, so we can see prejudices in everyone else but ourselves. Thanks to our ego-preserving blind spots, we cannot possibly have a prejudice, which is an irrational or mean-spirited feeling about all members of another group. Because are are not irrational or mean-spirited, any negative feelings we have about another group are justified; our dislikes are rational and well founded. It's theirs we need to suppress. Like the Hasids pounding on the Unprejudiced door at the Museum of Tolerance, we are blind to our own prejudices.""""When two people produce entirely different memories of the same event, observers usually assume that one of them is lying. Of course, some people do invent or embellish stories to manipulate or deceive their audiences, as James Frey notably did with his bestseller A Million Little Pieces. But most of us, most of the time, are neither telling the whole truth nor intentionally deceiving. We aren't lying; we are self-justifying. All of us, as we tell our stories, add details and omit inconvenient facts; we give the tale a small, self-enhancing spin; that spin goes over so well that the next time we add a slightly more dramatic embellishment; we justify that little white lie as making the story better and clearer - until what we remember may not have happened that way, or even may not have happened at all.""""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives. An appreciation of the distortions of memory, a realization that even deeply  felt memories might be wrong, might encourage people to hold their memories more lightly, to drop the certainty that their memories are always accurate, and to let go of the appealing impulse to use the past to justify problems of the present. If we are to be careful about what we wish for because it might come true, we must also be careful which memories we select to justify our lives, because than we will have to live by them.""""For any theory to be scientific, it must be stated in such a way that it can be shown to be false as well as true. If every outcome confirms your hypotheses that all men unconsciously suffer from castration anxiety; or that intelligent design, rather than evolution, accounts for the diversity of species; or that your favourite psychic would accurately have predicted 9/11 if only she hadn't been taking a shower that morning; or that all dolphins are kind to humans, your beliefs are a matter of faith, not science.""""Our implicit theories of why we and other people behave as we do come in one of two versions. We can say it's because of something in the situation or environment: ""The bank teller snapped at me because she is overworked today; there aren't enough tellers to handle these lines."" Or we can say it's because something is wrong with the person: ""That teller snapped at me because she is plain rude."" When we explain our own behavior, self-justification allows us to flatter ourselves: We give ourselves credit for our good actions but let the situation excuse the bad ones. When we do something that hurts another, for example, we rarely say, ""I behaved this way because I am a cruel and heartless human being."" We say, ""I was provoked; anyone would do what I did""; or ""I had no choice""; or ""Yes, I said some awful things, but that wasn't me - it's because I was drunk."" Yet when we do something generous, helpful, or brave, we don't say we did it because we were provoked or drunk or had no choice, or because the guy on the phone guilt-induced us into donating to charity. We did it because we are generous and open-hearted.""""Did Charles Graner and Lynndie England know what they were doing, let alone believe they were ""doing evil"" while they were deliberately inflicting pain and humiliation on their Iraqi prisoners and then laughing at them? No, they didn't, and that is why Amos Oz is wrong. Oz didn't reckon with the power of self-justification: We are good people. Therefore, if we deliberately inflict pain on another, the other must have deserved it. Therefore, we are not doing evil, quite the contrary. We are doing good. The relatively small percentage of people who cannot or will not reduce dissonance this way pay a large psychological price in guilt, anguish, anxiety, nightmares, and sleepless nights. The pain of living with horrors they have committed, but cannot morally accept, would be searing, which is why most people will reach for any justification available to assuage the dissonance. In the previous chapter, we saw on a smaller scale why many divorcing couples justify the hurt they inflict on each other. In the horrifying calculus of self-deception, the greater the pain we inflict on others, the greater the need to justify it to maintain our feelings of decency and self-worth. Because our victims deserved what they got, we hate them even more than we did before we harmed them, which in turn makes us inflict even more pain on them.""""But what are we supposed to do in our everyday lives? Call an external review board of cousins and in-laws to adjudicate every family quarrel? Videotape all parental interrogations of their teenagers? In our private relationships, we are on our own, and that calls for some self-awareness. Once we understand how and when we need to reduce dissonance, we can become more vigilant about the process and often nip it in the bud; like Oprah, we can catch ourselves before we slide too far down the pyramid. By looking at our actions critically and dispassionately, as if we were observing someone else, we stand a chance of bring out of the cycle of action followed by self-justification, followed by more committed action. We can learn to put a little space between what we feel and how we respond, insert a moment of reflection, and think about whether we really want to buy that canoe in January, really want to send good money after bad, really want to hold on to a belief that is unfettered by facts. We might even change our minds before our brains freeze our thoughts into consistent patterns.""""Humbling yes, but ultimately that's the point. Understanding how the mind yearns for consonance, and rejects information that questions our beliefs, decisions, or preferences, teaches us to be open to the possibility of error. It also helps us let go of the need to be right. Confidence is a fine and useful quality; none of us would want a physician who was forever wallowing in uncertainty and couldn't decide how to treat our illness, but we do want one who is open-minded and willing to learn. Nor would most of us wish to live without passions or convictions, which give our lives meaning and color, energy and hope. When confidence and convictions are unleavened by humility, by an acceptance of fallibility, people can easily cross the line from healthy self-assurance to arrogance. In this book, we have met many who crossed that line: the psychiatrists who are certain that they can tell if a recovered memory is valid; the physicians and judges who are certain that they are above conflicts of interest; the police officers who are certain that they can tell if a suspect is lying; the prosecutors who are certain that they convicted the guilty party; the husbands and wives who are certain that their interpretation of events is the right one; the nations who are certain that their version of history is the only one.""""Most Americans know they are supposed to say ""we learn from our mistakes,"" but deep down, they don't believe it for a minute. They think that mistakes mean you are stupid. Combined with the culture's famous amnesia for anything that happened more than a month ago, this attitude means that people treat mistakes like hot potatoes, eager to get rid of them as fast as possible, even if they have to toss them in someone else's lap."""
175,0151010986,http://goodreads.com/user/show/8435102-joan,3,"Why is it so hard for us to admit we have made a mistake? Why do we justify our actions? Why is it so hard to change our minds when we think we are right?The authors wrote this book with a goal of understanding those behaviors. I learned tons about why we say what we do to ourselves. Self-justification, for example. We convince ourselves we made the best choice possible. Unfortunately, that blocks us from seeing our errors and learning from them.I read about cognitive dissonance and how it changes our perception. When we see disconfirming evidence, we will criticize the source (fake news), distort or outright dismiss it. Maintaining the belief is more important than truth. And we have confirmation bias, the reason it is so hard to change our minds when we have made a firm decision. I also learned much about blind spots, how our memories change (or we change them purposely), and false memories. The authors give many examples of interrogators (such as child psychologists) manipulating people to confess to crimes or report non-existing events. They give examples of law enforcement officials and prosecutors refusing to admit mistakes even when DNA evidence finally proves them wrong.Rounding out this informative book are thoughts on the price paid for for justifying decisions that cause pain to others. For example, international acts are justified by saying our deeds were bad but not nearly as bad as theirs.The authors end the book reminding us of the benefits of admitting mistakes. There is a positive effect. For politicians, admitting a mistake results in constituents admiring the person is big enough to admit wrong and desire to learn from mistakes.This is an interesting book that is very informative and easy to read. I really found it enlightening in explaining much of the rhetoric we hear today."
176,0151010986,http://goodreads.com/user/show/28157679-susan-s-frederick,5,"Really opened my eyes to bias and lenses that are different for each of us, but have profound effect on how we see things, remember things, feel things. Fascinating."
177,0151010986,http://goodreads.com/user/show/4134989-chuck,4,"A well written exposure of dissonance avoidance, self-justification, confirmation bias and other forces that effect us all. The examples and insights here are especially helpful in understanding why ourself and others make mistakes, defend actions, and choose self-preserving narratives. A revelation into neural, natural wiring. A brave look into the mirror as well as the boundaries of tolerance we construct for others. Keen, practical eye-opening read. "
178,0151010986,http://goodreads.com/user/show/32598115-becky,5,This was an interesting look at how our minds work to dissociate with problems and errors in judgement.
179,0151010986,http://goodreads.com/user/show/2251009-esteban-del-mal,4,"Cognitive dissonance: The mental discomfort experienced by a person who holds two or more contradictory beliefs, ideas, or values. This discomfort is triggered by a situation in which a person's belief clashes with new evidence perceived by the person. When confronted with facts that contradict beliefs, ideals, and/or values, people will try to find a way to resolve the contradiction to reduce their discomfort (~squaring a circle).Cognitive bias: A systematic pattern of deviation from norm or rationality in judgment. Individuals create their own subjective social reality from their perception of the input. An individual's construction of social reality, not the objective input, may dictate his or her behavior in the social world; thus, cognitive biases may sometimes lead to perceptual distortion, inaccurate judgment, illogical interpretation, or what is broadly called irrationality. Catharsis: The psychodynamic principle of emotional release. It's a bullshit theory leftover from Freud. Self-justification: How, when a person encounters cognitive dissonance or a situation in which a person's behavior is inconsistent with his/her beliefs, that person tends to justify the behavior and deny any negative feedback associated with the behavior. Naive realism: The human tendency to believe that we see the world around us objectively and that people who disagree with us must be uninformed, irrational, or biased.Totalitaian ego: a) The ego/self is an organization of knowledge; b) ego/self is characterized by cognitive biases analogous to totalitarian information-control strategies, and; c) these totalitarian-ego biases function to preserve organization in cognitive structures.Reconstructive memory: A theory of memory recall in which the act of remembering is influenced by various other cognitive processes including perception, imagination, semantic memory, and beliefs. People view their memories as being a coherent and truthful account of episodic memory and believe their perspective is free from error during recall; however, the reconstructive process of memory recall is subject to distortion by other intervening cognitive functions such as individual perceptions, social influences, and world knowledge, all of which can lead to errors during reconstruction. [REPRESSED MEMORIES DO NOT EXIST]Source confusion: An attribute seen in different people's accounts of the same event after hearing people speak about the situation (for example, a witness who heard a police officer say someone had a gun who then states he/she saw the gun).Anomie: A condition in which society provides little moral guidance to individuals. This state evolves from conflict of belief systems and causes a breakdown of social bonds between an individual and the community. In a person, this condition can progress into a dysfunctional ability to integrate within the normative situations of his/her social world (for example, an unruly personal scenario that results in fragmentation of social identity and rejection of values). The term is commonly understood to mean normlessness.Imagination inflation: The finding that imagining an event which never happened can increase confidence that it actually occurred.Confidence-accuracy relationship: As one's confidence increases, so does one's level of accuracy (or belief therein).Benevolent dolphin problem: Every once in a while, a news story appears about a shipwrecked sailor who, on the verge of drowning, is nudged to safety by a dolphin. It is tempting to conclude that dolphins must really like human beings, enough to save us from drowning. But wait—are dolphins aware that humans don’t swim as well as they do? Are they actually intending to be helpful? To answer that question, we would need to know how many shipwrecked sailors have been gently nudged further out to sea by dolphins, there to drown and never be heard from again. We don’t know about those cases because the swimmers don’t live to tell us about their evil-dolphin experiences. If we had that information, we might conclude that dolphins are neither benevolent nor evil; they are just being playful.Effort justification: A person's tendency to attribute a value to an outcome which he/she had to put effort into achieving which is greater than the objective value of the outcome (i.e., the more effort put into something, the more it is valued).Implicit personality theory: The specific patterns and biases an individual uses when forming impressions based on a limited amount of initial information about an individual or situation."
180,0151010986,http://goodreads.com/user/show/11966043-lia,5,"4.5 starsI think this is one of the best non-fiction books I've ever read. It is so fascinating and it is so well-written. I've learned so much, about others and about myself. I honestly think that reading this book makes you a better person. I couldn't recommend it more."
181,0151010986,http://goodreads.com/user/show/23790728-amani,5,This was a very interesting and informative read. 
182,0151010986,http://goodreads.com/user/show/522647-kathy,4,"I'm so depressed. Humans, grrr. If you've ever wondered why people won't admit mistakes even in the face of verifiable truth contradicting their actions or beliefs, this book explains why. With sections on cognitive dissonance, why we think we're above outside influence, memory (yes, we make up our own ""memories""), scientific research fallacies, law enforcement/prosecution proceedings and relationship killers the gamut is pretty much covered. And, it's depressing. Did I mention that already? Well, it bears mentioning twice. We humans are geared to stick to our figurative guns no matter what. I have no hope for our current political unrest in the USA to get better any time soon. Sigh."
183,0151010986,http://goodreads.com/user/show/64733542-nafisa,5,"""A nation's character, and an individual's integrity, do not depend on being error-free. It depends on what we do after making an error.""Once in a while, I come across a book that makes me question my self-concept; this book is one of them. Broadly, it is about cognitive dissonance -- the psychological stress we face when our actions contradict our beliefs and ideals. Since we don't like to think of ourselves as incompetent or ill-intentioned, our natural tendency is to convince ourselves that we did the right thing. Mindless self-justification in the face of cognitive dissonance can have far-reaching (and often devastating) consequences, and the authors do a commendable job of documenting such examples from numerous distinct domains ranging from the criminal justice system, politics, medicine, and even marriage and relationships. A fresh set of ideas, quite compelling, and sometimes challenging to read as they force you to constantly self-reflect. I highly recommend it to anyone with an interest in psychology. The book is not intended to be self-help but offers a lot of scope for personal growth."
184,0151010986,http://goodreads.com/user/show/3669193-mah-ebr,5,i think everyone should read this one! 
185,0151010986,http://goodreads.com/user/show/901342-jacob,4,"This covers ground related to Evil Genes: Why Rome Fell, Hitler Rose, Enron Failed, and My Sister Stole My Mother's Boyfriend and The Honest Truth About Dishonesty: How We Lie to Everyone--Especially Ourselves, but it's specifically about self-justification. It's attempting to answer the question ""Why do people self-justify obvious mistakes?"" and look at the impact of doing so. It's pretty straightforward and quite readable.Self-justification is a useful and even essential way for humans to protect their ego and mental health, but it can get pretty out of whack. Self-justification is not only sad when it helps us decide to do things we shouldn't, it's extra sad when people do things they shouldn't only because they are trying to support an existing self-justification for a previous bad decision. One of the elaborated examples is when innocent people go to jail: it's bad enough when police and attorneys justify acting unethically in order to convict someone they ""know"" is guilty. Where it becomes absolutely unconscionable is where they work hard to prevent people from being proven innocent after the fact so they don't have to admit screwing up.On a lighter note, with books about human fallibility you have to chuckle when the authors display the very fallibility they're decrying. In one case, they claim to be certain about someone's motivation for making poor remarks without allowing for those remarks to be caused by that person looking for any excuse to self-justify behavior. In another case, they berate therapists for not thinking scientifically and not examining the disconfirming cases, then talk about the Gottmans' work on predicting divorce without examining the disconfirming cases (where the Gottmans predicted divorce and were wrong). They mention a case where of 10 of 47 couples were predicted to divorce, all 7 who did divorce were predicted ones. Of the remaining 40, all they say is that the 90% accuracy is impressive. But they don't address that 30% of the predicted divorces didn't happen, which pokes a hole in their nice theory about self-justification causing divorce. That wouldn't be a problem if they hadn't already spent a chapter bagging on therapists for having pet theories without looking at evidence that would contradict the theory.One of the reasons you chuckle over those kinds of mistakes instead of criticizing is because we ALL do those things. I'm not immune from doing those very same things, and neither is anyone else. But we might become less that way if we are aware of the phenomenon and try to identify when we are justifying ourselves."
186,0151010986,http://goodreads.com/user/show/7399266-camie,4,"I should start by saying I find social psychology fascinating! This book is about cognitive dissonance , which basically means having two conflicting beliefs and the measures we will resort to in order to defend and justify our beliefs , decisions, and actions. Backed by much research, this very insightful book explains how we all are capable of self deception, why we do it, why it is harmful, and how to overcome the very human mechanism of justifying our foolish beliefs, improper actions, poor decisions, and hurtful acts, and more importantly how to keep small things from escalating to disastrous proportions. Looking at everything from political situations, criminal acts, war, marriage, and personal levels it offers answers to how impossible atrocities come about , one justification at a time. ""How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self justification will do the rest."" From the politician who can't publically admit his actions, the torturer who feels no guilt, to the person who will say anything to win an argument, this book explains why it is so easy to see the hypocrisy of others while being totally blind to our own. Co-written by Elliot Aronson, author of The Social Animal , a great textbook, this is a very readable informative book. The introduction is called Knaves, Fools, Villains, and Hypocrites: How Do They Live With Themselves.... lol how do we ?? 4 stars"
187,0151010986,http://goodreads.com/user/show/51519663-diana-nahirna,5,"Well, that explains a lot of my recent purchases, Iraq, and why marriages fail. "
188,0151010986,http://goodreads.com/user/show/1974052-milan,5,"Mistakes Were Made (But Not by Me) is quite an enlightening book by Carol Tavris and Elliot Aronson. The authors examine our deep-rooted tendencies to underplay our faults and errors and to exaggerate the mistakes of others, especially when they go against us. ""Cognitive dissonance occurs when a person holds two or more contradictory beliefs, ideas, or values, or participates in an action that goes against one of these three, and experiences psychological stress because of that."" Two lessons from this theory: “First, the ability to reduce dissonance helps us in countless ways, preserving our beliefs, confidence, decisions, self-esteem, and well-being. Second, this ability can get us into big trouble.”The self-justification mechanisms like cognitive dissonance, confirmation bias, and fabricated memory play such an important role in our lives that they are hard to ignore. The authors provide very vivid examples from politics, therapy, conflict, wars, marriage, police and court procedures to show how these biases work. A few important lessons: •	 “Most human beings and institutions are going to do everything in their power to reduce dissonance in ways that are favorable to them, that allow them to justify their mistakes and maintain business as usual.” •	“Most people, when directly confronted by evidence that they are wrong, do not change their point of view or course of action but justify it even more tenaciously. Even irrefutable evidence is rarely enough to pierce the mental armor of self-justification.”•	Our ‘mistake-phobic’ culture causes people not to learn from their mistakes.•	Naive realism: the believe that everyone else sees the world as we do•	We all self-justify as a way to protect against cognitive dissonance, whether positively or negatively.•	Memories are easily modified to fit a narrative to reduce cognitive dissonance.•	We must be careful to not allow memory distortion to justify previous decisions.•	Therapists should be very concerned about confirmation bias, their expert assessments and also in their evaluations of people.•	Confessions can be elicited from accused legally by using deceit, trickery, etc.•	Successful couples will give the benefit of the doubt to their partners, just as they would to themselves. Unsuccessful couples do the opposite.•	We must strive to take self-justification into account in our lives and relationships to prevent incorrect decisions making.Two things to keep in mind – our personal life will suffer if we don’t admit our mistakes and society will work better if people admitted when they’re wrong."
189,0151010986,http://goodreads.com/user/show/28602450-vladyslav-sitalo,4,"You think about yourself as a reasonably nice person, with not perfect but good enough memory. Maybe you've done some things in your life, that you don't particularly like, but you think that in most cases, given the situation you were in, most of the people would've done the same.So you ain't perfect but better than the most, right?Well, this book would get you to at least question, how accurate is the description above. And it will also tell you how come you (and most of the people, even most morally flawed, from your perspective, people) think of themselves in this way.The book will tell you how your mind is desperately trying to maintain the self-image, you have about yourself and protect beliefs your hold. How it change your perceptions of things around you to fit this image/beliefs. And here comes more fun: it also employs your memory to justify your current self-perception/beliefs. So your memory is gradually, with each recall, become more compliant with this image. And eventually, all you left with is the nice, coherent story of your life that corresponds to your current view of yourself and your beliefs. But this story often has little or nothing to do with reality.As authors call it: Memory is your self-justifying historian (I would also highly recommend a novelette by Ted Chiang - ""The Truth of Fact, the Truth of Feeling"" as an exploration of this aspect of our memory: https://www.goodreads.com/book/show/1...).And the thing is that this process influences pretty much every aspect of your life regardless of your age/education or other things, you might think would influence the situation.So the process kicks in:When you're a nice, kind boy, who find himself in a company that is bullying a weaker guy. You don't particularly like the process but, as you want to be a part of this social group - you continue to participate in it. But there is dissonance here: how come you, as a nice, kind boy become a bully? So here the self-justification comes to your help: ""It's totally the guy's responsibility that he got bullied. Let's modify our image of the guy to leave our self-image preserved and justify what've done. Yay! And hey we're justified to continue to bully him as he is such a ....""Or let's say you're a student who don't have any strong position on cheating. You know it's generally considered a ""bad thing"" but you don't have any personal conviction either way. You haven't done it earlier because you didn't need to. But now you're in the situation when you need either cheat or fail this particular course. So situation can go in two ways from here:World 1: You've decided to cheat. ""Self-justification process: Ok we've cheated, as we know we're a generally good person, so we could not have possibly done a bad thing, so we may conclude that cheating is not a big deal"".World 2: You've decided not to cheat. ""Self-justification process: Ok we've failed the course. That's unfortunate but, well we didn't have any other option, right? We wouldn't even consider doing such a terrible thing as cheating"".Or you're a detective and you've interrogated your suspect to the point that he have given you a confession. But here comes the strong evidence (like DNA test or videotape) that he is innocent. So here it goes: ""I'm an honest infallible detective and my interrogation methods are great, and, after all, the guy has given confession after only 36 consecutive hours of interrogation. The evidence must be wrong""And let's upgrade a bit more. You're an honest politician, who is right now flying with a lobbyist on a luxury private plane to spend a nice weekend in some luxury resort. ""As we're an honest, good man, this situation can't possibly influence our political judgment in any way, right?"" (To understand how you got in this situation in a first place and for a lot of other good examples - read the book ;)The more deeply held self-belief that is contradicting to what you did the more actively you would justify the deed as the kind of deed that don't contradict this self-belief.You probably think to yourself: ""Ok maybe some of the cases described in this book can be true about me, but in most of them I would not have employed this level of self-justification""Well, the problem is that self-justification is largely unconscious process so when you do something that don't correspond to your self-image or see information that contradicts your belief - the justification process kicks in automatically in the background.So usually, you don't even notice on the conscious level that you've maybe done something wrong or that you hold a questionable belief. And correspondingly you don't have a chance to fix the situation before you internalize it as the normal state of things.That's why it's often said ""Hypocrite is obvious to all but himself""So you would probably at this point like to know - are we doomed? Can we do better? And the answer is yes we can! The book advises us to institute impartial external overview committees wherever possible (if necessary even against the will of involved people/institutions) because the external observer can usually notice an error much easier than somebody who have committed it. As he is not emotionally/financially/in other way invested in this decision.In the situations where setting up such an institutions is not feasible or reasonable (For example in the case of personal relationships), make sure that you and people around are aware and conscious about the magic of self-justification. You also can, to some level, train yourself to recognize the typical situations where the process may kick in and be especially careful when facing them. Also, be aware of the fact that this magic works on other people, so when you try to point out his/her error to somebody, be careful to do it in a way that will not make them self-defensive and more likely to justify this error.And don't be afraid to admit your errors, because as you relinquish wrong beliefs you become wiser, as you own up to your errors you gain more respect from people and you're less likely to make the same error in the future. Everybody makes mistakes, but you only can learn from yours, when you admit them."
190,0151010986,http://goodreads.com/user/show/21170365-amy-anderson,5,"I loved this book and found it so applicable to everyone. While we need justification to move forward in life and not second guess our every decision, we also need to be aware that justification can lead us to be blind sighted to truth. Its a fine line to walk. I could quote this whole book, but here are my favorites:""Self-justification is more powerful and dangerous than the explicit lie. It allows people to convince themselves that what they did was the best thing they could have done. In fact, come to think of it, it was the right thing."" p.4""Self-justification not only minimizes our mistakes and bad decision, it is also the reason that everyone can see a hypocrite in action except the hypocrite."" p.4""How in the world can they live with themselves? The answer is exactly the way the rest of us do."" p.9""Yet mindless self-justification, like quicksand, can draw us deeper into disaster. It blocks our ability to even see our errors, let alone correct them. It distorts reality, keeping us from getting all the information we need and assessing the issues clearly. It prolongs and widens rifts between lovers, friends, and nations. It keeps us from letting go of unhealthy habits. IT permits the guilty to avoid taking responsibility for their deeds."" p.9""I will look at any additional evidence to confirm the opinion to which I have already come."" Lord Molson p.17""These mechanisms provide a neurological basis for the observation that once our minds are made up, it is hard to change them."" p.19""People become more certain they are right about something they just did if they can't undo it."" p.22""Decades of experimental research have found exactly the opposite: that when people vent their feelings aggressively they often feel worse, pump up their blood pressure and make themselves angrier."" p.26""Aggression begets self-justification, which begets more aggression."" p.27""How do you get an honest man to lose his ethical compass? You get hi to take one step at a time, and self-justification will do the rest."" p.37""Parent blaming is a popular and convenient form of self-justification because it allows people to live less uncomfortably with their regrets and imperfections."" p.76""...current self-concepts blurred their memories, bringing their past selves into harmony with their present ones."" p.79""If a memory is a central part of your identity, a self-serving distortion is even more likely."" p.79""For those who are trying to remember something that never happened, writing analyzing dreams, and drawing pictures- techniques that are the staples of many psychotherapists- are all methods that quickly conflate imagination with reality."" p.86""Once the seed of belief was planted [they] began to search for confirming evidence."" p.90""...the story fits the needs of the experiences."" p.91"",,,experiences have internalized their new false memories and cannot now distinguish them from true ones. They have come to believe their own stories."" p.93""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives."" p.93""Successful partners extend to each other the same self-forgiving ways of thinking we extend to ourselves: They forgive each other's missteps as being due to the situation, but give each other credit for the thoughtful and loving things they do."" p.169""It may sometimes be hard to define good, but evil has its unmistakable odor: Every child knows what pain is. Therefore, each time we deliberately inflict pain on another, we know what we are doing. We are doing evil."" Amoz p.198""Would you rather admit you're wrong now or wait until someone else proves it?"" p.221""People will pursue self-destructive courses of action to protect the wisdom of their initial decisions."" p.222""They will treat people they have hurt even more harshly, because they convince themselves that their victims deserve it."" p.222""People who are insecure in their religious beliefs may feel the impulse to silence and harass those who disagree with them, because their mere existence arouses the painful dissonance of doubt."" p.222"
191,0151010986,http://goodreads.com/user/show/5301457-sergei-moska,4,"Although this book didn't actually teach me anything new in terms of theory (but did provide me with many details of practical cases), it nonetheless surprised me. First, I decided to read this book at this time because I've been a bit burned out from dense reading and wanted something useful but light. It was in fact both these things, but it was also far, far more depressing than I had expected. I expected this to be a “Ha ha, let's look at our foibles!” type of read. No, it's more of a “your identity is a joke and the world systematically does evil things. And so do you.” kind of experience. Structurally speaking, the book is very simple. The first part posits a simplified theory, and the rest of the book demonstrates the theory in action, in a few select areas of life. The theory is that we need to overcome the cognitive dissonance that emerges when our actions conflict with our self-image or beliefs. At such a moment, we are said to be at the top of a “pyramid” (a 2-dimensional triangle would be a better image), and the authors believe that whether or not we choose to justify ourselves to ourselves in such moments will lead us down one side of the pyramid or the other, with drastically different outcomes once we hit either side of the base of the pyramid. I may give up the idea that I'm such a great guy, or I can decide that the other person deserved the treatment, that it really wasn't a big deal, etc. The authors believe that whatever choice we make will cause us – in order to avoid further cognitive dissonance – to more extreme positions in order to justify our initial choice. A number of surprising findings come about as a result. For instance, the more helpless the victim, the more we will tend to denigrate him in order to justify our initial mistreatment of him. Beating up an angry drunk at a bar doesn't necessarily require much justification (“He was being threatening, and it's fine to beat up people that are threatening”), but participating in bullying usually does (“I'm a nice guy and beating him up, so it must be because he's a weenie who deserves to be humiliated. Plus he'd do it if he had the chance”.)A fun book to read, although it was too simplified for my taste in at least two ways. First, the authors' theory is *very* simple, and at times their application of the theory seems too universal. For instance, why do innocent people confess to crimes? The authors only seem to entertain the notion that it's in order to reduce cognitive dissonance: “I didn't do anything, but all the cops say that they have proof. The cops are honest and good people, so I must be the problem.” Yet at times this just seems dubious. The explanation is far more convincing when they apply it to the decision by the police to continue interrogation even in the absence of evidence. The second way that the book was too simplified for my taste is in its structure. After a very good exposition of their theory, I was hoping that the subsequent material would help develop the theory further. But what it turned out to be was “Here's a theory, and now we're going to show you the theory in X, Y, and Z.” This is a matter of taste, but I really don't like that format. What's more, I do think it hurts the authors, since it implies that the answer to the subtitle of the book is monolithic. I don't think that to be the case, and I suspect the authors don't either. In fairness, they do incidentally go through a number of additional mechanisms that are attached to the problem of cognitive dissonance, including a wonderful treatment on the foibles of memory, but it would have been really nice to make their answer more complex and complete, even at the risk of making it less parsimonious. Normally that kind of issue would be a big turn-off for me, but the book really is saved (for me) by their incredibly chilling accounts, especially in chapters 3-6. The writing is very clear and engaging, and the book is also thoroughly annotated, all of which makes me fall a little bit in love with the authors."
192,0151010986,http://goodreads.com/user/show/1677868-steven-peterson,4,"This is a well written, snappy book that addresses an important issue, best described by the book's title and subtitle: ""Mistakes Were Made (but not by me): Why we justify foolish beliefs, bad decisions, and hurtful acts."" The two authors, both well reputed psychologists, use the theory of cognitive dissonance as their starting point. Leon Festinger was one of the major theorists of this approach. The authors of this book simply define the perspective thus (page 13): ""Cognitive dissonance is a state of tension that occurs whenever a person holds two cognitions (ideas, attitudes, beliefs, opinions) that are psychologically inconsistent, such as 'Smoking is a dumb thing to do because it could kill me' and 'I smoke two packs a day.'"" How does one deal with this? By adopting one of the positions and then downgrading or rejecting the other. The end result is self-justification, self-deception, seeking out evidence to support the choice that we have made while rejecting evidence that does not fit with our choice. The brain itself shows evidence of the operation of cognitive dissonance. The example on page 19 of functional Magnetic Resonance Imaging (fMRI) and processing information about presidential candidates is telling. The end result is ""blind spots,"" in which people (page 42) ""fail to notice vital events and information that might make them question their behavior or their convictions."" As such, the authors note that cognitive dissonance makes mincemeat of such theoretical views as rational actor theory and psychoanalytic theory. One result of cognitive dissonance is what is called ""confirmation bias,"" the attending to evidence that supports our views and the rejection/suppression of evidence that does not support our views. Many examples are advanced to illustrate the case that the authors make. Issues include: moral lapses (e.g., Watergate participants), ""made up"" memories (raising serious questions about the whole idea of repressed memories), criminal justice system decisions on guilt or innocence, and so on. Much is at stake with cognitive dissonance as it operates. In the closing chapter, the authors try to indicate how understanding cognitive dissonance might help us to limit the damage that may occur as a result of its operation. Convincing? I'm not so sure, but this discussion does get one thinking about how we might address the harmful side effects of cognitive dissonance. A readable book that raises important issues. I think that more use of neuroscientific research could have strengthened this book that much more. Also, the work by cognitive psychologists like Kahneman and Tversky could have spoken to key points as well. This book might also profitably be read in tandem with another recent book on a similar subject, Cordelia Fine, ""A Mind of Its Own."" In addition, Linden's ""accidental Mind"" provides a perspective on related issues from a neuroscience viewpoint. "
193,0151010986,http://goodreads.com/user/show/9281934-louise,5,"Prior to reading this, I had only considered the theory of cognitive dissonance as it applied to holding two contrary opinions, the classic example being that of the racist with friends who are members of the race s/he denigrates. Tavris and Aronson demonstrate further applications of this theory and how destructive the behavior it spawns continues to be.The 1980's/90's day care scandals pre-dated the 24 hour cable cycle (imagine this being covered today by Fox) so it blipped in and out of my attention. I remember thinking how it didn't add up, but I wasn't really following it. Today, somewhere below my radar screen are the DNA absolved prisoners, and their continued incarceration doesn't add up either. Tavris and Aronson show how the professionals involved continued and continue to stick to their long fought for opinion, even as evidence pours in against it. As the dissonance theory predicts, the greater the commitment to the opinion the more the mind works to re-enforce it.The book is most convincing on the personal level such as the damage caused by the dynamics in divorce or accusations such as those made by those in the recovered memory therapies.While cognitive dissonance is undoubtedly operative, it is not the only culprit in the inability to admit mistakes. For commercial and public policy issues there is liability to be paid either through job loss, litigation, an election, or even everyday office politics. If the culprit is a principal player on a big stage, it could be a career ender for not only the decider, but his/her staff. It is not just the mind that keeps out contrary information, there is undoubtedly social support for the bad decision by those who also made the mistake or assisted in its execution. There are also families to consider, you admit the mistake, you could lose your job and there will be no college education for your kids. The books speaks of these barriers, but sticks to its purpose of illustrating the theory.For barriers beyond cognitive dissonance, I think of George Bush and the Iraq war. If he could bring himself to admit the mistake, he would face huge institutional and social acrimony from the policy makers who assisted him, the party who supported him, the military as an institution and the families who lost their loved ones. Ultimate decision makers on the Iraq War will wait, like Robert McNamara did, until the mistake is universally recognized.This is an excellent book. The authors develop their theory for the lay person with good examples from both everyday life and the world of public policy. I highly recommend it. "
194,0151010986,http://goodreads.com/user/show/2414293-adelle,3,"The authors' political biases came through as they used the beginning and the ending of the book to castigate then (2007) President George W. Bush, and to call Newt Gingrich a “hypocrite” for criticizing (now former) President Bill Clinton’s sexual affair…WITHOUT any allusion to Clinton’s defensive “I did not have sex with that woman…Miss Lewinski” statement. But most of the center sections of the book--which thankfully were relatively free of politics--- I found endlessly fascinating. Oh, how tenaciously we cling to “our version” of the story, filtering the facts so that what WE did/or didn’t do is seen to be of negligible consequence or perhaps even honorable, and what THE OTHER GUY did/or didn’t do is seen to be righteously reprehensible, obviously beyond the pale. I loved, too, the authors’ many demonstrations that the act that alienates one party or the other is not a stand-alone event. To reference Aesop, it is much more likely to be the straw that broke the camel’s back. Hurts and grievances in both parties have probably been building for some time. “Who were the victims? It depends on how many years, decades, and centuries you take into account” (206). Consider Kosovo. Consider the Crusades. As the authors describe these tragic events, IF one is not emotionally involved with one side or the other, one can see BOTH points of view. Likewise in personal relationships. “Of all the stories that people construct to justify their lives, loves, and losses, the ones they weave to account for being the instigator or the recipient of injustice or harm are the most compelling and have the most far-reaching consequences” (191). Tavris and Aronson continue, “We have all done something that made others angry at us, and we have all been spurred to anger by what others have done to us. We all have, intentionally or unintentionally, hurt another person who will forever regard us as the villain, the betrayer, the scoundrel. And we have all … [been:] on the receiving end” (191). It would seem it is seldom the absolute fault of “the other guy.” But…that would mean…and humans on the whole have SUCH a vested interest in protecting their own self-image.A interesting, engaging read."
195,0151010986,http://goodreads.com/user/show/25763919-mimi,4," This is phenomenal! .......it made me love Psychology even more.This book has a protagonist , well ,i think it's more of an antagonist (to us) named : cognitive dissonance (i am so in love with this character hhhhh) ""Mistakes Were Made But Not By Me"" discusses all SORTS of lengths human being may go in order to reduce cognitive dissonance.Acting in contradiction to what u believe (cognitive dissonance) is 'painful' 'uncomfortable' so what we do? the remedy is employed extensively by all yet little know about it : it's self justification.How it works: you hate cheating (this is your belief), it happened and you cheated once voluntarily (contradicting behavior) ====== results is cognitive dissonance ( your self image is shaken ,because your belief about 'cheating' has being shaken)Huh! now comes the remedy time : cheating isn't that bad. the exam was unfairly difficult that's why i cheated these are some of the thoughts we may have once we start justifying our actions (cheating) to reduce cognitive dissonance.OK , now let me introduce you other cognitive biases that leads u to screwing up immensely:Confirmation bias : this dude screws rational healthy discussions... for it blinds you for one side of an argument completely. You believe in one side, you keep looking for info to prove it without EVER checking the arguments and evidence the opposite view might present ( this is what makes some peoples' craniums rock-hard , never allowing the penetration of any of your ideas or arguments ) Snap decisions/judgements : this guys are super bad , if you could just turn them off when you are presented with anything which needs you opinion ....when you take a snap decision you are done for , it becomes harder to see the other angles of a person , an idea ...unless you knew how dangerous these guys are for your objectivity and try harder to make a balanced judgment. Sadly humans are hardwired with many biases that makes them fallible creatures....and without knowing them they will be extra fallible."
196,0151010986,http://goodreads.com/user/show/17485839-zena-ryder,4,"If you don't know what cognitive dissonance is, this is a great introduction. If you do know what it is, this is an easy, enjoyable read, with interesting stories and experiments that illustrate dissonance and the resulting self-justification, which will likely deepen your understanding of this all too human phenomenon. The authors also talk about the fascinating and related phenomenon of false memories — our memories tend to get distorted (or even created!) to be self-serving. I found the section on how easily children can be persuaded to have memories of things that didn't really happen both fascinating and disturbing. The authors also talk about the how police officers' confirmation bias and the need to avoid dissonance by those involved at the various stages of the justice system can and does lead to terrible miscarriages of justice.I guess the biggest thing that was missing, for me, was more detail of when we don't give in to self-justification in order to avoid dissonance. The authors do talk about this, but I would have liked more detail. I would also like more detail on people with low self esteem, who don't tend to resolve their dissonance in self-serving ways, but rather in ways that fit their self image of being incompetent, unlovable etc.While knowing about cognitive biases and flaws isn't enough to make them magically go away, the authors suggest that being aware of them should make us less confident in our own convictions and memories, especially when they are self-serving. I think that is an important lesson for anyone."
197,0151010986,http://goodreads.com/user/show/4532156-alaa-a,5,"This year I started to be more interested in social psychology books in my hope to change my default sitting to the world and understand it better, and what better way than saying I was wrong to your self and owning the mistakes to your self...Its a very challenging book to read its started to with an eases of pointing the mistakes of politics and countries and introducing the conformation biases then going to personal stories that we are confined that happened when all evidenced are against.One of the psychological insights that has been messing around with my mind is the selective memory and that even if you feel strongly sure and emotionally attached to it can be wrong or even planted made me question my memories and if I am a hypocrite the explanation for people's unwillingness to admit mistakes, even to themselves, in a variety of realms. This far-reaching BOOK tackles irrational prejudices, false memories, misjudgement as a psychotherapist, prosecuting the wrong individual, blaming one's spousethe part of repressed memory therapy of rape victimise was eye opening for me as how easy for as to follow :Cognitive dissonanceConfirmation biasI read in the book ""thinking fast and slow "" that knowing this biases dose not stop you form doing it even for the experts in this felid but it can make you stop your self and question why you think or act this way, and that is about it what you can do!! "
198,0151010986,http://goodreads.com/user/show/5856337-mark,5,"Having been put off by several popular books by social psychologists I read in recent years which I felt failed to deliver on the promised goods (""Emotional Intelligence"" and ""Social Intelligence,"" both by Daniel Goldman come quickly to mind), I was both relieved and impressed as I listened to the audiobook version of ""Mistakes Were Made.""The authors not only convincingly support and develop their thesis from start to finish, they do so in an entertaining fashion. Furthermore, the book offers plenty of opportunity for practical application for any casual reader who dares to pause to consider how his or her own pride, cognitive dissonance, confirmation biases, etc. may cause him/her to re-write history, justify themselves and their experiences, blind themselves from seeing the truth, etc. I will mention one area where the authors may possibly be a little ""off."" Toward the end of the book, they share an example of Japanese encouraging mistakes in the classroom and seem to generalize this example for Asian culture. However, across mainland China, Japan, Taiwan, and Korea, societies seems to be somewhat intolerant of mistakes. Having said all that, this is still a great book. Read it!"
199,0151010986,http://goodreads.com/user/show/2050800-kathy,1,"Although the authors have some good points about self-justification in a few sections of the book, they clearly spend way too much time on the ""problem"" and their political biases than a plausible solution to overcoming self-justification. I read the last page of the book in complete disgust as to the topic they chose to end with and completely irritated that very few solutions were offered to help minimize self-justification in ourselves as well as others. I guess I should have read the title a little closer: It states ""Why we..."" and not ""How to overcome why we..."" Also found it very fitting based on the severe bias that shone through the entire book that there was not one mention of the infamous ""I did not have sexual relations with that woman"" by Bill Clinton. Now that's a perfect example of self-justification if I've ever seen one!There is nothing more irritating to me than reading 200 pages about a problem and then getting to the end and realizing the author offered no real solutions but a ton of biased opinions. What a waste!"
200,0151010986,http://goodreads.com/user/show/1347209-jacob,5,"As much as I read, there are few books that are enlightening, educational, and entertaining enough for me to rate them so highly. This is one of those books that every time you put it down you have to run and find someone to tell what you just read. You find the content so interesting that you can't help but share it with others.The authors do a great job at explaining cognitive dissonance and how it leads to self-justification. They also apply the concepts well by focusing a chapter on a specific realm of how this impacts our world (legal interrogation, false memory recovery, etc).If you have ever read ""Leadership and Self Deception"" I think you would enjoy this book also. More of the science behind the story.Read this and then apply the information in your life. It is blessing me and those around me and I'm sure it will you."
201,0151010986,http://goodreads.com/user/show/1984886-tim-kadlec,3,"The book was full of good information, and good discussions around cognitive dissonance. It's fault, however, was that the anecdotes tended to be very politically charged, and very biased.Unfortunately, the authors bias came through very strongly in several of the examples used, and this distracts from the points the authors are attempting to make. In addition, a few of the examples felt like they didn't really fit in with the subject matter, and were instead used to continue to justify the authors biases (ironic I know)."
202,0151010986,http://goodreads.com/user/show/26434622-sophiacoming,5,"One of my favorite books! make me more aware of my silly impulses. I think understanding these limitation is the basis for having a crucial conversation, and making peace with yourself and people around you."
203,0151010986,http://goodreads.com/user/show/58909202-edu,2,"The concept is very interesting, even necessary to know, and mindblowing, wich I liked a lot. But there were many many examples and much of them from USA politics, which I don't care so much about. "
204,0151010986,http://goodreads.com/user/show/8778400-rebekka-steg,5,"This week I've been reading Mistakes Were Made (But Not by Me): Why We Justify Foolish Beliefs, Bad Decisions, and Hurtful Acts by Carol Tavris and Elliot Aronson, an absolutely amazing book, which everyone should be acquired to read.The book deals with the issue of self-justification, and the role it plays in all of our lives, from such ""minor"" issues as arguments within a relationship, to bullying, prejudicialness, torture, fraud etc.Written by two psychologist, the book is backed by research as well as real life cases and examples. It's easy to read, incredibly thought-provoking and it deals with such an important topic, which affects us all.

 Quotes ""We are all capable of believing things which we know to be untrue, and then, when we are finally proved wrong, impudently twisting the facts so as to show that we were right. Intellectually, it is possible to carry on this process for an indefinite time: the only check on it is that sooner or later a false belief bumps up against solid reality, usually on a battlefield.""- George Orwell (1946)""For example, Elliot predicted that if people go through a great deal of pain, discomfort, effort, or embarrassment to get something, they will be happier with that ""something"" than if it came to them easily. For behaviorists this was a preposterous prediction. Why would people like anything associated with pain? But for Elliot, the answer was obvious: self-justification. The cognition that I am a sensible, competent person is dissonant with the cognition that I went through a painful procedure to achieve something - say, joining a group that turned out to be boring and worthless. Therefore, I would distort my perceptions of the group in a positive direction, trying to find good things about them and ignoring the downside.""""Venting is especially likely to backfire if a person commits an aggressive act against another person directly, which is exactly what cognitive dissonance theory would predict. When you do anything that harms someone else - get them in trouble, verbally abuse them or punch them out - a powerful new factor comes into play: the need to justify what you did. Take a boy who goes along with a group of his fellow seventh graders who are taunting and bullying a weaker kid who did them no harm. The boy likes being part of the gang but his heart really isn't in the bullying. Later, he feels some dissonance about what he did. ""How can a decent kid like me,"" he wonders, ""have done such a cruel thing to a nice, innocent little kid like him?"" To reduce dissonance, he will try to convince himself that the victim is neither nice nor innocent: ""He is such a nerd and cry-baby. Besides, he would have done the same to me if he had the chance."" Once the boy starts down the path of blaming the victim, he becomes more likely to beat up on the victim with even greater ferocity the next chance he gets. Justifying his first hurtful act sets the stage for more aggression. That's why the catharsis hypothesis is wrong.""""Our convictions about who we are carry us through the day, and we are constantly interpreting the things that happen to us through the filter of those core beliefs. When they are violated, even by a good experience, it causes us discomfort. An appreciation of the power of self-justification helps us understand, therefore, why people who have low self-esteem, or who simply believe that they are incompetent in some domain, are not totally overjoyed when they do something well; why, on the contrary, they often feel like frauds. If the woman who believes she is unlovable meets a terrified guy who starts pursuing her seriously, she will feel momentarily pleased, but that pleasure is likely to be tarnished by a rush of dissonance: ""What does he see in me?"" Her resolution is unlikely to be ""How nice; I must be more appealing than I thought I was."" More likely, it will be ""As soon as he discovers the real me, he'll dump me."" She will pay a high psychological price to have that consonance restored.""""The Milgram experiment shows us how ordinary people can end up doing immoral and harmful things through a chain reaction of behavior and subsequent self-justification. When we, as observers, look at them in puzzlement or dismay, we fail to realize that we are often looking at the end of a long, slow process down that pyramid. At his sentencing, Magruder said to Judge John Sirica: ""I know what I have done, and Your Honor knows what I have done. Somewhere between my ambition and my ideals, I lost my ethical compass."" How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self-justification will do the rest.""""The brain is designed with blind spots, optical and psychological, and one of its cleverest tricks is to confer on us the comforting delusion that we, personally, do not have any. In a sense, dissonance theory is a theory of blind spots - of how and why people unintentionally blind themselves so that they fail to notice vital events and information that might make them question their behavior or their convictions. Along with the confirmation bias, the brain comes packaged with other self-serving habits that allow us to justify our own perceptions and beliefs as being accurate, realistic, and unbiased. Social psychologist Lee Ross calls this phenomenon ""naïve realism,"" the inescapable conviction that we perceive objects and events clearly, ""as they really are."" We assume that other reasonable people see things the same way we do. If they disagree with us, they obviously aren't seeing clearly. Naïve realism creates a logical labyrinth because it presupposes two things. One, people who are open-minded and fair ought to agree with a reasonable opinion. And two, any opinion I hold must be reasonable; if it weren't, I wouldn't hold it. Therefore, if I can just get my opponents to sit down here and listen to me, so I can tell them how things really are, they will agree with me. And if they don't, it must be because they are biased.""""As fallible human beings, all of us share the impulse to justify ourselves and avoid taking responsibility for any actions that turn out to be harmful, immoral, or stupid. ... Most people when directly confronted with proof that they are wrong, do not change their point of view or course of action but justify it even more tenaciously.""""Just as we can identify hypocrisy in everyone but ourselves, just as it's obvious that others can be influenced by money but not ourselves, so we can see prejudices in everyone else but ourselves. Thanks to our ego-preserving blind spots, we cannot possibly have a prejudice, which is an irrational or mean-spirited feeling about all members of another group. Because are are not irrational or mean-spirited, any negative feelings we have about another group are justified; our dislikes are rational and well founded. It's theirs we need to suppress. Like the Hasids pounding on the Unprejudiced door at the Museum of Tolerance, we are blind to our own prejudices.""""When two people produce entirely different memories of the same event, observers usually assume that one of them is lying. Of course, some people do invent or embellish stories to manipulate or deceive their audiences, as James Frey notably did with his bestseller A Million Little Pieces. But most of us, most of the time, are neither telling the whole truth nor intentionally deceiving. We aren't lying; we are self-justifying. All of us, as we tell our stories, add details and omit inconvenient facts; we give the tale a small, self-enhancing spin; that spin goes over so well that the next time we add a slightly more dramatic embellishment; we justify that little white lie as making the story better and clearer - until what we remember may not have happened that way, or even may not have happened at all.""""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives. An appreciation of the distortions of memory, a realization that even deeply  felt memories might be wrong, might encourage people to hold their memories more lightly, to drop the certainty that their memories are always accurate, and to let go of the appealing impulse to use the past to justify problems of the present. If we are to be careful about what we wish for because it might come true, we must also be careful which memories we select to justify our lives, because than we will have to live by them.""""For any theory to be scientific, it must be stated in such a way that it can be shown to be false as well as true. If every outcome confirms your hypotheses that all men unconsciously suffer from castration anxiety; or that intelligent design, rather than evolution, accounts for the diversity of species; or that your favourite psychic would accurately have predicted 9/11 if only she hadn't been taking a shower that morning; or that all dolphins are kind to humans, your beliefs are a matter of faith, not science.""""Our implicit theories of why we and other people behave as we do come in one of two versions. We can say it's because of something in the situation or environment: ""The bank teller snapped at me because she is overworked today; there aren't enough tellers to handle these lines."" Or we can say it's because something is wrong with the person: ""That teller snapped at me because she is plain rude."" When we explain our own behavior, self-justification allows us to flatter ourselves: We give ourselves credit for our good actions but let the situation excuse the bad ones. When we do something that hurts another, for example, we rarely say, ""I behaved this way because I am a cruel and heartless human being."" We say, ""I was provoked; anyone would do what I did""; or ""I had no choice""; or ""Yes, I said some awful things, but that wasn't me - it's because I was drunk."" Yet when we do something generous, helpful, or brave, we don't say we did it because we were provoked or drunk or had no choice, or because the guy on the phone guilt-induced us into donating to charity. We did it because we are generous and open-hearted.""""Did Charles Graner and Lynndie England know what they were doing, let alone believe they were ""doing evil"" while they were deliberately inflicting pain and humiliation on their Iraqi prisoners and then laughing at them? No, they didn't, and that is why Amos Oz is wrong. Oz didn't reckon with the power of self-justification: We are good people. Therefore, if we deliberately inflict pain on another, the other must have deserved it. Therefore, we are not doing evil, quite the contrary. We are doing good. The relatively small percentage of people who cannot or will not reduce dissonance this way pay a large psychological price in guilt, anguish, anxiety, nightmares, and sleepless nights. The pain of living with horrors they have committed, but cannot morally accept, would be searing, which is why most people will reach for any justification available to assuage the dissonance. In the previous chapter, we saw on a smaller scale why many divorcing couples justify the hurt they inflict on each other. In the horrifying calculus of self-deception, the greater the pain we inflict on others, the greater the need to justify it to maintain our feelings of decency and self-worth. Because our victims deserved what they got, we hate them even more than we did before we harmed them, which in turn makes us inflict even more pain on them.""""But what are we supposed to do in our everyday lives? Call an external review board of cousins and in-laws to adjudicate every family quarrel? Videotape all parental interrogations of their teenagers? In our private relationships, we are on our own, and that calls for some self-awareness. Once we understand how and when we need to reduce dissonance, we can become more vigilant about the process and often nip it in the bud; like Oprah, we can catch ourselves before we slide too far down the pyramid. By looking at our actions critically and dispassionately, as if we were observing someone else, we stand a chance of bring out of the cycle of action followed by self-justification, followed by more committed action. We can learn to put a little space between what we feel and how we respond, insert a moment of reflection, and think about whether we really want to buy that canoe in January, really want to send good money after bad, really want to hold on to a belief that is unfettered by facts. We might even change our minds before our brains freeze our thoughts into consistent patterns.""""Humbling yes, but ultimately that's the point. Understanding how the mind yearns for consonance, and rejects information that questions our beliefs, decisions, or preferences, teaches us to be open to the possibility of error. It also helps us let go of the need to be right. Confidence is a fine and useful quality; none of us would want a physician who was forever wallowing in uncertainty and couldn't decide how to treat our illness, but we do want one who is open-minded and willing to learn. Nor would most of us wish to live without passions or convictions, which give our lives meaning and color, energy and hope. When confidence and convictions are unleavened by humility, by an acceptance of fallibility, people can easily cross the line from healthy self-assurance to arrogance. In this book, we have met many who crossed that line: the psychiatrists who are certain that they can tell if a recovered memory is valid; the physicians and judges who are certain that they are above conflicts of interest; the police officers who are certain that they can tell if a suspect is lying; the prosecutors who are certain that they convicted the guilty party; the husbands and wives who are certain that their interpretation of events is the right one; the nations who are certain that their version of history is the only one.""""Most Americans know they are supposed to say ""we learn from our mistakes,"" but deep down, they don't believe it for a minute. They think that mistakes mean you are stupid. Combined with the culture's famous amnesia for anything that happened more than a month ago, this attitude means that people treat mistakes like hot potatoes, eager to get rid of them as fast as possible, even if they have to toss them in someone else's lap."""
205,0151010986,http://goodreads.com/user/show/8435102-joan,3,"Why is it so hard for us to admit we have made a mistake? Why do we justify our actions? Why is it so hard to change our minds when we think we are right?The authors wrote this book with a goal of understanding those behaviors. I learned tons about why we say what we do to ourselves. Self-justification, for example. We convince ourselves we made the best choice possible. Unfortunately, that blocks us from seeing our errors and learning from them.I read about cognitive dissonance and how it changes our perception. When we see disconfirming evidence, we will criticize the source (fake news), distort or outright dismiss it. Maintaining the belief is more important than truth. And we have confirmation bias, the reason it is so hard to change our minds when we have made a firm decision. I also learned much about blind spots, how our memories change (or we change them purposely), and false memories. The authors give many examples of interrogators (such as child psychologists) manipulating people to confess to crimes or report non-existing events. They give examples of law enforcement officials and prosecutors refusing to admit mistakes even when DNA evidence finally proves them wrong.Rounding out this informative book are thoughts on the price paid for for justifying decisions that cause pain to others. For example, international acts are justified by saying our deeds were bad but not nearly as bad as theirs.The authors end the book reminding us of the benefits of admitting mistakes. There is a positive effect. For politicians, admitting a mistake results in constituents admiring the person is big enough to admit wrong and desire to learn from mistakes.This is an interesting book that is very informative and easy to read. I really found it enlightening in explaining much of the rhetoric we hear today."
206,0151010986,http://goodreads.com/user/show/28157679-susan-s-frederick,5,"Really opened my eyes to bias and lenses that are different for each of us, but have profound effect on how we see things, remember things, feel things. Fascinating."
207,0151010986,http://goodreads.com/user/show/4134989-chuck,4,"A well written exposure of dissonance avoidance, self-justification, confirmation bias and other forces that effect us all. The examples and insights here are especially helpful in understanding why ourself and others make mistakes, defend actions, and choose self-preserving narratives. A revelation into neural, natural wiring. A brave look into the mirror as well as the boundaries of tolerance we construct for others. Keen, practical eye-opening read. "
208,0151010986,http://goodreads.com/user/show/32598115-becky,5,This was an interesting look at how our minds work to dissociate with problems and errors in judgement.
209,0151010986,http://goodreads.com/user/show/2251009-esteban-del-mal,4,"Cognitive dissonance: The mental discomfort experienced by a person who holds two or more contradictory beliefs, ideas, or values. This discomfort is triggered by a situation in which a person's belief clashes with new evidence perceived by the person. When confronted with facts that contradict beliefs, ideals, and/or values, people will try to find a way to resolve the contradiction to reduce their discomfort (~squaring a circle).Cognitive bias: A systematic pattern of deviation from norm or rationality in judgment. Individuals create their own subjective social reality from their perception of the input. An individual's construction of social reality, not the objective input, may dictate his or her behavior in the social world; thus, cognitive biases may sometimes lead to perceptual distortion, inaccurate judgment, illogical interpretation, or what is broadly called irrationality. Catharsis: The psychodynamic principle of emotional release. It's a bullshit theory leftover from Freud. Self-justification: How, when a person encounters cognitive dissonance or a situation in which a person's behavior is inconsistent with his/her beliefs, that person tends to justify the behavior and deny any negative feedback associated with the behavior. Naive realism: The human tendency to believe that we see the world around us objectively and that people who disagree with us must be uninformed, irrational, or biased.Totalitaian ego: a) The ego/self is an organization of knowledge; b) ego/self is characterized by cognitive biases analogous to totalitarian information-control strategies, and; c) these totalitarian-ego biases function to preserve organization in cognitive structures.Reconstructive memory: A theory of memory recall in which the act of remembering is influenced by various other cognitive processes including perception, imagination, semantic memory, and beliefs. People view their memories as being a coherent and truthful account of episodic memory and believe their perspective is free from error during recall; however, the reconstructive process of memory recall is subject to distortion by other intervening cognitive functions such as individual perceptions, social influences, and world knowledge, all of which can lead to errors during reconstruction. [REPRESSED MEMORIES DO NOT EXIST]Source confusion: An attribute seen in different people's accounts of the same event after hearing people speak about the situation (for example, a witness who heard a police officer say someone had a gun who then states he/she saw the gun).Anomie: A condition in which society provides little moral guidance to individuals. This state evolves from conflict of belief systems and causes a breakdown of social bonds between an individual and the community. In a person, this condition can progress into a dysfunctional ability to integrate within the normative situations of his/her social world (for example, an unruly personal scenario that results in fragmentation of social identity and rejection of values). The term is commonly understood to mean normlessness.Imagination inflation: The finding that imagining an event which never happened can increase confidence that it actually occurred.Confidence-accuracy relationship: As one's confidence increases, so does one's level of accuracy (or belief therein).Benevolent dolphin problem: Every once in a while, a news story appears about a shipwrecked sailor who, on the verge of drowning, is nudged to safety by a dolphin. It is tempting to conclude that dolphins must really like human beings, enough to save us from drowning. But wait—are dolphins aware that humans don’t swim as well as they do? Are they actually intending to be helpful? To answer that question, we would need to know how many shipwrecked sailors have been gently nudged further out to sea by dolphins, there to drown and never be heard from again. We don’t know about those cases because the swimmers don’t live to tell us about their evil-dolphin experiences. If we had that information, we might conclude that dolphins are neither benevolent nor evil; they are just being playful.Effort justification: A person's tendency to attribute a value to an outcome which he/she had to put effort into achieving which is greater than the objective value of the outcome (i.e., the more effort put into something, the more it is valued).Implicit personality theory: The specific patterns and biases an individual uses when forming impressions based on a limited amount of initial information about an individual or situation."
210,0151010986,http://goodreads.com/user/show/11966043-lia,5,"4.5 starsI think this is one of the best non-fiction books I've ever read. It is so fascinating and it is so well-written. I've learned so much, about others and about myself. I honestly think that reading this book makes you a better person. I couldn't recommend it more."
211,0151010986,http://goodreads.com/user/show/23790728-amani,5,This was a very interesting and informative read. 
212,0151010986,http://goodreads.com/user/show/522647-kathy,4,"I'm so depressed. Humans, grrr. If you've ever wondered why people won't admit mistakes even in the face of verifiable truth contradicting their actions or beliefs, this book explains why. With sections on cognitive dissonance, why we think we're above outside influence, memory (yes, we make up our own ""memories""), scientific research fallacies, law enforcement/prosecution proceedings and relationship killers the gamut is pretty much covered. And, it's depressing. Did I mention that already? Well, it bears mentioning twice. We humans are geared to stick to our figurative guns no matter what. I have no hope for our current political unrest in the USA to get better any time soon. Sigh."
213,0151010986,http://goodreads.com/user/show/64733542-nafisa,5,"""A nation's character, and an individual's integrity, do not depend on being error-free. It depends on what we do after making an error.""Once in a while, I come across a book that makes me question my self-concept; this book is one of them. Broadly, it is about cognitive dissonance -- the psychological stress we face when our actions contradict our beliefs and ideals. Since we don't like to think of ourselves as incompetent or ill-intentioned, our natural tendency is to convince ourselves that we did the right thing. Mindless self-justification in the face of cognitive dissonance can have far-reaching (and often devastating) consequences, and the authors do a commendable job of documenting such examples from numerous distinct domains ranging from the criminal justice system, politics, medicine, and even marriage and relationships. A fresh set of ideas, quite compelling, and sometimes challenging to read as they force you to constantly self-reflect. I highly recommend it to anyone with an interest in psychology. The book is not intended to be self-help but offers a lot of scope for personal growth."
214,0151010986,http://goodreads.com/user/show/3669193-mah-ebr,5,i think everyone should read this one! 
215,0151010986,http://goodreads.com/user/show/901342-jacob,4,"This covers ground related to Evil Genes: Why Rome Fell, Hitler Rose, Enron Failed, and My Sister Stole My Mother's Boyfriend and The Honest Truth About Dishonesty: How We Lie to Everyone--Especially Ourselves, but it's specifically about self-justification. It's attempting to answer the question ""Why do people self-justify obvious mistakes?"" and look at the impact of doing so. It's pretty straightforward and quite readable.Self-justification is a useful and even essential way for humans to protect their ego and mental health, but it can get pretty out of whack. Self-justification is not only sad when it helps us decide to do things we shouldn't, it's extra sad when people do things they shouldn't only because they are trying to support an existing self-justification for a previous bad decision. One of the elaborated examples is when innocent people go to jail: it's bad enough when police and attorneys justify acting unethically in order to convict someone they ""know"" is guilty. Where it becomes absolutely unconscionable is where they work hard to prevent people from being proven innocent after the fact so they don't have to admit screwing up.On a lighter note, with books about human fallibility you have to chuckle when the authors display the very fallibility they're decrying. In one case, they claim to be certain about someone's motivation for making poor remarks without allowing for those remarks to be caused by that person looking for any excuse to self-justify behavior. In another case, they berate therapists for not thinking scientifically and not examining the disconfirming cases, then talk about the Gottmans' work on predicting divorce without examining the disconfirming cases (where the Gottmans predicted divorce and were wrong). They mention a case where of 10 of 47 couples were predicted to divorce, all 7 who did divorce were predicted ones. Of the remaining 40, all they say is that the 90% accuracy is impressive. But they don't address that 30% of the predicted divorces didn't happen, which pokes a hole in their nice theory about self-justification causing divorce. That wouldn't be a problem if they hadn't already spent a chapter bagging on therapists for having pet theories without looking at evidence that would contradict the theory.One of the reasons you chuckle over those kinds of mistakes instead of criticizing is because we ALL do those things. I'm not immune from doing those very same things, and neither is anyone else. But we might become less that way if we are aware of the phenomenon and try to identify when we are justifying ourselves."
216,0151010986,http://goodreads.com/user/show/7399266-camie,4,"I should start by saying I find social psychology fascinating! This book is about cognitive dissonance , which basically means having two conflicting beliefs and the measures we will resort to in order to defend and justify our beliefs , decisions, and actions. Backed by much research, this very insightful book explains how we all are capable of self deception, why we do it, why it is harmful, and how to overcome the very human mechanism of justifying our foolish beliefs, improper actions, poor decisions, and hurtful acts, and more importantly how to keep small things from escalating to disastrous proportions. Looking at everything from political situations, criminal acts, war, marriage, and personal levels it offers answers to how impossible atrocities come about , one justification at a time. ""How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self justification will do the rest."" From the politician who can't publically admit his actions, the torturer who feels no guilt, to the person who will say anything to win an argument, this book explains why it is so easy to see the hypocrisy of others while being totally blind to our own. Co-written by Elliot Aronson, author of The Social Animal , a great textbook, this is a very readable informative book. The introduction is called Knaves, Fools, Villains, and Hypocrites: How Do They Live With Themselves.... lol how do we ?? 4 stars"
217,0151010986,http://goodreads.com/user/show/51519663-diana-nahirna,5,"Well, that explains a lot of my recent purchases, Iraq, and why marriages fail. "
218,0151010986,http://goodreads.com/user/show/1974052-milan,5,"Mistakes Were Made (But Not by Me) is quite an enlightening book by Carol Tavris and Elliot Aronson. The authors examine our deep-rooted tendencies to underplay our faults and errors and to exaggerate the mistakes of others, especially when they go against us. ""Cognitive dissonance occurs when a person holds two or more contradictory beliefs, ideas, or values, or participates in an action that goes against one of these three, and experiences psychological stress because of that."" Two lessons from this theory: “First, the ability to reduce dissonance helps us in countless ways, preserving our beliefs, confidence, decisions, self-esteem, and well-being. Second, this ability can get us into big trouble.”The self-justification mechanisms like cognitive dissonance, confirmation bias, and fabricated memory play such an important role in our lives that they are hard to ignore. The authors provide very vivid examples from politics, therapy, conflict, wars, marriage, police and court procedures to show how these biases work. A few important lessons: •	 “Most human beings and institutions are going to do everything in their power to reduce dissonance in ways that are favorable to them, that allow them to justify their mistakes and maintain business as usual.” •	“Most people, when directly confronted by evidence that they are wrong, do not change their point of view or course of action but justify it even more tenaciously. Even irrefutable evidence is rarely enough to pierce the mental armor of self-justification.”•	Our ‘mistake-phobic’ culture causes people not to learn from their mistakes.•	Naive realism: the believe that everyone else sees the world as we do•	We all self-justify as a way to protect against cognitive dissonance, whether positively or negatively.•	Memories are easily modified to fit a narrative to reduce cognitive dissonance.•	We must be careful to not allow memory distortion to justify previous decisions.•	Therapists should be very concerned about confirmation bias, their expert assessments and also in their evaluations of people.•	Confessions can be elicited from accused legally by using deceit, trickery, etc.•	Successful couples will give the benefit of the doubt to their partners, just as they would to themselves. Unsuccessful couples do the opposite.•	We must strive to take self-justification into account in our lives and relationships to prevent incorrect decisions making.Two things to keep in mind – our personal life will suffer if we don’t admit our mistakes and society will work better if people admitted when they’re wrong."
219,0151010986,http://goodreads.com/user/show/28602450-vladyslav-sitalo,4,"You think about yourself as a reasonably nice person, with not perfect but good enough memory. Maybe you've done some things in your life, that you don't particularly like, but you think that in most cases, given the situation you were in, most of the people would've done the same.So you ain't perfect but better than the most, right?Well, this book would get you to at least question, how accurate is the description above. And it will also tell you how come you (and most of the people, even most morally flawed, from your perspective, people) think of themselves in this way.The book will tell you how your mind is desperately trying to maintain the self-image, you have about yourself and protect beliefs your hold. How it change your perceptions of things around you to fit this image/beliefs. And here comes more fun: it also employs your memory to justify your current self-perception/beliefs. So your memory is gradually, with each recall, become more compliant with this image. And eventually, all you left with is the nice, coherent story of your life that corresponds to your current view of yourself and your beliefs. But this story often has little or nothing to do with reality.As authors call it: Memory is your self-justifying historian (I would also highly recommend a novelette by Ted Chiang - ""The Truth of Fact, the Truth of Feeling"" as an exploration of this aspect of our memory: https://www.goodreads.com/book/show/1...).And the thing is that this process influences pretty much every aspect of your life regardless of your age/education or other things, you might think would influence the situation.So the process kicks in:When you're a nice, kind boy, who find himself in a company that is bullying a weaker guy. You don't particularly like the process but, as you want to be a part of this social group - you continue to participate in it. But there is dissonance here: how come you, as a nice, kind boy become a bully? So here the self-justification comes to your help: ""It's totally the guy's responsibility that he got bullied. Let's modify our image of the guy to leave our self-image preserved and justify what've done. Yay! And hey we're justified to continue to bully him as he is such a ....""Or let's say you're a student who don't have any strong position on cheating. You know it's generally considered a ""bad thing"" but you don't have any personal conviction either way. You haven't done it earlier because you didn't need to. But now you're in the situation when you need either cheat or fail this particular course. So situation can go in two ways from here:World 1: You've decided to cheat. ""Self-justification process: Ok we've cheated, as we know we're a generally good person, so we could not have possibly done a bad thing, so we may conclude that cheating is not a big deal"".World 2: You've decided not to cheat. ""Self-justification process: Ok we've failed the course. That's unfortunate but, well we didn't have any other option, right? We wouldn't even consider doing such a terrible thing as cheating"".Or you're a detective and you've interrogated your suspect to the point that he have given you a confession. But here comes the strong evidence (like DNA test or videotape) that he is innocent. So here it goes: ""I'm an honest infallible detective and my interrogation methods are great, and, after all, the guy has given confession after only 36 consecutive hours of interrogation. The evidence must be wrong""And let's upgrade a bit more. You're an honest politician, who is right now flying with a lobbyist on a luxury private plane to spend a nice weekend in some luxury resort. ""As we're an honest, good man, this situation can't possibly influence our political judgment in any way, right?"" (To understand how you got in this situation in a first place and for a lot of other good examples - read the book ;)The more deeply held self-belief that is contradicting to what you did the more actively you would justify the deed as the kind of deed that don't contradict this self-belief.You probably think to yourself: ""Ok maybe some of the cases described in this book can be true about me, but in most of them I would not have employed this level of self-justification""Well, the problem is that self-justification is largely unconscious process so when you do something that don't correspond to your self-image or see information that contradicts your belief - the justification process kicks in automatically in the background.So usually, you don't even notice on the conscious level that you've maybe done something wrong or that you hold a questionable belief. And correspondingly you don't have a chance to fix the situation before you internalize it as the normal state of things.That's why it's often said ""Hypocrite is obvious to all but himself""So you would probably at this point like to know - are we doomed? Can we do better? And the answer is yes we can! The book advises us to institute impartial external overview committees wherever possible (if necessary even against the will of involved people/institutions) because the external observer can usually notice an error much easier than somebody who have committed it. As he is not emotionally/financially/in other way invested in this decision.In the situations where setting up such an institutions is not feasible or reasonable (For example in the case of personal relationships), make sure that you and people around are aware and conscious about the magic of self-justification. You also can, to some level, train yourself to recognize the typical situations where the process may kick in and be especially careful when facing them. Also, be aware of the fact that this magic works on other people, so when you try to point out his/her error to somebody, be careful to do it in a way that will not make them self-defensive and more likely to justify this error.And don't be afraid to admit your errors, because as you relinquish wrong beliefs you become wiser, as you own up to your errors you gain more respect from people and you're less likely to make the same error in the future. Everybody makes mistakes, but you only can learn from yours, when you admit them."
220,0151010986,http://goodreads.com/user/show/21170365-amy-anderson,5,"I loved this book and found it so applicable to everyone. While we need justification to move forward in life and not second guess our every decision, we also need to be aware that justification can lead us to be blind sighted to truth. Its a fine line to walk. I could quote this whole book, but here are my favorites:""Self-justification is more powerful and dangerous than the explicit lie. It allows people to convince themselves that what they did was the best thing they could have done. In fact, come to think of it, it was the right thing."" p.4""Self-justification not only minimizes our mistakes and bad decision, it is also the reason that everyone can see a hypocrite in action except the hypocrite."" p.4""How in the world can they live with themselves? The answer is exactly the way the rest of us do."" p.9""Yet mindless self-justification, like quicksand, can draw us deeper into disaster. It blocks our ability to even see our errors, let alone correct them. It distorts reality, keeping us from getting all the information we need and assessing the issues clearly. It prolongs and widens rifts between lovers, friends, and nations. It keeps us from letting go of unhealthy habits. IT permits the guilty to avoid taking responsibility for their deeds."" p.9""I will look at any additional evidence to confirm the opinion to which I have already come."" Lord Molson p.17""These mechanisms provide a neurological basis for the observation that once our minds are made up, it is hard to change them."" p.19""People become more certain they are right about something they just did if they can't undo it."" p.22""Decades of experimental research have found exactly the opposite: that when people vent their feelings aggressively they often feel worse, pump up their blood pressure and make themselves angrier."" p.26""Aggression begets self-justification, which begets more aggression."" p.27""How do you get an honest man to lose his ethical compass? You get hi to take one step at a time, and self-justification will do the rest."" p.37""Parent blaming is a popular and convenient form of self-justification because it allows people to live less uncomfortably with their regrets and imperfections."" p.76""...current self-concepts blurred their memories, bringing their past selves into harmony with their present ones."" p.79""If a memory is a central part of your identity, a self-serving distortion is even more likely."" p.79""For those who are trying to remember something that never happened, writing analyzing dreams, and drawing pictures- techniques that are the staples of many psychotherapists- are all methods that quickly conflate imagination with reality."" p.86""Once the seed of belief was planted [they] began to search for confirming evidence."" p.90""...the story fits the needs of the experiences."" p.91"",,,experiences have internalized their new false memories and cannot now distinguish them from true ones. They have come to believe their own stories."" p.93""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives."" p.93""Successful partners extend to each other the same self-forgiving ways of thinking we extend to ourselves: They forgive each other's missteps as being due to the situation, but give each other credit for the thoughtful and loving things they do."" p.169""It may sometimes be hard to define good, but evil has its unmistakable odor: Every child knows what pain is. Therefore, each time we deliberately inflict pain on another, we know what we are doing. We are doing evil."" Amoz p.198""Would you rather admit you're wrong now or wait until someone else proves it?"" p.221""People will pursue self-destructive courses of action to protect the wisdom of their initial decisions."" p.222""They will treat people they have hurt even more harshly, because they convince themselves that their victims deserve it."" p.222""People who are insecure in their religious beliefs may feel the impulse to silence and harass those who disagree with them, because their mere existence arouses the painful dissonance of doubt."" p.222"
221,0151010986,http://goodreads.com/user/show/5301457-sergei-moska,4,"Although this book didn't actually teach me anything new in terms of theory (but did provide me with many details of practical cases), it nonetheless surprised me. First, I decided to read this book at this time because I've been a bit burned out from dense reading and wanted something useful but light. It was in fact both these things, but it was also far, far more depressing than I had expected. I expected this to be a “Ha ha, let's look at our foibles!” type of read. No, it's more of a “your identity is a joke and the world systematically does evil things. And so do you.” kind of experience. Structurally speaking, the book is very simple. The first part posits a simplified theory, and the rest of the book demonstrates the theory in action, in a few select areas of life. The theory is that we need to overcome the cognitive dissonance that emerges when our actions conflict with our self-image or beliefs. At such a moment, we are said to be at the top of a “pyramid” (a 2-dimensional triangle would be a better image), and the authors believe that whether or not we choose to justify ourselves to ourselves in such moments will lead us down one side of the pyramid or the other, with drastically different outcomes once we hit either side of the base of the pyramid. I may give up the idea that I'm such a great guy, or I can decide that the other person deserved the treatment, that it really wasn't a big deal, etc. The authors believe that whatever choice we make will cause us – in order to avoid further cognitive dissonance – to more extreme positions in order to justify our initial choice. A number of surprising findings come about as a result. For instance, the more helpless the victim, the more we will tend to denigrate him in order to justify our initial mistreatment of him. Beating up an angry drunk at a bar doesn't necessarily require much justification (“He was being threatening, and it's fine to beat up people that are threatening”), but participating in bullying usually does (“I'm a nice guy and beating him up, so it must be because he's a weenie who deserves to be humiliated. Plus he'd do it if he had the chance”.)A fun book to read, although it was too simplified for my taste in at least two ways. First, the authors' theory is *very* simple, and at times their application of the theory seems too universal. For instance, why do innocent people confess to crimes? The authors only seem to entertain the notion that it's in order to reduce cognitive dissonance: “I didn't do anything, but all the cops say that they have proof. The cops are honest and good people, so I must be the problem.” Yet at times this just seems dubious. The explanation is far more convincing when they apply it to the decision by the police to continue interrogation even in the absence of evidence. The second way that the book was too simplified for my taste is in its structure. After a very good exposition of their theory, I was hoping that the subsequent material would help develop the theory further. But what it turned out to be was “Here's a theory, and now we're going to show you the theory in X, Y, and Z.” This is a matter of taste, but I really don't like that format. What's more, I do think it hurts the authors, since it implies that the answer to the subtitle of the book is monolithic. I don't think that to be the case, and I suspect the authors don't either. In fairness, they do incidentally go through a number of additional mechanisms that are attached to the problem of cognitive dissonance, including a wonderful treatment on the foibles of memory, but it would have been really nice to make their answer more complex and complete, even at the risk of making it less parsimonious. Normally that kind of issue would be a big turn-off for me, but the book really is saved (for me) by their incredibly chilling accounts, especially in chapters 3-6. The writing is very clear and engaging, and the book is also thoroughly annotated, all of which makes me fall a little bit in love with the authors."
222,0151010986,http://goodreads.com/user/show/1677868-steven-peterson,4,"This is a well written, snappy book that addresses an important issue, best described by the book's title and subtitle: ""Mistakes Were Made (but not by me): Why we justify foolish beliefs, bad decisions, and hurtful acts."" The two authors, both well reputed psychologists, use the theory of cognitive dissonance as their starting point. Leon Festinger was one of the major theorists of this approach. The authors of this book simply define the perspective thus (page 13): ""Cognitive dissonance is a state of tension that occurs whenever a person holds two cognitions (ideas, attitudes, beliefs, opinions) that are psychologically inconsistent, such as 'Smoking is a dumb thing to do because it could kill me' and 'I smoke two packs a day.'"" How does one deal with this? By adopting one of the positions and then downgrading or rejecting the other. The end result is self-justification, self-deception, seeking out evidence to support the choice that we have made while rejecting evidence that does not fit with our choice. The brain itself shows evidence of the operation of cognitive dissonance. The example on page 19 of functional Magnetic Resonance Imaging (fMRI) and processing information about presidential candidates is telling. The end result is ""blind spots,"" in which people (page 42) ""fail to notice vital events and information that might make them question their behavior or their convictions."" As such, the authors note that cognitive dissonance makes mincemeat of such theoretical views as rational actor theory and psychoanalytic theory. One result of cognitive dissonance is what is called ""confirmation bias,"" the attending to evidence that supports our views and the rejection/suppression of evidence that does not support our views. Many examples are advanced to illustrate the case that the authors make. Issues include: moral lapses (e.g., Watergate participants), ""made up"" memories (raising serious questions about the whole idea of repressed memories), criminal justice system decisions on guilt or innocence, and so on. Much is at stake with cognitive dissonance as it operates. In the closing chapter, the authors try to indicate how understanding cognitive dissonance might help us to limit the damage that may occur as a result of its operation. Convincing? I'm not so sure, but this discussion does get one thinking about how we might address the harmful side effects of cognitive dissonance. A readable book that raises important issues. I think that more use of neuroscientific research could have strengthened this book that much more. Also, the work by cognitive psychologists like Kahneman and Tversky could have spoken to key points as well. This book might also profitably be read in tandem with another recent book on a similar subject, Cordelia Fine, ""A Mind of Its Own."" In addition, Linden's ""accidental Mind"" provides a perspective on related issues from a neuroscience viewpoint. "
223,0151010986,http://goodreads.com/user/show/9281934-louise,5,"Prior to reading this, I had only considered the theory of cognitive dissonance as it applied to holding two contrary opinions, the classic example being that of the racist with friends who are members of the race s/he denigrates. Tavris and Aronson demonstrate further applications of this theory and how destructive the behavior it spawns continues to be.The 1980's/90's day care scandals pre-dated the 24 hour cable cycle (imagine this being covered today by Fox) so it blipped in and out of my attention. I remember thinking how it didn't add up, but I wasn't really following it. Today, somewhere below my radar screen are the DNA absolved prisoners, and their continued incarceration doesn't add up either. Tavris and Aronson show how the professionals involved continued and continue to stick to their long fought for opinion, even as evidence pours in against it. As the dissonance theory predicts, the greater the commitment to the opinion the more the mind works to re-enforce it.The book is most convincing on the personal level such as the damage caused by the dynamics in divorce or accusations such as those made by those in the recovered memory therapies.While cognitive dissonance is undoubtedly operative, it is not the only culprit in the inability to admit mistakes. For commercial and public policy issues there is liability to be paid either through job loss, litigation, an election, or even everyday office politics. If the culprit is a principal player on a big stage, it could be a career ender for not only the decider, but his/her staff. It is not just the mind that keeps out contrary information, there is undoubtedly social support for the bad decision by those who also made the mistake or assisted in its execution. There are also families to consider, you admit the mistake, you could lose your job and there will be no college education for your kids. The books speaks of these barriers, but sticks to its purpose of illustrating the theory.For barriers beyond cognitive dissonance, I think of George Bush and the Iraq war. If he could bring himself to admit the mistake, he would face huge institutional and social acrimony from the policy makers who assisted him, the party who supported him, the military as an institution and the families who lost their loved ones. Ultimate decision makers on the Iraq War will wait, like Robert McNamara did, until the mistake is universally recognized.This is an excellent book. The authors develop their theory for the lay person with good examples from both everyday life and the world of public policy. I highly recommend it. "
224,0151010986,http://goodreads.com/user/show/2414293-adelle,3,"The authors' political biases came through as they used the beginning and the ending of the book to castigate then (2007) President George W. Bush, and to call Newt Gingrich a “hypocrite” for criticizing (now former) President Bill Clinton’s sexual affair…WITHOUT any allusion to Clinton’s defensive “I did not have sex with that woman…Miss Lewinski” statement. But most of the center sections of the book--which thankfully were relatively free of politics--- I found endlessly fascinating. Oh, how tenaciously we cling to “our version” of the story, filtering the facts so that what WE did/or didn’t do is seen to be of negligible consequence or perhaps even honorable, and what THE OTHER GUY did/or didn’t do is seen to be righteously reprehensible, obviously beyond the pale. I loved, too, the authors’ many demonstrations that the act that alienates one party or the other is not a stand-alone event. To reference Aesop, it is much more likely to be the straw that broke the camel’s back. Hurts and grievances in both parties have probably been building for some time. “Who were the victims? It depends on how many years, decades, and centuries you take into account” (206). Consider Kosovo. Consider the Crusades. As the authors describe these tragic events, IF one is not emotionally involved with one side or the other, one can see BOTH points of view. Likewise in personal relationships. “Of all the stories that people construct to justify their lives, loves, and losses, the ones they weave to account for being the instigator or the recipient of injustice or harm are the most compelling and have the most far-reaching consequences” (191). Tavris and Aronson continue, “We have all done something that made others angry at us, and we have all been spurred to anger by what others have done to us. We all have, intentionally or unintentionally, hurt another person who will forever regard us as the villain, the betrayer, the scoundrel. And we have all … [been:] on the receiving end” (191). It would seem it is seldom the absolute fault of “the other guy.” But…that would mean…and humans on the whole have SUCH a vested interest in protecting their own self-image.A interesting, engaging read."
225,0151010986,http://goodreads.com/user/show/25763919-mimi,4," This is phenomenal! .......it made me love Psychology even more.This book has a protagonist , well ,i think it's more of an antagonist (to us) named : cognitive dissonance (i am so in love with this character hhhhh) ""Mistakes Were Made But Not By Me"" discusses all SORTS of lengths human being may go in order to reduce cognitive dissonance.Acting in contradiction to what u believe (cognitive dissonance) is 'painful' 'uncomfortable' so what we do? the remedy is employed extensively by all yet little know about it : it's self justification.How it works: you hate cheating (this is your belief), it happened and you cheated once voluntarily (contradicting behavior) ====== results is cognitive dissonance ( your self image is shaken ,because your belief about 'cheating' has being shaken)Huh! now comes the remedy time : cheating isn't that bad. the exam was unfairly difficult that's why i cheated these are some of the thoughts we may have once we start justifying our actions (cheating) to reduce cognitive dissonance.OK , now let me introduce you other cognitive biases that leads u to screwing up immensely:Confirmation bias : this dude screws rational healthy discussions... for it blinds you for one side of an argument completely. You believe in one side, you keep looking for info to prove it without EVER checking the arguments and evidence the opposite view might present ( this is what makes some peoples' craniums rock-hard , never allowing the penetration of any of your ideas or arguments ) Snap decisions/judgements : this guys are super bad , if you could just turn them off when you are presented with anything which needs you opinion ....when you take a snap decision you are done for , it becomes harder to see the other angles of a person , an idea ...unless you knew how dangerous these guys are for your objectivity and try harder to make a balanced judgment. Sadly humans are hardwired with many biases that makes them fallible creatures....and without knowing them they will be extra fallible."
226,0151010986,http://goodreads.com/user/show/17485839-zena-ryder,4,"If you don't know what cognitive dissonance is, this is a great introduction. If you do know what it is, this is an easy, enjoyable read, with interesting stories and experiments that illustrate dissonance and the resulting self-justification, which will likely deepen your understanding of this all too human phenomenon. The authors also talk about the fascinating and related phenomenon of false memories — our memories tend to get distorted (or even created!) to be self-serving. I found the section on how easily children can be persuaded to have memories of things that didn't really happen both fascinating and disturbing. The authors also talk about the how police officers' confirmation bias and the need to avoid dissonance by those involved at the various stages of the justice system can and does lead to terrible miscarriages of justice.I guess the biggest thing that was missing, for me, was more detail of when we don't give in to self-justification in order to avoid dissonance. The authors do talk about this, but I would have liked more detail. I would also like more detail on people with low self esteem, who don't tend to resolve their dissonance in self-serving ways, but rather in ways that fit their self image of being incompetent, unlovable etc.While knowing about cognitive biases and flaws isn't enough to make them magically go away, the authors suggest that being aware of them should make us less confident in our own convictions and memories, especially when they are self-serving. I think that is an important lesson for anyone."
227,0151010986,http://goodreads.com/user/show/4532156-alaa-a,5,"This year I started to be more interested in social psychology books in my hope to change my default sitting to the world and understand it better, and what better way than saying I was wrong to your self and owning the mistakes to your self...Its a very challenging book to read its started to with an eases of pointing the mistakes of politics and countries and introducing the conformation biases then going to personal stories that we are confined that happened when all evidenced are against.One of the psychological insights that has been messing around with my mind is the selective memory and that even if you feel strongly sure and emotionally attached to it can be wrong or even planted made me question my memories and if I am a hypocrite the explanation for people's unwillingness to admit mistakes, even to themselves, in a variety of realms. This far-reaching BOOK tackles irrational prejudices, false memories, misjudgement as a psychotherapist, prosecuting the wrong individual, blaming one's spousethe part of repressed memory therapy of rape victimise was eye opening for me as how easy for as to follow :Cognitive dissonanceConfirmation biasI read in the book ""thinking fast and slow "" that knowing this biases dose not stop you form doing it even for the experts in this felid but it can make you stop your self and question why you think or act this way, and that is about it what you can do!! "
228,0151010986,http://goodreads.com/user/show/5856337-mark,5,"Having been put off by several popular books by social psychologists I read in recent years which I felt failed to deliver on the promised goods (""Emotional Intelligence"" and ""Social Intelligence,"" both by Daniel Goldman come quickly to mind), I was both relieved and impressed as I listened to the audiobook version of ""Mistakes Were Made.""The authors not only convincingly support and develop their thesis from start to finish, they do so in an entertaining fashion. Furthermore, the book offers plenty of opportunity for practical application for any casual reader who dares to pause to consider how his or her own pride, cognitive dissonance, confirmation biases, etc. may cause him/her to re-write history, justify themselves and their experiences, blind themselves from seeing the truth, etc. I will mention one area where the authors may possibly be a little ""off."" Toward the end of the book, they share an example of Japanese encouraging mistakes in the classroom and seem to generalize this example for Asian culture. However, across mainland China, Japan, Taiwan, and Korea, societies seems to be somewhat intolerant of mistakes. Having said all that, this is still a great book. Read it!"
229,0151010986,http://goodreads.com/user/show/2050800-kathy,1,"Although the authors have some good points about self-justification in a few sections of the book, they clearly spend way too much time on the ""problem"" and their political biases than a plausible solution to overcoming self-justification. I read the last page of the book in complete disgust as to the topic they chose to end with and completely irritated that very few solutions were offered to help minimize self-justification in ourselves as well as others. I guess I should have read the title a little closer: It states ""Why we..."" and not ""How to overcome why we..."" Also found it very fitting based on the severe bias that shone through the entire book that there was not one mention of the infamous ""I did not have sexual relations with that woman"" by Bill Clinton. Now that's a perfect example of self-justification if I've ever seen one!There is nothing more irritating to me than reading 200 pages about a problem and then getting to the end and realizing the author offered no real solutions but a ton of biased opinions. What a waste!"
230,0151010986,http://goodreads.com/user/show/1347209-jacob,5,"As much as I read, there are few books that are enlightening, educational, and entertaining enough for me to rate them so highly. This is one of those books that every time you put it down you have to run and find someone to tell what you just read. You find the content so interesting that you can't help but share it with others.The authors do a great job at explaining cognitive dissonance and how it leads to self-justification. They also apply the concepts well by focusing a chapter on a specific realm of how this impacts our world (legal interrogation, false memory recovery, etc).If you have ever read ""Leadership and Self Deception"" I think you would enjoy this book also. More of the science behind the story.Read this and then apply the information in your life. It is blessing me and those around me and I'm sure it will you."
231,0151010986,http://goodreads.com/user/show/1984886-tim-kadlec,3,"The book was full of good information, and good discussions around cognitive dissonance. It's fault, however, was that the anecdotes tended to be very politically charged, and very biased.Unfortunately, the authors bias came through very strongly in several of the examples used, and this distracts from the points the authors are attempting to make. In addition, a few of the examples felt like they didn't really fit in with the subject matter, and were instead used to continue to justify the authors biases (ironic I know)."
232,0151010986,http://goodreads.com/user/show/26434622-sophiacoming,5,"One of my favorite books! make me more aware of my silly impulses. I think understanding these limitation is the basis for having a crucial conversation, and making peace with yourself and people around you."
233,0151010986,http://goodreads.com/user/show/58909202-edu,2,"The concept is very interesting, even necessary to know, and mindblowing, wich I liked a lot. But there were many many examples and much of them from USA politics, which I don't care so much about. "
234,0151010986,http://goodreads.com/user/show/8778400-rebekka-steg,5,"This week I've been reading Mistakes Were Made (But Not by Me): Why We Justify Foolish Beliefs, Bad Decisions, and Hurtful Acts by Carol Tavris and Elliot Aronson, an absolutely amazing book, which everyone should be acquired to read.The book deals with the issue of self-justification, and the role it plays in all of our lives, from such ""minor"" issues as arguments within a relationship, to bullying, prejudicialness, torture, fraud etc.Written by two psychologist, the book is backed by research as well as real life cases and examples. It's easy to read, incredibly thought-provoking and it deals with such an important topic, which affects us all.

 Quotes ""We are all capable of believing things which we know to be untrue, and then, when we are finally proved wrong, impudently twisting the facts so as to show that we were right. Intellectually, it is possible to carry on this process for an indefinite time: the only check on it is that sooner or later a false belief bumps up against solid reality, usually on a battlefield.""- George Orwell (1946)""For example, Elliot predicted that if people go through a great deal of pain, discomfort, effort, or embarrassment to get something, they will be happier with that ""something"" than if it came to them easily. For behaviorists this was a preposterous prediction. Why would people like anything associated with pain? But for Elliot, the answer was obvious: self-justification. The cognition that I am a sensible, competent person is dissonant with the cognition that I went through a painful procedure to achieve something - say, joining a group that turned out to be boring and worthless. Therefore, I would distort my perceptions of the group in a positive direction, trying to find good things about them and ignoring the downside.""""Venting is especially likely to backfire if a person commits an aggressive act against another person directly, which is exactly what cognitive dissonance theory would predict. When you do anything that harms someone else - get them in trouble, verbally abuse them or punch them out - a powerful new factor comes into play: the need to justify what you did. Take a boy who goes along with a group of his fellow seventh graders who are taunting and bullying a weaker kid who did them no harm. The boy likes being part of the gang but his heart really isn't in the bullying. Later, he feels some dissonance about what he did. ""How can a decent kid like me,"" he wonders, ""have done such a cruel thing to a nice, innocent little kid like him?"" To reduce dissonance, he will try to convince himself that the victim is neither nice nor innocent: ""He is such a nerd and cry-baby. Besides, he would have done the same to me if he had the chance."" Once the boy starts down the path of blaming the victim, he becomes more likely to beat up on the victim with even greater ferocity the next chance he gets. Justifying his first hurtful act sets the stage for more aggression. That's why the catharsis hypothesis is wrong.""""Our convictions about who we are carry us through the day, and we are constantly interpreting the things that happen to us through the filter of those core beliefs. When they are violated, even by a good experience, it causes us discomfort. An appreciation of the power of self-justification helps us understand, therefore, why people who have low self-esteem, or who simply believe that they are incompetent in some domain, are not totally overjoyed when they do something well; why, on the contrary, they often feel like frauds. If the woman who believes she is unlovable meets a terrified guy who starts pursuing her seriously, she will feel momentarily pleased, but that pleasure is likely to be tarnished by a rush of dissonance: ""What does he see in me?"" Her resolution is unlikely to be ""How nice; I must be more appealing than I thought I was."" More likely, it will be ""As soon as he discovers the real me, he'll dump me."" She will pay a high psychological price to have that consonance restored.""""The Milgram experiment shows us how ordinary people can end up doing immoral and harmful things through a chain reaction of behavior and subsequent self-justification. When we, as observers, look at them in puzzlement or dismay, we fail to realize that we are often looking at the end of a long, slow process down that pyramid. At his sentencing, Magruder said to Judge John Sirica: ""I know what I have done, and Your Honor knows what I have done. Somewhere between my ambition and my ideals, I lost my ethical compass."" How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self-justification will do the rest.""""The brain is designed with blind spots, optical and psychological, and one of its cleverest tricks is to confer on us the comforting delusion that we, personally, do not have any. In a sense, dissonance theory is a theory of blind spots - of how and why people unintentionally blind themselves so that they fail to notice vital events and information that might make them question their behavior or their convictions. Along with the confirmation bias, the brain comes packaged with other self-serving habits that allow us to justify our own perceptions and beliefs as being accurate, realistic, and unbiased. Social psychologist Lee Ross calls this phenomenon ""naïve realism,"" the inescapable conviction that we perceive objects and events clearly, ""as they really are."" We assume that other reasonable people see things the same way we do. If they disagree with us, they obviously aren't seeing clearly. Naïve realism creates a logical labyrinth because it presupposes two things. One, people who are open-minded and fair ought to agree with a reasonable opinion. And two, any opinion I hold must be reasonable; if it weren't, I wouldn't hold it. Therefore, if I can just get my opponents to sit down here and listen to me, so I can tell them how things really are, they will agree with me. And if they don't, it must be because they are biased.""""As fallible human beings, all of us share the impulse to justify ourselves and avoid taking responsibility for any actions that turn out to be harmful, immoral, or stupid. ... Most people when directly confronted with proof that they are wrong, do not change their point of view or course of action but justify it even more tenaciously.""""Just as we can identify hypocrisy in everyone but ourselves, just as it's obvious that others can be influenced by money but not ourselves, so we can see prejudices in everyone else but ourselves. Thanks to our ego-preserving blind spots, we cannot possibly have a prejudice, which is an irrational or mean-spirited feeling about all members of another group. Because are are not irrational or mean-spirited, any negative feelings we have about another group are justified; our dislikes are rational and well founded. It's theirs we need to suppress. Like the Hasids pounding on the Unprejudiced door at the Museum of Tolerance, we are blind to our own prejudices.""""When two people produce entirely different memories of the same event, observers usually assume that one of them is lying. Of course, some people do invent or embellish stories to manipulate or deceive their audiences, as James Frey notably did with his bestseller A Million Little Pieces. But most of us, most of the time, are neither telling the whole truth nor intentionally deceiving. We aren't lying; we are self-justifying. All of us, as we tell our stories, add details and omit inconvenient facts; we give the tale a small, self-enhancing spin; that spin goes over so well that the next time we add a slightly more dramatic embellishment; we justify that little white lie as making the story better and clearer - until what we remember may not have happened that way, or even may not have happened at all.""""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives. An appreciation of the distortions of memory, a realization that even deeply  felt memories might be wrong, might encourage people to hold their memories more lightly, to drop the certainty that their memories are always accurate, and to let go of the appealing impulse to use the past to justify problems of the present. If we are to be careful about what we wish for because it might come true, we must also be careful which memories we select to justify our lives, because than we will have to live by them.""""For any theory to be scientific, it must be stated in such a way that it can be shown to be false as well as true. If every outcome confirms your hypotheses that all men unconsciously suffer from castration anxiety; or that intelligent design, rather than evolution, accounts for the diversity of species; or that your favourite psychic would accurately have predicted 9/11 if only she hadn't been taking a shower that morning; or that all dolphins are kind to humans, your beliefs are a matter of faith, not science.""""Our implicit theories of why we and other people behave as we do come in one of two versions. We can say it's because of something in the situation or environment: ""The bank teller snapped at me because she is overworked today; there aren't enough tellers to handle these lines."" Or we can say it's because something is wrong with the person: ""That teller snapped at me because she is plain rude."" When we explain our own behavior, self-justification allows us to flatter ourselves: We give ourselves credit for our good actions but let the situation excuse the bad ones. When we do something that hurts another, for example, we rarely say, ""I behaved this way because I am a cruel and heartless human being."" We say, ""I was provoked; anyone would do what I did""; or ""I had no choice""; or ""Yes, I said some awful things, but that wasn't me - it's because I was drunk."" Yet when we do something generous, helpful, or brave, we don't say we did it because we were provoked or drunk or had no choice, or because the guy on the phone guilt-induced us into donating to charity. We did it because we are generous and open-hearted.""""Did Charles Graner and Lynndie England know what they were doing, let alone believe they were ""doing evil"" while they were deliberately inflicting pain and humiliation on their Iraqi prisoners and then laughing at them? No, they didn't, and that is why Amos Oz is wrong. Oz didn't reckon with the power of self-justification: We are good people. Therefore, if we deliberately inflict pain on another, the other must have deserved it. Therefore, we are not doing evil, quite the contrary. We are doing good. The relatively small percentage of people who cannot or will not reduce dissonance this way pay a large psychological price in guilt, anguish, anxiety, nightmares, and sleepless nights. The pain of living with horrors they have committed, but cannot morally accept, would be searing, which is why most people will reach for any justification available to assuage the dissonance. In the previous chapter, we saw on a smaller scale why many divorcing couples justify the hurt they inflict on each other. In the horrifying calculus of self-deception, the greater the pain we inflict on others, the greater the need to justify it to maintain our feelings of decency and self-worth. Because our victims deserved what they got, we hate them even more than we did before we harmed them, which in turn makes us inflict even more pain on them.""""But what are we supposed to do in our everyday lives? Call an external review board of cousins and in-laws to adjudicate every family quarrel? Videotape all parental interrogations of their teenagers? In our private relationships, we are on our own, and that calls for some self-awareness. Once we understand how and when we need to reduce dissonance, we can become more vigilant about the process and often nip it in the bud; like Oprah, we can catch ourselves before we slide too far down the pyramid. By looking at our actions critically and dispassionately, as if we were observing someone else, we stand a chance of bring out of the cycle of action followed by self-justification, followed by more committed action. We can learn to put a little space between what we feel and how we respond, insert a moment of reflection, and think about whether we really want to buy that canoe in January, really want to send good money after bad, really want to hold on to a belief that is unfettered by facts. We might even change our minds before our brains freeze our thoughts into consistent patterns.""""Humbling yes, but ultimately that's the point. Understanding how the mind yearns for consonance, and rejects information that questions our beliefs, decisions, or preferences, teaches us to be open to the possibility of error. It also helps us let go of the need to be right. Confidence is a fine and useful quality; none of us would want a physician who was forever wallowing in uncertainty and couldn't decide how to treat our illness, but we do want one who is open-minded and willing to learn. Nor would most of us wish to live without passions or convictions, which give our lives meaning and color, energy and hope. When confidence and convictions are unleavened by humility, by an acceptance of fallibility, people can easily cross the line from healthy self-assurance to arrogance. In this book, we have met many who crossed that line: the psychiatrists who are certain that they can tell if a recovered memory is valid; the physicians and judges who are certain that they are above conflicts of interest; the police officers who are certain that they can tell if a suspect is lying; the prosecutors who are certain that they convicted the guilty party; the husbands and wives who are certain that their interpretation of events is the right one; the nations who are certain that their version of history is the only one.""""Most Americans know they are supposed to say ""we learn from our mistakes,"" but deep down, they don't believe it for a minute. They think that mistakes mean you are stupid. Combined with the culture's famous amnesia for anything that happened more than a month ago, this attitude means that people treat mistakes like hot potatoes, eager to get rid of them as fast as possible, even if they have to toss them in someone else's lap."""
235,0151010986,http://goodreads.com/user/show/8435102-joan,3,"Why is it so hard for us to admit we have made a mistake? Why do we justify our actions? Why is it so hard to change our minds when we think we are right?The authors wrote this book with a goal of understanding those behaviors. I learned tons about why we say what we do to ourselves. Self-justification, for example. We convince ourselves we made the best choice possible. Unfortunately, that blocks us from seeing our errors and learning from them.I read about cognitive dissonance and how it changes our perception. When we see disconfirming evidence, we will criticize the source (fake news), distort or outright dismiss it. Maintaining the belief is more important than truth. And we have confirmation bias, the reason it is so hard to change our minds when we have made a firm decision. I also learned much about blind spots, how our memories change (or we change them purposely), and false memories. The authors give many examples of interrogators (such as child psychologists) manipulating people to confess to crimes or report non-existing events. They give examples of law enforcement officials and prosecutors refusing to admit mistakes even when DNA evidence finally proves them wrong.Rounding out this informative book are thoughts on the price paid for for justifying decisions that cause pain to others. For example, international acts are justified by saying our deeds were bad but not nearly as bad as theirs.The authors end the book reminding us of the benefits of admitting mistakes. There is a positive effect. For politicians, admitting a mistake results in constituents admiring the person is big enough to admit wrong and desire to learn from mistakes.This is an interesting book that is very informative and easy to read. I really found it enlightening in explaining much of the rhetoric we hear today."
236,0151010986,http://goodreads.com/user/show/28157679-susan-s-frederick,5,"Really opened my eyes to bias and lenses that are different for each of us, but have profound effect on how we see things, remember things, feel things. Fascinating."
237,0151010986,http://goodreads.com/user/show/4134989-chuck,4,"A well written exposure of dissonance avoidance, self-justification, confirmation bias and other forces that effect us all. The examples and insights here are especially helpful in understanding why ourself and others make mistakes, defend actions, and choose self-preserving narratives. A revelation into neural, natural wiring. A brave look into the mirror as well as the boundaries of tolerance we construct for others. Keen, practical eye-opening read. "
238,0151010986,http://goodreads.com/user/show/32598115-becky,5,This was an interesting look at how our minds work to dissociate with problems and errors in judgement.
239,0151010986,http://goodreads.com/user/show/2251009-esteban-del-mal,4,"Cognitive dissonance: The mental discomfort experienced by a person who holds two or more contradictory beliefs, ideas, or values. This discomfort is triggered by a situation in which a person's belief clashes with new evidence perceived by the person. When confronted with facts that contradict beliefs, ideals, and/or values, people will try to find a way to resolve the contradiction to reduce their discomfort (~squaring a circle).Cognitive bias: A systematic pattern of deviation from norm or rationality in judgment. Individuals create their own subjective social reality from their perception of the input. An individual's construction of social reality, not the objective input, may dictate his or her behavior in the social world; thus, cognitive biases may sometimes lead to perceptual distortion, inaccurate judgment, illogical interpretation, or what is broadly called irrationality. Catharsis: The psychodynamic principle of emotional release. It's a bullshit theory leftover from Freud. Self-justification: How, when a person encounters cognitive dissonance or a situation in which a person's behavior is inconsistent with his/her beliefs, that person tends to justify the behavior and deny any negative feedback associated with the behavior. Naive realism: The human tendency to believe that we see the world around us objectively and that people who disagree with us must be uninformed, irrational, or biased.Totalitaian ego: a) The ego/self is an organization of knowledge; b) ego/self is characterized by cognitive biases analogous to totalitarian information-control strategies, and; c) these totalitarian-ego biases function to preserve organization in cognitive structures.Reconstructive memory: A theory of memory recall in which the act of remembering is influenced by various other cognitive processes including perception, imagination, semantic memory, and beliefs. People view their memories as being a coherent and truthful account of episodic memory and believe their perspective is free from error during recall; however, the reconstructive process of memory recall is subject to distortion by other intervening cognitive functions such as individual perceptions, social influences, and world knowledge, all of which can lead to errors during reconstruction. [REPRESSED MEMORIES DO NOT EXIST]Source confusion: An attribute seen in different people's accounts of the same event after hearing people speak about the situation (for example, a witness who heard a police officer say someone had a gun who then states he/she saw the gun).Anomie: A condition in which society provides little moral guidance to individuals. This state evolves from conflict of belief systems and causes a breakdown of social bonds between an individual and the community. In a person, this condition can progress into a dysfunctional ability to integrate within the normative situations of his/her social world (for example, an unruly personal scenario that results in fragmentation of social identity and rejection of values). The term is commonly understood to mean normlessness.Imagination inflation: The finding that imagining an event which never happened can increase confidence that it actually occurred.Confidence-accuracy relationship: As one's confidence increases, so does one's level of accuracy (or belief therein).Benevolent dolphin problem: Every once in a while, a news story appears about a shipwrecked sailor who, on the verge of drowning, is nudged to safety by a dolphin. It is tempting to conclude that dolphins must really like human beings, enough to save us from drowning. But wait—are dolphins aware that humans don’t swim as well as they do? Are they actually intending to be helpful? To answer that question, we would need to know how many shipwrecked sailors have been gently nudged further out to sea by dolphins, there to drown and never be heard from again. We don’t know about those cases because the swimmers don’t live to tell us about their evil-dolphin experiences. If we had that information, we might conclude that dolphins are neither benevolent nor evil; they are just being playful.Effort justification: A person's tendency to attribute a value to an outcome which he/she had to put effort into achieving which is greater than the objective value of the outcome (i.e., the more effort put into something, the more it is valued).Implicit personality theory: The specific patterns and biases an individual uses when forming impressions based on a limited amount of initial information about an individual or situation."
240,0151010986,http://goodreads.com/user/show/11966043-lia,5,"4.5 starsI think this is one of the best non-fiction books I've ever read. It is so fascinating and it is so well-written. I've learned so much, about others and about myself. I honestly think that reading this book makes you a better person. I couldn't recommend it more."
241,0151010986,http://goodreads.com/user/show/23790728-amani,5,This was a very interesting and informative read. 
242,0151010986,http://goodreads.com/user/show/522647-kathy,4,"I'm so depressed. Humans, grrr. If you've ever wondered why people won't admit mistakes even in the face of verifiable truth contradicting their actions or beliefs, this book explains why. With sections on cognitive dissonance, why we think we're above outside influence, memory (yes, we make up our own ""memories""), scientific research fallacies, law enforcement/prosecution proceedings and relationship killers the gamut is pretty much covered. And, it's depressing. Did I mention that already? Well, it bears mentioning twice. We humans are geared to stick to our figurative guns no matter what. I have no hope for our current political unrest in the USA to get better any time soon. Sigh."
243,0151010986,http://goodreads.com/user/show/64733542-nafisa,5,"""A nation's character, and an individual's integrity, do not depend on being error-free. It depends on what we do after making an error.""Once in a while, I come across a book that makes me question my self-concept; this book is one of them. Broadly, it is about cognitive dissonance -- the psychological stress we face when our actions contradict our beliefs and ideals. Since we don't like to think of ourselves as incompetent or ill-intentioned, our natural tendency is to convince ourselves that we did the right thing. Mindless self-justification in the face of cognitive dissonance can have far-reaching (and often devastating) consequences, and the authors do a commendable job of documenting such examples from numerous distinct domains ranging from the criminal justice system, politics, medicine, and even marriage and relationships. A fresh set of ideas, quite compelling, and sometimes challenging to read as they force you to constantly self-reflect. I highly recommend it to anyone with an interest in psychology. The book is not intended to be self-help but offers a lot of scope for personal growth."
244,0151010986,http://goodreads.com/user/show/3669193-mah-ebr,5,i think everyone should read this one! 
245,0151010986,http://goodreads.com/user/show/901342-jacob,4,"This covers ground related to Evil Genes: Why Rome Fell, Hitler Rose, Enron Failed, and My Sister Stole My Mother's Boyfriend and The Honest Truth About Dishonesty: How We Lie to Everyone--Especially Ourselves, but it's specifically about self-justification. It's attempting to answer the question ""Why do people self-justify obvious mistakes?"" and look at the impact of doing so. It's pretty straightforward and quite readable.Self-justification is a useful and even essential way for humans to protect their ego and mental health, but it can get pretty out of whack. Self-justification is not only sad when it helps us decide to do things we shouldn't, it's extra sad when people do things they shouldn't only because they are trying to support an existing self-justification for a previous bad decision. One of the elaborated examples is when innocent people go to jail: it's bad enough when police and attorneys justify acting unethically in order to convict someone they ""know"" is guilty. Where it becomes absolutely unconscionable is where they work hard to prevent people from being proven innocent after the fact so they don't have to admit screwing up.On a lighter note, with books about human fallibility you have to chuckle when the authors display the very fallibility they're decrying. In one case, they claim to be certain about someone's motivation for making poor remarks without allowing for those remarks to be caused by that person looking for any excuse to self-justify behavior. In another case, they berate therapists for not thinking scientifically and not examining the disconfirming cases, then talk about the Gottmans' work on predicting divorce without examining the disconfirming cases (where the Gottmans predicted divorce and were wrong). They mention a case where of 10 of 47 couples were predicted to divorce, all 7 who did divorce were predicted ones. Of the remaining 40, all they say is that the 90% accuracy is impressive. But they don't address that 30% of the predicted divorces didn't happen, which pokes a hole in their nice theory about self-justification causing divorce. That wouldn't be a problem if they hadn't already spent a chapter bagging on therapists for having pet theories without looking at evidence that would contradict the theory.One of the reasons you chuckle over those kinds of mistakes instead of criticizing is because we ALL do those things. I'm not immune from doing those very same things, and neither is anyone else. But we might become less that way if we are aware of the phenomenon and try to identify when we are justifying ourselves."
246,0151010986,http://goodreads.com/user/show/7399266-camie,4,"I should start by saying I find social psychology fascinating! This book is about cognitive dissonance , which basically means having two conflicting beliefs and the measures we will resort to in order to defend and justify our beliefs , decisions, and actions. Backed by much research, this very insightful book explains how we all are capable of self deception, why we do it, why it is harmful, and how to overcome the very human mechanism of justifying our foolish beliefs, improper actions, poor decisions, and hurtful acts, and more importantly how to keep small things from escalating to disastrous proportions. Looking at everything from political situations, criminal acts, war, marriage, and personal levels it offers answers to how impossible atrocities come about , one justification at a time. ""How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self justification will do the rest."" From the politician who can't publically admit his actions, the torturer who feels no guilt, to the person who will say anything to win an argument, this book explains why it is so easy to see the hypocrisy of others while being totally blind to our own. Co-written by Elliot Aronson, author of The Social Animal , a great textbook, this is a very readable informative book. The introduction is called Knaves, Fools, Villains, and Hypocrites: How Do They Live With Themselves.... lol how do we ?? 4 stars"
247,0151010986,http://goodreads.com/user/show/51519663-diana-nahirna,5,"Well, that explains a lot of my recent purchases, Iraq, and why marriages fail. "
248,0151010986,http://goodreads.com/user/show/1974052-milan,5,"Mistakes Were Made (But Not by Me) is quite an enlightening book by Carol Tavris and Elliot Aronson. The authors examine our deep-rooted tendencies to underplay our faults and errors and to exaggerate the mistakes of others, especially when they go against us. ""Cognitive dissonance occurs when a person holds two or more contradictory beliefs, ideas, or values, or participates in an action that goes against one of these three, and experiences psychological stress because of that."" Two lessons from this theory: “First, the ability to reduce dissonance helps us in countless ways, preserving our beliefs, confidence, decisions, self-esteem, and well-being. Second, this ability can get us into big trouble.”The self-justification mechanisms like cognitive dissonance, confirmation bias, and fabricated memory play such an important role in our lives that they are hard to ignore. The authors provide very vivid examples from politics, therapy, conflict, wars, marriage, police and court procedures to show how these biases work. A few important lessons: •	 “Most human beings and institutions are going to do everything in their power to reduce dissonance in ways that are favorable to them, that allow them to justify their mistakes and maintain business as usual.” •	“Most people, when directly confronted by evidence that they are wrong, do not change their point of view or course of action but justify it even more tenaciously. Even irrefutable evidence is rarely enough to pierce the mental armor of self-justification.”•	Our ‘mistake-phobic’ culture causes people not to learn from their mistakes.•	Naive realism: the believe that everyone else sees the world as we do•	We all self-justify as a way to protect against cognitive dissonance, whether positively or negatively.•	Memories are easily modified to fit a narrative to reduce cognitive dissonance.•	We must be careful to not allow memory distortion to justify previous decisions.•	Therapists should be very concerned about confirmation bias, their expert assessments and also in their evaluations of people.•	Confessions can be elicited from accused legally by using deceit, trickery, etc.•	Successful couples will give the benefit of the doubt to their partners, just as they would to themselves. Unsuccessful couples do the opposite.•	We must strive to take self-justification into account in our lives and relationships to prevent incorrect decisions making.Two things to keep in mind – our personal life will suffer if we don’t admit our mistakes and society will work better if people admitted when they’re wrong."
249,0151010986,http://goodreads.com/user/show/28602450-vladyslav-sitalo,4,"You think about yourself as a reasonably nice person, with not perfect but good enough memory. Maybe you've done some things in your life, that you don't particularly like, but you think that in most cases, given the situation you were in, most of the people would've done the same.So you ain't perfect but better than the most, right?Well, this book would get you to at least question, how accurate is the description above. And it will also tell you how come you (and most of the people, even most morally flawed, from your perspective, people) think of themselves in this way.The book will tell you how your mind is desperately trying to maintain the self-image, you have about yourself and protect beliefs your hold. How it change your perceptions of things around you to fit this image/beliefs. And here comes more fun: it also employs your memory to justify your current self-perception/beliefs. So your memory is gradually, with each recall, become more compliant with this image. And eventually, all you left with is the nice, coherent story of your life that corresponds to your current view of yourself and your beliefs. But this story often has little or nothing to do with reality.As authors call it: Memory is your self-justifying historian (I would also highly recommend a novelette by Ted Chiang - ""The Truth of Fact, the Truth of Feeling"" as an exploration of this aspect of our memory: https://www.goodreads.com/book/show/1...).And the thing is that this process influences pretty much every aspect of your life regardless of your age/education or other things, you might think would influence the situation.So the process kicks in:When you're a nice, kind boy, who find himself in a company that is bullying a weaker guy. You don't particularly like the process but, as you want to be a part of this social group - you continue to participate in it. But there is dissonance here: how come you, as a nice, kind boy become a bully? So here the self-justification comes to your help: ""It's totally the guy's responsibility that he got bullied. Let's modify our image of the guy to leave our self-image preserved and justify what've done. Yay! And hey we're justified to continue to bully him as he is such a ....""Or let's say you're a student who don't have any strong position on cheating. You know it's generally considered a ""bad thing"" but you don't have any personal conviction either way. You haven't done it earlier because you didn't need to. But now you're in the situation when you need either cheat or fail this particular course. So situation can go in two ways from here:World 1: You've decided to cheat. ""Self-justification process: Ok we've cheated, as we know we're a generally good person, so we could not have possibly done a bad thing, so we may conclude that cheating is not a big deal"".World 2: You've decided not to cheat. ""Self-justification process: Ok we've failed the course. That's unfortunate but, well we didn't have any other option, right? We wouldn't even consider doing such a terrible thing as cheating"".Or you're a detective and you've interrogated your suspect to the point that he have given you a confession. But here comes the strong evidence (like DNA test or videotape) that he is innocent. So here it goes: ""I'm an honest infallible detective and my interrogation methods are great, and, after all, the guy has given confession after only 36 consecutive hours of interrogation. The evidence must be wrong""And let's upgrade a bit more. You're an honest politician, who is right now flying with a lobbyist on a luxury private plane to spend a nice weekend in some luxury resort. ""As we're an honest, good man, this situation can't possibly influence our political judgment in any way, right?"" (To understand how you got in this situation in a first place and for a lot of other good examples - read the book ;)The more deeply held self-belief that is contradicting to what you did the more actively you would justify the deed as the kind of deed that don't contradict this self-belief.You probably think to yourself: ""Ok maybe some of the cases described in this book can be true about me, but in most of them I would not have employed this level of self-justification""Well, the problem is that self-justification is largely unconscious process so when you do something that don't correspond to your self-image or see information that contradicts your belief - the justification process kicks in automatically in the background.So usually, you don't even notice on the conscious level that you've maybe done something wrong or that you hold a questionable belief. And correspondingly you don't have a chance to fix the situation before you internalize it as the normal state of things.That's why it's often said ""Hypocrite is obvious to all but himself""So you would probably at this point like to know - are we doomed? Can we do better? And the answer is yes we can! The book advises us to institute impartial external overview committees wherever possible (if necessary even against the will of involved people/institutions) because the external observer can usually notice an error much easier than somebody who have committed it. As he is not emotionally/financially/in other way invested in this decision.In the situations where setting up such an institutions is not feasible or reasonable (For example in the case of personal relationships), make sure that you and people around are aware and conscious about the magic of self-justification. You also can, to some level, train yourself to recognize the typical situations where the process may kick in and be especially careful when facing them. Also, be aware of the fact that this magic works on other people, so when you try to point out his/her error to somebody, be careful to do it in a way that will not make them self-defensive and more likely to justify this error.And don't be afraid to admit your errors, because as you relinquish wrong beliefs you become wiser, as you own up to your errors you gain more respect from people and you're less likely to make the same error in the future. Everybody makes mistakes, but you only can learn from yours, when you admit them."
250,0151010986,http://goodreads.com/user/show/21170365-amy-anderson,5,"I loved this book and found it so applicable to everyone. While we need justification to move forward in life and not second guess our every decision, we also need to be aware that justification can lead us to be blind sighted to truth. Its a fine line to walk. I could quote this whole book, but here are my favorites:""Self-justification is more powerful and dangerous than the explicit lie. It allows people to convince themselves that what they did was the best thing they could have done. In fact, come to think of it, it was the right thing."" p.4""Self-justification not only minimizes our mistakes and bad decision, it is also the reason that everyone can see a hypocrite in action except the hypocrite."" p.4""How in the world can they live with themselves? The answer is exactly the way the rest of us do."" p.9""Yet mindless self-justification, like quicksand, can draw us deeper into disaster. It blocks our ability to even see our errors, let alone correct them. It distorts reality, keeping us from getting all the information we need and assessing the issues clearly. It prolongs and widens rifts between lovers, friends, and nations. It keeps us from letting go of unhealthy habits. IT permits the guilty to avoid taking responsibility for their deeds."" p.9""I will look at any additional evidence to confirm the opinion to which I have already come."" Lord Molson p.17""These mechanisms provide a neurological basis for the observation that once our minds are made up, it is hard to change them."" p.19""People become more certain they are right about something they just did if they can't undo it."" p.22""Decades of experimental research have found exactly the opposite: that when people vent their feelings aggressively they often feel worse, pump up their blood pressure and make themselves angrier."" p.26""Aggression begets self-justification, which begets more aggression."" p.27""How do you get an honest man to lose his ethical compass? You get hi to take one step at a time, and self-justification will do the rest."" p.37""Parent blaming is a popular and convenient form of self-justification because it allows people to live less uncomfortably with their regrets and imperfections."" p.76""...current self-concepts blurred their memories, bringing their past selves into harmony with their present ones."" p.79""If a memory is a central part of your identity, a self-serving distortion is even more likely."" p.79""For those who are trying to remember something that never happened, writing analyzing dreams, and drawing pictures- techniques that are the staples of many psychotherapists- are all methods that quickly conflate imagination with reality."" p.86""Once the seed of belief was planted [they] began to search for confirming evidence."" p.90""...the story fits the needs of the experiences."" p.91"",,,experiences have internalized their new false memories and cannot now distinguish them from true ones. They have come to believe their own stories."" p.93""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives."" p.93""Successful partners extend to each other the same self-forgiving ways of thinking we extend to ourselves: They forgive each other's missteps as being due to the situation, but give each other credit for the thoughtful and loving things they do."" p.169""It may sometimes be hard to define good, but evil has its unmistakable odor: Every child knows what pain is. Therefore, each time we deliberately inflict pain on another, we know what we are doing. We are doing evil."" Amoz p.198""Would you rather admit you're wrong now or wait until someone else proves it?"" p.221""People will pursue self-destructive courses of action to protect the wisdom of their initial decisions."" p.222""They will treat people they have hurt even more harshly, because they convince themselves that their victims deserve it."" p.222""People who are insecure in their religious beliefs may feel the impulse to silence and harass those who disagree with them, because their mere existence arouses the painful dissonance of doubt."" p.222"
251,0151010986,http://goodreads.com/user/show/5301457-sergei-moska,4,"Although this book didn't actually teach me anything new in terms of theory (but did provide me with many details of practical cases), it nonetheless surprised me. First, I decided to read this book at this time because I've been a bit burned out from dense reading and wanted something useful but light. It was in fact both these things, but it was also far, far more depressing than I had expected. I expected this to be a “Ha ha, let's look at our foibles!” type of read. No, it's more of a “your identity is a joke and the world systematically does evil things. And so do you.” kind of experience. Structurally speaking, the book is very simple. The first part posits a simplified theory, and the rest of the book demonstrates the theory in action, in a few select areas of life. The theory is that we need to overcome the cognitive dissonance that emerges when our actions conflict with our self-image or beliefs. At such a moment, we are said to be at the top of a “pyramid” (a 2-dimensional triangle would be a better image), and the authors believe that whether or not we choose to justify ourselves to ourselves in such moments will lead us down one side of the pyramid or the other, with drastically different outcomes once we hit either side of the base of the pyramid. I may give up the idea that I'm such a great guy, or I can decide that the other person deserved the treatment, that it really wasn't a big deal, etc. The authors believe that whatever choice we make will cause us – in order to avoid further cognitive dissonance – to more extreme positions in order to justify our initial choice. A number of surprising findings come about as a result. For instance, the more helpless the victim, the more we will tend to denigrate him in order to justify our initial mistreatment of him. Beating up an angry drunk at a bar doesn't necessarily require much justification (“He was being threatening, and it's fine to beat up people that are threatening”), but participating in bullying usually does (“I'm a nice guy and beating him up, so it must be because he's a weenie who deserves to be humiliated. Plus he'd do it if he had the chance”.)A fun book to read, although it was too simplified for my taste in at least two ways. First, the authors' theory is *very* simple, and at times their application of the theory seems too universal. For instance, why do innocent people confess to crimes? The authors only seem to entertain the notion that it's in order to reduce cognitive dissonance: “I didn't do anything, but all the cops say that they have proof. The cops are honest and good people, so I must be the problem.” Yet at times this just seems dubious. The explanation is far more convincing when they apply it to the decision by the police to continue interrogation even in the absence of evidence. The second way that the book was too simplified for my taste is in its structure. After a very good exposition of their theory, I was hoping that the subsequent material would help develop the theory further. But what it turned out to be was “Here's a theory, and now we're going to show you the theory in X, Y, and Z.” This is a matter of taste, but I really don't like that format. What's more, I do think it hurts the authors, since it implies that the answer to the subtitle of the book is monolithic. I don't think that to be the case, and I suspect the authors don't either. In fairness, they do incidentally go through a number of additional mechanisms that are attached to the problem of cognitive dissonance, including a wonderful treatment on the foibles of memory, but it would have been really nice to make their answer more complex and complete, even at the risk of making it less parsimonious. Normally that kind of issue would be a big turn-off for me, but the book really is saved (for me) by their incredibly chilling accounts, especially in chapters 3-6. The writing is very clear and engaging, and the book is also thoroughly annotated, all of which makes me fall a little bit in love with the authors."
252,0151010986,http://goodreads.com/user/show/1677868-steven-peterson,4,"This is a well written, snappy book that addresses an important issue, best described by the book's title and subtitle: ""Mistakes Were Made (but not by me): Why we justify foolish beliefs, bad decisions, and hurtful acts."" The two authors, both well reputed psychologists, use the theory of cognitive dissonance as their starting point. Leon Festinger was one of the major theorists of this approach. The authors of this book simply define the perspective thus (page 13): ""Cognitive dissonance is a state of tension that occurs whenever a person holds two cognitions (ideas, attitudes, beliefs, opinions) that are psychologically inconsistent, such as 'Smoking is a dumb thing to do because it could kill me' and 'I smoke two packs a day.'"" How does one deal with this? By adopting one of the positions and then downgrading or rejecting the other. The end result is self-justification, self-deception, seeking out evidence to support the choice that we have made while rejecting evidence that does not fit with our choice. The brain itself shows evidence of the operation of cognitive dissonance. The example on page 19 of functional Magnetic Resonance Imaging (fMRI) and processing information about presidential candidates is telling. The end result is ""blind spots,"" in which people (page 42) ""fail to notice vital events and information that might make them question their behavior or their convictions."" As such, the authors note that cognitive dissonance makes mincemeat of such theoretical views as rational actor theory and psychoanalytic theory. One result of cognitive dissonance is what is called ""confirmation bias,"" the attending to evidence that supports our views and the rejection/suppression of evidence that does not support our views. Many examples are advanced to illustrate the case that the authors make. Issues include: moral lapses (e.g., Watergate participants), ""made up"" memories (raising serious questions about the whole idea of repressed memories), criminal justice system decisions on guilt or innocence, and so on. Much is at stake with cognitive dissonance as it operates. In the closing chapter, the authors try to indicate how understanding cognitive dissonance might help us to limit the damage that may occur as a result of its operation. Convincing? I'm not so sure, but this discussion does get one thinking about how we might address the harmful side effects of cognitive dissonance. A readable book that raises important issues. I think that more use of neuroscientific research could have strengthened this book that much more. Also, the work by cognitive psychologists like Kahneman and Tversky could have spoken to key points as well. This book might also profitably be read in tandem with another recent book on a similar subject, Cordelia Fine, ""A Mind of Its Own."" In addition, Linden's ""accidental Mind"" provides a perspective on related issues from a neuroscience viewpoint. "
253,0151010986,http://goodreads.com/user/show/9281934-louise,5,"Prior to reading this, I had only considered the theory of cognitive dissonance as it applied to holding two contrary opinions, the classic example being that of the racist with friends who are members of the race s/he denigrates. Tavris and Aronson demonstrate further applications of this theory and how destructive the behavior it spawns continues to be.The 1980's/90's day care scandals pre-dated the 24 hour cable cycle (imagine this being covered today by Fox) so it blipped in and out of my attention. I remember thinking how it didn't add up, but I wasn't really following it. Today, somewhere below my radar screen are the DNA absolved prisoners, and their continued incarceration doesn't add up either. Tavris and Aronson show how the professionals involved continued and continue to stick to their long fought for opinion, even as evidence pours in against it. As the dissonance theory predicts, the greater the commitment to the opinion the more the mind works to re-enforce it.The book is most convincing on the personal level such as the damage caused by the dynamics in divorce or accusations such as those made by those in the recovered memory therapies.While cognitive dissonance is undoubtedly operative, it is not the only culprit in the inability to admit mistakes. For commercial and public policy issues there is liability to be paid either through job loss, litigation, an election, or even everyday office politics. If the culprit is a principal player on a big stage, it could be a career ender for not only the decider, but his/her staff. It is not just the mind that keeps out contrary information, there is undoubtedly social support for the bad decision by those who also made the mistake or assisted in its execution. There are also families to consider, you admit the mistake, you could lose your job and there will be no college education for your kids. The books speaks of these barriers, but sticks to its purpose of illustrating the theory.For barriers beyond cognitive dissonance, I think of George Bush and the Iraq war. If he could bring himself to admit the mistake, he would face huge institutional and social acrimony from the policy makers who assisted him, the party who supported him, the military as an institution and the families who lost their loved ones. Ultimate decision makers on the Iraq War will wait, like Robert McNamara did, until the mistake is universally recognized.This is an excellent book. The authors develop their theory for the lay person with good examples from both everyday life and the world of public policy. I highly recommend it. "
254,0151010986,http://goodreads.com/user/show/2414293-adelle,3,"The authors' political biases came through as they used the beginning and the ending of the book to castigate then (2007) President George W. Bush, and to call Newt Gingrich a “hypocrite” for criticizing (now former) President Bill Clinton’s sexual affair…WITHOUT any allusion to Clinton’s defensive “I did not have sex with that woman…Miss Lewinski” statement. But most of the center sections of the book--which thankfully were relatively free of politics--- I found endlessly fascinating. Oh, how tenaciously we cling to “our version” of the story, filtering the facts so that what WE did/or didn’t do is seen to be of negligible consequence or perhaps even honorable, and what THE OTHER GUY did/or didn’t do is seen to be righteously reprehensible, obviously beyond the pale. I loved, too, the authors’ many demonstrations that the act that alienates one party or the other is not a stand-alone event. To reference Aesop, it is much more likely to be the straw that broke the camel’s back. Hurts and grievances in both parties have probably been building for some time. “Who were the victims? It depends on how many years, decades, and centuries you take into account” (206). Consider Kosovo. Consider the Crusades. As the authors describe these tragic events, IF one is not emotionally involved with one side or the other, one can see BOTH points of view. Likewise in personal relationships. “Of all the stories that people construct to justify their lives, loves, and losses, the ones they weave to account for being the instigator or the recipient of injustice or harm are the most compelling and have the most far-reaching consequences” (191). Tavris and Aronson continue, “We have all done something that made others angry at us, and we have all been spurred to anger by what others have done to us. We all have, intentionally or unintentionally, hurt another person who will forever regard us as the villain, the betrayer, the scoundrel. And we have all … [been:] on the receiving end” (191). It would seem it is seldom the absolute fault of “the other guy.” But…that would mean…and humans on the whole have SUCH a vested interest in protecting their own self-image.A interesting, engaging read."
255,0151010986,http://goodreads.com/user/show/25763919-mimi,4," This is phenomenal! .......it made me love Psychology even more.This book has a protagonist , well ,i think it's more of an antagonist (to us) named : cognitive dissonance (i am so in love with this character hhhhh) ""Mistakes Were Made But Not By Me"" discusses all SORTS of lengths human being may go in order to reduce cognitive dissonance.Acting in contradiction to what u believe (cognitive dissonance) is 'painful' 'uncomfortable' so what we do? the remedy is employed extensively by all yet little know about it : it's self justification.How it works: you hate cheating (this is your belief), it happened and you cheated once voluntarily (contradicting behavior) ====== results is cognitive dissonance ( your self image is shaken ,because your belief about 'cheating' has being shaken)Huh! now comes the remedy time : cheating isn't that bad. the exam was unfairly difficult that's why i cheated these are some of the thoughts we may have once we start justifying our actions (cheating) to reduce cognitive dissonance.OK , now let me introduce you other cognitive biases that leads u to screwing up immensely:Confirmation bias : this dude screws rational healthy discussions... for it blinds you for one side of an argument completely. You believe in one side, you keep looking for info to prove it without EVER checking the arguments and evidence the opposite view might present ( this is what makes some peoples' craniums rock-hard , never allowing the penetration of any of your ideas or arguments ) Snap decisions/judgements : this guys are super bad , if you could just turn them off when you are presented with anything which needs you opinion ....when you take a snap decision you are done for , it becomes harder to see the other angles of a person , an idea ...unless you knew how dangerous these guys are for your objectivity and try harder to make a balanced judgment. Sadly humans are hardwired with many biases that makes them fallible creatures....and without knowing them they will be extra fallible."
256,0151010986,http://goodreads.com/user/show/17485839-zena-ryder,4,"If you don't know what cognitive dissonance is, this is a great introduction. If you do know what it is, this is an easy, enjoyable read, with interesting stories and experiments that illustrate dissonance and the resulting self-justification, which will likely deepen your understanding of this all too human phenomenon. The authors also talk about the fascinating and related phenomenon of false memories — our memories tend to get distorted (or even created!) to be self-serving. I found the section on how easily children can be persuaded to have memories of things that didn't really happen both fascinating and disturbing. The authors also talk about the how police officers' confirmation bias and the need to avoid dissonance by those involved at the various stages of the justice system can and does lead to terrible miscarriages of justice.I guess the biggest thing that was missing, for me, was more detail of when we don't give in to self-justification in order to avoid dissonance. The authors do talk about this, but I would have liked more detail. I would also like more detail on people with low self esteem, who don't tend to resolve their dissonance in self-serving ways, but rather in ways that fit their self image of being incompetent, unlovable etc.While knowing about cognitive biases and flaws isn't enough to make them magically go away, the authors suggest that being aware of them should make us less confident in our own convictions and memories, especially when they are self-serving. I think that is an important lesson for anyone."
257,0151010986,http://goodreads.com/user/show/4532156-alaa-a,5,"This year I started to be more interested in social psychology books in my hope to change my default sitting to the world and understand it better, and what better way than saying I was wrong to your self and owning the mistakes to your self...Its a very challenging book to read its started to with an eases of pointing the mistakes of politics and countries and introducing the conformation biases then going to personal stories that we are confined that happened when all evidenced are against.One of the psychological insights that has been messing around with my mind is the selective memory and that even if you feel strongly sure and emotionally attached to it can be wrong or even planted made me question my memories and if I am a hypocrite the explanation for people's unwillingness to admit mistakes, even to themselves, in a variety of realms. This far-reaching BOOK tackles irrational prejudices, false memories, misjudgement as a psychotherapist, prosecuting the wrong individual, blaming one's spousethe part of repressed memory therapy of rape victimise was eye opening for me as how easy for as to follow :Cognitive dissonanceConfirmation biasI read in the book ""thinking fast and slow "" that knowing this biases dose not stop you form doing it even for the experts in this felid but it can make you stop your self and question why you think or act this way, and that is about it what you can do!! "
258,0151010986,http://goodreads.com/user/show/5856337-mark,5,"Having been put off by several popular books by social psychologists I read in recent years which I felt failed to deliver on the promised goods (""Emotional Intelligence"" and ""Social Intelligence,"" both by Daniel Goldman come quickly to mind), I was both relieved and impressed as I listened to the audiobook version of ""Mistakes Were Made.""The authors not only convincingly support and develop their thesis from start to finish, they do so in an entertaining fashion. Furthermore, the book offers plenty of opportunity for practical application for any casual reader who dares to pause to consider how his or her own pride, cognitive dissonance, confirmation biases, etc. may cause him/her to re-write history, justify themselves and their experiences, blind themselves from seeing the truth, etc. I will mention one area where the authors may possibly be a little ""off."" Toward the end of the book, they share an example of Japanese encouraging mistakes in the classroom and seem to generalize this example for Asian culture. However, across mainland China, Japan, Taiwan, and Korea, societies seems to be somewhat intolerant of mistakes. Having said all that, this is still a great book. Read it!"
259,0151010986,http://goodreads.com/user/show/2050800-kathy,1,"Although the authors have some good points about self-justification in a few sections of the book, they clearly spend way too much time on the ""problem"" and their political biases than a plausible solution to overcoming self-justification. I read the last page of the book in complete disgust as to the topic they chose to end with and completely irritated that very few solutions were offered to help minimize self-justification in ourselves as well as others. I guess I should have read the title a little closer: It states ""Why we..."" and not ""How to overcome why we..."" Also found it very fitting based on the severe bias that shone through the entire book that there was not one mention of the infamous ""I did not have sexual relations with that woman"" by Bill Clinton. Now that's a perfect example of self-justification if I've ever seen one!There is nothing more irritating to me than reading 200 pages about a problem and then getting to the end and realizing the author offered no real solutions but a ton of biased opinions. What a waste!"
260,0151010986,http://goodreads.com/user/show/1347209-jacob,5,"As much as I read, there are few books that are enlightening, educational, and entertaining enough for me to rate them so highly. This is one of those books that every time you put it down you have to run and find someone to tell what you just read. You find the content so interesting that you can't help but share it with others.The authors do a great job at explaining cognitive dissonance and how it leads to self-justification. They also apply the concepts well by focusing a chapter on a specific realm of how this impacts our world (legal interrogation, false memory recovery, etc).If you have ever read ""Leadership and Self Deception"" I think you would enjoy this book also. More of the science behind the story.Read this and then apply the information in your life. It is blessing me and those around me and I'm sure it will you."
261,0151010986,http://goodreads.com/user/show/1984886-tim-kadlec,3,"The book was full of good information, and good discussions around cognitive dissonance. It's fault, however, was that the anecdotes tended to be very politically charged, and very biased.Unfortunately, the authors bias came through very strongly in several of the examples used, and this distracts from the points the authors are attempting to make. In addition, a few of the examples felt like they didn't really fit in with the subject matter, and were instead used to continue to justify the authors biases (ironic I know)."
262,0151010986,http://goodreads.com/user/show/26434622-sophiacoming,5,"One of my favorite books! make me more aware of my silly impulses. I think understanding these limitation is the basis for having a crucial conversation, and making peace with yourself and people around you."
263,0151010986,http://goodreads.com/user/show/58909202-edu,2,"The concept is very interesting, even necessary to know, and mindblowing, wich I liked a lot. But there were many many examples and much of them from USA politics, which I don't care so much about. "
264,0151010986,http://goodreads.com/user/show/8778400-rebekka-steg,5,"This week I've been reading Mistakes Were Made (But Not by Me): Why We Justify Foolish Beliefs, Bad Decisions, and Hurtful Acts by Carol Tavris and Elliot Aronson, an absolutely amazing book, which everyone should be acquired to read.The book deals with the issue of self-justification, and the role it plays in all of our lives, from such ""minor"" issues as arguments within a relationship, to bullying, prejudicialness, torture, fraud etc.Written by two psychologist, the book is backed by research as well as real life cases and examples. It's easy to read, incredibly thought-provoking and it deals with such an important topic, which affects us all.

 Quotes ""We are all capable of believing things which we know to be untrue, and then, when we are finally proved wrong, impudently twisting the facts so as to show that we were right. Intellectually, it is possible to carry on this process for an indefinite time: the only check on it is that sooner or later a false belief bumps up against solid reality, usually on a battlefield.""- George Orwell (1946)""For example, Elliot predicted that if people go through a great deal of pain, discomfort, effort, or embarrassment to get something, they will be happier with that ""something"" than if it came to them easily. For behaviorists this was a preposterous prediction. Why would people like anything associated with pain? But for Elliot, the answer was obvious: self-justification. The cognition that I am a sensible, competent person is dissonant with the cognition that I went through a painful procedure to achieve something - say, joining a group that turned out to be boring and worthless. Therefore, I would distort my perceptions of the group in a positive direction, trying to find good things about them and ignoring the downside.""""Venting is especially likely to backfire if a person commits an aggressive act against another person directly, which is exactly what cognitive dissonance theory would predict. When you do anything that harms someone else - get them in trouble, verbally abuse them or punch them out - a powerful new factor comes into play: the need to justify what you did. Take a boy who goes along with a group of his fellow seventh graders who are taunting and bullying a weaker kid who did them no harm. The boy likes being part of the gang but his heart really isn't in the bullying. Later, he feels some dissonance about what he did. ""How can a decent kid like me,"" he wonders, ""have done such a cruel thing to a nice, innocent little kid like him?"" To reduce dissonance, he will try to convince himself that the victim is neither nice nor innocent: ""He is such a nerd and cry-baby. Besides, he would have done the same to me if he had the chance."" Once the boy starts down the path of blaming the victim, he becomes more likely to beat up on the victim with even greater ferocity the next chance he gets. Justifying his first hurtful act sets the stage for more aggression. That's why the catharsis hypothesis is wrong.""""Our convictions about who we are carry us through the day, and we are constantly interpreting the things that happen to us through the filter of those core beliefs. When they are violated, even by a good experience, it causes us discomfort. An appreciation of the power of self-justification helps us understand, therefore, why people who have low self-esteem, or who simply believe that they are incompetent in some domain, are not totally overjoyed when they do something well; why, on the contrary, they often feel like frauds. If the woman who believes she is unlovable meets a terrified guy who starts pursuing her seriously, she will feel momentarily pleased, but that pleasure is likely to be tarnished by a rush of dissonance: ""What does he see in me?"" Her resolution is unlikely to be ""How nice; I must be more appealing than I thought I was."" More likely, it will be ""As soon as he discovers the real me, he'll dump me."" She will pay a high psychological price to have that consonance restored.""""The Milgram experiment shows us how ordinary people can end up doing immoral and harmful things through a chain reaction of behavior and subsequent self-justification. When we, as observers, look at them in puzzlement or dismay, we fail to realize that we are often looking at the end of a long, slow process down that pyramid. At his sentencing, Magruder said to Judge John Sirica: ""I know what I have done, and Your Honor knows what I have done. Somewhere between my ambition and my ideals, I lost my ethical compass."" How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self-justification will do the rest.""""The brain is designed with blind spots, optical and psychological, and one of its cleverest tricks is to confer on us the comforting delusion that we, personally, do not have any. In a sense, dissonance theory is a theory of blind spots - of how and why people unintentionally blind themselves so that they fail to notice vital events and information that might make them question their behavior or their convictions. Along with the confirmation bias, the brain comes packaged with other self-serving habits that allow us to justify our own perceptions and beliefs as being accurate, realistic, and unbiased. Social psychologist Lee Ross calls this phenomenon ""naïve realism,"" the inescapable conviction that we perceive objects and events clearly, ""as they really are."" We assume that other reasonable people see things the same way we do. If they disagree with us, they obviously aren't seeing clearly. Naïve realism creates a logical labyrinth because it presupposes two things. One, people who are open-minded and fair ought to agree with a reasonable opinion. And two, any opinion I hold must be reasonable; if it weren't, I wouldn't hold it. Therefore, if I can just get my opponents to sit down here and listen to me, so I can tell them how things really are, they will agree with me. And if they don't, it must be because they are biased.""""As fallible human beings, all of us share the impulse to justify ourselves and avoid taking responsibility for any actions that turn out to be harmful, immoral, or stupid. ... Most people when directly confronted with proof that they are wrong, do not change their point of view or course of action but justify it even more tenaciously.""""Just as we can identify hypocrisy in everyone but ourselves, just as it's obvious that others can be influenced by money but not ourselves, so we can see prejudices in everyone else but ourselves. Thanks to our ego-preserving blind spots, we cannot possibly have a prejudice, which is an irrational or mean-spirited feeling about all members of another group. Because are are not irrational or mean-spirited, any negative feelings we have about another group are justified; our dislikes are rational and well founded. It's theirs we need to suppress. Like the Hasids pounding on the Unprejudiced door at the Museum of Tolerance, we are blind to our own prejudices.""""When two people produce entirely different memories of the same event, observers usually assume that one of them is lying. Of course, some people do invent or embellish stories to manipulate or deceive their audiences, as James Frey notably did with his bestseller A Million Little Pieces. But most of us, most of the time, are neither telling the whole truth nor intentionally deceiving. We aren't lying; we are self-justifying. All of us, as we tell our stories, add details and omit inconvenient facts; we give the tale a small, self-enhancing spin; that spin goes over so well that the next time we add a slightly more dramatic embellishment; we justify that little white lie as making the story better and clearer - until what we remember may not have happened that way, or even may not have happened at all.""""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives. An appreciation of the distortions of memory, a realization that even deeply  felt memories might be wrong, might encourage people to hold their memories more lightly, to drop the certainty that their memories are always accurate, and to let go of the appealing impulse to use the past to justify problems of the present. If we are to be careful about what we wish for because it might come true, we must also be careful which memories we select to justify our lives, because than we will have to live by them.""""For any theory to be scientific, it must be stated in such a way that it can be shown to be false as well as true. If every outcome confirms your hypotheses that all men unconsciously suffer from castration anxiety; or that intelligent design, rather than evolution, accounts for the diversity of species; or that your favourite psychic would accurately have predicted 9/11 if only she hadn't been taking a shower that morning; or that all dolphins are kind to humans, your beliefs are a matter of faith, not science.""""Our implicit theories of why we and other people behave as we do come in one of two versions. We can say it's because of something in the situation or environment: ""The bank teller snapped at me because she is overworked today; there aren't enough tellers to handle these lines."" Or we can say it's because something is wrong with the person: ""That teller snapped at me because she is plain rude."" When we explain our own behavior, self-justification allows us to flatter ourselves: We give ourselves credit for our good actions but let the situation excuse the bad ones. When we do something that hurts another, for example, we rarely say, ""I behaved this way because I am a cruel and heartless human being."" We say, ""I was provoked; anyone would do what I did""; or ""I had no choice""; or ""Yes, I said some awful things, but that wasn't me - it's because I was drunk."" Yet when we do something generous, helpful, or brave, we don't say we did it because we were provoked or drunk or had no choice, or because the guy on the phone guilt-induced us into donating to charity. We did it because we are generous and open-hearted.""""Did Charles Graner and Lynndie England know what they were doing, let alone believe they were ""doing evil"" while they were deliberately inflicting pain and humiliation on their Iraqi prisoners and then laughing at them? No, they didn't, and that is why Amos Oz is wrong. Oz didn't reckon with the power of self-justification: We are good people. Therefore, if we deliberately inflict pain on another, the other must have deserved it. Therefore, we are not doing evil, quite the contrary. We are doing good. The relatively small percentage of people who cannot or will not reduce dissonance this way pay a large psychological price in guilt, anguish, anxiety, nightmares, and sleepless nights. The pain of living with horrors they have committed, but cannot morally accept, would be searing, which is why most people will reach for any justification available to assuage the dissonance. In the previous chapter, we saw on a smaller scale why many divorcing couples justify the hurt they inflict on each other. In the horrifying calculus of self-deception, the greater the pain we inflict on others, the greater the need to justify it to maintain our feelings of decency and self-worth. Because our victims deserved what they got, we hate them even more than we did before we harmed them, which in turn makes us inflict even more pain on them.""""But what are we supposed to do in our everyday lives? Call an external review board of cousins and in-laws to adjudicate every family quarrel? Videotape all parental interrogations of their teenagers? In our private relationships, we are on our own, and that calls for some self-awareness. Once we understand how and when we need to reduce dissonance, we can become more vigilant about the process and often nip it in the bud; like Oprah, we can catch ourselves before we slide too far down the pyramid. By looking at our actions critically and dispassionately, as if we were observing someone else, we stand a chance of bring out of the cycle of action followed by self-justification, followed by more committed action. We can learn to put a little space between what we feel and how we respond, insert a moment of reflection, and think about whether we really want to buy that canoe in January, really want to send good money after bad, really want to hold on to a belief that is unfettered by facts. We might even change our minds before our brains freeze our thoughts into consistent patterns.""""Humbling yes, but ultimately that's the point. Understanding how the mind yearns for consonance, and rejects information that questions our beliefs, decisions, or preferences, teaches us to be open to the possibility of error. It also helps us let go of the need to be right. Confidence is a fine and useful quality; none of us would want a physician who was forever wallowing in uncertainty and couldn't decide how to treat our illness, but we do want one who is open-minded and willing to learn. Nor would most of us wish to live without passions or convictions, which give our lives meaning and color, energy and hope. When confidence and convictions are unleavened by humility, by an acceptance of fallibility, people can easily cross the line from healthy self-assurance to arrogance. In this book, we have met many who crossed that line: the psychiatrists who are certain that they can tell if a recovered memory is valid; the physicians and judges who are certain that they are above conflicts of interest; the police officers who are certain that they can tell if a suspect is lying; the prosecutors who are certain that they convicted the guilty party; the husbands and wives who are certain that their interpretation of events is the right one; the nations who are certain that their version of history is the only one.""""Most Americans know they are supposed to say ""we learn from our mistakes,"" but deep down, they don't believe it for a minute. They think that mistakes mean you are stupid. Combined with the culture's famous amnesia for anything that happened more than a month ago, this attitude means that people treat mistakes like hot potatoes, eager to get rid of them as fast as possible, even if they have to toss them in someone else's lap."""
265,0151010986,http://goodreads.com/user/show/8435102-joan,3,"Why is it so hard for us to admit we have made a mistake? Why do we justify our actions? Why is it so hard to change our minds when we think we are right?The authors wrote this book with a goal of understanding those behaviors. I learned tons about why we say what we do to ourselves. Self-justification, for example. We convince ourselves we made the best choice possible. Unfortunately, that blocks us from seeing our errors and learning from them.I read about cognitive dissonance and how it changes our perception. When we see disconfirming evidence, we will criticize the source (fake news), distort or outright dismiss it. Maintaining the belief is more important than truth. And we have confirmation bias, the reason it is so hard to change our minds when we have made a firm decision. I also learned much about blind spots, how our memories change (or we change them purposely), and false memories. The authors give many examples of interrogators (such as child psychologists) manipulating people to confess to crimes or report non-existing events. They give examples of law enforcement officials and prosecutors refusing to admit mistakes even when DNA evidence finally proves them wrong.Rounding out this informative book are thoughts on the price paid for for justifying decisions that cause pain to others. For example, international acts are justified by saying our deeds were bad but not nearly as bad as theirs.The authors end the book reminding us of the benefits of admitting mistakes. There is a positive effect. For politicians, admitting a mistake results in constituents admiring the person is big enough to admit wrong and desire to learn from mistakes.This is an interesting book that is very informative and easy to read. I really found it enlightening in explaining much of the rhetoric we hear today."
266,0151010986,http://goodreads.com/user/show/28157679-susan-s-frederick,5,"Really opened my eyes to bias and lenses that are different for each of us, but have profound effect on how we see things, remember things, feel things. Fascinating."
267,0151010986,http://goodreads.com/user/show/4134989-chuck,4,"A well written exposure of dissonance avoidance, self-justification, confirmation bias and other forces that effect us all. The examples and insights here are especially helpful in understanding why ourself and others make mistakes, defend actions, and choose self-preserving narratives. A revelation into neural, natural wiring. A brave look into the mirror as well as the boundaries of tolerance we construct for others. Keen, practical eye-opening read. "
268,0151010986,http://goodreads.com/user/show/32598115-becky,5,This was an interesting look at how our minds work to dissociate with problems and errors in judgement.
269,0151010986,http://goodreads.com/user/show/2251009-esteban-del-mal,4,"Cognitive dissonance: The mental discomfort experienced by a person who holds two or more contradictory beliefs, ideas, or values. This discomfort is triggered by a situation in which a person's belief clashes with new evidence perceived by the person. When confronted with facts that contradict beliefs, ideals, and/or values, people will try to find a way to resolve the contradiction to reduce their discomfort (~squaring a circle).Cognitive bias: A systematic pattern of deviation from norm or rationality in judgment. Individuals create their own subjective social reality from their perception of the input. An individual's construction of social reality, not the objective input, may dictate his or her behavior in the social world; thus, cognitive biases may sometimes lead to perceptual distortion, inaccurate judgment, illogical interpretation, or what is broadly called irrationality. Catharsis: The psychodynamic principle of emotional release. It's a bullshit theory leftover from Freud. Self-justification: How, when a person encounters cognitive dissonance or a situation in which a person's behavior is inconsistent with his/her beliefs, that person tends to justify the behavior and deny any negative feedback associated with the behavior. Naive realism: The human tendency to believe that we see the world around us objectively and that people who disagree with us must be uninformed, irrational, or biased.Totalitaian ego: a) The ego/self is an organization of knowledge; b) ego/self is characterized by cognitive biases analogous to totalitarian information-control strategies, and; c) these totalitarian-ego biases function to preserve organization in cognitive structures.Reconstructive memory: A theory of memory recall in which the act of remembering is influenced by various other cognitive processes including perception, imagination, semantic memory, and beliefs. People view their memories as being a coherent and truthful account of episodic memory and believe their perspective is free from error during recall; however, the reconstructive process of memory recall is subject to distortion by other intervening cognitive functions such as individual perceptions, social influences, and world knowledge, all of which can lead to errors during reconstruction. [REPRESSED MEMORIES DO NOT EXIST]Source confusion: An attribute seen in different people's accounts of the same event after hearing people speak about the situation (for example, a witness who heard a police officer say someone had a gun who then states he/she saw the gun).Anomie: A condition in which society provides little moral guidance to individuals. This state evolves from conflict of belief systems and causes a breakdown of social bonds between an individual and the community. In a person, this condition can progress into a dysfunctional ability to integrate within the normative situations of his/her social world (for example, an unruly personal scenario that results in fragmentation of social identity and rejection of values). The term is commonly understood to mean normlessness.Imagination inflation: The finding that imagining an event which never happened can increase confidence that it actually occurred.Confidence-accuracy relationship: As one's confidence increases, so does one's level of accuracy (or belief therein).Benevolent dolphin problem: Every once in a while, a news story appears about a shipwrecked sailor who, on the verge of drowning, is nudged to safety by a dolphin. It is tempting to conclude that dolphins must really like human beings, enough to save us from drowning. But wait—are dolphins aware that humans don’t swim as well as they do? Are they actually intending to be helpful? To answer that question, we would need to know how many shipwrecked sailors have been gently nudged further out to sea by dolphins, there to drown and never be heard from again. We don’t know about those cases because the swimmers don’t live to tell us about their evil-dolphin experiences. If we had that information, we might conclude that dolphins are neither benevolent nor evil; they are just being playful.Effort justification: A person's tendency to attribute a value to an outcome which he/she had to put effort into achieving which is greater than the objective value of the outcome (i.e., the more effort put into something, the more it is valued).Implicit personality theory: The specific patterns and biases an individual uses when forming impressions based on a limited amount of initial information about an individual or situation."
270,0151010986,http://goodreads.com/user/show/11966043-lia,5,"4.5 starsI think this is one of the best non-fiction books I've ever read. It is so fascinating and it is so well-written. I've learned so much, about others and about myself. I honestly think that reading this book makes you a better person. I couldn't recommend it more."
271,0151010986,http://goodreads.com/user/show/23790728-amani,5,This was a very interesting and informative read. 
272,0151010986,http://goodreads.com/user/show/522647-kathy,4,"I'm so depressed. Humans, grrr. If you've ever wondered why people won't admit mistakes even in the face of verifiable truth contradicting their actions or beliefs, this book explains why. With sections on cognitive dissonance, why we think we're above outside influence, memory (yes, we make up our own ""memories""), scientific research fallacies, law enforcement/prosecution proceedings and relationship killers the gamut is pretty much covered. And, it's depressing. Did I mention that already? Well, it bears mentioning twice. We humans are geared to stick to our figurative guns no matter what. I have no hope for our current political unrest in the USA to get better any time soon. Sigh."
273,0151010986,http://goodreads.com/user/show/64733542-nafisa,5,"""A nation's character, and an individual's integrity, do not depend on being error-free. It depends on what we do after making an error.""Once in a while, I come across a book that makes me question my self-concept; this book is one of them. Broadly, it is about cognitive dissonance -- the psychological stress we face when our actions contradict our beliefs and ideals. Since we don't like to think of ourselves as incompetent or ill-intentioned, our natural tendency is to convince ourselves that we did the right thing. Mindless self-justification in the face of cognitive dissonance can have far-reaching (and often devastating) consequences, and the authors do a commendable job of documenting such examples from numerous distinct domains ranging from the criminal justice system, politics, medicine, and even marriage and relationships. A fresh set of ideas, quite compelling, and sometimes challenging to read as they force you to constantly self-reflect. I highly recommend it to anyone with an interest in psychology. The book is not intended to be self-help but offers a lot of scope for personal growth."
274,0151010986,http://goodreads.com/user/show/3669193-mah-ebr,5,i think everyone should read this one! 
275,0151010986,http://goodreads.com/user/show/901342-jacob,4,"This covers ground related to Evil Genes: Why Rome Fell, Hitler Rose, Enron Failed, and My Sister Stole My Mother's Boyfriend and The Honest Truth About Dishonesty: How We Lie to Everyone--Especially Ourselves, but it's specifically about self-justification. It's attempting to answer the question ""Why do people self-justify obvious mistakes?"" and look at the impact of doing so. It's pretty straightforward and quite readable.Self-justification is a useful and even essential way for humans to protect their ego and mental health, but it can get pretty out of whack. Self-justification is not only sad when it helps us decide to do things we shouldn't, it's extra sad when people do things they shouldn't only because they are trying to support an existing self-justification for a previous bad decision. One of the elaborated examples is when innocent people go to jail: it's bad enough when police and attorneys justify acting unethically in order to convict someone they ""know"" is guilty. Where it becomes absolutely unconscionable is where they work hard to prevent people from being proven innocent after the fact so they don't have to admit screwing up.On a lighter note, with books about human fallibility you have to chuckle when the authors display the very fallibility they're decrying. In one case, they claim to be certain about someone's motivation for making poor remarks without allowing for those remarks to be caused by that person looking for any excuse to self-justify behavior. In another case, they berate therapists for not thinking scientifically and not examining the disconfirming cases, then talk about the Gottmans' work on predicting divorce without examining the disconfirming cases (where the Gottmans predicted divorce and were wrong). They mention a case where of 10 of 47 couples were predicted to divorce, all 7 who did divorce were predicted ones. Of the remaining 40, all they say is that the 90% accuracy is impressive. But they don't address that 30% of the predicted divorces didn't happen, which pokes a hole in their nice theory about self-justification causing divorce. That wouldn't be a problem if they hadn't already spent a chapter bagging on therapists for having pet theories without looking at evidence that would contradict the theory.One of the reasons you chuckle over those kinds of mistakes instead of criticizing is because we ALL do those things. I'm not immune from doing those very same things, and neither is anyone else. But we might become less that way if we are aware of the phenomenon and try to identify when we are justifying ourselves."
276,0151010986,http://goodreads.com/user/show/7399266-camie,4,"I should start by saying I find social psychology fascinating! This book is about cognitive dissonance , which basically means having two conflicting beliefs and the measures we will resort to in order to defend and justify our beliefs , decisions, and actions. Backed by much research, this very insightful book explains how we all are capable of self deception, why we do it, why it is harmful, and how to overcome the very human mechanism of justifying our foolish beliefs, improper actions, poor decisions, and hurtful acts, and more importantly how to keep small things from escalating to disastrous proportions. Looking at everything from political situations, criminal acts, war, marriage, and personal levels it offers answers to how impossible atrocities come about , one justification at a time. ""How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self justification will do the rest."" From the politician who can't publically admit his actions, the torturer who feels no guilt, to the person who will say anything to win an argument, this book explains why it is so easy to see the hypocrisy of others while being totally blind to our own. Co-written by Elliot Aronson, author of The Social Animal , a great textbook, this is a very readable informative book. The introduction is called Knaves, Fools, Villains, and Hypocrites: How Do They Live With Themselves.... lol how do we ?? 4 stars"
277,0151010986,http://goodreads.com/user/show/51519663-diana-nahirna,5,"Well, that explains a lot of my recent purchases, Iraq, and why marriages fail. "
278,0151010986,http://goodreads.com/user/show/1974052-milan,5,"Mistakes Were Made (But Not by Me) is quite an enlightening book by Carol Tavris and Elliot Aronson. The authors examine our deep-rooted tendencies to underplay our faults and errors and to exaggerate the mistakes of others, especially when they go against us. ""Cognitive dissonance occurs when a person holds two or more contradictory beliefs, ideas, or values, or participates in an action that goes against one of these three, and experiences psychological stress because of that."" Two lessons from this theory: “First, the ability to reduce dissonance helps us in countless ways, preserving our beliefs, confidence, decisions, self-esteem, and well-being. Second, this ability can get us into big trouble.”The self-justification mechanisms like cognitive dissonance, confirmation bias, and fabricated memory play such an important role in our lives that they are hard to ignore. The authors provide very vivid examples from politics, therapy, conflict, wars, marriage, police and court procedures to show how these biases work. A few important lessons: •	 “Most human beings and institutions are going to do everything in their power to reduce dissonance in ways that are favorable to them, that allow them to justify their mistakes and maintain business as usual.” •	“Most people, when directly confronted by evidence that they are wrong, do not change their point of view or course of action but justify it even more tenaciously. Even irrefutable evidence is rarely enough to pierce the mental armor of self-justification.”•	Our ‘mistake-phobic’ culture causes people not to learn from their mistakes.•	Naive realism: the believe that everyone else sees the world as we do•	We all self-justify as a way to protect against cognitive dissonance, whether positively or negatively.•	Memories are easily modified to fit a narrative to reduce cognitive dissonance.•	We must be careful to not allow memory distortion to justify previous decisions.•	Therapists should be very concerned about confirmation bias, their expert assessments and also in their evaluations of people.•	Confessions can be elicited from accused legally by using deceit, trickery, etc.•	Successful couples will give the benefit of the doubt to their partners, just as they would to themselves. Unsuccessful couples do the opposite.•	We must strive to take self-justification into account in our lives and relationships to prevent incorrect decisions making.Two things to keep in mind – our personal life will suffer if we don’t admit our mistakes and society will work better if people admitted when they’re wrong."
279,0151010986,http://goodreads.com/user/show/28602450-vladyslav-sitalo,4,"You think about yourself as a reasonably nice person, with not perfect but good enough memory. Maybe you've done some things in your life, that you don't particularly like, but you think that in most cases, given the situation you were in, most of the people would've done the same.So you ain't perfect but better than the most, right?Well, this book would get you to at least question, how accurate is the description above. And it will also tell you how come you (and most of the people, even most morally flawed, from your perspective, people) think of themselves in this way.The book will tell you how your mind is desperately trying to maintain the self-image, you have about yourself and protect beliefs your hold. How it change your perceptions of things around you to fit this image/beliefs. And here comes more fun: it also employs your memory to justify your current self-perception/beliefs. So your memory is gradually, with each recall, become more compliant with this image. And eventually, all you left with is the nice, coherent story of your life that corresponds to your current view of yourself and your beliefs. But this story often has little or nothing to do with reality.As authors call it: Memory is your self-justifying historian (I would also highly recommend a novelette by Ted Chiang - ""The Truth of Fact, the Truth of Feeling"" as an exploration of this aspect of our memory: https://www.goodreads.com/book/show/1...).And the thing is that this process influences pretty much every aspect of your life regardless of your age/education or other things, you might think would influence the situation.So the process kicks in:When you're a nice, kind boy, who find himself in a company that is bullying a weaker guy. You don't particularly like the process but, as you want to be a part of this social group - you continue to participate in it. But there is dissonance here: how come you, as a nice, kind boy become a bully? So here the self-justification comes to your help: ""It's totally the guy's responsibility that he got bullied. Let's modify our image of the guy to leave our self-image preserved and justify what've done. Yay! And hey we're justified to continue to bully him as he is such a ....""Or let's say you're a student who don't have any strong position on cheating. You know it's generally considered a ""bad thing"" but you don't have any personal conviction either way. You haven't done it earlier because you didn't need to. But now you're in the situation when you need either cheat or fail this particular course. So situation can go in two ways from here:World 1: You've decided to cheat. ""Self-justification process: Ok we've cheated, as we know we're a generally good person, so we could not have possibly done a bad thing, so we may conclude that cheating is not a big deal"".World 2: You've decided not to cheat. ""Self-justification process: Ok we've failed the course. That's unfortunate but, well we didn't have any other option, right? We wouldn't even consider doing such a terrible thing as cheating"".Or you're a detective and you've interrogated your suspect to the point that he have given you a confession. But here comes the strong evidence (like DNA test or videotape) that he is innocent. So here it goes: ""I'm an honest infallible detective and my interrogation methods are great, and, after all, the guy has given confession after only 36 consecutive hours of interrogation. The evidence must be wrong""And let's upgrade a bit more. You're an honest politician, who is right now flying with a lobbyist on a luxury private plane to spend a nice weekend in some luxury resort. ""As we're an honest, good man, this situation can't possibly influence our political judgment in any way, right?"" (To understand how you got in this situation in a first place and for a lot of other good examples - read the book ;)The more deeply held self-belief that is contradicting to what you did the more actively you would justify the deed as the kind of deed that don't contradict this self-belief.You probably think to yourself: ""Ok maybe some of the cases described in this book can be true about me, but in most of them I would not have employed this level of self-justification""Well, the problem is that self-justification is largely unconscious process so when you do something that don't correspond to your self-image or see information that contradicts your belief - the justification process kicks in automatically in the background.So usually, you don't even notice on the conscious level that you've maybe done something wrong or that you hold a questionable belief. And correspondingly you don't have a chance to fix the situation before you internalize it as the normal state of things.That's why it's often said ""Hypocrite is obvious to all but himself""So you would probably at this point like to know - are we doomed? Can we do better? And the answer is yes we can! The book advises us to institute impartial external overview committees wherever possible (if necessary even against the will of involved people/institutions) because the external observer can usually notice an error much easier than somebody who have committed it. As he is not emotionally/financially/in other way invested in this decision.In the situations where setting up such an institutions is not feasible or reasonable (For example in the case of personal relationships), make sure that you and people around are aware and conscious about the magic of self-justification. You also can, to some level, train yourself to recognize the typical situations where the process may kick in and be especially careful when facing them. Also, be aware of the fact that this magic works on other people, so when you try to point out his/her error to somebody, be careful to do it in a way that will not make them self-defensive and more likely to justify this error.And don't be afraid to admit your errors, because as you relinquish wrong beliefs you become wiser, as you own up to your errors you gain more respect from people and you're less likely to make the same error in the future. Everybody makes mistakes, but you only can learn from yours, when you admit them."
280,0151010986,http://goodreads.com/user/show/21170365-amy-anderson,5,"I loved this book and found it so applicable to everyone. While we need justification to move forward in life and not second guess our every decision, we also need to be aware that justification can lead us to be blind sighted to truth. Its a fine line to walk. I could quote this whole book, but here are my favorites:""Self-justification is more powerful and dangerous than the explicit lie. It allows people to convince themselves that what they did was the best thing they could have done. In fact, come to think of it, it was the right thing."" p.4""Self-justification not only minimizes our mistakes and bad decision, it is also the reason that everyone can see a hypocrite in action except the hypocrite."" p.4""How in the world can they live with themselves? The answer is exactly the way the rest of us do."" p.9""Yet mindless self-justification, like quicksand, can draw us deeper into disaster. It blocks our ability to even see our errors, let alone correct them. It distorts reality, keeping us from getting all the information we need and assessing the issues clearly. It prolongs and widens rifts between lovers, friends, and nations. It keeps us from letting go of unhealthy habits. IT permits the guilty to avoid taking responsibility for their deeds."" p.9""I will look at any additional evidence to confirm the opinion to which I have already come."" Lord Molson p.17""These mechanisms provide a neurological basis for the observation that once our minds are made up, it is hard to change them."" p.19""People become more certain they are right about something they just did if they can't undo it."" p.22""Decades of experimental research have found exactly the opposite: that when people vent their feelings aggressively they often feel worse, pump up their blood pressure and make themselves angrier."" p.26""Aggression begets self-justification, which begets more aggression."" p.27""How do you get an honest man to lose his ethical compass? You get hi to take one step at a time, and self-justification will do the rest."" p.37""Parent blaming is a popular and convenient form of self-justification because it allows people to live less uncomfortably with their regrets and imperfections."" p.76""...current self-concepts blurred their memories, bringing their past selves into harmony with their present ones."" p.79""If a memory is a central part of your identity, a self-serving distortion is even more likely."" p.79""For those who are trying to remember something that never happened, writing analyzing dreams, and drawing pictures- techniques that are the staples of many psychotherapists- are all methods that quickly conflate imagination with reality."" p.86""Once the seed of belief was planted [they] began to search for confirming evidence."" p.90""...the story fits the needs of the experiences."" p.91"",,,experiences have internalized their new false memories and cannot now distinguish them from true ones. They have come to believe their own stories."" p.93""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives."" p.93""Successful partners extend to each other the same self-forgiving ways of thinking we extend to ourselves: They forgive each other's missteps as being due to the situation, but give each other credit for the thoughtful and loving things they do."" p.169""It may sometimes be hard to define good, but evil has its unmistakable odor: Every child knows what pain is. Therefore, each time we deliberately inflict pain on another, we know what we are doing. We are doing evil."" Amoz p.198""Would you rather admit you're wrong now or wait until someone else proves it?"" p.221""People will pursue self-destructive courses of action to protect the wisdom of their initial decisions."" p.222""They will treat people they have hurt even more harshly, because they convince themselves that their victims deserve it."" p.222""People who are insecure in their religious beliefs may feel the impulse to silence and harass those who disagree with them, because their mere existence arouses the painful dissonance of doubt."" p.222"
281,0151010986,http://goodreads.com/user/show/5301457-sergei-moska,4,"Although this book didn't actually teach me anything new in terms of theory (but did provide me with many details of practical cases), it nonetheless surprised me. First, I decided to read this book at this time because I've been a bit burned out from dense reading and wanted something useful but light. It was in fact both these things, but it was also far, far more depressing than I had expected. I expected this to be a “Ha ha, let's look at our foibles!” type of read. No, it's more of a “your identity is a joke and the world systematically does evil things. And so do you.” kind of experience. Structurally speaking, the book is very simple. The first part posits a simplified theory, and the rest of the book demonstrates the theory in action, in a few select areas of life. The theory is that we need to overcome the cognitive dissonance that emerges when our actions conflict with our self-image or beliefs. At such a moment, we are said to be at the top of a “pyramid” (a 2-dimensional triangle would be a better image), and the authors believe that whether or not we choose to justify ourselves to ourselves in such moments will lead us down one side of the pyramid or the other, with drastically different outcomes once we hit either side of the base of the pyramid. I may give up the idea that I'm such a great guy, or I can decide that the other person deserved the treatment, that it really wasn't a big deal, etc. The authors believe that whatever choice we make will cause us – in order to avoid further cognitive dissonance – to more extreme positions in order to justify our initial choice. A number of surprising findings come about as a result. For instance, the more helpless the victim, the more we will tend to denigrate him in order to justify our initial mistreatment of him. Beating up an angry drunk at a bar doesn't necessarily require much justification (“He was being threatening, and it's fine to beat up people that are threatening”), but participating in bullying usually does (“I'm a nice guy and beating him up, so it must be because he's a weenie who deserves to be humiliated. Plus he'd do it if he had the chance”.)A fun book to read, although it was too simplified for my taste in at least two ways. First, the authors' theory is *very* simple, and at times their application of the theory seems too universal. For instance, why do innocent people confess to crimes? The authors only seem to entertain the notion that it's in order to reduce cognitive dissonance: “I didn't do anything, but all the cops say that they have proof. The cops are honest and good people, so I must be the problem.” Yet at times this just seems dubious. The explanation is far more convincing when they apply it to the decision by the police to continue interrogation even in the absence of evidence. The second way that the book was too simplified for my taste is in its structure. After a very good exposition of their theory, I was hoping that the subsequent material would help develop the theory further. But what it turned out to be was “Here's a theory, and now we're going to show you the theory in X, Y, and Z.” This is a matter of taste, but I really don't like that format. What's more, I do think it hurts the authors, since it implies that the answer to the subtitle of the book is monolithic. I don't think that to be the case, and I suspect the authors don't either. In fairness, they do incidentally go through a number of additional mechanisms that are attached to the problem of cognitive dissonance, including a wonderful treatment on the foibles of memory, but it would have been really nice to make their answer more complex and complete, even at the risk of making it less parsimonious. Normally that kind of issue would be a big turn-off for me, but the book really is saved (for me) by their incredibly chilling accounts, especially in chapters 3-6. The writing is very clear and engaging, and the book is also thoroughly annotated, all of which makes me fall a little bit in love with the authors."
282,0151010986,http://goodreads.com/user/show/1677868-steven-peterson,4,"This is a well written, snappy book that addresses an important issue, best described by the book's title and subtitle: ""Mistakes Were Made (but not by me): Why we justify foolish beliefs, bad decisions, and hurtful acts."" The two authors, both well reputed psychologists, use the theory of cognitive dissonance as their starting point. Leon Festinger was one of the major theorists of this approach. The authors of this book simply define the perspective thus (page 13): ""Cognitive dissonance is a state of tension that occurs whenever a person holds two cognitions (ideas, attitudes, beliefs, opinions) that are psychologically inconsistent, such as 'Smoking is a dumb thing to do because it could kill me' and 'I smoke two packs a day.'"" How does one deal with this? By adopting one of the positions and then downgrading or rejecting the other. The end result is self-justification, self-deception, seeking out evidence to support the choice that we have made while rejecting evidence that does not fit with our choice. The brain itself shows evidence of the operation of cognitive dissonance. The example on page 19 of functional Magnetic Resonance Imaging (fMRI) and processing information about presidential candidates is telling. The end result is ""blind spots,"" in which people (page 42) ""fail to notice vital events and information that might make them question their behavior or their convictions."" As such, the authors note that cognitive dissonance makes mincemeat of such theoretical views as rational actor theory and psychoanalytic theory. One result of cognitive dissonance is what is called ""confirmation bias,"" the attending to evidence that supports our views and the rejection/suppression of evidence that does not support our views. Many examples are advanced to illustrate the case that the authors make. Issues include: moral lapses (e.g., Watergate participants), ""made up"" memories (raising serious questions about the whole idea of repressed memories), criminal justice system decisions on guilt or innocence, and so on. Much is at stake with cognitive dissonance as it operates. In the closing chapter, the authors try to indicate how understanding cognitive dissonance might help us to limit the damage that may occur as a result of its operation. Convincing? I'm not so sure, but this discussion does get one thinking about how we might address the harmful side effects of cognitive dissonance. A readable book that raises important issues. I think that more use of neuroscientific research could have strengthened this book that much more. Also, the work by cognitive psychologists like Kahneman and Tversky could have spoken to key points as well. This book might also profitably be read in tandem with another recent book on a similar subject, Cordelia Fine, ""A Mind of Its Own."" In addition, Linden's ""accidental Mind"" provides a perspective on related issues from a neuroscience viewpoint. "
283,0151010986,http://goodreads.com/user/show/9281934-louise,5,"Prior to reading this, I had only considered the theory of cognitive dissonance as it applied to holding two contrary opinions, the classic example being that of the racist with friends who are members of the race s/he denigrates. Tavris and Aronson demonstrate further applications of this theory and how destructive the behavior it spawns continues to be.The 1980's/90's day care scandals pre-dated the 24 hour cable cycle (imagine this being covered today by Fox) so it blipped in and out of my attention. I remember thinking how it didn't add up, but I wasn't really following it. Today, somewhere below my radar screen are the DNA absolved prisoners, and their continued incarceration doesn't add up either. Tavris and Aronson show how the professionals involved continued and continue to stick to their long fought for opinion, even as evidence pours in against it. As the dissonance theory predicts, the greater the commitment to the opinion the more the mind works to re-enforce it.The book is most convincing on the personal level such as the damage caused by the dynamics in divorce or accusations such as those made by those in the recovered memory therapies.While cognitive dissonance is undoubtedly operative, it is not the only culprit in the inability to admit mistakes. For commercial and public policy issues there is liability to be paid either through job loss, litigation, an election, or even everyday office politics. If the culprit is a principal player on a big stage, it could be a career ender for not only the decider, but his/her staff. It is not just the mind that keeps out contrary information, there is undoubtedly social support for the bad decision by those who also made the mistake or assisted in its execution. There are also families to consider, you admit the mistake, you could lose your job and there will be no college education for your kids. The books speaks of these barriers, but sticks to its purpose of illustrating the theory.For barriers beyond cognitive dissonance, I think of George Bush and the Iraq war. If he could bring himself to admit the mistake, he would face huge institutional and social acrimony from the policy makers who assisted him, the party who supported him, the military as an institution and the families who lost their loved ones. Ultimate decision makers on the Iraq War will wait, like Robert McNamara did, until the mistake is universally recognized.This is an excellent book. The authors develop their theory for the lay person with good examples from both everyday life and the world of public policy. I highly recommend it. "
284,0151010986,http://goodreads.com/user/show/2414293-adelle,3,"The authors' political biases came through as they used the beginning and the ending of the book to castigate then (2007) President George W. Bush, and to call Newt Gingrich a “hypocrite” for criticizing (now former) President Bill Clinton’s sexual affair…WITHOUT any allusion to Clinton’s defensive “I did not have sex with that woman…Miss Lewinski” statement. But most of the center sections of the book--which thankfully were relatively free of politics--- I found endlessly fascinating. Oh, how tenaciously we cling to “our version” of the story, filtering the facts so that what WE did/or didn’t do is seen to be of negligible consequence or perhaps even honorable, and what THE OTHER GUY did/or didn’t do is seen to be righteously reprehensible, obviously beyond the pale. I loved, too, the authors’ many demonstrations that the act that alienates one party or the other is not a stand-alone event. To reference Aesop, it is much more likely to be the straw that broke the camel’s back. Hurts and grievances in both parties have probably been building for some time. “Who were the victims? It depends on how many years, decades, and centuries you take into account” (206). Consider Kosovo. Consider the Crusades. As the authors describe these tragic events, IF one is not emotionally involved with one side or the other, one can see BOTH points of view. Likewise in personal relationships. “Of all the stories that people construct to justify their lives, loves, and losses, the ones they weave to account for being the instigator or the recipient of injustice or harm are the most compelling and have the most far-reaching consequences” (191). Tavris and Aronson continue, “We have all done something that made others angry at us, and we have all been spurred to anger by what others have done to us. We all have, intentionally or unintentionally, hurt another person who will forever regard us as the villain, the betrayer, the scoundrel. And we have all … [been:] on the receiving end” (191). It would seem it is seldom the absolute fault of “the other guy.” But…that would mean…and humans on the whole have SUCH a vested interest in protecting their own self-image.A interesting, engaging read."
285,0151010986,http://goodreads.com/user/show/25763919-mimi,4," This is phenomenal! .......it made me love Psychology even more.This book has a protagonist , well ,i think it's more of an antagonist (to us) named : cognitive dissonance (i am so in love with this character hhhhh) ""Mistakes Were Made But Not By Me"" discusses all SORTS of lengths human being may go in order to reduce cognitive dissonance.Acting in contradiction to what u believe (cognitive dissonance) is 'painful' 'uncomfortable' so what we do? the remedy is employed extensively by all yet little know about it : it's self justification.How it works: you hate cheating (this is your belief), it happened and you cheated once voluntarily (contradicting behavior) ====== results is cognitive dissonance ( your self image is shaken ,because your belief about 'cheating' has being shaken)Huh! now comes the remedy time : cheating isn't that bad. the exam was unfairly difficult that's why i cheated these are some of the thoughts we may have once we start justifying our actions (cheating) to reduce cognitive dissonance.OK , now let me introduce you other cognitive biases that leads u to screwing up immensely:Confirmation bias : this dude screws rational healthy discussions... for it blinds you for one side of an argument completely. You believe in one side, you keep looking for info to prove it without EVER checking the arguments and evidence the opposite view might present ( this is what makes some peoples' craniums rock-hard , never allowing the penetration of any of your ideas or arguments ) Snap decisions/judgements : this guys are super bad , if you could just turn them off when you are presented with anything which needs you opinion ....when you take a snap decision you are done for , it becomes harder to see the other angles of a person , an idea ...unless you knew how dangerous these guys are for your objectivity and try harder to make a balanced judgment. Sadly humans are hardwired with many biases that makes them fallible creatures....and without knowing them they will be extra fallible."
286,0151010986,http://goodreads.com/user/show/17485839-zena-ryder,4,"If you don't know what cognitive dissonance is, this is a great introduction. If you do know what it is, this is an easy, enjoyable read, with interesting stories and experiments that illustrate dissonance and the resulting self-justification, which will likely deepen your understanding of this all too human phenomenon. The authors also talk about the fascinating and related phenomenon of false memories — our memories tend to get distorted (or even created!) to be self-serving. I found the section on how easily children can be persuaded to have memories of things that didn't really happen both fascinating and disturbing. The authors also talk about the how police officers' confirmation bias and the need to avoid dissonance by those involved at the various stages of the justice system can and does lead to terrible miscarriages of justice.I guess the biggest thing that was missing, for me, was more detail of when we don't give in to self-justification in order to avoid dissonance. The authors do talk about this, but I would have liked more detail. I would also like more detail on people with low self esteem, who don't tend to resolve their dissonance in self-serving ways, but rather in ways that fit their self image of being incompetent, unlovable etc.While knowing about cognitive biases and flaws isn't enough to make them magically go away, the authors suggest that being aware of them should make us less confident in our own convictions and memories, especially when they are self-serving. I think that is an important lesson for anyone."
287,0151010986,http://goodreads.com/user/show/4532156-alaa-a,5,"This year I started to be more interested in social psychology books in my hope to change my default sitting to the world and understand it better, and what better way than saying I was wrong to your self and owning the mistakes to your self...Its a very challenging book to read its started to with an eases of pointing the mistakes of politics and countries and introducing the conformation biases then going to personal stories that we are confined that happened when all evidenced are against.One of the psychological insights that has been messing around with my mind is the selective memory and that even if you feel strongly sure and emotionally attached to it can be wrong or even planted made me question my memories and if I am a hypocrite the explanation for people's unwillingness to admit mistakes, even to themselves, in a variety of realms. This far-reaching BOOK tackles irrational prejudices, false memories, misjudgement as a psychotherapist, prosecuting the wrong individual, blaming one's spousethe part of repressed memory therapy of rape victimise was eye opening for me as how easy for as to follow :Cognitive dissonanceConfirmation biasI read in the book ""thinking fast and slow "" that knowing this biases dose not stop you form doing it even for the experts in this felid but it can make you stop your self and question why you think or act this way, and that is about it what you can do!! "
288,0151010986,http://goodreads.com/user/show/5856337-mark,5,"Having been put off by several popular books by social psychologists I read in recent years which I felt failed to deliver on the promised goods (""Emotional Intelligence"" and ""Social Intelligence,"" both by Daniel Goldman come quickly to mind), I was both relieved and impressed as I listened to the audiobook version of ""Mistakes Were Made.""The authors not only convincingly support and develop their thesis from start to finish, they do so in an entertaining fashion. Furthermore, the book offers plenty of opportunity for practical application for any casual reader who dares to pause to consider how his or her own pride, cognitive dissonance, confirmation biases, etc. may cause him/her to re-write history, justify themselves and their experiences, blind themselves from seeing the truth, etc. I will mention one area where the authors may possibly be a little ""off."" Toward the end of the book, they share an example of Japanese encouraging mistakes in the classroom and seem to generalize this example for Asian culture. However, across mainland China, Japan, Taiwan, and Korea, societies seems to be somewhat intolerant of mistakes. Having said all that, this is still a great book. Read it!"
289,0151010986,http://goodreads.com/user/show/2050800-kathy,1,"Although the authors have some good points about self-justification in a few sections of the book, they clearly spend way too much time on the ""problem"" and their political biases than a plausible solution to overcoming self-justification. I read the last page of the book in complete disgust as to the topic they chose to end with and completely irritated that very few solutions were offered to help minimize self-justification in ourselves as well as others. I guess I should have read the title a little closer: It states ""Why we..."" and not ""How to overcome why we..."" Also found it very fitting based on the severe bias that shone through the entire book that there was not one mention of the infamous ""I did not have sexual relations with that woman"" by Bill Clinton. Now that's a perfect example of self-justification if I've ever seen one!There is nothing more irritating to me than reading 200 pages about a problem and then getting to the end and realizing the author offered no real solutions but a ton of biased opinions. What a waste!"
290,0151010986,http://goodreads.com/user/show/1347209-jacob,5,"As much as I read, there are few books that are enlightening, educational, and entertaining enough for me to rate them so highly. This is one of those books that every time you put it down you have to run and find someone to tell what you just read. You find the content so interesting that you can't help but share it with others.The authors do a great job at explaining cognitive dissonance and how it leads to self-justification. They also apply the concepts well by focusing a chapter on a specific realm of how this impacts our world (legal interrogation, false memory recovery, etc).If you have ever read ""Leadership and Self Deception"" I think you would enjoy this book also. More of the science behind the story.Read this and then apply the information in your life. It is blessing me and those around me and I'm sure it will you."
291,0151010986,http://goodreads.com/user/show/1984886-tim-kadlec,3,"The book was full of good information, and good discussions around cognitive dissonance. It's fault, however, was that the anecdotes tended to be very politically charged, and very biased.Unfortunately, the authors bias came through very strongly in several of the examples used, and this distracts from the points the authors are attempting to make. In addition, a few of the examples felt like they didn't really fit in with the subject matter, and were instead used to continue to justify the authors biases (ironic I know)."
292,0151010986,http://goodreads.com/user/show/26434622-sophiacoming,5,"One of my favorite books! make me more aware of my silly impulses. I think understanding these limitation is the basis for having a crucial conversation, and making peace with yourself and people around you."
293,0151010986,http://goodreads.com/user/show/58909202-edu,2,"The concept is very interesting, even necessary to know, and mindblowing, wich I liked a lot. But there were many many examples and much of them from USA politics, which I don't care so much about. "
294,0151010986,http://goodreads.com/user/show/8778400-rebekka-steg,5,"This week I've been reading Mistakes Were Made (But Not by Me): Why We Justify Foolish Beliefs, Bad Decisions, and Hurtful Acts by Carol Tavris and Elliot Aronson, an absolutely amazing book, which everyone should be acquired to read.The book deals with the issue of self-justification, and the role it plays in all of our lives, from such ""minor"" issues as arguments within a relationship, to bullying, prejudicialness, torture, fraud etc.Written by two psychologist, the book is backed by research as well as real life cases and examples. It's easy to read, incredibly thought-provoking and it deals with such an important topic, which affects us all.

 Quotes ""We are all capable of believing things which we know to be untrue, and then, when we are finally proved wrong, impudently twisting the facts so as to show that we were right. Intellectually, it is possible to carry on this process for an indefinite time: the only check on it is that sooner or later a false belief bumps up against solid reality, usually on a battlefield.""- George Orwell (1946)""For example, Elliot predicted that if people go through a great deal of pain, discomfort, effort, or embarrassment to get something, they will be happier with that ""something"" than if it came to them easily. For behaviorists this was a preposterous prediction. Why would people like anything associated with pain? But for Elliot, the answer was obvious: self-justification. The cognition that I am a sensible, competent person is dissonant with the cognition that I went through a painful procedure to achieve something - say, joining a group that turned out to be boring and worthless. Therefore, I would distort my perceptions of the group in a positive direction, trying to find good things about them and ignoring the downside.""""Venting is especially likely to backfire if a person commits an aggressive act against another person directly, which is exactly what cognitive dissonance theory would predict. When you do anything that harms someone else - get them in trouble, verbally abuse them or punch them out - a powerful new factor comes into play: the need to justify what you did. Take a boy who goes along with a group of his fellow seventh graders who are taunting and bullying a weaker kid who did them no harm. The boy likes being part of the gang but his heart really isn't in the bullying. Later, he feels some dissonance about what he did. ""How can a decent kid like me,"" he wonders, ""have done such a cruel thing to a nice, innocent little kid like him?"" To reduce dissonance, he will try to convince himself that the victim is neither nice nor innocent: ""He is such a nerd and cry-baby. Besides, he would have done the same to me if he had the chance."" Once the boy starts down the path of blaming the victim, he becomes more likely to beat up on the victim with even greater ferocity the next chance he gets. Justifying his first hurtful act sets the stage for more aggression. That's why the catharsis hypothesis is wrong.""""Our convictions about who we are carry us through the day, and we are constantly interpreting the things that happen to us through the filter of those core beliefs. When they are violated, even by a good experience, it causes us discomfort. An appreciation of the power of self-justification helps us understand, therefore, why people who have low self-esteem, or who simply believe that they are incompetent in some domain, are not totally overjoyed when they do something well; why, on the contrary, they often feel like frauds. If the woman who believes she is unlovable meets a terrified guy who starts pursuing her seriously, she will feel momentarily pleased, but that pleasure is likely to be tarnished by a rush of dissonance: ""What does he see in me?"" Her resolution is unlikely to be ""How nice; I must be more appealing than I thought I was."" More likely, it will be ""As soon as he discovers the real me, he'll dump me."" She will pay a high psychological price to have that consonance restored.""""The Milgram experiment shows us how ordinary people can end up doing immoral and harmful things through a chain reaction of behavior and subsequent self-justification. When we, as observers, look at them in puzzlement or dismay, we fail to realize that we are often looking at the end of a long, slow process down that pyramid. At his sentencing, Magruder said to Judge John Sirica: ""I know what I have done, and Your Honor knows what I have done. Somewhere between my ambition and my ideals, I lost my ethical compass."" How do you get an honest man to lose his ethical compass? You get him to take one step at a time, and self-justification will do the rest.""""The brain is designed with blind spots, optical and psychological, and one of its cleverest tricks is to confer on us the comforting delusion that we, personally, do not have any. In a sense, dissonance theory is a theory of blind spots - of how and why people unintentionally blind themselves so that they fail to notice vital events and information that might make them question their behavior or their convictions. Along with the confirmation bias, the brain comes packaged with other self-serving habits that allow us to justify our own perceptions and beliefs as being accurate, realistic, and unbiased. Social psychologist Lee Ross calls this phenomenon ""naïve realism,"" the inescapable conviction that we perceive objects and events clearly, ""as they really are."" We assume that other reasonable people see things the same way we do. If they disagree with us, they obviously aren't seeing clearly. Naïve realism creates a logical labyrinth because it presupposes two things. One, people who are open-minded and fair ought to agree with a reasonable opinion. And two, any opinion I hold must be reasonable; if it weren't, I wouldn't hold it. Therefore, if I can just get my opponents to sit down here and listen to me, so I can tell them how things really are, they will agree with me. And if they don't, it must be because they are biased.""""As fallible human beings, all of us share the impulse to justify ourselves and avoid taking responsibility for any actions that turn out to be harmful, immoral, or stupid. ... Most people when directly confronted with proof that they are wrong, do not change their point of view or course of action but justify it even more tenaciously.""""Just as we can identify hypocrisy in everyone but ourselves, just as it's obvious that others can be influenced by money but not ourselves, so we can see prejudices in everyone else but ourselves. Thanks to our ego-preserving blind spots, we cannot possibly have a prejudice, which is an irrational or mean-spirited feeling about all members of another group. Because are are not irrational or mean-spirited, any negative feelings we have about another group are justified; our dislikes are rational and well founded. It's theirs we need to suppress. Like the Hasids pounding on the Unprejudiced door at the Museum of Tolerance, we are blind to our own prejudices.""""When two people produce entirely different memories of the same event, observers usually assume that one of them is lying. Of course, some people do invent or embellish stories to manipulate or deceive their audiences, as James Frey notably did with his bestseller A Million Little Pieces. But most of us, most of the time, are neither telling the whole truth nor intentionally deceiving. We aren't lying; we are self-justifying. All of us, as we tell our stories, add details and omit inconvenient facts; we give the tale a small, self-enhancing spin; that spin goes over so well that the next time we add a slightly more dramatic embellishment; we justify that little white lie as making the story better and clearer - until what we remember may not have happened that way, or even may not have happened at all.""""False memories allow us to forgive ourselves and justify our mistakes, but sometimes at a high price: an inability to take responsibility for our lives. An appreciation of the distortions of memory, a realization that even deeply  felt memories might be wrong, might encourage people to hold their memories more lightly, to drop the certainty that their memories are always accurate, and to let go of the appealing impulse to use the past to justify problems of the present. If we are to be careful about what we wish for because it might come true, we must also be careful which memories we select to justify our lives, because than we will have to live by them.""""For any theory to be scientific, it must be stated in such a way that it can be shown to be false as well as true. If every outcome confirms your hypotheses that all men unconsciously suffer from castration anxiety; or that intelligent design, rather than evolution, accounts for the diversity of species; or that your favourite psychic would accurately have predicted 9/11 if only she hadn't been taking a shower that morning; or that all dolphins are kind to humans, your beliefs are a matter of faith, not science.""""Our implicit theories of why we and other people behave as we do come in one of two versions. We can say it's because of something in the situation or environment: ""The bank teller snapped at me because she is overworked today; there aren't enough tellers to handle these lines."" Or we can say it's because something is wrong with the person: ""That teller snapped at me because she is plain rude."" When we explain our own behavior, self-justification allows us to flatter ourselves: We give ourselves credit for our good actions but let the situation excuse the bad ones. When we do something that hurts another, for example, we rarely say, ""I behaved this way because I am a cruel and heartless human being."" We say, ""I was provoked; anyone would do what I did""; or ""I had no choice""; or ""Yes, I said some awful things, but that wasn't me - it's because I was drunk."" Yet when we do something generous, helpful, or brave, we don't say we did it because we were provoked or drunk or had no choice, or because the guy on the phone guilt-induced us into donating to charity. We did it because we are generous and open-hearted.""""Did Charles Graner and Lynndie England know what they were doing, let alone believe they were ""doing evil"" while they were deliberately inflicting pain and humiliation on their Iraqi prisoners and then laughing at them? No, they didn't, and that is why Amos Oz is wrong. Oz didn't reckon with the power of self-justification: We are good people. Therefore, if we deliberately inflict pain on another, the other must have deserved it. Therefore, we are not doing evil, quite the contrary. We are doing good. The relatively small percentage of people who cannot or will not reduce dissonance this way pay a large psychological price in guilt, anguish, anxiety, nightmares, and sleepless nights. The pain of living with horrors they have committed, but cannot morally accept, would be searing, which is why most people will reach for any justification available to assuage the dissonance. In the previous chapter, we saw on a smaller scale why many divorcing couples justify the hurt they inflict on each other. In the horrifying calculus of self-deception, the greater the pain we inflict on others, the greater the need to justify it to maintain our feelings of decency and self-worth. Because our victims deserved what they got, we hate them even more than we did before we harmed them, which in turn makes us inflict even more pain on them.""""But what are we supposed to do in our everyday lives? Call an external review board of cousins and in-laws to adjudicate every family quarrel? Videotape all parental interrogations of their teenagers? In our private relationships, we are on our own, and that calls for some self-awareness. Once we understand how and when we need to reduce dissonance, we can become more vigilant about the process and often nip it in the bud; like Oprah, we can catch ourselves before we slide too far down the pyramid. By looking at our actions critically and dispassionately, as if we were observing someone else, we stand a chance of bring out of the cycle of action followed by self-justification, followed by more committed action. We can learn to put a little space between what we feel and how we respond, insert a moment of reflection, and think about whether we really want to buy that canoe in January, really want to send good money after bad, really want to hold on to a belief that is unfettered by facts. We might even change our minds before our brains freeze our thoughts into consistent patterns.""""Humbling yes, but ultimately that's the point. Understanding how the mind yearns for consonance, and rejects information that questions our beliefs, decisions, or preferences, teaches us to be open to the possibility of error. It also helps us let go of the need to be right. Confidence is a fine and useful quality; none of us would want a physician who was forever wallowing in uncertainty and couldn't decide how to treat our illness, but we do want one who is open-minded and willing to learn. Nor would most of us wish to live without passions or convictions, which give our lives meaning and color, energy and hope. When confidence and convictions are unleavened by humility, by an acceptance of fallibility, people can easily cross the line from healthy self-assurance to arrogance. In this book, we have met many who crossed that line: the psychiatrists who are certain that they can tell if a recovered memory is valid; the physicians and judges who are certain that they are above conflicts of interest; the police officers who are certain that they can tell if a suspect is lying; the prosecutors who are certain that they convicted the guilty party; the husbands and wives who are certain that their interpretation of events is the right one; the nations who are certain that their version of history is the only one.""""Most Americans know they are supposed to say ""we learn from our mistakes,"" but deep down, they don't believe it for a minute. They think that mistakes mean you are stupid. Combined with the culture's famous amnesia for anything that happened more than a month ago, this attitude means that people treat mistakes like hot potatoes, eager to get rid of them as fast as possible, even if they have to toss them in someone else's lap."""
295,0151010986,http://goodreads.com/user/show/8435102-joan,3,"Why is it so hard for us to admit we have made a mistake? Why do we justify our actions? Why is it so hard to change our minds when we think we are right?The authors wrote this book with a goal of understanding those behaviors. I learned tons about why we say what we do to ourselves. Self-justification, for example. We convince ourselves we made the best choice possible. Unfortunately, that blocks us from seeing our errors and learning from them.I read about cognitive dissonance and how it changes our perception. When we see disconfirming evidence, we will criticize the source (fake news), distort or outright dismiss it. Maintaining the belief is more important than truth. And we have confirmation bias, the reason it is so hard to change our minds when we have made a firm decision. I also learned much about blind spots, how our memories change (or we change them purposely), and false memories. The authors give many examples of interrogators (such as child psychologists) manipulating people to confess to crimes or report non-existing events. They give examples of law enforcement officials and prosecutors refusing to admit mistakes even when DNA evidence finally proves them wrong.Rounding out this informative book are thoughts on the price paid for for justifying decisions that cause pain to others. For example, international acts are justified by saying our deeds were bad but not nearly as bad as theirs.The authors end the book reminding us of the benefits of admitting mistakes. There is a positive effect. For politicians, admitting a mistake results in constituents admiring the person is big enough to admit wrong and desire to learn from mistakes.This is an interesting book that is very informative and easy to read. I really found it enlightening in explaining much of the rhetoric we hear today."
296,0151010986,http://goodreads.com/user/show/28157679-susan-s-frederick,5,"Really opened my eyes to bias and lenses that are different for each of us, but have profound effect on how we see things, remember things, feel things. Fascinating."
297,0151010986,http://goodreads.com/user/show/4134989-chuck,4,"A well written exposure of dissonance avoidance, self-justification, confirmation bias and other forces that effect us all. The examples and insights here are especially helpful in understanding why ourself and others make mistakes, defend actions, and choose self-preserving narratives. A revelation into neural, natural wiring. A brave look into the mirror as well as the boundaries of tolerance we construct for others. Keen, practical eye-opening read. "
298,0151010986,http://goodreads.com/user/show/32598115-becky,5,This was an interesting look at how our minds work to dissociate with problems and errors in judgement.
299,0151010986,http://goodreads.com/user/show/2251009-esteban-del-mal,4,"Cognitive dissonance: The mental discomfort experienced by a person who holds two or more contradictory beliefs, ideas, or values. This discomfort is triggered by a situation in which a person's belief clashes with new evidence perceived by the person. When confronted with facts that contradict beliefs, ideals, and/or values, people will try to find a way to resolve the contradiction to reduce their discomfort (~squaring a circle).Cognitive bias: A systematic pattern of deviation from norm or rationality in judgment. Individuals create their own subjective social reality from their perception of the input. An individual's construction of social reality, not the objective input, may dictate his or her behavior in the social world; thus, cognitive biases may sometimes lead to perceptual distortion, inaccurate judgment, illogical interpretation, or what is broadly called irrationality. Catharsis: The psychodynamic principle of emotional release. It's a bullshit theory leftover from Freud. Self-justification: How, when a person encounters cognitive dissonance or a situation in which a person's behavior is inconsistent with his/her beliefs, that person tends to justify the behavior and deny any negative feedback associated with the behavior. Naive realism: The human tendency to believe that we see the world around us objectively and that people who disagree with us must be uninformed, irrational, or biased.Totalitaian ego: a) The ego/self is an organization of knowledge; b) ego/self is characterized by cognitive biases analogous to totalitarian information-control strategies, and; c) these totalitarian-ego biases function to preserve organization in cognitive structures.Reconstructive memory: A theory of memory recall in which the act of remembering is influenced by various other cognitive processes including perception, imagination, semantic memory, and beliefs. People view their memories as being a coherent and truthful account of episodic memory and believe their perspective is free from error during recall; however, the reconstructive process of memory recall is subject to distortion by other intervening cognitive functions such as individual perceptions, social influences, and world knowledge, all of which can lead to errors during reconstruction. [REPRESSED MEMORIES DO NOT EXIST]Source confusion: An attribute seen in different people's accounts of the same event after hearing people speak about the situation (for example, a witness who heard a police officer say someone had a gun who then states he/she saw the gun).Anomie: A condition in which society provides little moral guidance to individuals. This state evolves from conflict of belief systems and causes a breakdown of social bonds between an individual and the community. In a person, this condition can progress into a dysfunctional ability to integrate within the normative situations of his/her social world (for example, an unruly personal scenario that results in fragmentation of social identity and rejection of values). The term is commonly understood to mean normlessness.Imagination inflation: The finding that imagining an event which never happened can increase confidence that it actually occurred.Confidence-accuracy relationship: As one's confidence increases, so does one's level of accuracy (or belief therein).Benevolent dolphin problem: Every once in a while, a news story appears about a shipwrecked sailor who, on the verge of drowning, is nudged to safety by a dolphin. It is tempting to conclude that dolphins must really like human beings, enough to save us from drowning. But wait—are dolphins aware that humans don’t swim as well as they do? Are they actually intending to be helpful? To answer that question, we would need to know how many shipwrecked sailors have been gently nudged further out to sea by dolphins, there to drown and never be heard from again. We don’t know about those cases because the swimmers don’t live to tell us about their evil-dolphin experiences. If we had that information, we might conclude that dolphins are neither benevolent nor evil; they are just being playful.Effort justification: A person's tendency to attribute a value to an outcome which he/she had to put effort into achieving which is greater than the objective value of the outcome (i.e., the more effort put into something, the more it is valued).Implicit personality theory: The specific patterns and biases an individual uses when forming impressions based on a limited amount of initial information about an individual or situation."
