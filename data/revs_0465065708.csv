,isbn,user_link,ranking,review
0,0465065708,http://goodreads.com/user/show/11004626-gwern,2,"Domingos wants to cover all of machine learning for the layman, but it winds up being a big mess. This is quite possibly the single worst thing I have read in my life about machine learning.The level of explanation veers wildly from ridiculously oversimplified to technical minutiae. It is more confusing than enlightening as it goes through topics in an almost random order, scattering them all throughout the book. (You would think that Hume's problem of induction, the underdetermination of data, Occam's razor, the curse of dimensionality, and overfitting, would all be discussed in one and the same place in order to set the stage for how the various 'tribes' work, but you would be wrong.) The manic stream-of-consciousness writing style also drives me nuts, and the little medieval-fantasy passages come off as puerile. (I smiled. Once.) The explanations are almost uniformly terrible (another reviewer asks if this is the worst explanation of Bayesian inference one has ever read; I would have to say that at least for me, this is competitive for that distinction), and most are explained as briefly as decision trees are endlessly waxed upon. Major premises like there being any really universal algorithm are poorly presented; compare Domingo's argument for there being a neural algorithm with, say Jacob Cannell's ""The Brain as a Universal Learning Machine"", where Domingos is provoking rather than thought-provoking.Content-wise, I have to seriously question the inclusion of evolutionary programming as a top-tier paradigm, and analogies hardly seem much more relevant a grouping either, and all that space comes at a huge cost of extreme superficiality about what deep learning is doing right now. Let me remark on how astounding it is to read a book whose self-proclaimed goal is to de-mystify machine learning for the layman, explain recent advances in deep learning that have created such media hype and sparked so much commercial & public & research interest, and which seems to only go from strength to strength to the point where sometimes it feels like one can hardly even skim a fascinating paper before yet another one has been uploaded to Arxiv, and which winds up doing little but explaining what backpropagation is and then passing grandiosely onto other topics and not, y'know, covering anything like solving ImageNet, caption generation, logical inference using reading of passages, etc. Or to read a decent capsule description of the general paradigm of reinforcement learning... and then see deep reinforcement learning described in a few sentences mostly to the effect that learning can be unstable - really? That is what laymen need to know about deep reinforcement learning, that - whatever it is - it can be unstable?Oh, and he offers us his thoughts on AI risk, the fruit of his decades of experience with machine learning:Relax. The chances that an AI equipped with the Master Algorithm will take over the world are zero. The reason is simple: unlike humans, computers don’t have a will of their own. They’re products of engineering, not evolution. Even an infinitely powerful computer would still be only an extension of our will and nothing to fear...The optimizer then does everything in its power to maximize the evaluation function—no more and no less—and the evaluation function is determined by us. A more powerful computer will just optimize it better. There’s no risk of it getting out of control, even if it’s a genetic algorithm. A learned system that didn’t do what we want would be severely unfit and soon die out. In fact, it’s the systems that have even a slight edge in serving us better that will, generation after generation, multiply and take over the gene pool. Of course, if we’re so foolish as to deliberately program a computer to put itself above us, then maybe we’ll get what we deserve. The same reasoning applies to all AI systems because they all—explicitly or implicitly—have the same three components. They can vary what they do, even come up with surprising plans, but only in service of the goals we set them. A robot whose programmed goal is “make a good dinner” may decide to cook a steak, a bouillabaisse, or even a delicious new dish of its own creation, but it can’t decide to murder its owner any more than a car can decide to fly away. The purpose of AI systems is to solve NP-complete problems, which, as you may recall from Chapter 2, may take exponential time, but the solutions can always be checked efficiently. We should therefore welcome with open arms computers that are vastly more powerful than our brains, safe in the knowledge that our job is exponentially easier than theirs.How I wish I was making up these arguments. (Aside from the invocation of complexity theory which is not even wrong as many problems we want AI to solve are not expressible as decision problems, the ones which are can fall into anything of 'much easier than NP-complete' or 'much harder', and a problem falling into a particular complexity class is no guarantee of safety in the first place, this sort of naiveté is sad coming from someone so enthusiastic about genetic algorithms - where researchers routinely discover that defining a good reward/fitness/evaluation function is quite difficult and they have to fight their algorithms to get a useful rather than a hilariously perversely correct answer!)Overall, I would absolutely recommend against this book for any laymen interested in statistics or machine learning. The explanations are so poor and garbled that you will either not learn anything or what you take away will be as likely to be misleading as not. You will be better off with Silver's The Signal and the Noise, reading random presentations on Schmidhuber's website, Bostrom's Superintelligence or even Hutter's Machine Super Intelligence or Domingos's own ""A Few Useful Things to Know about Machine Learning"" (which was really good) or anything really. (Suggestions are welcomed on things I can recommend for laymen instead of this...)"
1,0465065708,http://goodreads.com/user/show/6100646-brian-clegg,3,"I am really struggling to remember a book that has irritated me as much as this one, which is a shame because it's on a very interesting and significant subject. Pedro Domingos takes us into the world of computer programs that solve problems through learning, exploring everything from back propagating neural networks to Bayesian algorithms, looking for the direction in which we might spot the computing equivalent of the theory of everything, the master algorithm that can do pretty much anything that can be done with a computer (Turing proved a long time ago that there will always be some things that can't). As the subtitle puts it, this is the quest for the ultimate learning machine that will remake our world.So far, so good. Not only an interesting subject but one I have a personal interest in as I had some involvement in artificial intelligence many moons ago. But just reading the prologue put my hackles up. It was one of those descriptions of how a technology influences every moment of your life, as the author takes us through a typical day. Except 90% of his examples have only ever been experienced by a Silicon Valley geek, and those that the rest of us have come across, like algorithms to make recommendations to you on shopping websites and video streaming sites, in my experience, are always so terrible that they are almost funny.The pain carries on in part because of a kind of messianic fervour for the topic that means that the author seems convinced it is about to totally takeover the world - and like most fanatics, he presents this view while viciously attacking everyone who disagrees, from the likes of Marvin Minsky and Noam Chomsky to Black Swan author Nassim Nicholas Taleb. It's interesting that Domingos is totally dismissive of the early knowledge engineers who thought their methodology would take over the world, but can't see that his own pursuit of the 'master algorithm' (think of Lord of the Rings, but substitute 'algorithm' for 'ring') is equally likely to be a pursuit that is much easier to theorise about than to bring to success.To make matters worse, Domingos repeatedly claims, for instance, that thanks to learning algorithms it's possible to predict the movement of the stock market, or to predict the kind of 'black swan' events that Taleb shows so convincingly are unpredictable. Yet I have never seen any evidence that this is true, it seems to go totally against what we know from chaos theory, and Domingos doesn't present any evidence, he just states it as fact. (Could you really have predicted the existence of black swans before they were discovered? How about blue ones?)One other problem I have with the book is that the author isn't very good at explaining the complexities he is dealing with. I've seen many explanations of Bayesian statistics over the years, for instance, and this was one of the most impenetrable I've ever seen.I can't tell you to avoid this book, because I've not come across another that introduces the whole range of machine learning options in the way that Domingos does. But any recommendation has to be made through gritted teeth because I did not like the way that information was put across."
2,0465065708,http://goodreads.com/user/show/28709846-manuel-ant-o,4,"If you're into stuff like this, you can read the full review.Machine Learning Made Easier (or NOT!): ""The Master Algorithm"" by Pedro Domingos Published September 22nd 2015.  How can one become an expert in ML? All one needs is a basic background in (multivariate) Calculus, Linear Algebra, and Probability. ML is math. If one wants to understand the techniques, one has to understand the math. No shortcut. If one wants to start looking into the field of ML, this book is for you. If not, stay well clear. My background is in computer science and software engineering and I've been interested in ML since I can remember. In 2013 I took Andrew NG's ML class at Stanford University (for those of you who want to dive into stuff like this here are mynotes of the class; while learning the needed math can look daunting at first it is actually quite fun once you get into it), and I was never literally the same…After that I made some Python coding to get a feel for the real thing, which I’m still doing to this day. Humans ARE machines, albeit biologically-based. Billions of highly interconnected neurons receiving sensory input, lots of internal feedback, and signals that go out to motors, etc. Emotions, feelings, consciousness, are all just “concepts” we've constructed through a mixture of self-introspection and communicating with other self-introspecting machines (humans). Read on, if learning comes as second nature to you."
3,0465065708,http://goodreads.com/user/show/20749430-maria-espadinha,4,"Remembering Sophia...While reading this book , the image of Sophia was constantly assaulting my mental screen!I'm sure most of you remember that gorgeous social robot, that could blink, smile, raise an eyebrow, and was capable of 59 more facial expressions.She has been a media darling, showing herself in magazines, newspapers, tv news, talk shows,... spreading her charm all over the world.She could handle a clever conversation, make eye contact and even show some sense of humour!Sophia dreams about helping humanity building a better world, and trembles with the thought of taking a shower 😜She belongs to a project of genious-androids -- highly intelligent robots, whose main skill is solving all those mind cracking problems, human brains find so hard to unravel!According to their creators, in something like twentie years time, androids will be able to perform most of human jobs.Scary?!...My one and only fear is, by the time it happens, the ones who'll be ending like robots, will be us, common mortals! HeHe!... Just kidding! Robots will always need us around! I'm sure they will demonstrate great abilities as collaborators, but couldn't possibly 100% substitute us.The creation never surpasses its Master!Since I'm crazy about happy endings, I have a strong feeling this Humanoids Creation story will grow into a happily ever after -- Sophia's dream will come true and we'll all live and share a better world. Can't get worse, can it?!...Androids intelligence is possible, thanks to machine learning -- this book's core.Hence, if you are curious about knowing all possible scopes of machine learning, when applied to human society, this book is for you 👍I'm ending this review with a video, where you'll be watching a conversation between Sophia and Jimmy Fallon, on Tonight's Show. It’s really amazing:https://m.youtube.com/watch?v=Bg_tJvC..."
4,0465065708,http://goodreads.com/user/show/78485297-mario-the-lone-bookwolf,4,"An algorithm to quantify them, find them all, drive them into social media and tie them as customers.Please note that I have put the original German text to the end of this review. Just if you might be interested.The advantage of the best algorithm will lie in its autonomous development and improvement, to which nothing can catch up with. Just as a beginner has no chance against a professional with decades of training. However, the AI takes only moments or maybe days to surpass the level of a human master in more and more disciplines. If this is broken down to fractions of a second in the foreseeable future, any AI can not only absorb the theoretical, dry knowledge. But the application, research, and development alone, 24/7 and proceed forever.Human geniuses that will influence the development are an unpredictable factor. Critical elements for the functioning of many modern technologies were only possible through single individuals. And just a few hundred people worldwide understand this one special aspect. Before the Eureka moment, decades often passed, in which an already existing concept was therefore not feasible. Or it failed because of the technical prerequisites, an unknown factor or an overlooked mistake.An individual can really change the world in some ways. Hopefully the birth of the next century genius will take place in a country that has a decent educational system. That is an incentive for the educational systems of this world. So far, luminaries in their field, concerning the coming social influence of programmers, were nothing.Different basic concepts, secret algorithms, and various development paths expand the possibilities. Chance and research flow into each other and a broad range of approaches are being developed. Many different varieties can be made out of the 5 basic concepts probabilistic inference, support vector machines, backpropogation, genetic algorithm and inverse deduction. There can be a breakthrough at any given time in a software architecture that puts it above all others. Or mergers from different concepts and intelligence applications that complement each other. In the right balance and combination of the strengths and weaknesses of the systems, the master algorithm is likely to be hidden.The imitation of natural data processing systems, both hardware and software, is a cornerstone. And to compensate the weaknesses of these systems with the advantages of AI. Once an AI has understood the functioning of mind and brain, personality and emotion will be broken down into a logically comprehensible pattern. Both from the point of hardware (neurochemical processes) and software (ego, emotions). Humans are conditioned pattern recognition machines with reproducible and predictable functional mechanisms.Misanthropic ones can look at it this way: Endeavored to mitigate damage, one must also ask the question, how long and under how many more victims people continue to make many decisions. The hitherto man-made system shows its dysfunctionality in the history and the current state of the environment. To back on a new, better horse cannot even cause such destruction in worst case scenarios. It would be just too illogical and stupid, deeply human attributes. Too low standard for an AI. In that sense, it would be necessary for the algorithms to take people by the hand and give them an unimportant decision now and then as a reward. Otherwise, the creators should stay away from the levers of power to avoid debacles as in the past.What literally corresponds to deus ex machina is the lack of traceability of decision-making. Due to the complexity and the many thousands of specialists who work on such entities, nothing can be deciphered anymore. In principle, it is an already self-existent and functioning AI that one just can not understand anymore. And humans push all threads, decision-making processes and infrastructures in its hands. Historically, a consistent continuation of the tradition of oracles, omnipotence and blind obedience.This raises the question of the influences that could manipulate decision-making. Once again the quanta and all the levels that we do not understand yet. One knows that there is a great deal of barely understood topics lurking out of theoretical physics. Nevertheless, one accepts the decisions of an AI that makes inexplicable modes of calculation under unknown influences for essential decisions.To strive for a sci-fi scenario: nothing would be more attractive than to manipulate the oracle of a civilization that has no real control over it. For better or for worse. Nobody would notice anything.Ein Algorithmus sie zu quantifizieren, sie alle zu finden, in die sozialen Medien zu treiben und als Kunden zu binden.Der Vorteil des besten Algorithmus wird in seiner autonomen Weiterentwicklung liegen, die man so nicht mehr einholen kann. Wie ein Anfänger einem Profi mit jahrzehntelangem Training nicht das Wasser reichen kann. Nur dass die KI nur Augenblicke oder höchstens Tage braucht, um das Niveau eines menschlichen Meisters in immer mehr Disziplinen zu übertreffen. Wenn das in absehbarer Zukunft auf Sekundenbruchteile herab gebrochen ist, kann jede KI nicht nur das theoretische, trockene Wissen absorbieren. Sondern die Anwendung, Forschung und Weiterentwicklung alleine, 24/7 und für immer voran treiben.Auch menschliche Genies, die die Entwicklung noch beeinflussen werden, sind ein unvorhersehbarer Faktor. Wurden doch Schlüsselelemente für das Funktionieren vieler moderner Technologien nur durch Einzelpersonen möglich. Und nur ein paar Hundert Menschen weltweit verstehen diesen Teilaspekt. Vor dem Heureka Moment vergingen oft Jahrzehnte, in denen ein bereits vorhandenes Konzept deswegen nicht umsetzbar war. Oder es scheiterte an den technischen Vorraussetzungen, einem unbekannten Faktor oder einem übersehenen Fehler. Ein einzelner kann in mancherlei Hinsicht wirklich die Welt verändern. Es steht zu hoffen, dass die Geburt der nächsten Jahrhundertgenies in einem Land statt findet, dass ein seiner würdiges Bildungssystem hat. Das ist einmal ein Anreiz für die Bildungssysteme dieser Welt. Bisher waren Koryphäen auf ihrem Gebiet, in Relation zu dem kommenden gesellschaftlichen Einfluss von Programmierern, nichts. Verschiedene Grundkonzepte, geheime Algorithmen und unterschiedliche Entwicklungswege erweitern die Möglichkeiten. Zufall und Forschung fließen ineinander über und ein breiter Reigen an Ansätzen wird immer weiter entwickelt. Es kann jederzeit bei einer Softwarearchitektur einen Durchbruch geben, der sie über alle anderen erhebt. Oder Fusionen aus verschiedenen Konzepten und Intelligenzanwendungen, die sich gegenseitig ergänzen. In der richtigen Balance und Kombination der Stärken und Schwächen der Systeme dürfte der Meisteralgorithmus verborgen sein.Die Imitation natürlicher Datenverarbeitungssysteme sowohl bei Hardware als auch Software ist ein Grundpfeiler. Und die Schwächen dieser Systeme mit den Vorteilen der KI zu kompensieren. Hat eine KI erst die Funktionsweisen von Geist und Hirn verstanden, wird auch Persönlichkeit und Emotion auf ein logisch nachvollziehbares Muster herunter gebrochen werden können. Sowohl von der Hardware (neurochemische Prozesse) als auch von der Software (Ego, Emotionen) her. Menschen sind konditionierte Mustererkennungsmaschinen mit reproduzierbaren und vorhersagbaren Funktionsmechanismen.Misantrophisch kann man es so betrachten: Lapidar und auf Schadensbegrenzung bemüht muss man sich auch die Frage stellen, wie lange und unter wie vielen Opfern weiterhin Menschen viele Entscheidungen treffen sollen. Das bisher von Menschen geschaffene System zeigt an der Geschichte und dem aktuellen Zustand der Umwelt seine Dysfunktionalität. Auf ein neues, besseres Pferd zu setzen, kann nicht einmal in Worst Case Szenarien derartige Zerstörungen anrichten. Es wäre schlicht zu unlogisch und dumm, zutiefst menschliche Attribute. Insofern täte es Not, dass die Algorithmen die Menschen bei der Hand nehmen und ihnen hin und wieder als Belohnung eine unwichtige Entscheidung spendieren. Ansonsten sollten die Erschaffer aber weit entfernt von den Schalthebeln der Macht bleiben, um Debakel wie in der Vergangenheit zu vermeiden. Was wortwörtlich deus ex machina entspricht, ist die nicht vorhandene Rückverfolgbarkeit der Entscheidungsfindung. Aufgrund der Komplexität, der vielen Tausend Spezialisten, die an solchen Entitäten arbeiten, lässt sich nichts mehr dechiffrieren. Es ist im Prinzip eine jetzt schon autark existierende und funktionierende KI, die man schlichtweg nicht mehr verstehen kann. Und der man alle Fäden, Entscheidungsprozesse und Infrastrukturen in die Hand drückt. Geschichtlich betrachtet eine konsequente Fortsetzung der Tradition von Orakeln, Allmachtsansprüchen und blindem Gehorsam.Das wirft die Frage nach den Einflüssen auf, die die Entscheidungsfindung manipulieren können. Wieder einmal die Quanten und all die Ebenen, die wir noch nicht verstehen. Man weiß, dass da sehr viel sehr Unverstandenes in der theoretischen Physik lauert. Trotzdem akzeptiert man die Entscheidungen einer KI, die auf unerklärlichen Wegen unter unbekannten Einflüssen essentielle Berechnungen anfertigt. Um ein Sci Fi Szenario zu bemühen: Nichts wäre attraktiver als das Orakel einer Zivilisation, dass dieses selbst nicht unter Kontrolle hat, zu manipulieren. Zum Guten oder zum Schlechten. Niemand würde etwas merken. "
5,0465065708,http://goodreads.com/user/show/53209373-simon-clark,4,"This review is a combination of 3- and 5 star reviews, so on average a 4 star rating.I give these two ratings depending on who is reading this review. If you are a total novice in the world of computer science, or science in general for that matter, then this will likely be a 5 star book. It does a great job of introducing not just the concepts in machine learning, but also statistical ideas like variance, over-fitting, and even principal components. The key word there however is concepts. If you are a person with some programming or scientific research experience, such as myself, then you’ll likely find this book incredibly frustrating, though eventually rewarding.Domingos has written The Master Algorithm as a primer to the various camps of machine learning, because, as I now know, there are many ways of approaching the concept of getting a machine to think like a human. There are for example the symbolists, who allow the computer to develop rules which it applies to a set of data to come to a conclusion, e.g. whether a voter with a certain voting history will vote Republican or Democrat. By contrast there are the connectionists, who create neural networks modelled on the brain, Bayesians who view machine learning as nothing more than another application of Bayes’ theorem, and evolutionaries who allow competing, mutated programs to duke it out in an arms race of algorithmic performance. The book excels as a top-down look at the kingdom of machine learning, and offers some interesting insights into how these various camps of thought can be combined into a titular ‘master algorithm’ capable of re-discovering the sum total of human knowledge given the raw data… and then some. The last few chapters offer a mind-expanding look at how machine learning, and a master algorithm, could fundamentally reshape society and the human race itself. Curing cancer, it turns out, would be one of the minor achievements of machine learning.So far so good. A useful overview (likely useful even for those who have studied machine learning and perhaps have not explored beyond the walls of their camp of thought) and an authoritative look at the potential future of machine learning. So why as a scientist did I find this book frustrating?Apart from the style of prose, which I didn’t particularly care for (count the number of books Domingos unnecessarily name-drops in the text), my major problem with the book was the lack of mathematical detail. As the book is aimed at a general audience this is to be expected, but it is immensely frustrating to see a concept explained in a hand-wavy way using a thousand words, when that same concept could be exactly explained in a few equations and sentences of explanation. After reading this book I immediately needed to read the actual papers that are discussed (and, it should be noted, are usefully acknowledged) so that I could really understand the techniques discussed.As I said in the beginning, this won’t be a problem for the majority of readers, and if you don’t find this criticism particularly vexing then this book will likely be a 5 star read. It may well change your perception of computer science and uncover an interest that you never knew you had. However a word of caution to those with mathematical training – keep going through the waffly bits. It gets more interesting. Much, according to Domingos, like the field of machine learning itself."
6,0465065708,http://goodreads.com/user/show/12925436-annie,4,"This book is filled with complex computer science concepts. I got halfway before getting lost in most of the content. It is hard to grasp unless you've studied computer science. Essentially, this book is about the quest to create 'The Master Algorithm,' which can create all other algorithms. There won't be a need for a human to create specific applications for each desired need, like an app that is only capable of playing chess. The Master Algorithm will be able to learn how to create other apps. An analogy to the Master Algorithm is the hand, which can use tools to create everything else that humans want."
7,0465065708,http://goodreads.com/user/show/6243880-gary-beauregard-bottomley,5,"The author states that ""intuition is what you use when you don't have enough data"". The author will show heuristically how intuition is slowly being taken out of analyzing big data and being replaced with algorithms which teach themselves how to make the data speak for themselves. ""All learning starts with some knowledge"" (a quote from Hume, that the author invokes), and from Hume we know that there is a problem with induction, no matter what the particular can not prove the universal. The trick is to get from the data (the particular) to the universal and the author explains in detail the five general ways we learn and shows how they work in practice. The five ways are Symbolic (think: rational thought), Connective (modeling like the Network in the brain), Bayesian (nothing is certain and all is contingent), Evolutionary (see ""The Selfish Gene"" by Dawkins), and by Analogy.The key is to use some variations of the ways ('tribes') and have the method (algorithm) use the data to exploit the information that is within the data set and do it recursively (and as Douglas Hofstadter says ""I am a Strange Loop""). The computers are becoming faster, cheaper and can manipulate ever larger and more easily accessible data sets, and the methods have become more refined and usable. For example, brute force Bayesian methods are not used since the whole decision tree necessary for learning complex solutions are never practical and are now replaced by naive Bayesian techniques (only some of the dependent states need to be computed) giving only a small loss in overall accuracy.The overall point of the book is to show that there is evolutionary thinking going on in writing smart algorithms which are able to let the data speak for themselves and the computer scientists have a tool box of techniques which enable real objective knowledge to be extracted from the data.I like the TV show Person of Interest. Everything that ""The Machine"" does on that show can be explained by the techniques discussed in this book. This author doesn't think the computer will ever be able to think or have its own ""will"". I think this book would be an excellent lead in to the Nick Bostrom book ""Superintelligence: Paths, Dangers and Strategies"". That book does think super AI will happen and a computer will develop a 'will'. This book, ""Master Algorithm"" is an excellent primer for someone who believes the ""singularity is near"" even though the author disagrees (It's odd this author thinks the super AI is not possible because the way he starts off the book by explaining the P=NP problem and how solving that could create a master algorithm which in my way of thinking would lead to a super AI)."
8,0465065708,http://goodreads.com/user/show/7656537-ismail,2,"I like Pedro Domingos. He has some very nice accessible papers, and he seems like a nice guy (having done an online course, being open source fan, etc etc).But, this book is a pile of crap. Despite his best efforts, Domingos isn't a novelist, which makes the writing a bit cheesy. Putting that aside, I think that the book has several problems:- The entire premise of the book is that a master algorithm exist. I don't think that we have any idea about that yet.- The separation of machine learning people into groups looked to me extremely superficial. The author gives the expression that the communities are almost completely separated from each other which is far from true. Michael Jordan (arguably the biggest machine learning scientist of our time) has given contribute in neural networks in the past, as he has done in clustering, but now works more on graphical models. Andrew Ng did his college as a student of Mitchell, did his PhD with Jordan, but his current work is on the same 'group' as Hinton. - The book is confusing at times, and jumps from topic to topic. I don't know if not machine learning scientists were able to understand much from it, while on the same time, there wasn't anything interesting for people who are familiar with machine learning.- 'No free lunch' relation with 'no classifier can do better than the coin flip classifier' is arguably the worst explanation of 'no free lunch in statistics' 'theorem'. Same about Bayesian inference.- For a book that mentions a lot of time how better the data is to intuition, concluding it with complete intuition about the future of machine learning looked a bit controversial to me.On the bright side, I liked the Lord of the Ring-ish poetry about the Master Algorithm in the last chapter.1.5 stars out of 5. Hoping that Domingos sticks to scientific papers."
9,0465065708,http://goodreads.com/user/show/10327053-meghan,3,"Good overview of machine learning. The master algorithm seems like an overwhelming concept at first, but the book is very accessible for anyone who has a basic education in comp sci. However it's pretty clear that the intended audience is nerdy high school boys considering a career in machine learning, despite the author saying this book is written for everyone/anyone. Also, I can't help but find his depiction of the post-master algorithm world creepy. Call me old fashioned."
10,0465065708,http://goodreads.com/user/show/2531665-charlene,3,"Most of this book was great because it read like a short summary of what is taught in an introduction to cognitive science class. While spouting about how Bayesian stats decidedly kick frequentist stat's ass, to which I agree, the author showed how to look at the world itself, and everything in it, through a more Bayesian lens. He hammered home the central point that nothing can be understood in isolation and must rather be understood through its connection to the things around it. One more book on my list that belongs on the complexity/emergence/network shelf. Any book in that category, if it's any good at all, will be among my favorites. Adding to that, this author did a great job of covering one of my favorite subjects, Markov chains. Every time I dictate into my phone and realize that Apple has corrected ""thus"" to DOS and can recognize any computer programing term but not the science terms I dictate, I laugh to myself at the coders who create the Markov chains. They are seriously biased in favor of programmers. But in the end, that is because they are programmers:)This book does an exceptional job of explaining Bayes, providing a brief history of how it came to be used, and showing how it is at work naturally, all around us-- neurons, self driving cars, electrons, etc.In my opinion, he should have stopped before writing the last chapter. He basically ruined his beautiful book by merging it with the Selfish Gene theory and going on a rant about how humans are special. Does he know that any and every time we humans thought we were special, it turned out we were wrong? For some reason, he thinks humans will always control AI. He doesn't seem to be of the opinion that AI itself will be a mashup of human and machine, with no differentiation. He also went on to trash any advances that arise from Moore's Law, which he said was on it's last leg. Tell that to Stephen Hawking who just used tech derived from Moore's Law to create AI nanoships that will literally sail to Alpha Centauri to search for life on the earth-like planet in that system. "
11,0465065708,http://goodreads.com/user/show/11437893-oliver-sampson,5,"While coached as a guidebook to help find ""The Master Algorithm,"" the one AI algorithm ""that will rule them all"" (his words, not mine), this book is much, much more. At times written whimsically, and at times treating very advance material in a way that non-sophisticated readers can understand, the book is part history lesson, part cultural commentary, and part description of the scientific process. I work exactly in the field of Artificial Intelligence and Machine Learning, and I am definitely a member of the target audience. Maybe I'm just an ML fanboy, but I found the treatment of everything, including that of the author's own work, to be at just the right level to keep the non-specialist interested, while informing the specialist about those other areas, where he is not a specialist.The book finishes with musings about what it means to be a source of data for the corporations (and governments) that would use that data for good and/or evil. This alone makes the book worth reading. Such candor from those in the field of machine learning is really refreshing."
12,0465065708,http://goodreads.com/user/show/20308977-brian-nwokedi,3,"From a content standpoint, The Master Algorithm by Pedro Domingos is a great crash course for anyone who is interested in learning more about machine learning. But from an “ease of comprehension” standpoint, this book is far from the layman’s journey that Domingos claims it is. I found myself able to follow roughly 70% or so of the technical content of this book, and there were definitely some times that it was a bit too technical for me to completely grasp what he was trying to say. The writing at times can become circular in nature and to use a nerd joke… feels like a bit of a “circular reference” J. Based on these two components (content vs. comprehension), I believe that the Master Algorithm is a 2.5 to 3.0 star book that is worth reading if you are remotely interested in A.I., machine learning, and computer science. You just have to be comfortable with some of the complex concepts that he covers (maybe that is just me) More about the book itself… The main point that I grabbed onto and took away is that there are five distinct methods/tribes for machine learning that will have to come together to create the Master Algorithm. The five tribes/methods are as follows: 1. Symbologists (inverse deduction);2. Connectionists (backpropogation);3. Evoluntionaries (genetic algorithms);4. Bayesians (probablistic inference);5. Analogizers (support vector machines))Each of these five tribes has a piece of the puzzle that will ultimately help to create the Master Algorithm. And with this algorithm, true and grand machine learning will be able to flourish in a way that we have yet to see. The Master Algorithm is the unifier of machine learning: it lets any application use any learner, by abstracting the learners into a common form that is all the applications need to know. But as Domingos states, the future of machine learning, although bright, is very much dependent on cracking the code of this Master Algorithm. Domingos implores each of us, novice and expert alike, to play our part in the development of this future and I suggest anyone interested in this material go to the websites that are in the book and take a look. There is some pretty cool stuff out there!"
13,0465065708,http://goodreads.com/user/show/12406850-roxanne-russell,4,"Bill Gates put this book on his list of recommended reads this year. It interested me because of my work on an ed tech tool to help young adults read better and enjoy their reading experience more. To get the tool right, we have had to integrate artificial intelligence and to make it better we will need machine learning. We have experts on the team for that, but I like to know what's going on around me. I can't pretend I now fully understand machine learning, but Domingos did an excellent job surveying the field so I could get a gist of it. He lays the foundations for machine learning and then identifies 5 approaches that are being pursued now and details the formal languages they rely on:Symbolists- LogicConnectionists- Neural NetworksEvolutionaries- Genetic ProgramsBayesians- Graphical ModelingAnalogizers- Specific InstancesThroughout these explanations he explores the challenges:Complexity monsterOverfitting problemCurse of dimensionalityExploration/Exploitation dilemmaMy background in educational philosophy and epistemology helped me follow along with ease and enthusiasm as he discussed the concepts that were related to learning theories, but I could only just barely hang on for the rides through mathematical foundations. Points of interest:Machine learning helped Obama's campaign make strategic ad buying decisions in 2012.Machine learning's version of the nature v nurture debate is whether or not the brain or evolution are better models for the master algorithm. Mastering Tetris is a great step towards solving 1000s of problems because it is a basic NP completeness problem."
14,0465065708,http://goodreads.com/user/show/31565948-dan,3,"I found the Master Algorithm both enlightening and frustrating. Domingos does an excellent job explaining the 5 basic approaches to machine learning, but later in attempting to unify these fields he quickly lost me. He references information from earlier chapters as if the reader is an expert or professional, not as a novice newly introduced to the topic. My personal experience in computer science includes several college level software coding, computer hardware design, and computing mathematics courses, and even I was left behind. I feel this book falls into the uncanny valley of being too complex for the layman nonfiction aficionado yet mathematically barren for the professional researcher. I still learned a great deal (I am especially grateful for Domingos' insight on S-curves), but my feelings on the book as a whole are mixed."
15,0465065708,http://goodreads.com/user/show/4611417-x,4,"I've finally came around to finishing this book after I started reading it more than a year ago. The Master Algorithm attempts to present a high-level overview of machine learning for the non-technical reader. The author describes the five different 'tribes' of machine learning (analogizers, evolutionaries, Bayesians, connectionists, and symbolists). The author also talks about unsupervised learning and attempts (although in a very superficial way) to combine the five different tribes into one that uses a universal machine learning algorithm that he calls 'the Master Algorithm'. The book has several interesting anecdotes. I really enjoyed the last chapter that was mainly a discussion about (among other things) the future of AI, privacy, digital ethics, and the author's view of Kurzweil's looming 'singularity'."
16,0465065708,http://goodreads.com/user/show/917269-thomas,4,I definitely enjoyed and appreciated this a lot more on my second read. The key difference this time was that I've finally been digging into the machine learning world a bit and had more context on which to connect the ideas.
17,0465065708,http://goodreads.com/user/show/146952-grumpus,1,"I have an interest in this topic. I would love to ""crack the code"" on something but this was repetitious and unreadable. If you are considering this and want more detail on my opinion, please review the other 1-star reviews as I agree with nearly all of them. Could not finish."
18,0465065708,http://goodreads.com/user/show/33933505-luci,5,"""The statistician knows that prediction is hard, especially about the future, and the computer scientist knows that the best way to predict the future is to invent it, but the unexamined future is not worth inventing.""""... The greatest benefit of machine learning may ultimately be not what the machines learn but what we learn by teaching them.""Although I didn't agree with all of the points about the present and future of AI in this book and there were a lot of fanciful metaphors being tossed around, this was a very enjoyable read. Taking computer science classes about machine learning means I'm knee deep in the math and code but this allowed me to take a step back and look at AI from a greater perspective. The author explains a few common algorithms so it's also good as a tour through ML for laypeople.There just aren't enough books out there about this subject written in a non-textbook fashion. "
19,0465065708,http://goodreads.com/user/show/22427805-tiffany-c,5,"This book was an Amazon recommended read (thanks AMZ algorithm!), and I'm so grateful. It's a fascinating read about the various AI philosophies and a prediction for the future of/with machine learning. I laughed; I pondered; I learned about learning. It was a bit heavy at times on (typically mathematical) concepts that would be more easily understood by a CS major, but overall Domingo's writing style actually enabled me to understand more than I had expected. He has such a captivating and persuasive way of writing, particularly his imagery and analogies, that added depth and oftentimes humor to otherwise dry concepts.The only negative with this book is the regret I feel for not pursuing a computer science degree. :( "
20,0465065708,http://goodreads.com/user/show/13133290-semen-frish,5,"In short it's totally inspiring :) some parts on statistics and probabilities are kind of not too active and in general math made as simple to understand as it possible. The book is much more on philosophy, computer science core concepts and people learning than on artificial intelligence and machine learning. Indeed everything to know to start and go further and no to be stuck with ML is here :) Strongly recommended! #AI"
21,0465065708,http://goodreads.com/user/show/1680974-alex-zakharov,4,"I have been doing a bit of ML professionally and of course also following the avalanche of AI hype that has been sweeping through media and industry for a handful of years, and the noise is only getting louder. In fairness a decent chunk of that hype is deserved – data science is eating the world rejuvenating UBI discussions and mitochondria alike. Sure, Kurzweil is a bit crazy and Hawkins is a bit paranoid but Chinese have been mapping out IQ at a genetic level and just opened the first national gene bank a couple of weeks ago. Meanwhile it seems that ML learning MOOCs and resources are multiplying so chances are pretty soon we’ll have an army of barely competent ML engineers, akin to that infamous legion of VB “programmers” in the 90s. Against this backdrop Domingo’s book is quite good – sober, measured and mostly realistic. He gives a very nice overview of the 5 tribes of ML, their main domain of inspiration, representation of the world and primary learning methods: symbolists (logic, trees, inverse deduction), connectionists (neuroscience, neural nets, backpropagation), evolutionaries (evolution, genetic algorithms), Bayesians (statistics, belief networks, probabilistic inference), analogizers (psychology, templates, kernels). Domingo whiffs up a nice little ontological diagram of the tribes here https://rkbookreviews.files.wordpress.... The description, history and a relatively decent dive into methods of each of the tribes is the best part of the book and the reason why I bought it. It is funny that these days the media makes it sound like connectionists (deep learning etc) are the only game in town so it is healthy to take a step back to get a broader view of the playing field and gain some appreciation of the relationships and dependencies among the different approaches. I’m also happy to report that despite not relying on math Domingo doesn’t always dumb down the subject matter – the chapter on Belief Networks and Hidden Markov Models got pretty gnarly for a pop-sci book. Of course the holy grail of ML is human-level trans-domain learner capable of absorbing anything that is in principle learnable. Connectionists who dominate the discourse these days call it AGI (artficial general intelligence) which is how most people outside the field have gotten acquainted with the idea. Naturally connectionists' approach is very deep learning heavy. Domingo suggests his own version of a universal learner (i.e. master algorithm) which attempts to unify all 5 tribes in the same spirit that Maxwell unified electricity and magnetism. But Domingo is no Maxwell - his algo is cute but way too hodgepodgy. I would put my money on a more consistent approach, perhaps in the spirit of deep learning after all, but I do think we are still missing some major pieces of the puzzle and we have a few fundamental understanding gaps that need to be bridged before we get near AGI. He spends a couple of chapters on implications of ML on society and how it will affect jobs and leisure, as well as his thoughts on singularity. Pretty decent chapters but nothing you haven't heard before. He is very optimistic on the jobs but also self-contradicting: first he maintains that there is nothing to worry about and it is just another technological revolution yielding net benefits but if not and 50%+ of population is unemployable we'll simply have UBI. Well, which one is it? Mostly unemployable population even with money is a pretty radical societal change it seems to me. On singularity he dismisses Kurzweill out right and doesn't buy Bostrom's worries at all. I too am somewhat skeptical of Bostrom's argument yet Domingo's position doesn't make sense to me - after all he DOES think we'll have a master algo (aka AGI) but he doesn't give any credence to the control problem. I think that IF we do get genuine AGI then there will be a reason to worry about converging and possibly dangerous instrumental goals even if we manage to come up with a reasonable objective function.  At the tail end of the book Domingos briefly explores a pretty cute idea of how we could have virtualized models of ourselves effectively negotiating on our behalf with learning algos, and eventually virtualized models negotiating with other virtualized models for say dating or job searches. As ridiculous as it sounds I think Domingo's idea has more legs than VR-Reality conflation craze that I sometimes hear. Anyway, the main strength of the book is description of 5 ML tribes and I highly recommend it, as ML is here to stay. Last 3rd of the book is optional as you've probably been following (willingly or otherwise) the incessant AGI debates which are becoming a cottage industry of its own."
22,0465065708,http://goodreads.com/user/show/7463675-steve,4,"Finally, a factual account of machine learning to help balance out the crazy headlines that have more to do with ""The Terminator"" than reality. It doesn't get everything right, but I think that it does a solid job of piercing the veil on machine learning (at least to a degree) and should attract some outsiders to join the machine learning ranks. I'd say anyone who is spending their free time preparing to welcome their new robot overlords should read this book.Domingos sets out to describe the varied field of machine learning to a non-technical audience to show that there's no magic to it, just computers running programs like they always do (which may be equally mysterious to many people). In any event, he divides up machine learning into five ""tribes"" based on how they approach the problem of getting computers to learn from data. Writing this review as a researcher in the field, I have no problem with presenting these tribes as an organizing structure of a book about machine learning. I liked seeing them all together in one narrative. I believe the author fairly pointed out the pros and cons of each of these approaches and also which ones are attracting the most attention these days. Everyone in the field has their own biases, but since Domingos has worked across these boundaries in his career, I thought he did a good job mainly reporting the facts. (The symbolists might have gotten a bad shake, but eh, I'm not one of them so who cares?) I personally thought that the presentation of the analogizers material was a bit rough to read through - if I didn't already have experience with things like support vector machines etc., I'm not sure that I would've really understood the appeal of that particular tribe from the text.In any event, a reader is unlikely to find a better overview of the general approaches to machine learning in single place right now. Textbooks in this field tend to jump into technical details almost from the outset, providing little to no guidance as to why these techniques were developed or whether they belong to a larger family of similar concepts. Additionally, they tend to focus on algorithms from just one or two tribes per textbook, and then rush to get to the author's pet projects. Well, I guess that is where this book and typical data mining/machine learning textbooks resemble each other: entirely too much time is focused on Markov Logic Networks (MLNs) as the best approximation to the titular master learning algorithm. I remain unconvinced that MLNs are going to inherit the machine learning world, and not because I have my own pet formalization that I think should be the front runner. I just don't think it's necessary to have a master algorithm - neither as a device to lure people into reading the book nor as a scientific objective. It starts to make the book more technical than it needs to be and risks alienating its target audience, and isn't juxtaposed with competing approaches either so that readers can come to a conclusion on their own. I would've much preferred Domingos to have taken an approach of abstracting on top of the five tribes, or to examine if there is room for a new way of thinking about machine learning - a sixth tribe - rather than diving into the master algorithm discussion, but it's not the end of the world.I thought Domingos presented a lot of fun anecdotes in the book, and it was successful far more often than not. Despite some of my complaints, I hope a lot of people read this book and the population at large gets smarter on machine learning - before computers outsmart us!"
23,0465065708,http://goodreads.com/user/show/9039058-darren,4,"Machine learning is a fascinating subject, the stuff of sci-fi legend and something that is often misunderstood and feared by many. Computers are getting more and more intelligent, aided by man, yet nonetheless they are playing an increasingly important part in our lives, whether it is getting a film recommendation from Netflix or the development of driverless cars.We are not yet there with machine learning perfection. Boffins are still seeking the most powerful algorithm of all, the so-called Master Algorithm, which will not be limited to solving particular problems but will be able to learn anything and solve any problem. Scientists such as the author are leading the hunt for this magical thing – can it ever exist in the form that we expect? Who knows for sure, but it theoretically has the power to become the most powerful technology humanity has ever devised.The author has done a good job in explaining the idea and implementation of machine learning to a broad audience, bringing its current-day usage into focus through practical examples. Not every machine-learning algorithm necessarily helps us: we may feel that some are working against us when we don’t get short-listed for a job we’ve sought or if we’ve been under-rated for a pay rise. Is that the fault of the machine, those who programmed it or even the subject…?It was interesting to learn some of the different types of machine learning and the thought processes that go behind them. The author notes that hundreds of new learning algorithms are invented every year, but they’re all based on the same few basic ideas so far. The author says that there are five “tribes” of machine learning that each have their own master algorithm or way of thinking.You do not need to be a maths nerd to enjoy this book. It was a great read for the generalist and an informative support work for the more focussed specialist. The tentacles of machine learning are everywhere, even in elections and healthcare research. What the future may bring with the combination of technological development and possibly this killer algorithm remains unknown, but exciting times may be ahead of us in any case.A recommendable book that is capable of giving a lot if you let it.Autamme.com"
24,0465065708,http://goodreads.com/user/show/12700288-paul,1,"Inane verbiage with no educational content. Just constant fawning and endless lists of potential and current applications of learning algorithms. The writing is beyond tiresome. Here's just one paragraph:""You’ve reached the final stage of your quest. You knock on the door of the Tower of Support Vectors. A menacing-looking guard opens it, and you suddenly realize that you don’t know the password. “Kernel,” you blurt out, trying to keep the panic from your voice. The guard bows and steps aside. Regaining your composure, you step in, mentally kicking yourself for your carelessness. The entire ground floor of the tower is taken up by a lavishly appointed circular chamber, with what seems to be a marble representation of an SVM occupying pride of place at the center. As you walk around it, you notice a door on the far side. It must lead to the central tower—the Tower of the Master Algorithm. The door seems unguarded. You decide to take a shortcut. Slipping through the doorway, you walk down a short corridor and find yourself in an even larger pentagonal chamber, with a door in each wall. In the center, a spiral staircase rises as high as the eye can see. You hear voices above and duck into the doorway opposite. This one leads to the Tower of Neural Networks. Once again you’re in a circular chamber, this one with a sculpture of a multilayer perceptron as the centerpiece. Its parts are different from the SVM’s, but their arrangement is remarkably similar. Suddenly you see it: an SVM is just a multilayer perceptron with a hidden layer composed of kernels instead of S curves and an output that’s a linear combination instead of another S curve.""Had enough yet? There are chapters full of this drivel. This is actually representative even of parts of the book that aren't an acid trip. Just like the rest of the book this passage mentions concepts without explaining any of them and mixes everything together without any reason or structure. Who is this book for? There are in-jokes dotted around like the Jennifer Aniston one or concepts like centaurs (in relation to chess) and neither they nor their backstories are ever explained yet it's clearly aimed at the general reader."
25,0465065708,http://goodreads.com/user/show/3677821-pete,4,"The Master Algorithm (2015) by Pedro Domingos looks at machine learning and describes the possible impact of machine learning on society and provides a survey for layman of major methods used in machine learning. Domingos is a Professor at the University of Washing in machine learning who also has an online course for learning more about Machine Learning on Coursera.The book is perhaps a bit too keen in boosting machine learning, but it may be that the impact of machine learning is going to be as big as Domingos predicts. However, even if it's somewhat less machine learning has already had a substantial impact in Search, recommendations and autonomously operation vehicles. The book divides the machine learning world into five camps, evolutionist, connectionists, symbolists, Bayesians and analogizers. The symbolists use inverse deduction, the evolutionists genetic algorithms, the connectionists back propagation, the Bayesians, Bayesian classifiers, the analogizers use support vector machines. Domingos then describes how what he researching, Markov logic networks are going to provide a unifying system for all of machine learning. Domingos also provides a short an interesting critique of the singularity and machine learning. The book is fun to read if you're a programmer and are looking for some inspiration to learn some machine learning and are looking to get some awareness of machine learning. It's inspiring enough for me to make me want to go and learn more and actually program and play with some of the algorithms described."
26,0465065708,http://goodreads.com/user/show/30484141-sahaj,3,"'The Master Algorithm' (not the book) is a computer science equivalent to 'the theory of everything' of the universe.One algorithm that does it all.It is a very nice book. But at times it will throw at you some basic machine learning (ML) jargon, which, if you are not familiar with the field, you will need to Google. The author starts with examples of how ML is already part of our lives, and lists out problems still needed to be solved. Problems so complex that can only be solved by powerful ML algorithms or artificial intelligence, a subset of ML.The core of the book is to introduce you to the algorithms used in ML, their capabilities and limitations. These algorithms fall into two categories - supervised learning, and unsupervised learning.The last chapter deals with the fear of AI rising very well, arguing that the ML/AI algorithms are powerful in solving or doing only a subset of tasks which we as humans need to do in everyday life. The author argues that machines don't have a will of their own. Some good points in automation and ML taking away jobs are also there - the point here is if you are afraid of your job getting automated, automate it yourself. This way you still own it.A good book with good insights. Do read if you ever wonder how Siri works."
27,0465065708,http://goodreads.com/user/show/5931737-pedro-martinez,3,"Every time you interact with your PC or Phone, you are not only getting what you need, but you are also teaching your device about yourself. An ""algorithm"" is a sequence of instructions telling your computer what to do. The ""learning algorithms"" are the ones that create other ""algorithms."" They let Amazon recommend you what to purchase, Netflix what to watch next, or a phone camera to recognize your face. If you are interested in the topic, have a look at Pedro Domingos' ""Master Algorithm."" A compelling essay on how they have changed the way we purchase, work, and live. And how will they drastically disrupting this in the years to come."
28,0465065708,http://goodreads.com/user/show/4967521-sowmya,4,"I read this book a couple of months ago, after prebooking it on amazon and waiting for it to arrive. I really liked it despite the evangelizing tone. I felt the author succeeded in neatly summarizing most of the major ideas in machine learning, and how they are applied in developing some of the applications we use today. "
29,0465065708,http://goodreads.com/user/show/52696775-chi-tathon-kupwiwat,4,"Great book about programs that can learn and develop themselves. The most interesting part ,for me, is about methods computer scientists imprinted in these machines so that these programs can learn. Most of these methods are derived from how human learn and some derived from possibilities and abilities to manage them in feasible times and spaces."
30,0465065708,http://goodreads.com/user/show/50245822-srinath-srinath,4,"Great book, gives an overall view of how 5 groups(bayesians,analogizers,symbolists,connectionists,evolutionaries) of people have been competing and trying to solve intelligence. The technical details have been very well explained for a layman to understand."
31,0465065708,http://goodreads.com/user/show/16463508-toma,4,"It is a bit technical for someone who is not in the field or used to some of the theories presented but a great read to understand Artificial Intelligence, Machine Learning and the major schools/philosophies in the field."
32,0465065708,http://goodreads.com/user/show/20064141-maureen-fitzpatrick,4,"It might be a five star book, but this is a book that is just beyond what I understand; however, what I understand is greater having read the book."
33,0465065708,http://goodreads.com/user/show/40460162-steve-jay,5,"If you're a huge nerd and have an interest in futurology, mathematics and computers, this is a must read! Blew my mind."
34,0465065708,http://goodreads.com/user/show/38024135-theodore-kinni,3,"Probably good for budding data scientists, but it's dense and too detailed for the untutored"
35,0465065708,http://goodreads.com/user/show/15317284-carlos-vasconcelos,4,A good book for a broad audience. 
36,0465065708,http://goodreads.com/user/show/50847541-florin-grigoriu,3,"OK to recap the ML notions, the fiction style is too mainstream making the book sometime too buzz-word-ish"
37,0465065708,http://goodreads.com/user/show/76014-raghu,4,"Artificial Intelligence has gradually become a part of our routine discourse. It is because we experience it in varying degrees in even our humdrum lives. We read in the news that driverless cars are already running on our roads. When we sign on to Netflix, we see movie recommendations for us. Often, they turn out to be better than what our friends and relatives suggest to us. Websites help us save money on airline tickets more than before. Google predicts flu outbreaks before CDC has been able to do so. All this is due to Artificial Intelligence or AI for short, of varying degrees. AI is a vast field and has been an area of research since the 1950s. This book is about one branch of AI which is hot today, called Machine Learning.Historically, we have written specific computer programs to solve specific problems using the computer. Each such program is in effect an algorithm to deal with that problem. Machine learning diverges from this traditional approach. It provides computers with the ability to learn. A specific problem is solved without being explicitly programmed for it. Machine learning consists of programs that can teach themselves to grow and change when exposed to more and more data. This book goes one step further. It discusses the holy grail of Machine Learning that researchers are working on, called the Master Algorithm. Right in the first chapter, the author defines this holy grail as follows: ""All knowledge - present, past and future - can be derived by a single, universal learning algorithm"".Now, this might seem ambitious to most of us, including scientists in the field. Some might even slam it as typical of the 'techno-hubris' of Silicon Valley. But the author makes a case that a master algorithm is a feature of nature itself. He shows that there are similar examples in Neuroscience and Evolution. The book captures Machine learning succinctly by the following unwritten rule through which it works:""we must induce the most widely applicable rules we can and reduce their scope only when data forces us to do so"".There are five approaches to Machine Learning today. They are classified as the Symbolists, the Connectionists, the Evolutionaries, the Bayesians and the Analogizers. Each of them is explained briefly as follows:Symbolists believe all intelligence can be reduced to manipulating symbols just as we do in Mathematics. In simple terms, Symbolists start with some existing premises and conclusions. Then, they work backward to fill in the gaps in knowledge by analyzing existing data sets. This is called inverse deduction. Connectionists believe that we must reverse engineer the brain and achieve machine learning. This approach is called 'deep learning'. It consists of creating 'digital neurons' in the computer and connecting them in a neural network model. Google uses this approach in machine translation. It is also used in image processing.Evolutionaries believe in learning through genetic programming. This method mates and evolves computer programs the way nature evolves species. It applies the ideas similar to that of Genomes and DNA in the evolutionary process to data structures. The Genetic programming model works by quantifying the performance of data. It is used to determine the retention and propagation of algorithms in an evolutionary way.Bayesians believe in using Bayes theorem and its derivatives to learn through probabilistic inference. This method proposes a few hypotheses. Then, it assigns probabilities for the likely outcomes of applying these hypotheses. By applying more and more data to test these hypotheses, some of them become more likely than the others. In this way, we arrive at the most likely solution to the problem. This is used in spam filters on emails.Analogizers believe the key to learning is recognizing similarities between situations. This principle is called the nearest neighbour principle. One important aspect of Analogy is that it lets you learn from little data. Analogizers can learn from even just one example - You are what you resemble. Charles Darwin used Malthus' theory of the struggle for survival in society to formulate the biological theory of evolution. Niels Bohr used the solar system model to formulate his theory of the atomic model. A website like Netflix uses it in the recommendations it gives to customers. For example, let us say that someone, whose profile is similar to yours, liked the movie 'Avatar'. Then it is likely that you will like Avatar as well, if you have not seen it already. So, a recommendation of Avatar is made for you. However, all these approaches are not mutually exclusive. Machine learning uses a selective combination of them, depending on the problem. For example, in medicine, the Evolutionary approach is not preferred. The way nature learns is through making mistakes - a luxury we don't have in our societies. Doctors must diagnose in a foolproof way. For example, failing to find a tumor that is really there, is potentially much worse than inferring one that isn't. It needs optimal decisions and this where the Bayesian approach is more useful. In AI, Symbolists held sway in the first few decades of cognitive psychology. Then Connectionists held sway in the 1980s and 90s, and it is the Bayesians' time in the Sun now. The author is upbeat about the future transformations that Machine Learning will bring to our societies. He suggests that in the not too distant future, we will all have a 'digital half' which will do our bidding all 24 hours of the day. They will interact with the digital halves of every person and organization we deal with. Tomorrow's cyberspace will be a giant parallel world. It will be like a new, global subconscious, the collective id of the human race. My only caveat about the book is its prognosis for the future. There is no doubt that the future will be transformed in many ways by Machine Learning. Scientists have been mostly right about predicting the future technological inventions. On the other hand, scientists from Thomas Malthus to Paul Ehrlich to the Club of Rome have made dire predictions about the future of mankind and disaster for thickly populated countries like India and China. They were woefully wrong in this. Not all scientific advances have a smooth path to their full potential. The expected potentials of Nuclear energy and Genetically Modified crops have not materialized because of resistance in our societies. There is also resistance to Stem cells and possibilities of Human cloning. Machine learning is in its infancy now. As it develops and impacts our lives more and more, the technology is bound to make mistakes in a way that affect our lives negatively. If some of them happen to be of the dimension of the Chernobyl accident in Nuclear energy, then there may be a big backlash to the advance of AI too. The other related danger is to rely on vast quantities of data on a phenomenon which leave out key attributes of representing the phenomena correctly, but use it anyway to make crucial decisions. One example in the past of such misuse of data happened in the 1960s. Sen.Robert McNamara, Secy of Defence in the Johnson administration, went about escalating the Vietnam war by relying on 'death count of US and Vietcong soldiers' as a key data indicator of how the war was progressing. The data did not capture the will and determination of the Vietnamese communists to rid themselves of foreign occupation of their land. We all know the consequences of this key error.I enjoyed reading the book as it was educational for me and I learnt much from it. The chapters elaborating the five approaches to Machine Learning need some focus and concentration to fully understand them. Readers, who find these chapters a bit hard, can still simply read just the first 60 pages to get a very good idea of the subject. All in all, it is a great effort to present this exciting subject in a simple way."
38,0465065708,http://goodreads.com/user/show/10768018-jo-o,3,"The idea of a master algorithm is a kind of computer science saint graal. An optimal model for most problems in reality, a robust super-A.I. with the best qualities of organic brains and computer power merged. For this to happen Domingos argues that the 5 tribes of machine learning have to merge as if currently they were very different communities. Those are: symbolists (e.g. logic-based models, decision trees); connectionists (e.g. neural networks); evolutionaries (genetic algorithms); bayesians (graph theory and Bayes-inspired modelling); analogizers (support vector machines, etc.). While this is a ""cool"" vision I find it hard to argue that models can be categorized under that schematic (many hybrids, or some are just specific cases of others) or that the communities of researchers are isolated in any way. Most people with MAJOR published contributions/advances in any of the ""5 tribes"", has papers in the others... usually dozens... (and some are really important as well)!From what else I've read from Domingos I'd rather recommend his short essays, and scientific papers. The big book format gives too much space for random rambling and there are a lot of cringe sentences like random name dropping e.g. ""Kant was also a fan."" with no further exposition or mention.Ultimately, Domingos has a very solid technical view of most stuff he discusses, but then he brings a lot of his personal intuitive futuristic views that can either happen or not. His conclusions and views in more social/political problems, like how should we share our data with AI companies, are also troubling for me. Overall too much utopian gut-feeling in a book about data-centred approaches."
39,0465065708,http://goodreads.com/user/show/23963235-akshith-rao,3,"This book captures the various types of machine learning techniques and how they have progressed through time. The author, being an academician, gets too technical. Even a decent understanding of math did not prevent some pages from turning into Latin for me. If you are someone who is knee deep in math and probability and would like to get an overall picture I would definitely recommend this book to you. For everyone else, it might be better to start looking somewhere else or just skip the math side of things in this book."
40,0465065708,http://goodreads.com/user/show/7297326-jim-crocker,5,"I'm not really finished. This is the kind of book that will go on and on and on with amazing insights and revelations about AI and Machine Learning. I've already heard that it is outta date. But, hey, whaddaya gonna do? Things move fast out there. With me it moves a little slower. I read and think and read and on it goes... This book was an eye-opener for me. I discovered a whole knew point of view. Essentially, it was a paradigm shift.This is a glimpse of the future of humans and the interactions, transactions and associations that will be taking place over the coming years. It's really transformational stuff that's going on. Here's two quotes that I liked (there's a ton more):** ""Most of all, we have to worry about what the Master Algorithm could do in the wrong hands.""** ""...you also have an ethical duty to share data for the common good.""I like that last one best of all!For your convenience, you can get this wonderful book right here:www.blackdogebooks.com/redhot-pick"
41,0465065708,http://goodreads.com/user/show/1173423-peter,5,"Really nice read. Serves as an accessible introduction to machine learning whilst simultaneously outlining the respective strengths and weaknesses of its 5 different ""tribes"" and ultimately showing how they can be connected. This makes the book valuable even for machine learning practitioners. Furthermore, in these days where deep learning reigns supreme and the media make it seem it is the end-all-be-all of machine learning, this book adds a valuable historical and conceptual perspective. The derivation and description of the current best stab at the Master Algorithm is more technical though, and probably more difficult to follow for the non-technical reader.The author is very bullish in the scale and scope of the application of machine learning and he offers powerful examples of AI in the form of personal agents negotiating the world on our behalf, the enabler of systems biology, and eventually designing and enhancing humans. However I think his view is quite utopian and that he downplays several potential negative scenarios of both weak and strong AI. For instance, Domingos believes that job displacement will not be grave (the argument that more new jobs that we now can't imagine will be created than will be destroyed), and that even if this were to happen, then if it reaches critical mass (>50%), then in a democracy that majority will vote for lifelong salaries for just being alive (i.e. universal basic income). However I think there is a path-dependance here on things staying the same politically. Let's contrast it with the scenario in Yuval Harari's Homo Deus of the creation of a class of ""useless"" humans who don't have to offer anything economically nor militarily. The political power of the masses would then be greatly diminished, perhaps even up to the point of threatening liberal democracy.Looking even further into the future, he does not take into account the dangers of reductionist goals. He basically argues that because machines don't have goals of their own, we are safe. Nick Bostrom belabors the dangers of strong AI in his book Superintelligence.In conclusion, although I think the dangers of AI were downplayed, I think it was a great read. I would recommend pairing this book (written by an machine learning researcher & practitioner) up with Homo Deus (written by a historian) and Superintelligence (by a philosopher) for a more holistic view if your interest is primarily on the (future) impact of AI."
42,0465065708,http://goodreads.com/user/show/38621776-an-l-tuncel,1,"Disappointing. This book has no scientific value. No one should read this book, not even teenagers (they will get confused). "
43,0465065708,http://goodreads.com/user/show/19014583-t,4,"I enjoyed this book overall but had some frustrations with it. Enough so that it was a real debate between 3 and 4 stars for me; I'm giving it 4 now as a benefit of the doubt but I may reread and drop it to 3 if it doesn't seem better.First, the topic couldn't be more relevant and interesting to our time; both for buzz word purposes and real discussion of the current state of the field the book was interesting. That said, I had several annoyances. First, the author seemed quite taken with creating fanciful allegories for things that were clear attempts to be poetic or entertaining and in practice were often just kind of dumb. In the more lower level cases they would help add to understanding, but the broader they got the more you felt like you were wasting your time while he talked about wandering through a city and spent time describing the turrets or telling you what you suddenly remembered or felt. Ick. Second, the premise at the start of the book seemed to be that anyone could understand and contribute to all of the field and the rest of the book seemed, to me at least, to rather disprove that. I think he tried to make this accessible to all and thus went a step too far; he'd have been better off saying the requirements of the field are not so high as many fear and thus are accessible to many more than would expect it. Saying anyone could do it even without complicated math just seemed inaccurate even using his own description by the end.Finally, the overall structure of the book and the discussion of the five ""tribes"" left me somewhat uncertain. I couldn't decide if that was an actually useful description or more confusing than helpful. In part this was because my reading was rather fractured through time so I'm reserving judgment of this for a more thorough reread.All that said, the book was still an interesting overview of the current state and problems of the machine learning world and, when not trying to wax poetic, was a pretty good and understandable summary of those and a nice encouragement for those of us on the edge of the field to get into it."
44,0465065708,http://goodreads.com/user/show/3550209-adrian,5,"Who knew the 'S' curve was the most important function ever?I picked up ""The Master Algorithm"" hoping it would serve as a primer as I began my journey into the world of deep learning. At first, I found it overly figurative and difficult to follow so I stopped reading it. After about 6 months of Andrew Ng YouTube videos, SciKit Learn, PyImageSearch, and other well-organized tutorials, I revisited the book and fell in love with it. What I appreciated most was the discussion of the 5 tribes of machine learning and how he was able to merge the mentality of the different camps. I'd consider myself an Analogizer and I work with a Bayesian. Often, it feels like we are talking different languages. I had to chuckle a few time as this book addressed this common dynamic.I enjoyed Chapter 9 the most with his fanciful depiction of a continent divided into 5 territories: Symbolist, Connectionists, Evolutionists, Bayesians, and Analogizers with Master Algorithm serving as the capital city. He did an excellent job conceptualizing how different aspects of each 'tribe' would contribute to the one unifying, but elusive, algorithm. He went to great lengths to establish his sci-fi bona fides with references to Lord of the Rings, The Matrix, Robocop, and much more. My favorite came when he was discussing Support Vector Machines and visualizing the border between classes as a snake slithering down the no-man's-land with the support vectors serving as mines. It's ""like the sandworms in Dune: big, tough, and able to survive a few explosions from slithering over landmines but not too many"". A five-star rating was locked after that."
45,0465065708,http://goodreads.com/user/show/5858138-nic-brisbourne,4,"Domingos provides a detailed and pretty technical explanation of five different areas of artificial intelligence:* Symbolists - observe and inducer Dix logic in the world and code it - works well in limited domains and highly explainable, but impossible to scale* Neural networks - infer rules from large amounts of data to by looking at training sets - if it's seen enough pictures of cats it can compute the probability that a new image is a cat* Genetic algorithms - define an objective and let evolve according to rules, and then keep the solutions that beat fit the desired goal, and then repeat. Key is choosing the rules and fit algorithms well* Bayesians and probabalistic influence- great at finding categories and classifying things* Analogisers and Support Vector Machines - good for spotting similarities between things and making predictions about other things that might be similar - if I have flu, and we are friends but don't live in the same town, what is the chance that you also have flu?This stuff is quite dense! I have a solid grounding in maths, science, and stats but haven't practiced for decades and understood most of it, but had to read slowly. Domingos writes well and with humour which makes reading much easier. Finally - I should also say that he does a good job of making it real with examples and a semi-good job of predicting where the future will take us. "
46,0465065708,http://goodreads.com/user/show/47032429-kenta-suzuki,4,"Pedro Domingo describes the machine learnings from its origin to now, and how it can be used in the future. He purports that the Master Algorithm be the one that is ultimate goal of machine learning or universal learner as he call it. This algorithm will be replete with or fall into the intersection of the five bailiwicks: Symbolists, Connectionists, Evolutionaries, Bayesians, and Analogizers. For symbolists, Inverse Deduction is algorithm, Gradient Descent for Connectionists, Genetic Search for Evolutionaries, Probabilistic Inference for Bayesian and Constrained Optimization for Analogizers. For instance, Netflix uses k-nearest- neighbor algorithm, which finds the correlations with each others, to create recommendation system.This algorithm is so important that recommender system consists of a third of Amazon's business. In the future, he claims, that there will be one version of yourself who or which basically do most of the things on behalf of you faster than you could. He also argues that the fears some people have toward AI or Singularity will be relinquished if humans deal with them carefully. For instance, there will no infinite growth of AI as is the case with Moore's law. It will eventually taper off as S curve deliniates. This book will gives some prelude to those areas for those who do not have solid backgrounds for statistics or machine learning. "
47,0465065708,http://goodreads.com/user/show/51672399-david,4,"Domingos' attraction to analogical learning leads him to fill this book with analogies for almost everything he talks about. I wonder if a computer develops consciousness would they find it as annoying as I did? Other than this nuisance, the book gives a great overview of the history and state of machine learning. The various subfields outlined in the novel are very well abstracted to show the significant similarities and differences between them.However, Domingos' view of the future, as stated in the last chapter, wouldn't be the most inspiring. The possibility of an algorithm that could predict cancer treatment through genome mapping is surely an excellent use of machine learning but his belief that war will be ""fought"" by between different learners isn't something I'm looking forward to. The author assures the reader of this certainty. For me, this is just a stark reminder that technology advancement does not necessarily advance society in a positive way. In the case of fighting algorithms, there will be a victor and whomever or whatever possesses this technology will be the one with the power to rule a lot of important aspects in this world. This scenario just looks like a continuation of the current trend in the concentration of wealth and power into the hands of the few and not the many."
48,0465065708,http://goodreads.com/user/show/8146846-satyabrata-mishra,5,"Pedros Domingos does a fascinating job describing complex machine learning algorithms in forms of simple (and sometimes silly) metaphors and examples; like dividing the different forms of AI-engineers into tribes and walking down the cities of their design.For someone who wants to peek into machine learning and understand the powers and faults of each algorithm, the master algorithm is a great choice. I picked it up as a pre-read before my ML classes starts and I could not have made a better choice. "
49,0465065708,http://goodreads.com/user/show/60299397-victor-villas,3,"The book starts very slowly, hyping up the idea of the master algorithm. The middle parts are really interesting, where each of the ""five tribes"" of machine learning are discussed. It ends with some self promotion for the alchemy thingy the author is part of. For serious machine learning students this book might be a waste of time, but is still entertaining for the laymen."
50,0465065708,http://goodreads.com/user/show/4696922-ushan,1,"I took Prof. Domingos's data mining course at the UW night school in 2001, and I was wondering whether this book can give a good overview of the progress of the machine learning since then. It doesn't. It is plainly badly written. If I were a layman, I wouldn't have understood anything."
51,0465065708,http://goodreads.com/user/show/2237619-josh,3,"It's been over 200 years since Babbage, and around 60 years since the first serious forays into developing intelligent electronic machines, and we finally seem to have come to a point in history where machine learning is coming of age. The history of AI cautions one against excessive optimism, but the successes of machine learning are becoming impossible to ignore. Machine learners have steadily encroached on areas of intelligence previously thought to be accessible only to the human mind. The lowlands of human thought are rapidly being filled by the flood of artificial intelligence, and there's little reason to believe that the rising tide is going to stop any time soon. There is hardly a field of academic research or sector of the economy that has not been affected in some way by machine learning, and more radical changes loom. Advances in neuroscience along with a torrent of machine learning research hint at a general learning algorithm that would make all other advances in human science seem trivial in comparison. To repeat an oft-quoted phrase, ""the first ultraintelligent machine is the last invention that man need ever make"". That, in essence, is what Pedro Domingos' book is about.It starts off with a broad overview of how machine learning algorithms (he calls them learners), are omnipresent in modern society. Algorithms help decide what you see on your social media news feed, which videos you watch, which products you buy, which stocks to add to your portfolio, which ads you see, which political candidates you vote for and who you decide to date. I don't think it's an exaggeration to say that machine learning has revolutionized almost every aspect of how we live our day-to-day lives.And that's just getting started.Domingos divides machine learning research into five 'tribes' and spends some time discussing each of them in detail: the Symbolists, the Connectionists, the Evolutionaries, the Bayesians, and the Analogizers.The Symbolists advocate a rule-based approach to learning, and use logical inference as their main tool. This was a common tactic with the expert AI systems of the 80s, and still has a large place in automated systems today. A big problem that every machine learning algorithm has to deal with when understanding large datasets is the vast set of possible interpretations for that data, and the Symbolists have a few effective ways of dealing with this. If you want to build a system that can diagnose an illness, you might go about it by forming a decision tree. Does the person have a rash? If so, does that person also have a cold? And so on. Anyone who's played the game 20 questions can probably see why this approach might be an effective way of building intelligent systems. It also has the downside that these systems are costly and time-consuming to construct, not to mention they lack a certain degree of generality. Domingos doesn't seem to be a fan of this school of research, and for the most part he quickly passes it by so he can move on to other methods. Rule-based inference, for the most part, does not seem like a particularly effective way of interpreting data, and it certainly isn't how human brains interpret data. For a more biologically inspired learning method we have the connectionists.If you've heard any of the recent headlines about DeepMind's AlphaGo beating the world Go champion, you've heard about connectionism. Connectionists are the practitioners of neural networks--artificial simulations of the sort of neurons we see in animal brains. Since human-level intelligence has so far only been exhibited in human brains, a natural approach to programming intelligence is by reverse engineering the human brain. People have been programming neural networks for about as long as programmable computers have been around--the first attempts were made in the 50s, and despite a steady following of researchers in the meantime it is only recently that neural networks have really begun to have their full potential realized. This is due in part to the fact that processors today are more powerful than ever, but also because the Internet is a rich sea of data that we can use to train our networks. Still, neural nets, despite their amazing versatility for solving problems, are quite cumbersome and aren't exact representations of the human brain. It's not even clear whether an exact simulation of how the brain works would be an efficient computational model. They also take a lot of computing power to train, so for certain situations they are not ideal.Another biologically-inspired approach to machine learning is evolutionary computing. The idea behind this one is sound: human intelligence arose through evolutionary processes, so why can't we write programs to 'evolve' through a sort of Darwinian selection process? If we select for the tributes we want a program to have, say for a self-driving car to drive safely, and reject the attributes we don't want it to have, say, crashing into stop signs, we can eventually produce a program that will be a good driver. In theory, at least. The problem, of course, is that human intelligence took hundreds of millions of years to evolve to where it is now, and researchers don't have that kind of time to spend. It also seems to be a bit of a fluke that intelligence even arose at all, considering all the time in prehistory where it wasn't around. Evolution is a tricky thing to recreate, and the successes of evolutionary computing have been overshadowed by other methods. It remains to be seen if they will one day come into the spotlight like connectionism has in recent years.The Bayesians are mostly involved in applying Bayes' theorem to machine learning problem. Thomas Bayes, a 17th century Englishman, was a statistician who formulated one of the most famous theorems in probability theory. His theorem helps us understand how events are related to each other, and how the probability of one event affects another. Applications of this fairly simple theory are among the most popular approaches to machine learning and still seen to be the most widely used. While this approach isn't as biologically inspired as the other methods, Bayesian inference does still represent something our brains have to do to interact intelligently with the world. Bayesian theory is very robust in its application and can be applied to a wide range of real-world problems. Things do tend to get a bit hairy when dealing with problems that have a lot of variables, but with the right simplifying assumptions this has proved to be a very powerful theory.The Analogizers, as Domingos calls them, aren't as unified as the other tribes. Human learning could perhaps be best characterized as learning by analogy. We learn new concepts by associating them with old concepts we already know. It turns out statistical formulations of this type of learning are also quite effective, as can be seen by various automated recommendation systems designed by companies like Netflix or Amazon. Truth be told it wasn't entirely clear to me how this approach differed significantly from the other approaches already discussed, but I guess Domingos felt the distinction was necessary.He then goes on to discuss a hodgepodge of various other learning strategies that take influence from human psychology, notably reinforcement learning. Reinforcement learning agents choose between possible actions to take in an environment based on the expectation of future rewards from that action. If pressing a button rewards a reinforcement learning agent, the agent will quickly learning to spend as much of its time pressing that button as possible. Reinforcement learning by itself doesn't generalize to other problems outside of a narrow domain especially well, but when combined with neural networks it can be a powerful approach for machine learning problems.The final chapter of the book is about the future of machine learning, and full of the typical sort of predictions that authors of this type of book seem to love. Personally I feel like most of what Domingos has to say in this chapter has been dealt with better by other authors, but I digress. Machine learning will certainly have a huge impact on every aspect of our lives. In a very real way you are the data that you create. Other people make models of you based on your behavior just like Netflix makes models of your movie-viewing habits. The reason so many companies have started racing to collect your data is because that data is powerful. It influences the choices we make at an individual level and thus influences the whole of our society. This is a scary thought to some, and is certainly something that should be taken into consideration by human rights organizations and governments. On the flipside, data is becoming democratized very quickly--a fact which is helping facilitate positive social change at a faster rate than ever before in the history of civilization. Some are worried about machines achieving human levels of intelligence, but I think those fears are misguided. It is far more advantageous for us to consider what new avenues of possibility have opened up than to dwell on the roads we will leave behind. To quote Domingos: ""The real history of automation is not what it replaces but what it enables.""Overall the book is a good general overview of the research being done in machine learning today. It does not, however, substitute for a more serious mathematical treatment of the subject, and those wishing to delve deeper into the subject would be better served elsewhere. Still, as a light introduction to the subject this book is worth looking into."
52,0465065708,http://goodreads.com/user/show/3055905-nils,4,"A useful book that lays out the five “tribes” of machine learning and ecumenically proposes that the true “master algorithm” (AGI) will combine all five: the symbolists’ inverse deduction, the connectionists’ backpropagation, the evolutionists’ genetic programming, the Bayesians’ various theorems, and the analogizers’ support vector machines.What’s most dated about this 2015 book is how utterly sanguine he is about what moving toward a master algorithm will produce in terms of social effects. It’s not just that he rejects the scaremongering of the Singulatarians (as he points out, the algorithms are never going to have wills of their own), but it’s more than he doesn’t consider except in the most glancing way what may happen if bad people control the algorithm, or the more profound problem of what it means if each of us has a shadow algorithmically optimized version of ourselves representing us in the world — how this could ironically lead to a loss of will, a surrender to the algorithmic engine that supposedly understands our preferences better than we do. Do we really want to live in a world where, “everyone has an entourage of bots, smoothing his or her way through the world.… Your digital half will be like power steering for your life.” Occasionally he glimpses the dystopian possibilities but then handwaves then away: “This does not mean that you’ll end up in a ‘filter bubble,’ seeing only what you reliably like, with no room for the unexpected,” he reassures us. “The digital you knows better than that. Part of its brief is to leave some things open to chance, to expose you to new experiences, and to look for serendipity.” Nor does he really consider the philosophical implications of a situation where “You have your model of every person in the organization you interact with, and they each have their model of you. As the models improve, their interaction becomes more and more like the ones you would have in the real world.” What’s happening in this scenario is that border between human and machine is eroding, with humans themselves evolving and in many cases likely to surrender control, happily turning over their decision making to their digital self. Are we so sure, in this scenario that the distinction between the willful human and the enslaved machines makes sense? We need not worry about silly infinite paperclip scenarios, is a world where many of us have become merely wired bundles of continuously satisfied Id a world we want to live in? Is a world where technology splinters the unity of the human race, as he predicts, not a world with truly fearsome possibilities? Consider this passage: “One of the greatest talents a politician can have is the ability to understand voters, individually or in small groups, and to speak directly to them (or seem to). Bill Clinton is the paradigmatic example of this in recent memory. The effect of machine learning is like having a dedicated Bill Clinton for every voter.” Wait, is that a promise, or a threat?! Likewise, would anyone in 2019 in good conscience be able to write that, “Democracy works better because the bandwidth of communications between voters and politicians increases enormously.... Big data and machine learning [will] change the equation. In the future, provided voter models are accurate, elected officials will be able to ask a voters what they want 1000 times a day and act accordingly – without having to pester the actual flesh and blood citizens.” Provided voter models are accurate is doing a whole lotta work there, wouldn’t you say?"
53,0465065708,http://goodreads.com/user/show/56104661-mark,3,"Pedro Domingos wastes no time in laying out his bold hypothesis on which The Master Algorithm: How The Quest for the Ultimate Learning Machine Will Remake Our World is based. Early in chapter two, he declares that: “All knowledge—past, present, and future—can be derived from data by a single, universal learning algorithm.” Clearly, Domingos believes that such an algorithm can be developed, but for the doubting Thomases among us, he cites strong lines of evidence from the disciplines of neuroscience, evolution, physics, statistics, and computer science.The search for the Master Algorithm does not have to start from scratch, Domingos tells us. The bulk of the book describes five current approaches to machine learning—or “five tribes of machine learning,” as he labels them—namely, symbolists, connectionists, evolutionaries, Bayesians, and analogizers. These tribes each have a set of core beliefs, and a central problem they must solve. Domingos’s detailed descriptions of how they do that occasionally results in dense and complex narrative, but he cleverly illustrates his points with familiar, daily-life examples, with equally familiar organizations, such as Google, Amazon, Netflix, and Facebook.Of course, the true Master Algorithm must solve the problems of all five tribes, and the reader is encouraged to stick with the narrative and even take a leap of faith in some of the more involved explanations (“Bayesian networks and Naïve Bayes classifier” was this reader’s particular leap of faith!). The author’s writing is captivating and teasing as he describes the benefits and shortcomings of each machine learning style, steadily building belief in the Master Algorithm at the end of each chapter. However, drawing from the five tribes is still not enough to satisfy specifications of the Master Algorithm: Domingos goes on to talk about the need for principal component analysis, dimensionality reduction, and metalearning.By the time one reaches the chapter, “The Pieces of the Puzzle Fall into Place,” and Domingos has pulled together the five models of learning into one elegant and beautiful schematic, the reader is convinced of the feasibility of the Master Algorithm. Domingos hammers home this conviction by explaining how his derived model handles the three necessary elements of representation (a model's formal language of expression), evaluation (a scoring function to say how good a model is), and optimization (the search for the highest-scoring model). In the closing chapter, “This is the World on Machine Learning,” Domingos anticipates how machine learning and the Master Algorithm will affect society as a whole and each and every one of us in many aspects of daily life. Overall, Domingos has crafted a thought-provoking book about a thrilling subject, as fantastic as it is believable. He deftly keeps the reader turning the pages with bursts of humor, big-picture concepts, and behind-the-scenes glimpses of existing learning models. This book is both serious entertainment and education!"
54,0465065708,http://goodreads.com/user/show/11375563-michael-huang,3,"Domingos writes eloquently and lucidly about what machine learning (ML) is doing to the society (helping scientists do them work and make Obama win elections) and how it's supposedly going to change everything (industrial and information revolution automated manual and mental work respectively, ML will automate the automation). And he points out a simple and clearly stated hypothesis, the central hypothesis of the book: ""All knowledge - past, present, and future - can be derived from data by a single, universal learning algorithm"". He then tantalizingly showed the arguments from neural science (we as a species learned knowledge didn't we?); from evolution (our brain was evolved from virtually nothing, why not some master algorithm?); from physics (witness the unreasonable effectiveness of math in natural science); from statistics (Bayes's theorem describes how you can update any belief); from Computer Science (didn't Turing show us how there is a universal machine). By the time I finished Chapter 2, the book looks up to be by far the best book I've read this year (out of 96).Unfortunately, the rest of the book seems to be written by a different person. The lucidity is out. In come weird analogies and references that impede understanding rather than helping it. Maybe he is too excited and his neurons keep firing at even weak associations, but the text would have been returned as ""Needing major revision"" if it was submitted to a journal. Nevertheless, he did explain the five different sub communities of the umbrella community of ML in the next 5 chapters; and rather unconvincingly touted his own research as potentially the ""Master Algorithm"". (I don't mean to suggest his research is bad. In fact, his description of Alchemy seems completely fine and something he should definitely continue to look into. It's just not of the table-pounding, forehead-palming why-didn't-I-think-of-that variety.) At last he closes with what the future holds store once the Master Algorithm arrives. This part is, thankfully, deprived of unnecessary analogies and similes, but is rather anticlimactic (e.g., in the future ""let your people call mine"" becomes ""let your algorithm talk to mine"")."
55,0465065708,http://goodreads.com/user/show/108995717-dan,4,"Very nice overview of the current machine learning paradigms and algorithms: symbolism and induction, connectionism and backpropagation, evolutionism and genetic algorithms, Bayesian and statistical inference, analogy and support vector machines. In its attempt to unify them, it also points to similarities/dissimilarities, weaknesses/strengths, and so on. On the other hand, the Messianic expectation of “The Master Algorithm” that will unify the five different paradigms/algorithms in the same way a Theory of Everything will unify everything in Physics is ridiculous. Most likely, in new data intensive fields completely new and specialized algorithms will emerge beyond the five mentioned in this book and they will stay distinct and specialized. Google is organizing and manipulating the Internet, Amazon is overselling to us, Facebook is selling our profiles, genetic medicine is trying to make sense of the huge amount of data it possesses, the self-driving cars are generating their own data, satellites are mapping the Earth and the sky in small details, and so on. Specialized algorithms can predict and control almost anything in these limited, commercial, and digital fields. But beyond these few data intensive fields, there is no data available and we still need to generate data in the old fashion, small, and expensive ways as we always did if we have some specific hypotheses/questions. Defining “everything that is” and “human intelligence and science” along these commercial data-algorithm ways betrays some naive ontology and epistemology. Moreover, expecting that algorithms that perform extremely well in very specific situations/fields to converge to some Mater Algorithm that explains everything and that will take our human understanding to a new level is an unjustified extrapolation."
56,0465065708,http://goodreads.com/user/show/58987379-ville,3,"Great topic – difficult approachThe book covers three different topics of which each could make a thick book on their own.-	The technical history of machine learning and development of the major algorithms-	Mr Rodriques idea of a universal learning algorithm (‘the master algorithm’)-	Ideas how machine learning has affected our lives and speculations about the futureThese are some of my favourite topics and I would love to love this book, but I can’t. The most problematic was the actual beef of the book: the master algorithm. Even as I have done my fair share of machine learning as M.Sc. in process control and worked with many of the algorithms described for years at work, I found it very difficult to follow and even understand his idea of the MLN method. It was just too difficult approach without some actual examples for me at least.The best parts of the book were some awesome insights that only a true master could state with such simple and entertaining terms.My favorite highlights.-	Believe it or not, every algorithm, no matter how complex, can be reduced to just these three operations: AND, OR, and NOT.-	People often think computers are all about numbers, but they’re not. Computers are all about logic.-	Overfitting is the central problem in machine learning. More papers have been written about it than about any other topic… Humans are not immune to overfitting, either. You could even say that it’s the root cause of a lot of our evils. Consider the little white girl who, upon seeing a Latina baby at the mall, blurted out “Look, Mom, a baby maid!” (True event.) It’s not that she’s a natural-born bigot.-	S curves are a nice halfway house between the dumbness of linear functions and the hardness of step functions.-	An autoencoder is a multilayer perceptron whose output is the same as its input. In goes a picture of your grandmother and out comes—the same picture of your grandmother …the network is forced to encode the input in fewer bits, so it can be represented in the hidden layer, and then decode those bits back to full size. …. However the neet trick was to make the hidden layer actually bigger than the input-output-layers but only allow a few of them to fire at any given moment…-	(k-) nearest neighbor is truly a superfast algorithm but with the slow database connections a trained neural network is sure to win.-	Symbolist methods, for one, are fairly good at disposing of irrelevant attributes. If an attribute has no information about the class, it’s just never included in the decision tree or rule set. But nearest-neighbor is hopelessly confused by irrelevant attributes because they all contribute to the similarity between examples.-	No learner is immune to the curse of dimensionality. It’s the second worst problem in machine learning, after overfitting.-	PCA is to unsupervised learning what linear regression is to the supervised variety.-	Random forests are some of the most accurate classifiers around. Microsoft’s Kinect uses them to figure out what you’re doing, and they regularly win machine-learning competitions.-	(The problem with) combined models can be quite opaque. (“I believe you have prostate cancer because the decision tree, the genetic algorithm, and Naïve Bayes say so, although the multilayer perceptron and the SVM disagree.”)About the future:-	The first robo-lawyers that argue for a particular verdict based on precedents have already been built…Perhaps in a future cybercourt, in session somewhere on Amazon’s cloud, a robo-lawyer will beat the speeding ticket that RoboCop issued to your driverless car, all while you go to the beach, and Leibniz’s dream of reducing all argument to calculation will finally have come true.-	Some researchers even argue that the way to create intelligent machines is to build a robot baby and let him experience the world as a human baby does…The question, of course, is what algorithm should be running in Robby’s brain at birth.-	(You have already “a digital self” living in the internet databases that is good at finding things for you that you are interested.) Even more interesting, the process doesn’t end when you find a car, a house, a doctor, a date, or a job. Your digital half is continually learning from its experiences, just as you would. It figures out what works and doesn’t, whether it’s in job interviews, dating, or real-estate hunting. -	You have your model of every person and organization you interact with, and they each have their model of you. As the models improve, their interactions become more and more like the ones you would have in the real world—except millions of times faster and in silicon. Tomorrow’s cyberspace will be a vast parallel world that selects only the most promising things to try out in the real one. It will be like a new, global subconscious, the collective id of the human race.-	(But the problem right now is that) everyone has only a sliver of it. Google sees your searches, Amazon your online purchases, AT&T your phone calls, Apple your music downloads, Safeway your groceries, Capital One your credit-card transactions. Companies like Acxiom collate and sell information about you, but if you inspect it (which in Acxiom’s case you can, at aboutthedata.com), it’s not much, and some of it is wrong. No one has anything even approaching a complete picture of you.-	Eventually, we’ll start talking about the employment rate instead of the unemployment one and reducing it will be seen as a sign of progress. (“The US is falling behind. Our employment rate is still 23 percent.”)-	People will seek meaning in human relationships, self-actualization, and spirituality, much as they do now. The need to earn a living will be a distant memory, another piece of humanity’s barbaric past that we rose above. -	Picture two strands of DNA going for a swim in their private pool, aka a bacterium’s cytoplasm, two billion years ago. They’re pondering a momentous decision. “I’m worried, Diana,” says one. “If we start making multicellular creatures, will they take over?” -	Contrary to what we like to believe today, humans quite easily fall into obeying others, and any sufficiently advanced AI is indistinguishable from God. People worry that computers will get too smart and take over the world, but the real problem is that they’re too stupid and they’ve already taken over the world. "
57,0465065708,http://goodreads.com/user/show/56609924-flaviu-vescan,3,"I was looking for a book that explains ML and AI concepts for non-practitioners. It did a great job at that. It goes through the most used 7 types of ML algorithms/concepts and explains how they work using high-level math and analogies. It blends a bit of the history of the field so that's always nice to contextualize the information. What made me only give it 3 stars are the detours it keeps making into predicting the future and the crazy soft stance it takes towards the tech giants like FB and GOOG. I'm not sure if Mr. Domingos is still willing to be have such a friendly opinion of them after the latest findings on how they use ML and the many privacy breaches they've had, but I hope not. In any case I'm judging the books version of events and it's lacking any criticism towards the uses of ML in manipulating public opinion. The book is great at teaching you the high-level workings of ML. The problem I had was it kept trying to do more than that by taking a stab at predicting the future of the field influence on humanity. Even for a specialist, it's mostly speculation. "
58,0465065708,http://goodreads.com/user/show/96942737-gautham,3,"A book for those who wish to have an aerial / Birdseye view of the subject, probably a novice in the field but I don’t think it can be of much help for a layman. It was as if Domingos wanted to explain almost all the topics / tribes of the world of Machine learning, from their basics, under one cover, which may have been possible if the book had housed at least about a 1000 or so pages maybe but his choice of including as many topics as he did has trumped the point of ‘understandability’ which a book like this should be focusing on in the first place.The slithering snake analogy for explaining SVMs was the worst of the analogies that he could come up with.However, there are certain learnings that one could get from this book but at the cost 300 pages @ your individual reading speeds is too big a price to pay.The last two chapters of the book seems like the summary of the rest of the chapters with an extension and conclusion. So, if you want to take a quick read, you know where to start."
59,0465065708,http://goodreads.com/user/show/93344337-benny,4,"A few years ago, I came across a list of machine learning algorithms that aspiring data scientists should familiarise themselves with. Since then, I have delved into various machine learning algorithms intermittently during my spare time. In this book, Pedro Domingos has broadly classified them into 5 different families of algorithms. To take these applications further, he suggested that eventually one Master Algorithm can perform that roles that each family of algorithms plays in deciphering our physical world. Below are some of the algorithms that are covered by the author.Genetic AlgorithmNeural Networks(eg. backpropagation, gradient descent)K-nearest NeighbourSupport Vector Machines(eg. kernels)Bayes NetworkK-means ClusteringPCARandom ForestEigenfaces....The book provides a neat high-level summary into the development of these algorithms and how they have come about. With prior understanding of how they work, it is pleasant way to review how these machine learning algorithms optimise, learn and automate our tasks without needing to immerse oneself in the math and computer science that are powering all these AI applications behind the scenes."
60,0465065708,http://goodreads.com/user/show/50245822-srinath-srinath,4,"Great book, gives an overall view of how 5 groups(bayesians,analogizers,symbolists,connectionists,evolutionaries) of people have been competing and trying to solve intelligence. The technical details have been very well explained for a layman to understand."
61,0465065708,http://goodreads.com/user/show/16463508-toma,4,"It is a bit technical for someone who is not in the field or used to some of the theories presented but a great read to understand Artificial Intelligence, Machine Learning and the major schools/philosophies in the field."
62,0465065708,http://goodreads.com/user/show/20064141-maureen-fitzpatrick,4,"It might be a five star book, but this is a book that is just beyond what I understand; however, what I understand is greater having read the book."
63,0465065708,http://goodreads.com/user/show/40460162-steve-jay,5,"If you're a huge nerd and have an interest in futurology, mathematics and computers, this is a must read! Blew my mind."
64,0465065708,http://goodreads.com/user/show/38024135-theodore-kinni,3,"Probably good for budding data scientists, but it's dense and too detailed for the untutored"
65,0465065708,http://goodreads.com/user/show/15317284-carlos-vasconcelos,4,A good book for a broad audience. 
66,0465065708,http://goodreads.com/user/show/50847541-florin-grigoriu,3,"OK to recap the ML notions, the fiction style is too mainstream making the book sometime too buzz-word-ish"
67,0465065708,http://goodreads.com/user/show/76014-raghu,4,"Artificial Intelligence has gradually become a part of our routine discourse. It is because we experience it in varying degrees in even our humdrum lives. We read in the news that driverless cars are already running on our roads. When we sign on to Netflix, we see movie recommendations for us. Often, they turn out to be better than what our friends and relatives suggest to us. Websites help us save money on airline tickets more than before. Google predicts flu outbreaks before CDC has been able to do so. All this is due to Artificial Intelligence or AI for short, of varying degrees. AI is a vast field and has been an area of research since the 1950s. This book is about one branch of AI which is hot today, called Machine Learning.Historically, we have written specific computer programs to solve specific problems using the computer. Each such program is in effect an algorithm to deal with that problem. Machine learning diverges from this traditional approach. It provides computers with the ability to learn. A specific problem is solved without being explicitly programmed for it. Machine learning consists of programs that can teach themselves to grow and change when exposed to more and more data. This book goes one step further. It discusses the holy grail of Machine Learning that researchers are working on, called the Master Algorithm. Right in the first chapter, the author defines this holy grail as follows: ""All knowledge - present, past and future - can be derived by a single, universal learning algorithm"".Now, this might seem ambitious to most of us, including scientists in the field. Some might even slam it as typical of the 'techno-hubris' of Silicon Valley. But the author makes a case that a master algorithm is a feature of nature itself. He shows that there are similar examples in Neuroscience and Evolution. The book captures Machine learning succinctly by the following unwritten rule through which it works:""we must induce the most widely applicable rules we can and reduce their scope only when data forces us to do so"".There are five approaches to Machine Learning today. They are classified as the Symbolists, the Connectionists, the Evolutionaries, the Bayesians and the Analogizers. Each of them is explained briefly as follows:Symbolists believe all intelligence can be reduced to manipulating symbols just as we do in Mathematics. In simple terms, Symbolists start with some existing premises and conclusions. Then, they work backward to fill in the gaps in knowledge by analyzing existing data sets. This is called inverse deduction. Connectionists believe that we must reverse engineer the brain and achieve machine learning. This approach is called 'deep learning'. It consists of creating 'digital neurons' in the computer and connecting them in a neural network model. Google uses this approach in machine translation. It is also used in image processing.Evolutionaries believe in learning through genetic programming. This method mates and evolves computer programs the way nature evolves species. It applies the ideas similar to that of Genomes and DNA in the evolutionary process to data structures. The Genetic programming model works by quantifying the performance of data. It is used to determine the retention and propagation of algorithms in an evolutionary way.Bayesians believe in using Bayes theorem and its derivatives to learn through probabilistic inference. This method proposes a few hypotheses. Then, it assigns probabilities for the likely outcomes of applying these hypotheses. By applying more and more data to test these hypotheses, some of them become more likely than the others. In this way, we arrive at the most likely solution to the problem. This is used in spam filters on emails.Analogizers believe the key to learning is recognizing similarities between situations. This principle is called the nearest neighbour principle. One important aspect of Analogy is that it lets you learn from little data. Analogizers can learn from even just one example - You are what you resemble. Charles Darwin used Malthus' theory of the struggle for survival in society to formulate the biological theory of evolution. Niels Bohr used the solar system model to formulate his theory of the atomic model. A website like Netflix uses it in the recommendations it gives to customers. For example, let us say that someone, whose profile is similar to yours, liked the movie 'Avatar'. Then it is likely that you will like Avatar as well, if you have not seen it already. So, a recommendation of Avatar is made for you. However, all these approaches are not mutually exclusive. Machine learning uses a selective combination of them, depending on the problem. For example, in medicine, the Evolutionary approach is not preferred. The way nature learns is through making mistakes - a luxury we don't have in our societies. Doctors must diagnose in a foolproof way. For example, failing to find a tumor that is really there, is potentially much worse than inferring one that isn't. It needs optimal decisions and this where the Bayesian approach is more useful. In AI, Symbolists held sway in the first few decades of cognitive psychology. Then Connectionists held sway in the 1980s and 90s, and it is the Bayesians' time in the Sun now. The author is upbeat about the future transformations that Machine Learning will bring to our societies. He suggests that in the not too distant future, we will all have a 'digital half' which will do our bidding all 24 hours of the day. They will interact with the digital halves of every person and organization we deal with. Tomorrow's cyberspace will be a giant parallel world. It will be like a new, global subconscious, the collective id of the human race. My only caveat about the book is its prognosis for the future. There is no doubt that the future will be transformed in many ways by Machine Learning. Scientists have been mostly right about predicting the future technological inventions. On the other hand, scientists from Thomas Malthus to Paul Ehrlich to the Club of Rome have made dire predictions about the future of mankind and disaster for thickly populated countries like India and China. They were woefully wrong in this. Not all scientific advances have a smooth path to their full potential. The expected potentials of Nuclear energy and Genetically Modified crops have not materialized because of resistance in our societies. There is also resistance to Stem cells and possibilities of Human cloning. Machine learning is in its infancy now. As it develops and impacts our lives more and more, the technology is bound to make mistakes in a way that affect our lives negatively. If some of them happen to be of the dimension of the Chernobyl accident in Nuclear energy, then there may be a big backlash to the advance of AI too. The other related danger is to rely on vast quantities of data on a phenomenon which leave out key attributes of representing the phenomena correctly, but use it anyway to make crucial decisions. One example in the past of such misuse of data happened in the 1960s. Sen.Robert McNamara, Secy of Defence in the Johnson administration, went about escalating the Vietnam war by relying on 'death count of US and Vietcong soldiers' as a key data indicator of how the war was progressing. The data did not capture the will and determination of the Vietnamese communists to rid themselves of foreign occupation of their land. We all know the consequences of this key error.I enjoyed reading the book as it was educational for me and I learnt much from it. The chapters elaborating the five approaches to Machine Learning need some focus and concentration to fully understand them. Readers, who find these chapters a bit hard, can still simply read just the first 60 pages to get a very good idea of the subject. All in all, it is a great effort to present this exciting subject in a simple way."
68,0465065708,http://goodreads.com/user/show/10768018-jo-o,3,"The idea of a master algorithm is a kind of computer science saint graal. An optimal model for most problems in reality, a robust super-A.I. with the best qualities of organic brains and computer power merged. For this to happen Domingos argues that the 5 tribes of machine learning have to merge as if currently they were very different communities. Those are: symbolists (e.g. logic-based models, decision trees); connectionists (e.g. neural networks); evolutionaries (genetic algorithms); bayesians (graph theory and Bayes-inspired modelling); analogizers (support vector machines, etc.). While this is a ""cool"" vision I find it hard to argue that models can be categorized under that schematic (many hybrids, or some are just specific cases of others) or that the communities of researchers are isolated in any way. Most people with MAJOR published contributions/advances in any of the ""5 tribes"", has papers in the others... usually dozens... (and some are really important as well)!From what else I've read from Domingos I'd rather recommend his short essays, and scientific papers. The big book format gives too much space for random rambling and there are a lot of cringe sentences like random name dropping e.g. ""Kant was also a fan."" with no further exposition or mention.Ultimately, Domingos has a very solid technical view of most stuff he discusses, but then he brings a lot of his personal intuitive futuristic views that can either happen or not. His conclusions and views in more social/political problems, like how should we share our data with AI companies, are also troubling for me. Overall too much utopian gut-feeling in a book about data-centred approaches."
69,0465065708,http://goodreads.com/user/show/23963235-akshith-rao,3,"This book captures the various types of machine learning techniques and how they have progressed through time. The author, being an academician, gets too technical. Even a decent understanding of math did not prevent some pages from turning into Latin for me. If you are someone who is knee deep in math and probability and would like to get an overall picture I would definitely recommend this book to you. For everyone else, it might be better to start looking somewhere else or just skip the math side of things in this book."
70,0465065708,http://goodreads.com/user/show/7297326-jim-crocker,5,"I'm not really finished. This is the kind of book that will go on and on and on with amazing insights and revelations about AI and Machine Learning. I've already heard that it is outta date. But, hey, whaddaya gonna do? Things move fast out there. With me it moves a little slower. I read and think and read and on it goes... This book was an eye-opener for me. I discovered a whole knew point of view. Essentially, it was a paradigm shift.This is a glimpse of the future of humans and the interactions, transactions and associations that will be taking place over the coming years. It's really transformational stuff that's going on. Here's two quotes that I liked (there's a ton more):** ""Most of all, we have to worry about what the Master Algorithm could do in the wrong hands.""** ""...you also have an ethical duty to share data for the common good.""I like that last one best of all!For your convenience, you can get this wonderful book right here:www.blackdogebooks.com/redhot-pick"
71,0465065708,http://goodreads.com/user/show/1173423-peter,5,"Really nice read. Serves as an accessible introduction to machine learning whilst simultaneously outlining the respective strengths and weaknesses of its 5 different ""tribes"" and ultimately showing how they can be connected. This makes the book valuable even for machine learning practitioners. Furthermore, in these days where deep learning reigns supreme and the media make it seem it is the end-all-be-all of machine learning, this book adds a valuable historical and conceptual perspective. The derivation and description of the current best stab at the Master Algorithm is more technical though, and probably more difficult to follow for the non-technical reader.The author is very bullish in the scale and scope of the application of machine learning and he offers powerful examples of AI in the form of personal agents negotiating the world on our behalf, the enabler of systems biology, and eventually designing and enhancing humans. However I think his view is quite utopian and that he downplays several potential negative scenarios of both weak and strong AI. For instance, Domingos believes that job displacement will not be grave (the argument that more new jobs that we now can't imagine will be created than will be destroyed), and that even if this were to happen, then if it reaches critical mass (>50%), then in a democracy that majority will vote for lifelong salaries for just being alive (i.e. universal basic income). However I think there is a path-dependance here on things staying the same politically. Let's contrast it with the scenario in Yuval Harari's Homo Deus of the creation of a class of ""useless"" humans who don't have to offer anything economically nor militarily. The political power of the masses would then be greatly diminished, perhaps even up to the point of threatening liberal democracy.Looking even further into the future, he does not take into account the dangers of reductionist goals. He basically argues that because machines don't have goals of their own, we are safe. Nick Bostrom belabors the dangers of strong AI in his book Superintelligence.In conclusion, although I think the dangers of AI were downplayed, I think it was a great read. I would recommend pairing this book (written by an machine learning researcher & practitioner) up with Homo Deus (written by a historian) and Superintelligence (by a philosopher) for a more holistic view if your interest is primarily on the (future) impact of AI."
72,0465065708,http://goodreads.com/user/show/38621776-an-l-tuncel,1,"Disappointing. This book has no scientific value. No one should read this book, not even teenagers (they will get confused). "
73,0465065708,http://goodreads.com/user/show/19014583-t,4,"I enjoyed this book overall but had some frustrations with it. Enough so that it was a real debate between 3 and 4 stars for me; I'm giving it 4 now as a benefit of the doubt but I may reread and drop it to 3 if it doesn't seem better.First, the topic couldn't be more relevant and interesting to our time; both for buzz word purposes and real discussion of the current state of the field the book was interesting. That said, I had several annoyances. First, the author seemed quite taken with creating fanciful allegories for things that were clear attempts to be poetic or entertaining and in practice were often just kind of dumb. In the more lower level cases they would help add to understanding, but the broader they got the more you felt like you were wasting your time while he talked about wandering through a city and spent time describing the turrets or telling you what you suddenly remembered or felt. Ick. Second, the premise at the start of the book seemed to be that anyone could understand and contribute to all of the field and the rest of the book seemed, to me at least, to rather disprove that. I think he tried to make this accessible to all and thus went a step too far; he'd have been better off saying the requirements of the field are not so high as many fear and thus are accessible to many more than would expect it. Saying anyone could do it even without complicated math just seemed inaccurate even using his own description by the end.Finally, the overall structure of the book and the discussion of the five ""tribes"" left me somewhat uncertain. I couldn't decide if that was an actually useful description or more confusing than helpful. In part this was because my reading was rather fractured through time so I'm reserving judgment of this for a more thorough reread.All that said, the book was still an interesting overview of the current state and problems of the machine learning world and, when not trying to wax poetic, was a pretty good and understandable summary of those and a nice encouragement for those of us on the edge of the field to get into it."
74,0465065708,http://goodreads.com/user/show/3550209-adrian,5,"Who knew the 'S' curve was the most important function ever?I picked up ""The Master Algorithm"" hoping it would serve as a primer as I began my journey into the world of deep learning. At first, I found it overly figurative and difficult to follow so I stopped reading it. After about 6 months of Andrew Ng YouTube videos, SciKit Learn, PyImageSearch, and other well-organized tutorials, I revisited the book and fell in love with it. What I appreciated most was the discussion of the 5 tribes of machine learning and how he was able to merge the mentality of the different camps. I'd consider myself an Analogizer and I work with a Bayesian. Often, it feels like we are talking different languages. I had to chuckle a few time as this book addressed this common dynamic.I enjoyed Chapter 9 the most with his fanciful depiction of a continent divided into 5 territories: Symbolist, Connectionists, Evolutionists, Bayesians, and Analogizers with Master Algorithm serving as the capital city. He did an excellent job conceptualizing how different aspects of each 'tribe' would contribute to the one unifying, but elusive, algorithm. He went to great lengths to establish his sci-fi bona fides with references to Lord of the Rings, The Matrix, Robocop, and much more. My favorite came when he was discussing Support Vector Machines and visualizing the border between classes as a snake slithering down the no-man's-land with the support vectors serving as mines. It's ""like the sandworms in Dune: big, tough, and able to survive a few explosions from slithering over landmines but not too many"". A five-star rating was locked after that."
75,0465065708,http://goodreads.com/user/show/5858138-nic-brisbourne,4,"Domingos provides a detailed and pretty technical explanation of five different areas of artificial intelligence:* Symbolists - observe and inducer Dix logic in the world and code it - works well in limited domains and highly explainable, but impossible to scale* Neural networks - infer rules from large amounts of data to by looking at training sets - if it's seen enough pictures of cats it can compute the probability that a new image is a cat* Genetic algorithms - define an objective and let evolve according to rules, and then keep the solutions that beat fit the desired goal, and then repeat. Key is choosing the rules and fit algorithms well* Bayesians and probabalistic influence- great at finding categories and classifying things* Analogisers and Support Vector Machines - good for spotting similarities between things and making predictions about other things that might be similar - if I have flu, and we are friends but don't live in the same town, what is the chance that you also have flu?This stuff is quite dense! I have a solid grounding in maths, science, and stats but haven't practiced for decades and understood most of it, but had to read slowly. Domingos writes well and with humour which makes reading much easier. Finally - I should also say that he does a good job of making it real with examples and a semi-good job of predicting where the future will take us. "
76,0465065708,http://goodreads.com/user/show/47032429-kenta-suzuki,4,"Pedro Domingo describes the machine learnings from its origin to now, and how it can be used in the future. He purports that the Master Algorithm be the one that is ultimate goal of machine learning or universal learner as he call it. This algorithm will be replete with or fall into the intersection of the five bailiwicks: Symbolists, Connectionists, Evolutionaries, Bayesians, and Analogizers. For symbolists, Inverse Deduction is algorithm, Gradient Descent for Connectionists, Genetic Search for Evolutionaries, Probabilistic Inference for Bayesian and Constrained Optimization for Analogizers. For instance, Netflix uses k-nearest- neighbor algorithm, which finds the correlations with each others, to create recommendation system.This algorithm is so important that recommender system consists of a third of Amazon's business. In the future, he claims, that there will be one version of yourself who or which basically do most of the things on behalf of you faster than you could. He also argues that the fears some people have toward AI or Singularity will be relinquished if humans deal with them carefully. For instance, there will no infinite growth of AI as is the case with Moore's law. It will eventually taper off as S curve deliniates. This book will gives some prelude to those areas for those who do not have solid backgrounds for statistics or machine learning. "
77,0465065708,http://goodreads.com/user/show/51672399-david,4,"Domingos' attraction to analogical learning leads him to fill this book with analogies for almost everything he talks about. I wonder if a computer develops consciousness would they find it as annoying as I did? Other than this nuisance, the book gives a great overview of the history and state of machine learning. The various subfields outlined in the novel are very well abstracted to show the significant similarities and differences between them.However, Domingos' view of the future, as stated in the last chapter, wouldn't be the most inspiring. The possibility of an algorithm that could predict cancer treatment through genome mapping is surely an excellent use of machine learning but his belief that war will be ""fought"" by between different learners isn't something I'm looking forward to. The author assures the reader of this certainty. For me, this is just a stark reminder that technology advancement does not necessarily advance society in a positive way. In the case of fighting algorithms, there will be a victor and whomever or whatever possesses this technology will be the one with the power to rule a lot of important aspects in this world. This scenario just looks like a continuation of the current trend in the concentration of wealth and power into the hands of the few and not the many."
78,0465065708,http://goodreads.com/user/show/8146846-satyabrata-mishra,5,"Pedros Domingos does a fascinating job describing complex machine learning algorithms in forms of simple (and sometimes silly) metaphors and examples; like dividing the different forms of AI-engineers into tribes and walking down the cities of their design.For someone who wants to peek into machine learning and understand the powers and faults of each algorithm, the master algorithm is a great choice. I picked it up as a pre-read before my ML classes starts and I could not have made a better choice. "
79,0465065708,http://goodreads.com/user/show/60299397-victor-villas,3,"The book starts very slowly, hyping up the idea of the master algorithm. The middle parts are really interesting, where each of the ""five tribes"" of machine learning are discussed. It ends with some self promotion for the alchemy thingy the author is part of. For serious machine learning students this book might be a waste of time, but is still entertaining for the laymen."
80,0465065708,http://goodreads.com/user/show/4696922-ushan,1,"I took Prof. Domingos's data mining course at the UW night school in 2001, and I was wondering whether this book can give a good overview of the progress of the machine learning since then. It doesn't. It is plainly badly written. If I were a layman, I wouldn't have understood anything."
81,0465065708,http://goodreads.com/user/show/2237619-josh,3,"It's been over 200 years since Babbage, and around 60 years since the first serious forays into developing intelligent electronic machines, and we finally seem to have come to a point in history where machine learning is coming of age. The history of AI cautions one against excessive optimism, but the successes of machine learning are becoming impossible to ignore. Machine learners have steadily encroached on areas of intelligence previously thought to be accessible only to the human mind. The lowlands of human thought are rapidly being filled by the flood of artificial intelligence, and there's little reason to believe that the rising tide is going to stop any time soon. There is hardly a field of academic research or sector of the economy that has not been affected in some way by machine learning, and more radical changes loom. Advances in neuroscience along with a torrent of machine learning research hint at a general learning algorithm that would make all other advances in human science seem trivial in comparison. To repeat an oft-quoted phrase, ""the first ultraintelligent machine is the last invention that man need ever make"". That, in essence, is what Pedro Domingos' book is about.It starts off with a broad overview of how machine learning algorithms (he calls them learners), are omnipresent in modern society. Algorithms help decide what you see on your social media news feed, which videos you watch, which products you buy, which stocks to add to your portfolio, which ads you see, which political candidates you vote for and who you decide to date. I don't think it's an exaggeration to say that machine learning has revolutionized almost every aspect of how we live our day-to-day lives.And that's just getting started.Domingos divides machine learning research into five 'tribes' and spends some time discussing each of them in detail: the Symbolists, the Connectionists, the Evolutionaries, the Bayesians, and the Analogizers.The Symbolists advocate a rule-based approach to learning, and use logical inference as their main tool. This was a common tactic with the expert AI systems of the 80s, and still has a large place in automated systems today. A big problem that every machine learning algorithm has to deal with when understanding large datasets is the vast set of possible interpretations for that data, and the Symbolists have a few effective ways of dealing with this. If you want to build a system that can diagnose an illness, you might go about it by forming a decision tree. Does the person have a rash? If so, does that person also have a cold? And so on. Anyone who's played the game 20 questions can probably see why this approach might be an effective way of building intelligent systems. It also has the downside that these systems are costly and time-consuming to construct, not to mention they lack a certain degree of generality. Domingos doesn't seem to be a fan of this school of research, and for the most part he quickly passes it by so he can move on to other methods. Rule-based inference, for the most part, does not seem like a particularly effective way of interpreting data, and it certainly isn't how human brains interpret data. For a more biologically inspired learning method we have the connectionists.If you've heard any of the recent headlines about DeepMind's AlphaGo beating the world Go champion, you've heard about connectionism. Connectionists are the practitioners of neural networks--artificial simulations of the sort of neurons we see in animal brains. Since human-level intelligence has so far only been exhibited in human brains, a natural approach to programming intelligence is by reverse engineering the human brain. People have been programming neural networks for about as long as programmable computers have been around--the first attempts were made in the 50s, and despite a steady following of researchers in the meantime it is only recently that neural networks have really begun to have their full potential realized. This is due in part to the fact that processors today are more powerful than ever, but also because the Internet is a rich sea of data that we can use to train our networks. Still, neural nets, despite their amazing versatility for solving problems, are quite cumbersome and aren't exact representations of the human brain. It's not even clear whether an exact simulation of how the brain works would be an efficient computational model. They also take a lot of computing power to train, so for certain situations they are not ideal.Another biologically-inspired approach to machine learning is evolutionary computing. The idea behind this one is sound: human intelligence arose through evolutionary processes, so why can't we write programs to 'evolve' through a sort of Darwinian selection process? If we select for the tributes we want a program to have, say for a self-driving car to drive safely, and reject the attributes we don't want it to have, say, crashing into stop signs, we can eventually produce a program that will be a good driver. In theory, at least. The problem, of course, is that human intelligence took hundreds of millions of years to evolve to where it is now, and researchers don't have that kind of time to spend. It also seems to be a bit of a fluke that intelligence even arose at all, considering all the time in prehistory where it wasn't around. Evolution is a tricky thing to recreate, and the successes of evolutionary computing have been overshadowed by other methods. It remains to be seen if they will one day come into the spotlight like connectionism has in recent years.The Bayesians are mostly involved in applying Bayes' theorem to machine learning problem. Thomas Bayes, a 17th century Englishman, was a statistician who formulated one of the most famous theorems in probability theory. His theorem helps us understand how events are related to each other, and how the probability of one event affects another. Applications of this fairly simple theory are among the most popular approaches to machine learning and still seen to be the most widely used. While this approach isn't as biologically inspired as the other methods, Bayesian inference does still represent something our brains have to do to interact intelligently with the world. Bayesian theory is very robust in its application and can be applied to a wide range of real-world problems. Things do tend to get a bit hairy when dealing with problems that have a lot of variables, but with the right simplifying assumptions this has proved to be a very powerful theory.The Analogizers, as Domingos calls them, aren't as unified as the other tribes. Human learning could perhaps be best characterized as learning by analogy. We learn new concepts by associating them with old concepts we already know. It turns out statistical formulations of this type of learning are also quite effective, as can be seen by various automated recommendation systems designed by companies like Netflix or Amazon. Truth be told it wasn't entirely clear to me how this approach differed significantly from the other approaches already discussed, but I guess Domingos felt the distinction was necessary.He then goes on to discuss a hodgepodge of various other learning strategies that take influence from human psychology, notably reinforcement learning. Reinforcement learning agents choose between possible actions to take in an environment based on the expectation of future rewards from that action. If pressing a button rewards a reinforcement learning agent, the agent will quickly learning to spend as much of its time pressing that button as possible. Reinforcement learning by itself doesn't generalize to other problems outside of a narrow domain especially well, but when combined with neural networks it can be a powerful approach for machine learning problems.The final chapter of the book is about the future of machine learning, and full of the typical sort of predictions that authors of this type of book seem to love. Personally I feel like most of what Domingos has to say in this chapter has been dealt with better by other authors, but I digress. Machine learning will certainly have a huge impact on every aspect of our lives. In a very real way you are the data that you create. Other people make models of you based on your behavior just like Netflix makes models of your movie-viewing habits. The reason so many companies have started racing to collect your data is because that data is powerful. It influences the choices we make at an individual level and thus influences the whole of our society. This is a scary thought to some, and is certainly something that should be taken into consideration by human rights organizations and governments. On the flipside, data is becoming democratized very quickly--a fact which is helping facilitate positive social change at a faster rate than ever before in the history of civilization. Some are worried about machines achieving human levels of intelligence, but I think those fears are misguided. It is far more advantageous for us to consider what new avenues of possibility have opened up than to dwell on the roads we will leave behind. To quote Domingos: ""The real history of automation is not what it replaces but what it enables.""Overall the book is a good general overview of the research being done in machine learning today. It does not, however, substitute for a more serious mathematical treatment of the subject, and those wishing to delve deeper into the subject would be better served elsewhere. Still, as a light introduction to the subject this book is worth looking into."
82,0465065708,http://goodreads.com/user/show/3055905-nils,4,"A useful book that lays out the five “tribes” of machine learning and ecumenically proposes that the true “master algorithm” (AGI) will combine all five: the symbolists’ inverse deduction, the connectionists’ backpropagation, the evolutionists’ genetic programming, the Bayesians’ various theorems, and the analogizers’ support vector machines.What’s most dated about this 2015 book is how utterly sanguine he is about what moving toward a master algorithm will produce in terms of social effects. It’s not just that he rejects the scaremongering of the Singulatarians (as he points out, the algorithms are never going to have wills of their own), but it’s more than he doesn’t consider except in the most glancing way what may happen if bad people control the algorithm, or the more profound problem of what it means if each of us has a shadow algorithmically optimized version of ourselves representing us in the world — how this could ironically lead to a loss of will, a surrender to the algorithmic engine that supposedly understands our preferences better than we do. Do we really want to live in a world where, “everyone has an entourage of bots, smoothing his or her way through the world.… Your digital half will be like power steering for your life.” Occasionally he glimpses the dystopian possibilities but then handwaves then away: “This does not mean that you’ll end up in a ‘filter bubble,’ seeing only what you reliably like, with no room for the unexpected,” he reassures us. “The digital you knows better than that. Part of its brief is to leave some things open to chance, to expose you to new experiences, and to look for serendipity.” Nor does he really consider the philosophical implications of a situation where “You have your model of every person in the organization you interact with, and they each have their model of you. As the models improve, their interaction becomes more and more like the ones you would have in the real world.” What’s happening in this scenario is that border between human and machine is eroding, with humans themselves evolving and in many cases likely to surrender control, happily turning over their decision making to their digital self. Are we so sure, in this scenario that the distinction between the willful human and the enslaved machines makes sense? We need not worry about silly infinite paperclip scenarios, is a world where many of us have become merely wired bundles of continuously satisfied Id a world we want to live in? Is a world where technology splinters the unity of the human race, as he predicts, not a world with truly fearsome possibilities? Consider this passage: “One of the greatest talents a politician can have is the ability to understand voters, individually or in small groups, and to speak directly to them (or seem to). Bill Clinton is the paradigmatic example of this in recent memory. The effect of machine learning is like having a dedicated Bill Clinton for every voter.” Wait, is that a promise, or a threat?! Likewise, would anyone in 2019 in good conscience be able to write that, “Democracy works better because the bandwidth of communications between voters and politicians increases enormously.... Big data and machine learning [will] change the equation. In the future, provided voter models are accurate, elected officials will be able to ask a voters what they want 1000 times a day and act accordingly – without having to pester the actual flesh and blood citizens.” Provided voter models are accurate is doing a whole lotta work there, wouldn’t you say?"
83,0465065708,http://goodreads.com/user/show/56104661-mark,3,"Pedro Domingos wastes no time in laying out his bold hypothesis on which The Master Algorithm: How The Quest for the Ultimate Learning Machine Will Remake Our World is based. Early in chapter two, he declares that: “All knowledge—past, present, and future—can be derived from data by a single, universal learning algorithm.” Clearly, Domingos believes that such an algorithm can be developed, but for the doubting Thomases among us, he cites strong lines of evidence from the disciplines of neuroscience, evolution, physics, statistics, and computer science.The search for the Master Algorithm does not have to start from scratch, Domingos tells us. The bulk of the book describes five current approaches to machine learning—or “five tribes of machine learning,” as he labels them—namely, symbolists, connectionists, evolutionaries, Bayesians, and analogizers. These tribes each have a set of core beliefs, and a central problem they must solve. Domingos’s detailed descriptions of how they do that occasionally results in dense and complex narrative, but he cleverly illustrates his points with familiar, daily-life examples, with equally familiar organizations, such as Google, Amazon, Netflix, and Facebook.Of course, the true Master Algorithm must solve the problems of all five tribes, and the reader is encouraged to stick with the narrative and even take a leap of faith in some of the more involved explanations (“Bayesian networks and Naïve Bayes classifier” was this reader’s particular leap of faith!). The author’s writing is captivating and teasing as he describes the benefits and shortcomings of each machine learning style, steadily building belief in the Master Algorithm at the end of each chapter. However, drawing from the five tribes is still not enough to satisfy specifications of the Master Algorithm: Domingos goes on to talk about the need for principal component analysis, dimensionality reduction, and metalearning.By the time one reaches the chapter, “The Pieces of the Puzzle Fall into Place,” and Domingos has pulled together the five models of learning into one elegant and beautiful schematic, the reader is convinced of the feasibility of the Master Algorithm. Domingos hammers home this conviction by explaining how his derived model handles the three necessary elements of representation (a model's formal language of expression), evaluation (a scoring function to say how good a model is), and optimization (the search for the highest-scoring model). In the closing chapter, “This is the World on Machine Learning,” Domingos anticipates how machine learning and the Master Algorithm will affect society as a whole and each and every one of us in many aspects of daily life. Overall, Domingos has crafted a thought-provoking book about a thrilling subject, as fantastic as it is believable. He deftly keeps the reader turning the pages with bursts of humor, big-picture concepts, and behind-the-scenes glimpses of existing learning models. This book is both serious entertainment and education!"
84,0465065708,http://goodreads.com/user/show/11375563-michael-huang,3,"Domingos writes eloquently and lucidly about what machine learning (ML) is doing to the society (helping scientists do them work and make Obama win elections) and how it's supposedly going to change everything (industrial and information revolution automated manual and mental work respectively, ML will automate the automation). And he points out a simple and clearly stated hypothesis, the central hypothesis of the book: ""All knowledge - past, present, and future - can be derived from data by a single, universal learning algorithm"". He then tantalizingly showed the arguments from neural science (we as a species learned knowledge didn't we?); from evolution (our brain was evolved from virtually nothing, why not some master algorithm?); from physics (witness the unreasonable effectiveness of math in natural science); from statistics (Bayes's theorem describes how you can update any belief); from Computer Science (didn't Turing show us how there is a universal machine). By the time I finished Chapter 2, the book looks up to be by far the best book I've read this year (out of 96).Unfortunately, the rest of the book seems to be written by a different person. The lucidity is out. In come weird analogies and references that impede understanding rather than helping it. Maybe he is too excited and his neurons keep firing at even weak associations, but the text would have been returned as ""Needing major revision"" if it was submitted to a journal. Nevertheless, he did explain the five different sub communities of the umbrella community of ML in the next 5 chapters; and rather unconvincingly touted his own research as potentially the ""Master Algorithm"". (I don't mean to suggest his research is bad. In fact, his description of Alchemy seems completely fine and something he should definitely continue to look into. It's just not of the table-pounding, forehead-palming why-didn't-I-think-of-that variety.) At last he closes with what the future holds store once the Master Algorithm arrives. This part is, thankfully, deprived of unnecessary analogies and similes, but is rather anticlimactic (e.g., in the future ""let your people call mine"" becomes ""let your algorithm talk to mine"")."
85,0465065708,http://goodreads.com/user/show/108995717-dan,4,"Very nice overview of the current machine learning paradigms and algorithms: symbolism and induction, connectionism and backpropagation, evolutionism and genetic algorithms, Bayesian and statistical inference, analogy and support vector machines. In its attempt to unify them, it also points to similarities/dissimilarities, weaknesses/strengths, and so on. On the other hand, the Messianic expectation of “The Master Algorithm” that will unify the five different paradigms/algorithms in the same way a Theory of Everything will unify everything in Physics is ridiculous. Most likely, in new data intensive fields completely new and specialized algorithms will emerge beyond the five mentioned in this book and they will stay distinct and specialized. Google is organizing and manipulating the Internet, Amazon is overselling to us, Facebook is selling our profiles, genetic medicine is trying to make sense of the huge amount of data it possesses, the self-driving cars are generating their own data, satellites are mapping the Earth and the sky in small details, and so on. Specialized algorithms can predict and control almost anything in these limited, commercial, and digital fields. But beyond these few data intensive fields, there is no data available and we still need to generate data in the old fashion, small, and expensive ways as we always did if we have some specific hypotheses/questions. Defining “everything that is” and “human intelligence and science” along these commercial data-algorithm ways betrays some naive ontology and epistemology. Moreover, expecting that algorithms that perform extremely well in very specific situations/fields to converge to some Mater Algorithm that explains everything and that will take our human understanding to a new level is an unjustified extrapolation."
86,0465065708,http://goodreads.com/user/show/58987379-ville,3,"Great topic – difficult approachThe book covers three different topics of which each could make a thick book on their own.-	The technical history of machine learning and development of the major algorithms-	Mr Rodriques idea of a universal learning algorithm (‘the master algorithm’)-	Ideas how machine learning has affected our lives and speculations about the futureThese are some of my favourite topics and I would love to love this book, but I can’t. The most problematic was the actual beef of the book: the master algorithm. Even as I have done my fair share of machine learning as M.Sc. in process control and worked with many of the algorithms described for years at work, I found it very difficult to follow and even understand his idea of the MLN method. It was just too difficult approach without some actual examples for me at least.The best parts of the book were some awesome insights that only a true master could state with such simple and entertaining terms.My favorite highlights.-	Believe it or not, every algorithm, no matter how complex, can be reduced to just these three operations: AND, OR, and NOT.-	People often think computers are all about numbers, but they’re not. Computers are all about logic.-	Overfitting is the central problem in machine learning. More papers have been written about it than about any other topic… Humans are not immune to overfitting, either. You could even say that it’s the root cause of a lot of our evils. Consider the little white girl who, upon seeing a Latina baby at the mall, blurted out “Look, Mom, a baby maid!” (True event.) It’s not that she’s a natural-born bigot.-	S curves are a nice halfway house between the dumbness of linear functions and the hardness of step functions.-	An autoencoder is a multilayer perceptron whose output is the same as its input. In goes a picture of your grandmother and out comes—the same picture of your grandmother …the network is forced to encode the input in fewer bits, so it can be represented in the hidden layer, and then decode those bits back to full size. …. However the neet trick was to make the hidden layer actually bigger than the input-output-layers but only allow a few of them to fire at any given moment…-	(k-) nearest neighbor is truly a superfast algorithm but with the slow database connections a trained neural network is sure to win.-	Symbolist methods, for one, are fairly good at disposing of irrelevant attributes. If an attribute has no information about the class, it’s just never included in the decision tree or rule set. But nearest-neighbor is hopelessly confused by irrelevant attributes because they all contribute to the similarity between examples.-	No learner is immune to the curse of dimensionality. It’s the second worst problem in machine learning, after overfitting.-	PCA is to unsupervised learning what linear regression is to the supervised variety.-	Random forests are some of the most accurate classifiers around. Microsoft’s Kinect uses them to figure out what you’re doing, and they regularly win machine-learning competitions.-	(The problem with) combined models can be quite opaque. (“I believe you have prostate cancer because the decision tree, the genetic algorithm, and Naïve Bayes say so, although the multilayer perceptron and the SVM disagree.”)About the future:-	The first robo-lawyers that argue for a particular verdict based on precedents have already been built…Perhaps in a future cybercourt, in session somewhere on Amazon’s cloud, a robo-lawyer will beat the speeding ticket that RoboCop issued to your driverless car, all while you go to the beach, and Leibniz’s dream of reducing all argument to calculation will finally have come true.-	Some researchers even argue that the way to create intelligent machines is to build a robot baby and let him experience the world as a human baby does…The question, of course, is what algorithm should be running in Robby’s brain at birth.-	(You have already “a digital self” living in the internet databases that is good at finding things for you that you are interested.) Even more interesting, the process doesn’t end when you find a car, a house, a doctor, a date, or a job. Your digital half is continually learning from its experiences, just as you would. It figures out what works and doesn’t, whether it’s in job interviews, dating, or real-estate hunting. -	You have your model of every person and organization you interact with, and they each have their model of you. As the models improve, their interactions become more and more like the ones you would have in the real world—except millions of times faster and in silicon. Tomorrow’s cyberspace will be a vast parallel world that selects only the most promising things to try out in the real one. It will be like a new, global subconscious, the collective id of the human race.-	(But the problem right now is that) everyone has only a sliver of it. Google sees your searches, Amazon your online purchases, AT&T your phone calls, Apple your music downloads, Safeway your groceries, Capital One your credit-card transactions. Companies like Acxiom collate and sell information about you, but if you inspect it (which in Acxiom’s case you can, at aboutthedata.com), it’s not much, and some of it is wrong. No one has anything even approaching a complete picture of you.-	Eventually, we’ll start talking about the employment rate instead of the unemployment one and reducing it will be seen as a sign of progress. (“The US is falling behind. Our employment rate is still 23 percent.”)-	People will seek meaning in human relationships, self-actualization, and spirituality, much as they do now. The need to earn a living will be a distant memory, another piece of humanity’s barbaric past that we rose above. -	Picture two strands of DNA going for a swim in their private pool, aka a bacterium’s cytoplasm, two billion years ago. They’re pondering a momentous decision. “I’m worried, Diana,” says one. “If we start making multicellular creatures, will they take over?” -	Contrary to what we like to believe today, humans quite easily fall into obeying others, and any sufficiently advanced AI is indistinguishable from God. People worry that computers will get too smart and take over the world, but the real problem is that they’re too stupid and they’ve already taken over the world. "
87,0465065708,http://goodreads.com/user/show/56609924-flaviu-vescan,3,"I was looking for a book that explains ML and AI concepts for non-practitioners. It did a great job at that. It goes through the most used 7 types of ML algorithms/concepts and explains how they work using high-level math and analogies. It blends a bit of the history of the field so that's always nice to contextualize the information. What made me only give it 3 stars are the detours it keeps making into predicting the future and the crazy soft stance it takes towards the tech giants like FB and GOOG. I'm not sure if Mr. Domingos is still willing to be have such a friendly opinion of them after the latest findings on how they use ML and the many privacy breaches they've had, but I hope not. In any case I'm judging the books version of events and it's lacking any criticism towards the uses of ML in manipulating public opinion. The book is great at teaching you the high-level workings of ML. The problem I had was it kept trying to do more than that by taking a stab at predicting the future of the field influence on humanity. Even for a specialist, it's mostly speculation. "
88,0465065708,http://goodreads.com/user/show/96942737-gautham,3,"A book for those who wish to have an aerial / Birdseye view of the subject, probably a novice in the field but I don’t think it can be of much help for a layman. It was as if Domingos wanted to explain almost all the topics / tribes of the world of Machine learning, from their basics, under one cover, which may have been possible if the book had housed at least about a 1000 or so pages maybe but his choice of including as many topics as he did has trumped the point of ‘understandability’ which a book like this should be focusing on in the first place.The slithering snake analogy for explaining SVMs was the worst of the analogies that he could come up with.However, there are certain learnings that one could get from this book but at the cost 300 pages @ your individual reading speeds is too big a price to pay.The last two chapters of the book seems like the summary of the rest of the chapters with an extension and conclusion. So, if you want to take a quick read, you know where to start."
89,0465065708,http://goodreads.com/user/show/93344337-benny,4,"A few years ago, I came across a list of machine learning algorithms that aspiring data scientists should familiarise themselves with. Since then, I have delved into various machine learning algorithms intermittently during my spare time. In this book, Pedro Domingos has broadly classified them into 5 different families of algorithms. To take these applications further, he suggested that eventually one Master Algorithm can perform that roles that each family of algorithms plays in deciphering our physical world. Below are some of the algorithms that are covered by the author.Genetic AlgorithmNeural Networks(eg. backpropagation, gradient descent)K-nearest NeighbourSupport Vector Machines(eg. kernels)Bayes NetworkK-means ClusteringPCARandom ForestEigenfaces....The book provides a neat high-level summary into the development of these algorithms and how they have come about. With prior understanding of how they work, it is pleasant way to review how these machine learning algorithms optimise, learn and automate our tasks without needing to immerse oneself in the math and computer science that are powering all these AI applications behind the scenes."
90,0465065708,http://goodreads.com/user/show/50245822-srinath-srinath,4,"Great book, gives an overall view of how 5 groups(bayesians,analogizers,symbolists,connectionists,evolutionaries) of people have been competing and trying to solve intelligence. The technical details have been very well explained for a layman to understand."
91,0465065708,http://goodreads.com/user/show/16463508-toma,4,"It is a bit technical for someone who is not in the field or used to some of the theories presented but a great read to understand Artificial Intelligence, Machine Learning and the major schools/philosophies in the field."
92,0465065708,http://goodreads.com/user/show/20064141-maureen-fitzpatrick,4,"It might be a five star book, but this is a book that is just beyond what I understand; however, what I understand is greater having read the book."
93,0465065708,http://goodreads.com/user/show/40460162-steve-jay,5,"If you're a huge nerd and have an interest in futurology, mathematics and computers, this is a must read! Blew my mind."
94,0465065708,http://goodreads.com/user/show/38024135-theodore-kinni,3,"Probably good for budding data scientists, but it's dense and too detailed for the untutored"
95,0465065708,http://goodreads.com/user/show/15317284-carlos-vasconcelos,4,A good book for a broad audience. 
96,0465065708,http://goodreads.com/user/show/50847541-florin-grigoriu,3,"OK to recap the ML notions, the fiction style is too mainstream making the book sometime too buzz-word-ish"
97,0465065708,http://goodreads.com/user/show/76014-raghu,4,"Artificial Intelligence has gradually become a part of our routine discourse. It is because we experience it in varying degrees in even our humdrum lives. We read in the news that driverless cars are already running on our roads. When we sign on to Netflix, we see movie recommendations for us. Often, they turn out to be better than what our friends and relatives suggest to us. Websites help us save money on airline tickets more than before. Google predicts flu outbreaks before CDC has been able to do so. All this is due to Artificial Intelligence or AI for short, of varying degrees. AI is a vast field and has been an area of research since the 1950s. This book is about one branch of AI which is hot today, called Machine Learning.Historically, we have written specific computer programs to solve specific problems using the computer. Each such program is in effect an algorithm to deal with that problem. Machine learning diverges from this traditional approach. It provides computers with the ability to learn. A specific problem is solved without being explicitly programmed for it. Machine learning consists of programs that can teach themselves to grow and change when exposed to more and more data. This book goes one step further. It discusses the holy grail of Machine Learning that researchers are working on, called the Master Algorithm. Right in the first chapter, the author defines this holy grail as follows: ""All knowledge - present, past and future - can be derived by a single, universal learning algorithm"".Now, this might seem ambitious to most of us, including scientists in the field. Some might even slam it as typical of the 'techno-hubris' of Silicon Valley. But the author makes a case that a master algorithm is a feature of nature itself. He shows that there are similar examples in Neuroscience and Evolution. The book captures Machine learning succinctly by the following unwritten rule through which it works:""we must induce the most widely applicable rules we can and reduce their scope only when data forces us to do so"".There are five approaches to Machine Learning today. They are classified as the Symbolists, the Connectionists, the Evolutionaries, the Bayesians and the Analogizers. Each of them is explained briefly as follows:Symbolists believe all intelligence can be reduced to manipulating symbols just as we do in Mathematics. In simple terms, Symbolists start with some existing premises and conclusions. Then, they work backward to fill in the gaps in knowledge by analyzing existing data sets. This is called inverse deduction. Connectionists believe that we must reverse engineer the brain and achieve machine learning. This approach is called 'deep learning'. It consists of creating 'digital neurons' in the computer and connecting them in a neural network model. Google uses this approach in machine translation. It is also used in image processing.Evolutionaries believe in learning through genetic programming. This method mates and evolves computer programs the way nature evolves species. It applies the ideas similar to that of Genomes and DNA in the evolutionary process to data structures. The Genetic programming model works by quantifying the performance of data. It is used to determine the retention and propagation of algorithms in an evolutionary way.Bayesians believe in using Bayes theorem and its derivatives to learn through probabilistic inference. This method proposes a few hypotheses. Then, it assigns probabilities for the likely outcomes of applying these hypotheses. By applying more and more data to test these hypotheses, some of them become more likely than the others. In this way, we arrive at the most likely solution to the problem. This is used in spam filters on emails.Analogizers believe the key to learning is recognizing similarities between situations. This principle is called the nearest neighbour principle. One important aspect of Analogy is that it lets you learn from little data. Analogizers can learn from even just one example - You are what you resemble. Charles Darwin used Malthus' theory of the struggle for survival in society to formulate the biological theory of evolution. Niels Bohr used the solar system model to formulate his theory of the atomic model. A website like Netflix uses it in the recommendations it gives to customers. For example, let us say that someone, whose profile is similar to yours, liked the movie 'Avatar'. Then it is likely that you will like Avatar as well, if you have not seen it already. So, a recommendation of Avatar is made for you. However, all these approaches are not mutually exclusive. Machine learning uses a selective combination of them, depending on the problem. For example, in medicine, the Evolutionary approach is not preferred. The way nature learns is through making mistakes - a luxury we don't have in our societies. Doctors must diagnose in a foolproof way. For example, failing to find a tumor that is really there, is potentially much worse than inferring one that isn't. It needs optimal decisions and this where the Bayesian approach is more useful. In AI, Symbolists held sway in the first few decades of cognitive psychology. Then Connectionists held sway in the 1980s and 90s, and it is the Bayesians' time in the Sun now. The author is upbeat about the future transformations that Machine Learning will bring to our societies. He suggests that in the not too distant future, we will all have a 'digital half' which will do our bidding all 24 hours of the day. They will interact with the digital halves of every person and organization we deal with. Tomorrow's cyberspace will be a giant parallel world. It will be like a new, global subconscious, the collective id of the human race. My only caveat about the book is its prognosis for the future. There is no doubt that the future will be transformed in many ways by Machine Learning. Scientists have been mostly right about predicting the future technological inventions. On the other hand, scientists from Thomas Malthus to Paul Ehrlich to the Club of Rome have made dire predictions about the future of mankind and disaster for thickly populated countries like India and China. They were woefully wrong in this. Not all scientific advances have a smooth path to their full potential. The expected potentials of Nuclear energy and Genetically Modified crops have not materialized because of resistance in our societies. There is also resistance to Stem cells and possibilities of Human cloning. Machine learning is in its infancy now. As it develops and impacts our lives more and more, the technology is bound to make mistakes in a way that affect our lives negatively. If some of them happen to be of the dimension of the Chernobyl accident in Nuclear energy, then there may be a big backlash to the advance of AI too. The other related danger is to rely on vast quantities of data on a phenomenon which leave out key attributes of representing the phenomena correctly, but use it anyway to make crucial decisions. One example in the past of such misuse of data happened in the 1960s. Sen.Robert McNamara, Secy of Defence in the Johnson administration, went about escalating the Vietnam war by relying on 'death count of US and Vietcong soldiers' as a key data indicator of how the war was progressing. The data did not capture the will and determination of the Vietnamese communists to rid themselves of foreign occupation of their land. We all know the consequences of this key error.I enjoyed reading the book as it was educational for me and I learnt much from it. The chapters elaborating the five approaches to Machine Learning need some focus and concentration to fully understand them. Readers, who find these chapters a bit hard, can still simply read just the first 60 pages to get a very good idea of the subject. All in all, it is a great effort to present this exciting subject in a simple way."
98,0465065708,http://goodreads.com/user/show/10768018-jo-o,3,"The idea of a master algorithm is a kind of computer science saint graal. An optimal model for most problems in reality, a robust super-A.I. with the best qualities of organic brains and computer power merged. For this to happen Domingos argues that the 5 tribes of machine learning have to merge as if currently they were very different communities. Those are: symbolists (e.g. logic-based models, decision trees); connectionists (e.g. neural networks); evolutionaries (genetic algorithms); bayesians (graph theory and Bayes-inspired modelling); analogizers (support vector machines, etc.). While this is a ""cool"" vision I find it hard to argue that models can be categorized under that schematic (many hybrids, or some are just specific cases of others) or that the communities of researchers are isolated in any way. Most people with MAJOR published contributions/advances in any of the ""5 tribes"", has papers in the others... usually dozens... (and some are really important as well)!From what else I've read from Domingos I'd rather recommend his short essays, and scientific papers. The big book format gives too much space for random rambling and there are a lot of cringe sentences like random name dropping e.g. ""Kant was also a fan."" with no further exposition or mention.Ultimately, Domingos has a very solid technical view of most stuff he discusses, but then he brings a lot of his personal intuitive futuristic views that can either happen or not. His conclusions and views in more social/political problems, like how should we share our data with AI companies, are also troubling for me. Overall too much utopian gut-feeling in a book about data-centred approaches."
99,0465065708,http://goodreads.com/user/show/23963235-akshith-rao,3,"This book captures the various types of machine learning techniques and how they have progressed through time. The author, being an academician, gets too technical. Even a decent understanding of math did not prevent some pages from turning into Latin for me. If you are someone who is knee deep in math and probability and would like to get an overall picture I would definitely recommend this book to you. For everyone else, it might be better to start looking somewhere else or just skip the math side of things in this book."
100,0465065708,http://goodreads.com/user/show/7297326-jim-crocker,5,"I'm not really finished. This is the kind of book that will go on and on and on with amazing insights and revelations about AI and Machine Learning. I've already heard that it is outta date. But, hey, whaddaya gonna do? Things move fast out there. With me it moves a little slower. I read and think and read and on it goes... This book was an eye-opener for me. I discovered a whole knew point of view. Essentially, it was a paradigm shift.This is a glimpse of the future of humans and the interactions, transactions and associations that will be taking place over the coming years. It's really transformational stuff that's going on. Here's two quotes that I liked (there's a ton more):** ""Most of all, we have to worry about what the Master Algorithm could do in the wrong hands.""** ""...you also have an ethical duty to share data for the common good.""I like that last one best of all!For your convenience, you can get this wonderful book right here:www.blackdogebooks.com/redhot-pick"
101,0465065708,http://goodreads.com/user/show/1173423-peter,5,"Really nice read. Serves as an accessible introduction to machine learning whilst simultaneously outlining the respective strengths and weaknesses of its 5 different ""tribes"" and ultimately showing how they can be connected. This makes the book valuable even for machine learning practitioners. Furthermore, in these days where deep learning reigns supreme and the media make it seem it is the end-all-be-all of machine learning, this book adds a valuable historical and conceptual perspective. The derivation and description of the current best stab at the Master Algorithm is more technical though, and probably more difficult to follow for the non-technical reader.The author is very bullish in the scale and scope of the application of machine learning and he offers powerful examples of AI in the form of personal agents negotiating the world on our behalf, the enabler of systems biology, and eventually designing and enhancing humans. However I think his view is quite utopian and that he downplays several potential negative scenarios of both weak and strong AI. For instance, Domingos believes that job displacement will not be grave (the argument that more new jobs that we now can't imagine will be created than will be destroyed), and that even if this were to happen, then if it reaches critical mass (>50%), then in a democracy that majority will vote for lifelong salaries for just being alive (i.e. universal basic income). However I think there is a path-dependance here on things staying the same politically. Let's contrast it with the scenario in Yuval Harari's Homo Deus of the creation of a class of ""useless"" humans who don't have to offer anything economically nor militarily. The political power of the masses would then be greatly diminished, perhaps even up to the point of threatening liberal democracy.Looking even further into the future, he does not take into account the dangers of reductionist goals. He basically argues that because machines don't have goals of their own, we are safe. Nick Bostrom belabors the dangers of strong AI in his book Superintelligence.In conclusion, although I think the dangers of AI were downplayed, I think it was a great read. I would recommend pairing this book (written by an machine learning researcher & practitioner) up with Homo Deus (written by a historian) and Superintelligence (by a philosopher) for a more holistic view if your interest is primarily on the (future) impact of AI."
102,0465065708,http://goodreads.com/user/show/38621776-an-l-tuncel,1,"Disappointing. This book has no scientific value. No one should read this book, not even teenagers (they will get confused). "
103,0465065708,http://goodreads.com/user/show/19014583-t,4,"I enjoyed this book overall but had some frustrations with it. Enough so that it was a real debate between 3 and 4 stars for me; I'm giving it 4 now as a benefit of the doubt but I may reread and drop it to 3 if it doesn't seem better.First, the topic couldn't be more relevant and interesting to our time; both for buzz word purposes and real discussion of the current state of the field the book was interesting. That said, I had several annoyances. First, the author seemed quite taken with creating fanciful allegories for things that were clear attempts to be poetic or entertaining and in practice were often just kind of dumb. In the more lower level cases they would help add to understanding, but the broader they got the more you felt like you were wasting your time while he talked about wandering through a city and spent time describing the turrets or telling you what you suddenly remembered or felt. Ick. Second, the premise at the start of the book seemed to be that anyone could understand and contribute to all of the field and the rest of the book seemed, to me at least, to rather disprove that. I think he tried to make this accessible to all and thus went a step too far; he'd have been better off saying the requirements of the field are not so high as many fear and thus are accessible to many more than would expect it. Saying anyone could do it even without complicated math just seemed inaccurate even using his own description by the end.Finally, the overall structure of the book and the discussion of the five ""tribes"" left me somewhat uncertain. I couldn't decide if that was an actually useful description or more confusing than helpful. In part this was because my reading was rather fractured through time so I'm reserving judgment of this for a more thorough reread.All that said, the book was still an interesting overview of the current state and problems of the machine learning world and, when not trying to wax poetic, was a pretty good and understandable summary of those and a nice encouragement for those of us on the edge of the field to get into it."
104,0465065708,http://goodreads.com/user/show/3550209-adrian,5,"Who knew the 'S' curve was the most important function ever?I picked up ""The Master Algorithm"" hoping it would serve as a primer as I began my journey into the world of deep learning. At first, I found it overly figurative and difficult to follow so I stopped reading it. After about 6 months of Andrew Ng YouTube videos, SciKit Learn, PyImageSearch, and other well-organized tutorials, I revisited the book and fell in love with it. What I appreciated most was the discussion of the 5 tribes of machine learning and how he was able to merge the mentality of the different camps. I'd consider myself an Analogizer and I work with a Bayesian. Often, it feels like we are talking different languages. I had to chuckle a few time as this book addressed this common dynamic.I enjoyed Chapter 9 the most with his fanciful depiction of a continent divided into 5 territories: Symbolist, Connectionists, Evolutionists, Bayesians, and Analogizers with Master Algorithm serving as the capital city. He did an excellent job conceptualizing how different aspects of each 'tribe' would contribute to the one unifying, but elusive, algorithm. He went to great lengths to establish his sci-fi bona fides with references to Lord of the Rings, The Matrix, Robocop, and much more. My favorite came when he was discussing Support Vector Machines and visualizing the border between classes as a snake slithering down the no-man's-land with the support vectors serving as mines. It's ""like the sandworms in Dune: big, tough, and able to survive a few explosions from slithering over landmines but not too many"". A five-star rating was locked after that."
105,0465065708,http://goodreads.com/user/show/5858138-nic-brisbourne,4,"Domingos provides a detailed and pretty technical explanation of five different areas of artificial intelligence:* Symbolists - observe and inducer Dix logic in the world and code it - works well in limited domains and highly explainable, but impossible to scale* Neural networks - infer rules from large amounts of data to by looking at training sets - if it's seen enough pictures of cats it can compute the probability that a new image is a cat* Genetic algorithms - define an objective and let evolve according to rules, and then keep the solutions that beat fit the desired goal, and then repeat. Key is choosing the rules and fit algorithms well* Bayesians and probabalistic influence- great at finding categories and classifying things* Analogisers and Support Vector Machines - good for spotting similarities between things and making predictions about other things that might be similar - if I have flu, and we are friends but don't live in the same town, what is the chance that you also have flu?This stuff is quite dense! I have a solid grounding in maths, science, and stats but haven't practiced for decades and understood most of it, but had to read slowly. Domingos writes well and with humour which makes reading much easier. Finally - I should also say that he does a good job of making it real with examples and a semi-good job of predicting where the future will take us. "
106,0465065708,http://goodreads.com/user/show/47032429-kenta-suzuki,4,"Pedro Domingo describes the machine learnings from its origin to now, and how it can be used in the future. He purports that the Master Algorithm be the one that is ultimate goal of machine learning or universal learner as he call it. This algorithm will be replete with or fall into the intersection of the five bailiwicks: Symbolists, Connectionists, Evolutionaries, Bayesians, and Analogizers. For symbolists, Inverse Deduction is algorithm, Gradient Descent for Connectionists, Genetic Search for Evolutionaries, Probabilistic Inference for Bayesian and Constrained Optimization for Analogizers. For instance, Netflix uses k-nearest- neighbor algorithm, which finds the correlations with each others, to create recommendation system.This algorithm is so important that recommender system consists of a third of Amazon's business. In the future, he claims, that there will be one version of yourself who or which basically do most of the things on behalf of you faster than you could. He also argues that the fears some people have toward AI or Singularity will be relinquished if humans deal with them carefully. For instance, there will no infinite growth of AI as is the case with Moore's law. It will eventually taper off as S curve deliniates. This book will gives some prelude to those areas for those who do not have solid backgrounds for statistics or machine learning. "
107,0465065708,http://goodreads.com/user/show/51672399-david,4,"Domingos' attraction to analogical learning leads him to fill this book with analogies for almost everything he talks about. I wonder if a computer develops consciousness would they find it as annoying as I did? Other than this nuisance, the book gives a great overview of the history and state of machine learning. The various subfields outlined in the novel are very well abstracted to show the significant similarities and differences between them.However, Domingos' view of the future, as stated in the last chapter, wouldn't be the most inspiring. The possibility of an algorithm that could predict cancer treatment through genome mapping is surely an excellent use of machine learning but his belief that war will be ""fought"" by between different learners isn't something I'm looking forward to. The author assures the reader of this certainty. For me, this is just a stark reminder that technology advancement does not necessarily advance society in a positive way. In the case of fighting algorithms, there will be a victor and whomever or whatever possesses this technology will be the one with the power to rule a lot of important aspects in this world. This scenario just looks like a continuation of the current trend in the concentration of wealth and power into the hands of the few and not the many."
108,0465065708,http://goodreads.com/user/show/8146846-satyabrata-mishra,5,"Pedros Domingos does a fascinating job describing complex machine learning algorithms in forms of simple (and sometimes silly) metaphors and examples; like dividing the different forms of AI-engineers into tribes and walking down the cities of their design.For someone who wants to peek into machine learning and understand the powers and faults of each algorithm, the master algorithm is a great choice. I picked it up as a pre-read before my ML classes starts and I could not have made a better choice. "
109,0465065708,http://goodreads.com/user/show/60299397-victor-villas,3,"The book starts very slowly, hyping up the idea of the master algorithm. The middle parts are really interesting, where each of the ""five tribes"" of machine learning are discussed. It ends with some self promotion for the alchemy thingy the author is part of. For serious machine learning students this book might be a waste of time, but is still entertaining for the laymen."
110,0465065708,http://goodreads.com/user/show/4696922-ushan,1,"I took Prof. Domingos's data mining course at the UW night school in 2001, and I was wondering whether this book can give a good overview of the progress of the machine learning since then. It doesn't. It is plainly badly written. If I were a layman, I wouldn't have understood anything."
111,0465065708,http://goodreads.com/user/show/2237619-josh,3,"It's been over 200 years since Babbage, and around 60 years since the first serious forays into developing intelligent electronic machines, and we finally seem to have come to a point in history where machine learning is coming of age. The history of AI cautions one against excessive optimism, but the successes of machine learning are becoming impossible to ignore. Machine learners have steadily encroached on areas of intelligence previously thought to be accessible only to the human mind. The lowlands of human thought are rapidly being filled by the flood of artificial intelligence, and there's little reason to believe that the rising tide is going to stop any time soon. There is hardly a field of academic research or sector of the economy that has not been affected in some way by machine learning, and more radical changes loom. Advances in neuroscience along with a torrent of machine learning research hint at a general learning algorithm that would make all other advances in human science seem trivial in comparison. To repeat an oft-quoted phrase, ""the first ultraintelligent machine is the last invention that man need ever make"". That, in essence, is what Pedro Domingos' book is about.It starts off with a broad overview of how machine learning algorithms (he calls them learners), are omnipresent in modern society. Algorithms help decide what you see on your social media news feed, which videos you watch, which products you buy, which stocks to add to your portfolio, which ads you see, which political candidates you vote for and who you decide to date. I don't think it's an exaggeration to say that machine learning has revolutionized almost every aspect of how we live our day-to-day lives.And that's just getting started.Domingos divides machine learning research into five 'tribes' and spends some time discussing each of them in detail: the Symbolists, the Connectionists, the Evolutionaries, the Bayesians, and the Analogizers.The Symbolists advocate a rule-based approach to learning, and use logical inference as their main tool. This was a common tactic with the expert AI systems of the 80s, and still has a large place in automated systems today. A big problem that every machine learning algorithm has to deal with when understanding large datasets is the vast set of possible interpretations for that data, and the Symbolists have a few effective ways of dealing with this. If you want to build a system that can diagnose an illness, you might go about it by forming a decision tree. Does the person have a rash? If so, does that person also have a cold? And so on. Anyone who's played the game 20 questions can probably see why this approach might be an effective way of building intelligent systems. It also has the downside that these systems are costly and time-consuming to construct, not to mention they lack a certain degree of generality. Domingos doesn't seem to be a fan of this school of research, and for the most part he quickly passes it by so he can move on to other methods. Rule-based inference, for the most part, does not seem like a particularly effective way of interpreting data, and it certainly isn't how human brains interpret data. For a more biologically inspired learning method we have the connectionists.If you've heard any of the recent headlines about DeepMind's AlphaGo beating the world Go champion, you've heard about connectionism. Connectionists are the practitioners of neural networks--artificial simulations of the sort of neurons we see in animal brains. Since human-level intelligence has so far only been exhibited in human brains, a natural approach to programming intelligence is by reverse engineering the human brain. People have been programming neural networks for about as long as programmable computers have been around--the first attempts were made in the 50s, and despite a steady following of researchers in the meantime it is only recently that neural networks have really begun to have their full potential realized. This is due in part to the fact that processors today are more powerful than ever, but also because the Internet is a rich sea of data that we can use to train our networks. Still, neural nets, despite their amazing versatility for solving problems, are quite cumbersome and aren't exact representations of the human brain. It's not even clear whether an exact simulation of how the brain works would be an efficient computational model. They also take a lot of computing power to train, so for certain situations they are not ideal.Another biologically-inspired approach to machine learning is evolutionary computing. The idea behind this one is sound: human intelligence arose through evolutionary processes, so why can't we write programs to 'evolve' through a sort of Darwinian selection process? If we select for the tributes we want a program to have, say for a self-driving car to drive safely, and reject the attributes we don't want it to have, say, crashing into stop signs, we can eventually produce a program that will be a good driver. In theory, at least. The problem, of course, is that human intelligence took hundreds of millions of years to evolve to where it is now, and researchers don't have that kind of time to spend. It also seems to be a bit of a fluke that intelligence even arose at all, considering all the time in prehistory where it wasn't around. Evolution is a tricky thing to recreate, and the successes of evolutionary computing have been overshadowed by other methods. It remains to be seen if they will one day come into the spotlight like connectionism has in recent years.The Bayesians are mostly involved in applying Bayes' theorem to machine learning problem. Thomas Bayes, a 17th century Englishman, was a statistician who formulated one of the most famous theorems in probability theory. His theorem helps us understand how events are related to each other, and how the probability of one event affects another. Applications of this fairly simple theory are among the most popular approaches to machine learning and still seen to be the most widely used. While this approach isn't as biologically inspired as the other methods, Bayesian inference does still represent something our brains have to do to interact intelligently with the world. Bayesian theory is very robust in its application and can be applied to a wide range of real-world problems. Things do tend to get a bit hairy when dealing with problems that have a lot of variables, but with the right simplifying assumptions this has proved to be a very powerful theory.The Analogizers, as Domingos calls them, aren't as unified as the other tribes. Human learning could perhaps be best characterized as learning by analogy. We learn new concepts by associating them with old concepts we already know. It turns out statistical formulations of this type of learning are also quite effective, as can be seen by various automated recommendation systems designed by companies like Netflix or Amazon. Truth be told it wasn't entirely clear to me how this approach differed significantly from the other approaches already discussed, but I guess Domingos felt the distinction was necessary.He then goes on to discuss a hodgepodge of various other learning strategies that take influence from human psychology, notably reinforcement learning. Reinforcement learning agents choose between possible actions to take in an environment based on the expectation of future rewards from that action. If pressing a button rewards a reinforcement learning agent, the agent will quickly learning to spend as much of its time pressing that button as possible. Reinforcement learning by itself doesn't generalize to other problems outside of a narrow domain especially well, but when combined with neural networks it can be a powerful approach for machine learning problems.The final chapter of the book is about the future of machine learning, and full of the typical sort of predictions that authors of this type of book seem to love. Personally I feel like most of what Domingos has to say in this chapter has been dealt with better by other authors, but I digress. Machine learning will certainly have a huge impact on every aspect of our lives. In a very real way you are the data that you create. Other people make models of you based on your behavior just like Netflix makes models of your movie-viewing habits. The reason so many companies have started racing to collect your data is because that data is powerful. It influences the choices we make at an individual level and thus influences the whole of our society. This is a scary thought to some, and is certainly something that should be taken into consideration by human rights organizations and governments. On the flipside, data is becoming democratized very quickly--a fact which is helping facilitate positive social change at a faster rate than ever before in the history of civilization. Some are worried about machines achieving human levels of intelligence, but I think those fears are misguided. It is far more advantageous for us to consider what new avenues of possibility have opened up than to dwell on the roads we will leave behind. To quote Domingos: ""The real history of automation is not what it replaces but what it enables.""Overall the book is a good general overview of the research being done in machine learning today. It does not, however, substitute for a more serious mathematical treatment of the subject, and those wishing to delve deeper into the subject would be better served elsewhere. Still, as a light introduction to the subject this book is worth looking into."
112,0465065708,http://goodreads.com/user/show/3055905-nils,4,"A useful book that lays out the five “tribes” of machine learning and ecumenically proposes that the true “master algorithm” (AGI) will combine all five: the symbolists’ inverse deduction, the connectionists’ backpropagation, the evolutionists’ genetic programming, the Bayesians’ various theorems, and the analogizers’ support vector machines.What’s most dated about this 2015 book is how utterly sanguine he is about what moving toward a master algorithm will produce in terms of social effects. It’s not just that he rejects the scaremongering of the Singulatarians (as he points out, the algorithms are never going to have wills of their own), but it’s more than he doesn’t consider except in the most glancing way what may happen if bad people control the algorithm, or the more profound problem of what it means if each of us has a shadow algorithmically optimized version of ourselves representing us in the world — how this could ironically lead to a loss of will, a surrender to the algorithmic engine that supposedly understands our preferences better than we do. Do we really want to live in a world where, “everyone has an entourage of bots, smoothing his or her way through the world.… Your digital half will be like power steering for your life.” Occasionally he glimpses the dystopian possibilities but then handwaves then away: “This does not mean that you’ll end up in a ‘filter bubble,’ seeing only what you reliably like, with no room for the unexpected,” he reassures us. “The digital you knows better than that. Part of its brief is to leave some things open to chance, to expose you to new experiences, and to look for serendipity.” Nor does he really consider the philosophical implications of a situation where “You have your model of every person in the organization you interact with, and they each have their model of you. As the models improve, their interaction becomes more and more like the ones you would have in the real world.” What’s happening in this scenario is that border between human and machine is eroding, with humans themselves evolving and in many cases likely to surrender control, happily turning over their decision making to their digital self. Are we so sure, in this scenario that the distinction between the willful human and the enslaved machines makes sense? We need not worry about silly infinite paperclip scenarios, is a world where many of us have become merely wired bundles of continuously satisfied Id a world we want to live in? Is a world where technology splinters the unity of the human race, as he predicts, not a world with truly fearsome possibilities? Consider this passage: “One of the greatest talents a politician can have is the ability to understand voters, individually or in small groups, and to speak directly to them (or seem to). Bill Clinton is the paradigmatic example of this in recent memory. The effect of machine learning is like having a dedicated Bill Clinton for every voter.” Wait, is that a promise, or a threat?! Likewise, would anyone in 2019 in good conscience be able to write that, “Democracy works better because the bandwidth of communications between voters and politicians increases enormously.... Big data and machine learning [will] change the equation. In the future, provided voter models are accurate, elected officials will be able to ask a voters what they want 1000 times a day and act accordingly – without having to pester the actual flesh and blood citizens.” Provided voter models are accurate is doing a whole lotta work there, wouldn’t you say?"
113,0465065708,http://goodreads.com/user/show/56104661-mark,3,"Pedro Domingos wastes no time in laying out his bold hypothesis on which The Master Algorithm: How The Quest for the Ultimate Learning Machine Will Remake Our World is based. Early in chapter two, he declares that: “All knowledge—past, present, and future—can be derived from data by a single, universal learning algorithm.” Clearly, Domingos believes that such an algorithm can be developed, but for the doubting Thomases among us, he cites strong lines of evidence from the disciplines of neuroscience, evolution, physics, statistics, and computer science.The search for the Master Algorithm does not have to start from scratch, Domingos tells us. The bulk of the book describes five current approaches to machine learning—or “five tribes of machine learning,” as he labels them—namely, symbolists, connectionists, evolutionaries, Bayesians, and analogizers. These tribes each have a set of core beliefs, and a central problem they must solve. Domingos’s detailed descriptions of how they do that occasionally results in dense and complex narrative, but he cleverly illustrates his points with familiar, daily-life examples, with equally familiar organizations, such as Google, Amazon, Netflix, and Facebook.Of course, the true Master Algorithm must solve the problems of all five tribes, and the reader is encouraged to stick with the narrative and even take a leap of faith in some of the more involved explanations (“Bayesian networks and Naïve Bayes classifier” was this reader’s particular leap of faith!). The author’s writing is captivating and teasing as he describes the benefits and shortcomings of each machine learning style, steadily building belief in the Master Algorithm at the end of each chapter. However, drawing from the five tribes is still not enough to satisfy specifications of the Master Algorithm: Domingos goes on to talk about the need for principal component analysis, dimensionality reduction, and metalearning.By the time one reaches the chapter, “The Pieces of the Puzzle Fall into Place,” and Domingos has pulled together the five models of learning into one elegant and beautiful schematic, the reader is convinced of the feasibility of the Master Algorithm. Domingos hammers home this conviction by explaining how his derived model handles the three necessary elements of representation (a model's formal language of expression), evaluation (a scoring function to say how good a model is), and optimization (the search for the highest-scoring model). In the closing chapter, “This is the World on Machine Learning,” Domingos anticipates how machine learning and the Master Algorithm will affect society as a whole and each and every one of us in many aspects of daily life. Overall, Domingos has crafted a thought-provoking book about a thrilling subject, as fantastic as it is believable. He deftly keeps the reader turning the pages with bursts of humor, big-picture concepts, and behind-the-scenes glimpses of existing learning models. This book is both serious entertainment and education!"
114,0465065708,http://goodreads.com/user/show/11375563-michael-huang,3,"Domingos writes eloquently and lucidly about what machine learning (ML) is doing to the society (helping scientists do them work and make Obama win elections) and how it's supposedly going to change everything (industrial and information revolution automated manual and mental work respectively, ML will automate the automation). And he points out a simple and clearly stated hypothesis, the central hypothesis of the book: ""All knowledge - past, present, and future - can be derived from data by a single, universal learning algorithm"". He then tantalizingly showed the arguments from neural science (we as a species learned knowledge didn't we?); from evolution (our brain was evolved from virtually nothing, why not some master algorithm?); from physics (witness the unreasonable effectiveness of math in natural science); from statistics (Bayes's theorem describes how you can update any belief); from Computer Science (didn't Turing show us how there is a universal machine). By the time I finished Chapter 2, the book looks up to be by far the best book I've read this year (out of 96).Unfortunately, the rest of the book seems to be written by a different person. The lucidity is out. In come weird analogies and references that impede understanding rather than helping it. Maybe he is too excited and his neurons keep firing at even weak associations, but the text would have been returned as ""Needing major revision"" if it was submitted to a journal. Nevertheless, he did explain the five different sub communities of the umbrella community of ML in the next 5 chapters; and rather unconvincingly touted his own research as potentially the ""Master Algorithm"". (I don't mean to suggest his research is bad. In fact, his description of Alchemy seems completely fine and something he should definitely continue to look into. It's just not of the table-pounding, forehead-palming why-didn't-I-think-of-that variety.) At last he closes with what the future holds store once the Master Algorithm arrives. This part is, thankfully, deprived of unnecessary analogies and similes, but is rather anticlimactic (e.g., in the future ""let your people call mine"" becomes ""let your algorithm talk to mine"")."
115,0465065708,http://goodreads.com/user/show/108995717-dan,4,"Very nice overview of the current machine learning paradigms and algorithms: symbolism and induction, connectionism and backpropagation, evolutionism and genetic algorithms, Bayesian and statistical inference, analogy and support vector machines. In its attempt to unify them, it also points to similarities/dissimilarities, weaknesses/strengths, and so on. On the other hand, the Messianic expectation of “The Master Algorithm” that will unify the five different paradigms/algorithms in the same way a Theory of Everything will unify everything in Physics is ridiculous. Most likely, in new data intensive fields completely new and specialized algorithms will emerge beyond the five mentioned in this book and they will stay distinct and specialized. Google is organizing and manipulating the Internet, Amazon is overselling to us, Facebook is selling our profiles, genetic medicine is trying to make sense of the huge amount of data it possesses, the self-driving cars are generating their own data, satellites are mapping the Earth and the sky in small details, and so on. Specialized algorithms can predict and control almost anything in these limited, commercial, and digital fields. But beyond these few data intensive fields, there is no data available and we still need to generate data in the old fashion, small, and expensive ways as we always did if we have some specific hypotheses/questions. Defining “everything that is” and “human intelligence and science” along these commercial data-algorithm ways betrays some naive ontology and epistemology. Moreover, expecting that algorithms that perform extremely well in very specific situations/fields to converge to some Mater Algorithm that explains everything and that will take our human understanding to a new level is an unjustified extrapolation."
116,0465065708,http://goodreads.com/user/show/58987379-ville,3,"Great topic – difficult approachThe book covers three different topics of which each could make a thick book on their own.-	The technical history of machine learning and development of the major algorithms-	Mr Rodriques idea of a universal learning algorithm (‘the master algorithm’)-	Ideas how machine learning has affected our lives and speculations about the futureThese are some of my favourite topics and I would love to love this book, but I can’t. The most problematic was the actual beef of the book: the master algorithm. Even as I have done my fair share of machine learning as M.Sc. in process control and worked with many of the algorithms described for years at work, I found it very difficult to follow and even understand his idea of the MLN method. It was just too difficult approach without some actual examples for me at least.The best parts of the book were some awesome insights that only a true master could state with such simple and entertaining terms.My favorite highlights.-	Believe it or not, every algorithm, no matter how complex, can be reduced to just these three operations: AND, OR, and NOT.-	People often think computers are all about numbers, but they’re not. Computers are all about logic.-	Overfitting is the central problem in machine learning. More papers have been written about it than about any other topic… Humans are not immune to overfitting, either. You could even say that it’s the root cause of a lot of our evils. Consider the little white girl who, upon seeing a Latina baby at the mall, blurted out “Look, Mom, a baby maid!” (True event.) It’s not that she’s a natural-born bigot.-	S curves are a nice halfway house between the dumbness of linear functions and the hardness of step functions.-	An autoencoder is a multilayer perceptron whose output is the same as its input. In goes a picture of your grandmother and out comes—the same picture of your grandmother …the network is forced to encode the input in fewer bits, so it can be represented in the hidden layer, and then decode those bits back to full size. …. However the neet trick was to make the hidden layer actually bigger than the input-output-layers but only allow a few of them to fire at any given moment…-	(k-) nearest neighbor is truly a superfast algorithm but with the slow database connections a trained neural network is sure to win.-	Symbolist methods, for one, are fairly good at disposing of irrelevant attributes. If an attribute has no information about the class, it’s just never included in the decision tree or rule set. But nearest-neighbor is hopelessly confused by irrelevant attributes because they all contribute to the similarity between examples.-	No learner is immune to the curse of dimensionality. It’s the second worst problem in machine learning, after overfitting.-	PCA is to unsupervised learning what linear regression is to the supervised variety.-	Random forests are some of the most accurate classifiers around. Microsoft’s Kinect uses them to figure out what you’re doing, and they regularly win machine-learning competitions.-	(The problem with) combined models can be quite opaque. (“I believe you have prostate cancer because the decision tree, the genetic algorithm, and Naïve Bayes say so, although the multilayer perceptron and the SVM disagree.”)About the future:-	The first robo-lawyers that argue for a particular verdict based on precedents have already been built…Perhaps in a future cybercourt, in session somewhere on Amazon’s cloud, a robo-lawyer will beat the speeding ticket that RoboCop issued to your driverless car, all while you go to the beach, and Leibniz’s dream of reducing all argument to calculation will finally have come true.-	Some researchers even argue that the way to create intelligent machines is to build a robot baby and let him experience the world as a human baby does…The question, of course, is what algorithm should be running in Robby’s brain at birth.-	(You have already “a digital self” living in the internet databases that is good at finding things for you that you are interested.) Even more interesting, the process doesn’t end when you find a car, a house, a doctor, a date, or a job. Your digital half is continually learning from its experiences, just as you would. It figures out what works and doesn’t, whether it’s in job interviews, dating, or real-estate hunting. -	You have your model of every person and organization you interact with, and they each have their model of you. As the models improve, their interactions become more and more like the ones you would have in the real world—except millions of times faster and in silicon. Tomorrow’s cyberspace will be a vast parallel world that selects only the most promising things to try out in the real one. It will be like a new, global subconscious, the collective id of the human race.-	(But the problem right now is that) everyone has only a sliver of it. Google sees your searches, Amazon your online purchases, AT&T your phone calls, Apple your music downloads, Safeway your groceries, Capital One your credit-card transactions. Companies like Acxiom collate and sell information about you, but if you inspect it (which in Acxiom’s case you can, at aboutthedata.com), it’s not much, and some of it is wrong. No one has anything even approaching a complete picture of you.-	Eventually, we’ll start talking about the employment rate instead of the unemployment one and reducing it will be seen as a sign of progress. (“The US is falling behind. Our employment rate is still 23 percent.”)-	People will seek meaning in human relationships, self-actualization, and spirituality, much as they do now. The need to earn a living will be a distant memory, another piece of humanity’s barbaric past that we rose above. -	Picture two strands of DNA going for a swim in their private pool, aka a bacterium’s cytoplasm, two billion years ago. They’re pondering a momentous decision. “I’m worried, Diana,” says one. “If we start making multicellular creatures, will they take over?” -	Contrary to what we like to believe today, humans quite easily fall into obeying others, and any sufficiently advanced AI is indistinguishable from God. People worry that computers will get too smart and take over the world, but the real problem is that they’re too stupid and they’ve already taken over the world. "
117,0465065708,http://goodreads.com/user/show/56609924-flaviu-vescan,3,"I was looking for a book that explains ML and AI concepts for non-practitioners. It did a great job at that. It goes through the most used 7 types of ML algorithms/concepts and explains how they work using high-level math and analogies. It blends a bit of the history of the field so that's always nice to contextualize the information. What made me only give it 3 stars are the detours it keeps making into predicting the future and the crazy soft stance it takes towards the tech giants like FB and GOOG. I'm not sure if Mr. Domingos is still willing to be have such a friendly opinion of them after the latest findings on how they use ML and the many privacy breaches they've had, but I hope not. In any case I'm judging the books version of events and it's lacking any criticism towards the uses of ML in manipulating public opinion. The book is great at teaching you the high-level workings of ML. The problem I had was it kept trying to do more than that by taking a stab at predicting the future of the field influence on humanity. Even for a specialist, it's mostly speculation. "
118,0465065708,http://goodreads.com/user/show/96942737-gautham,3,"A book for those who wish to have an aerial / Birdseye view of the subject, probably a novice in the field but I don’t think it can be of much help for a layman. It was as if Domingos wanted to explain almost all the topics / tribes of the world of Machine learning, from their basics, under one cover, which may have been possible if the book had housed at least about a 1000 or so pages maybe but his choice of including as many topics as he did has trumped the point of ‘understandability’ which a book like this should be focusing on in the first place.The slithering snake analogy for explaining SVMs was the worst of the analogies that he could come up with.However, there are certain learnings that one could get from this book but at the cost 300 pages @ your individual reading speeds is too big a price to pay.The last two chapters of the book seems like the summary of the rest of the chapters with an extension and conclusion. So, if you want to take a quick read, you know where to start."
119,0465065708,http://goodreads.com/user/show/93344337-benny,4,"A few years ago, I came across a list of machine learning algorithms that aspiring data scientists should familiarise themselves with. Since then, I have delved into various machine learning algorithms intermittently during my spare time. In this book, Pedro Domingos has broadly classified them into 5 different families of algorithms. To take these applications further, he suggested that eventually one Master Algorithm can perform that roles that each family of algorithms plays in deciphering our physical world. Below are some of the algorithms that are covered by the author.Genetic AlgorithmNeural Networks(eg. backpropagation, gradient descent)K-nearest NeighbourSupport Vector Machines(eg. kernels)Bayes NetworkK-means ClusteringPCARandom ForestEigenfaces....The book provides a neat high-level summary into the development of these algorithms and how they have come about. With prior understanding of how they work, it is pleasant way to review how these machine learning algorithms optimise, learn and automate our tasks without needing to immerse oneself in the math and computer science that are powering all these AI applications behind the scenes."
120,0465065708,http://goodreads.com/user/show/50245822-srinath-srinath,4,"Great book, gives an overall view of how 5 groups(bayesians,analogizers,symbolists,connectionists,evolutionaries) of people have been competing and trying to solve intelligence. The technical details have been very well explained for a layman to understand."
121,0465065708,http://goodreads.com/user/show/16463508-toma,4,"It is a bit technical for someone who is not in the field or used to some of the theories presented but a great read to understand Artificial Intelligence, Machine Learning and the major schools/philosophies in the field."
122,0465065708,http://goodreads.com/user/show/20064141-maureen-fitzpatrick,4,"It might be a five star book, but this is a book that is just beyond what I understand; however, what I understand is greater having read the book."
123,0465065708,http://goodreads.com/user/show/40460162-steve-jay,5,"If you're a huge nerd and have an interest in futurology, mathematics and computers, this is a must read! Blew my mind."
124,0465065708,http://goodreads.com/user/show/38024135-theodore-kinni,3,"Probably good for budding data scientists, but it's dense and too detailed for the untutored"
125,0465065708,http://goodreads.com/user/show/15317284-carlos-vasconcelos,4,A good book for a broad audience. 
126,0465065708,http://goodreads.com/user/show/50847541-florin-grigoriu,3,"OK to recap the ML notions, the fiction style is too mainstream making the book sometime too buzz-word-ish"
127,0465065708,http://goodreads.com/user/show/76014-raghu,4,"Artificial Intelligence has gradually become a part of our routine discourse. It is because we experience it in varying degrees in even our humdrum lives. We read in the news that driverless cars are already running on our roads. When we sign on to Netflix, we see movie recommendations for us. Often, they turn out to be better than what our friends and relatives suggest to us. Websites help us save money on airline tickets more than before. Google predicts flu outbreaks before CDC has been able to do so. All this is due to Artificial Intelligence or AI for short, of varying degrees. AI is a vast field and has been an area of research since the 1950s. This book is about one branch of AI which is hot today, called Machine Learning.Historically, we have written specific computer programs to solve specific problems using the computer. Each such program is in effect an algorithm to deal with that problem. Machine learning diverges from this traditional approach. It provides computers with the ability to learn. A specific problem is solved without being explicitly programmed for it. Machine learning consists of programs that can teach themselves to grow and change when exposed to more and more data. This book goes one step further. It discusses the holy grail of Machine Learning that researchers are working on, called the Master Algorithm. Right in the first chapter, the author defines this holy grail as follows: ""All knowledge - present, past and future - can be derived by a single, universal learning algorithm"".Now, this might seem ambitious to most of us, including scientists in the field. Some might even slam it as typical of the 'techno-hubris' of Silicon Valley. But the author makes a case that a master algorithm is a feature of nature itself. He shows that there are similar examples in Neuroscience and Evolution. The book captures Machine learning succinctly by the following unwritten rule through which it works:""we must induce the most widely applicable rules we can and reduce their scope only when data forces us to do so"".There are five approaches to Machine Learning today. They are classified as the Symbolists, the Connectionists, the Evolutionaries, the Bayesians and the Analogizers. Each of them is explained briefly as follows:Symbolists believe all intelligence can be reduced to manipulating symbols just as we do in Mathematics. In simple terms, Symbolists start with some existing premises and conclusions. Then, they work backward to fill in the gaps in knowledge by analyzing existing data sets. This is called inverse deduction. Connectionists believe that we must reverse engineer the brain and achieve machine learning. This approach is called 'deep learning'. It consists of creating 'digital neurons' in the computer and connecting them in a neural network model. Google uses this approach in machine translation. It is also used in image processing.Evolutionaries believe in learning through genetic programming. This method mates and evolves computer programs the way nature evolves species. It applies the ideas similar to that of Genomes and DNA in the evolutionary process to data structures. The Genetic programming model works by quantifying the performance of data. It is used to determine the retention and propagation of algorithms in an evolutionary way.Bayesians believe in using Bayes theorem and its derivatives to learn through probabilistic inference. This method proposes a few hypotheses. Then, it assigns probabilities for the likely outcomes of applying these hypotheses. By applying more and more data to test these hypotheses, some of them become more likely than the others. In this way, we arrive at the most likely solution to the problem. This is used in spam filters on emails.Analogizers believe the key to learning is recognizing similarities between situations. This principle is called the nearest neighbour principle. One important aspect of Analogy is that it lets you learn from little data. Analogizers can learn from even just one example - You are what you resemble. Charles Darwin used Malthus' theory of the struggle for survival in society to formulate the biological theory of evolution. Niels Bohr used the solar system model to formulate his theory of the atomic model. A website like Netflix uses it in the recommendations it gives to customers. For example, let us say that someone, whose profile is similar to yours, liked the movie 'Avatar'. Then it is likely that you will like Avatar as well, if you have not seen it already. So, a recommendation of Avatar is made for you. However, all these approaches are not mutually exclusive. Machine learning uses a selective combination of them, depending on the problem. For example, in medicine, the Evolutionary approach is not preferred. The way nature learns is through making mistakes - a luxury we don't have in our societies. Doctors must diagnose in a foolproof way. For example, failing to find a tumor that is really there, is potentially much worse than inferring one that isn't. It needs optimal decisions and this where the Bayesian approach is more useful. In AI, Symbolists held sway in the first few decades of cognitive psychology. Then Connectionists held sway in the 1980s and 90s, and it is the Bayesians' time in the Sun now. The author is upbeat about the future transformations that Machine Learning will bring to our societies. He suggests that in the not too distant future, we will all have a 'digital half' which will do our bidding all 24 hours of the day. They will interact with the digital halves of every person and organization we deal with. Tomorrow's cyberspace will be a giant parallel world. It will be like a new, global subconscious, the collective id of the human race. My only caveat about the book is its prognosis for the future. There is no doubt that the future will be transformed in many ways by Machine Learning. Scientists have been mostly right about predicting the future technological inventions. On the other hand, scientists from Thomas Malthus to Paul Ehrlich to the Club of Rome have made dire predictions about the future of mankind and disaster for thickly populated countries like India and China. They were woefully wrong in this. Not all scientific advances have a smooth path to their full potential. The expected potentials of Nuclear energy and Genetically Modified crops have not materialized because of resistance in our societies. There is also resistance to Stem cells and possibilities of Human cloning. Machine learning is in its infancy now. As it develops and impacts our lives more and more, the technology is bound to make mistakes in a way that affect our lives negatively. If some of them happen to be of the dimension of the Chernobyl accident in Nuclear energy, then there may be a big backlash to the advance of AI too. The other related danger is to rely on vast quantities of data on a phenomenon which leave out key attributes of representing the phenomena correctly, but use it anyway to make crucial decisions. One example in the past of such misuse of data happened in the 1960s. Sen.Robert McNamara, Secy of Defence in the Johnson administration, went about escalating the Vietnam war by relying on 'death count of US and Vietcong soldiers' as a key data indicator of how the war was progressing. The data did not capture the will and determination of the Vietnamese communists to rid themselves of foreign occupation of their land. We all know the consequences of this key error.I enjoyed reading the book as it was educational for me and I learnt much from it. The chapters elaborating the five approaches to Machine Learning need some focus and concentration to fully understand them. Readers, who find these chapters a bit hard, can still simply read just the first 60 pages to get a very good idea of the subject. All in all, it is a great effort to present this exciting subject in a simple way."
128,0465065708,http://goodreads.com/user/show/10768018-jo-o,3,"The idea of a master algorithm is a kind of computer science saint graal. An optimal model for most problems in reality, a robust super-A.I. with the best qualities of organic brains and computer power merged. For this to happen Domingos argues that the 5 tribes of machine learning have to merge as if currently they were very different communities. Those are: symbolists (e.g. logic-based models, decision trees); connectionists (e.g. neural networks); evolutionaries (genetic algorithms); bayesians (graph theory and Bayes-inspired modelling); analogizers (support vector machines, etc.). While this is a ""cool"" vision I find it hard to argue that models can be categorized under that schematic (many hybrids, or some are just specific cases of others) or that the communities of researchers are isolated in any way. Most people with MAJOR published contributions/advances in any of the ""5 tribes"", has papers in the others... usually dozens... (and some are really important as well)!From what else I've read from Domingos I'd rather recommend his short essays, and scientific papers. The big book format gives too much space for random rambling and there are a lot of cringe sentences like random name dropping e.g. ""Kant was also a fan."" with no further exposition or mention.Ultimately, Domingos has a very solid technical view of most stuff he discusses, but then he brings a lot of his personal intuitive futuristic views that can either happen or not. His conclusions and views in more social/political problems, like how should we share our data with AI companies, are also troubling for me. Overall too much utopian gut-feeling in a book about data-centred approaches."
129,0465065708,http://goodreads.com/user/show/23963235-akshith-rao,3,"This book captures the various types of machine learning techniques and how they have progressed through time. The author, being an academician, gets too technical. Even a decent understanding of math did not prevent some pages from turning into Latin for me. If you are someone who is knee deep in math and probability and would like to get an overall picture I would definitely recommend this book to you. For everyone else, it might be better to start looking somewhere else or just skip the math side of things in this book."
130,0465065708,http://goodreads.com/user/show/7297326-jim-crocker,5,"I'm not really finished. This is the kind of book that will go on and on and on with amazing insights and revelations about AI and Machine Learning. I've already heard that it is outta date. But, hey, whaddaya gonna do? Things move fast out there. With me it moves a little slower. I read and think and read and on it goes... This book was an eye-opener for me. I discovered a whole knew point of view. Essentially, it was a paradigm shift.This is a glimpse of the future of humans and the interactions, transactions and associations that will be taking place over the coming years. It's really transformational stuff that's going on. Here's two quotes that I liked (there's a ton more):** ""Most of all, we have to worry about what the Master Algorithm could do in the wrong hands.""** ""...you also have an ethical duty to share data for the common good.""I like that last one best of all!For your convenience, you can get this wonderful book right here:www.blackdogebooks.com/redhot-pick"
131,0465065708,http://goodreads.com/user/show/1173423-peter,5,"Really nice read. Serves as an accessible introduction to machine learning whilst simultaneously outlining the respective strengths and weaknesses of its 5 different ""tribes"" and ultimately showing how they can be connected. This makes the book valuable even for machine learning practitioners. Furthermore, in these days where deep learning reigns supreme and the media make it seem it is the end-all-be-all of machine learning, this book adds a valuable historical and conceptual perspective. The derivation and description of the current best stab at the Master Algorithm is more technical though, and probably more difficult to follow for the non-technical reader.The author is very bullish in the scale and scope of the application of machine learning and he offers powerful examples of AI in the form of personal agents negotiating the world on our behalf, the enabler of systems biology, and eventually designing and enhancing humans. However I think his view is quite utopian and that he downplays several potential negative scenarios of both weak and strong AI. For instance, Domingos believes that job displacement will not be grave (the argument that more new jobs that we now can't imagine will be created than will be destroyed), and that even if this were to happen, then if it reaches critical mass (>50%), then in a democracy that majority will vote for lifelong salaries for just being alive (i.e. universal basic income). However I think there is a path-dependance here on things staying the same politically. Let's contrast it with the scenario in Yuval Harari's Homo Deus of the creation of a class of ""useless"" humans who don't have to offer anything economically nor militarily. The political power of the masses would then be greatly diminished, perhaps even up to the point of threatening liberal democracy.Looking even further into the future, he does not take into account the dangers of reductionist goals. He basically argues that because machines don't have goals of their own, we are safe. Nick Bostrom belabors the dangers of strong AI in his book Superintelligence.In conclusion, although I think the dangers of AI were downplayed, I think it was a great read. I would recommend pairing this book (written by an machine learning researcher & practitioner) up with Homo Deus (written by a historian) and Superintelligence (by a philosopher) for a more holistic view if your interest is primarily on the (future) impact of AI."
132,0465065708,http://goodreads.com/user/show/38621776-an-l-tuncel,1,"Disappointing. This book has no scientific value. No one should read this book, not even teenagers (they will get confused). "
133,0465065708,http://goodreads.com/user/show/19014583-t,4,"I enjoyed this book overall but had some frustrations with it. Enough so that it was a real debate between 3 and 4 stars for me; I'm giving it 4 now as a benefit of the doubt but I may reread and drop it to 3 if it doesn't seem better.First, the topic couldn't be more relevant and interesting to our time; both for buzz word purposes and real discussion of the current state of the field the book was interesting. That said, I had several annoyances. First, the author seemed quite taken with creating fanciful allegories for things that were clear attempts to be poetic or entertaining and in practice were often just kind of dumb. In the more lower level cases they would help add to understanding, but the broader they got the more you felt like you were wasting your time while he talked about wandering through a city and spent time describing the turrets or telling you what you suddenly remembered or felt. Ick. Second, the premise at the start of the book seemed to be that anyone could understand and contribute to all of the field and the rest of the book seemed, to me at least, to rather disprove that. I think he tried to make this accessible to all and thus went a step too far; he'd have been better off saying the requirements of the field are not so high as many fear and thus are accessible to many more than would expect it. Saying anyone could do it even without complicated math just seemed inaccurate even using his own description by the end.Finally, the overall structure of the book and the discussion of the five ""tribes"" left me somewhat uncertain. I couldn't decide if that was an actually useful description or more confusing than helpful. In part this was because my reading was rather fractured through time so I'm reserving judgment of this for a more thorough reread.All that said, the book was still an interesting overview of the current state and problems of the machine learning world and, when not trying to wax poetic, was a pretty good and understandable summary of those and a nice encouragement for those of us on the edge of the field to get into it."
134,0465065708,http://goodreads.com/user/show/3550209-adrian,5,"Who knew the 'S' curve was the most important function ever?I picked up ""The Master Algorithm"" hoping it would serve as a primer as I began my journey into the world of deep learning. At first, I found it overly figurative and difficult to follow so I stopped reading it. After about 6 months of Andrew Ng YouTube videos, SciKit Learn, PyImageSearch, and other well-organized tutorials, I revisited the book and fell in love with it. What I appreciated most was the discussion of the 5 tribes of machine learning and how he was able to merge the mentality of the different camps. I'd consider myself an Analogizer and I work with a Bayesian. Often, it feels like we are talking different languages. I had to chuckle a few time as this book addressed this common dynamic.I enjoyed Chapter 9 the most with his fanciful depiction of a continent divided into 5 territories: Symbolist, Connectionists, Evolutionists, Bayesians, and Analogizers with Master Algorithm serving as the capital city. He did an excellent job conceptualizing how different aspects of each 'tribe' would contribute to the one unifying, but elusive, algorithm. He went to great lengths to establish his sci-fi bona fides with references to Lord of the Rings, The Matrix, Robocop, and much more. My favorite came when he was discussing Support Vector Machines and visualizing the border between classes as a snake slithering down the no-man's-land with the support vectors serving as mines. It's ""like the sandworms in Dune: big, tough, and able to survive a few explosions from slithering over landmines but not too many"". A five-star rating was locked after that."
135,0465065708,http://goodreads.com/user/show/5858138-nic-brisbourne,4,"Domingos provides a detailed and pretty technical explanation of five different areas of artificial intelligence:* Symbolists - observe and inducer Dix logic in the world and code it - works well in limited domains and highly explainable, but impossible to scale* Neural networks - infer rules from large amounts of data to by looking at training sets - if it's seen enough pictures of cats it can compute the probability that a new image is a cat* Genetic algorithms - define an objective and let evolve according to rules, and then keep the solutions that beat fit the desired goal, and then repeat. Key is choosing the rules and fit algorithms well* Bayesians and probabalistic influence- great at finding categories and classifying things* Analogisers and Support Vector Machines - good for spotting similarities between things and making predictions about other things that might be similar - if I have flu, and we are friends but don't live in the same town, what is the chance that you also have flu?This stuff is quite dense! I have a solid grounding in maths, science, and stats but haven't practiced for decades and understood most of it, but had to read slowly. Domingos writes well and with humour which makes reading much easier. Finally - I should also say that he does a good job of making it real with examples and a semi-good job of predicting where the future will take us. "
136,0465065708,http://goodreads.com/user/show/47032429-kenta-suzuki,4,"Pedro Domingo describes the machine learnings from its origin to now, and how it can be used in the future. He purports that the Master Algorithm be the one that is ultimate goal of machine learning or universal learner as he call it. This algorithm will be replete with or fall into the intersection of the five bailiwicks: Symbolists, Connectionists, Evolutionaries, Bayesians, and Analogizers. For symbolists, Inverse Deduction is algorithm, Gradient Descent for Connectionists, Genetic Search for Evolutionaries, Probabilistic Inference for Bayesian and Constrained Optimization for Analogizers. For instance, Netflix uses k-nearest- neighbor algorithm, which finds the correlations with each others, to create recommendation system.This algorithm is so important that recommender system consists of a third of Amazon's business. In the future, he claims, that there will be one version of yourself who or which basically do most of the things on behalf of you faster than you could. He also argues that the fears some people have toward AI or Singularity will be relinquished if humans deal with them carefully. For instance, there will no infinite growth of AI as is the case with Moore's law. It will eventually taper off as S curve deliniates. This book will gives some prelude to those areas for those who do not have solid backgrounds for statistics or machine learning. "
137,0465065708,http://goodreads.com/user/show/51672399-david,4,"Domingos' attraction to analogical learning leads him to fill this book with analogies for almost everything he talks about. I wonder if a computer develops consciousness would they find it as annoying as I did? Other than this nuisance, the book gives a great overview of the history and state of machine learning. The various subfields outlined in the novel are very well abstracted to show the significant similarities and differences between them.However, Domingos' view of the future, as stated in the last chapter, wouldn't be the most inspiring. The possibility of an algorithm that could predict cancer treatment through genome mapping is surely an excellent use of machine learning but his belief that war will be ""fought"" by between different learners isn't something I'm looking forward to. The author assures the reader of this certainty. For me, this is just a stark reminder that technology advancement does not necessarily advance society in a positive way. In the case of fighting algorithms, there will be a victor and whomever or whatever possesses this technology will be the one with the power to rule a lot of important aspects in this world. This scenario just looks like a continuation of the current trend in the concentration of wealth and power into the hands of the few and not the many."
138,0465065708,http://goodreads.com/user/show/8146846-satyabrata-mishra,5,"Pedros Domingos does a fascinating job describing complex machine learning algorithms in forms of simple (and sometimes silly) metaphors and examples; like dividing the different forms of AI-engineers into tribes and walking down the cities of their design.For someone who wants to peek into machine learning and understand the powers and faults of each algorithm, the master algorithm is a great choice. I picked it up as a pre-read before my ML classes starts and I could not have made a better choice. "
139,0465065708,http://goodreads.com/user/show/60299397-victor-villas,3,"The book starts very slowly, hyping up the idea of the master algorithm. The middle parts are really interesting, where each of the ""five tribes"" of machine learning are discussed. It ends with some self promotion for the alchemy thingy the author is part of. For serious machine learning students this book might be a waste of time, but is still entertaining for the laymen."
140,0465065708,http://goodreads.com/user/show/4696922-ushan,1,"I took Prof. Domingos's data mining course at the UW night school in 2001, and I was wondering whether this book can give a good overview of the progress of the machine learning since then. It doesn't. It is plainly badly written. If I were a layman, I wouldn't have understood anything."
141,0465065708,http://goodreads.com/user/show/2237619-josh,3,"It's been over 200 years since Babbage, and around 60 years since the first serious forays into developing intelligent electronic machines, and we finally seem to have come to a point in history where machine learning is coming of age. The history of AI cautions one against excessive optimism, but the successes of machine learning are becoming impossible to ignore. Machine learners have steadily encroached on areas of intelligence previously thought to be accessible only to the human mind. The lowlands of human thought are rapidly being filled by the flood of artificial intelligence, and there's little reason to believe that the rising tide is going to stop any time soon. There is hardly a field of academic research or sector of the economy that has not been affected in some way by machine learning, and more radical changes loom. Advances in neuroscience along with a torrent of machine learning research hint at a general learning algorithm that would make all other advances in human science seem trivial in comparison. To repeat an oft-quoted phrase, ""the first ultraintelligent machine is the last invention that man need ever make"". That, in essence, is what Pedro Domingos' book is about.It starts off with a broad overview of how machine learning algorithms (he calls them learners), are omnipresent in modern society. Algorithms help decide what you see on your social media news feed, which videos you watch, which products you buy, which stocks to add to your portfolio, which ads you see, which political candidates you vote for and who you decide to date. I don't think it's an exaggeration to say that machine learning has revolutionized almost every aspect of how we live our day-to-day lives.And that's just getting started.Domingos divides machine learning research into five 'tribes' and spends some time discussing each of them in detail: the Symbolists, the Connectionists, the Evolutionaries, the Bayesians, and the Analogizers.The Symbolists advocate a rule-based approach to learning, and use logical inference as their main tool. This was a common tactic with the expert AI systems of the 80s, and still has a large place in automated systems today. A big problem that every machine learning algorithm has to deal with when understanding large datasets is the vast set of possible interpretations for that data, and the Symbolists have a few effective ways of dealing with this. If you want to build a system that can diagnose an illness, you might go about it by forming a decision tree. Does the person have a rash? If so, does that person also have a cold? And so on. Anyone who's played the game 20 questions can probably see why this approach might be an effective way of building intelligent systems. It also has the downside that these systems are costly and time-consuming to construct, not to mention they lack a certain degree of generality. Domingos doesn't seem to be a fan of this school of research, and for the most part he quickly passes it by so he can move on to other methods. Rule-based inference, for the most part, does not seem like a particularly effective way of interpreting data, and it certainly isn't how human brains interpret data. For a more biologically inspired learning method we have the connectionists.If you've heard any of the recent headlines about DeepMind's AlphaGo beating the world Go champion, you've heard about connectionism. Connectionists are the practitioners of neural networks--artificial simulations of the sort of neurons we see in animal brains. Since human-level intelligence has so far only been exhibited in human brains, a natural approach to programming intelligence is by reverse engineering the human brain. People have been programming neural networks for about as long as programmable computers have been around--the first attempts were made in the 50s, and despite a steady following of researchers in the meantime it is only recently that neural networks have really begun to have their full potential realized. This is due in part to the fact that processors today are more powerful than ever, but also because the Internet is a rich sea of data that we can use to train our networks. Still, neural nets, despite their amazing versatility for solving problems, are quite cumbersome and aren't exact representations of the human brain. It's not even clear whether an exact simulation of how the brain works would be an efficient computational model. They also take a lot of computing power to train, so for certain situations they are not ideal.Another biologically-inspired approach to machine learning is evolutionary computing. The idea behind this one is sound: human intelligence arose through evolutionary processes, so why can't we write programs to 'evolve' through a sort of Darwinian selection process? If we select for the tributes we want a program to have, say for a self-driving car to drive safely, and reject the attributes we don't want it to have, say, crashing into stop signs, we can eventually produce a program that will be a good driver. In theory, at least. The problem, of course, is that human intelligence took hundreds of millions of years to evolve to where it is now, and researchers don't have that kind of time to spend. It also seems to be a bit of a fluke that intelligence even arose at all, considering all the time in prehistory where it wasn't around. Evolution is a tricky thing to recreate, and the successes of evolutionary computing have been overshadowed by other methods. It remains to be seen if they will one day come into the spotlight like connectionism has in recent years.The Bayesians are mostly involved in applying Bayes' theorem to machine learning problem. Thomas Bayes, a 17th century Englishman, was a statistician who formulated one of the most famous theorems in probability theory. His theorem helps us understand how events are related to each other, and how the probability of one event affects another. Applications of this fairly simple theory are among the most popular approaches to machine learning and still seen to be the most widely used. While this approach isn't as biologically inspired as the other methods, Bayesian inference does still represent something our brains have to do to interact intelligently with the world. Bayesian theory is very robust in its application and can be applied to a wide range of real-world problems. Things do tend to get a bit hairy when dealing with problems that have a lot of variables, but with the right simplifying assumptions this has proved to be a very powerful theory.The Analogizers, as Domingos calls them, aren't as unified as the other tribes. Human learning could perhaps be best characterized as learning by analogy. We learn new concepts by associating them with old concepts we already know. It turns out statistical formulations of this type of learning are also quite effective, as can be seen by various automated recommendation systems designed by companies like Netflix or Amazon. Truth be told it wasn't entirely clear to me how this approach differed significantly from the other approaches already discussed, but I guess Domingos felt the distinction was necessary.He then goes on to discuss a hodgepodge of various other learning strategies that take influence from human psychology, notably reinforcement learning. Reinforcement learning agents choose between possible actions to take in an environment based on the expectation of future rewards from that action. If pressing a button rewards a reinforcement learning agent, the agent will quickly learning to spend as much of its time pressing that button as possible. Reinforcement learning by itself doesn't generalize to other problems outside of a narrow domain especially well, but when combined with neural networks it can be a powerful approach for machine learning problems.The final chapter of the book is about the future of machine learning, and full of the typical sort of predictions that authors of this type of book seem to love. Personally I feel like most of what Domingos has to say in this chapter has been dealt with better by other authors, but I digress. Machine learning will certainly have a huge impact on every aspect of our lives. In a very real way you are the data that you create. Other people make models of you based on your behavior just like Netflix makes models of your movie-viewing habits. The reason so many companies have started racing to collect your data is because that data is powerful. It influences the choices we make at an individual level and thus influences the whole of our society. This is a scary thought to some, and is certainly something that should be taken into consideration by human rights organizations and governments. On the flipside, data is becoming democratized very quickly--a fact which is helping facilitate positive social change at a faster rate than ever before in the history of civilization. Some are worried about machines achieving human levels of intelligence, but I think those fears are misguided. It is far more advantageous for us to consider what new avenues of possibility have opened up than to dwell on the roads we will leave behind. To quote Domingos: ""The real history of automation is not what it replaces but what it enables.""Overall the book is a good general overview of the research being done in machine learning today. It does not, however, substitute for a more serious mathematical treatment of the subject, and those wishing to delve deeper into the subject would be better served elsewhere. Still, as a light introduction to the subject this book is worth looking into."
142,0465065708,http://goodreads.com/user/show/3055905-nils,4,"A useful book that lays out the five “tribes” of machine learning and ecumenically proposes that the true “master algorithm” (AGI) will combine all five: the symbolists’ inverse deduction, the connectionists’ backpropagation, the evolutionists’ genetic programming, the Bayesians’ various theorems, and the analogizers’ support vector machines.What’s most dated about this 2015 book is how utterly sanguine he is about what moving toward a master algorithm will produce in terms of social effects. It’s not just that he rejects the scaremongering of the Singulatarians (as he points out, the algorithms are never going to have wills of their own), but it’s more than he doesn’t consider except in the most glancing way what may happen if bad people control the algorithm, or the more profound problem of what it means if each of us has a shadow algorithmically optimized version of ourselves representing us in the world — how this could ironically lead to a loss of will, a surrender to the algorithmic engine that supposedly understands our preferences better than we do. Do we really want to live in a world where, “everyone has an entourage of bots, smoothing his or her way through the world.… Your digital half will be like power steering for your life.” Occasionally he glimpses the dystopian possibilities but then handwaves then away: “This does not mean that you’ll end up in a ‘filter bubble,’ seeing only what you reliably like, with no room for the unexpected,” he reassures us. “The digital you knows better than that. Part of its brief is to leave some things open to chance, to expose you to new experiences, and to look for serendipity.” Nor does he really consider the philosophical implications of a situation where “You have your model of every person in the organization you interact with, and they each have their model of you. As the models improve, their interaction becomes more and more like the ones you would have in the real world.” What’s happening in this scenario is that border between human and machine is eroding, with humans themselves evolving and in many cases likely to surrender control, happily turning over their decision making to their digital self. Are we so sure, in this scenario that the distinction between the willful human and the enslaved machines makes sense? We need not worry about silly infinite paperclip scenarios, is a world where many of us have become merely wired bundles of continuously satisfied Id a world we want to live in? Is a world where technology splinters the unity of the human race, as he predicts, not a world with truly fearsome possibilities? Consider this passage: “One of the greatest talents a politician can have is the ability to understand voters, individually or in small groups, and to speak directly to them (or seem to). Bill Clinton is the paradigmatic example of this in recent memory. The effect of machine learning is like having a dedicated Bill Clinton for every voter.” Wait, is that a promise, or a threat?! Likewise, would anyone in 2019 in good conscience be able to write that, “Democracy works better because the bandwidth of communications between voters and politicians increases enormously.... Big data and machine learning [will] change the equation. In the future, provided voter models are accurate, elected officials will be able to ask a voters what they want 1000 times a day and act accordingly – without having to pester the actual flesh and blood citizens.” Provided voter models are accurate is doing a whole lotta work there, wouldn’t you say?"
143,0465065708,http://goodreads.com/user/show/56104661-mark,3,"Pedro Domingos wastes no time in laying out his bold hypothesis on which The Master Algorithm: How The Quest for the Ultimate Learning Machine Will Remake Our World is based. Early in chapter two, he declares that: “All knowledge—past, present, and future—can be derived from data by a single, universal learning algorithm.” Clearly, Domingos believes that such an algorithm can be developed, but for the doubting Thomases among us, he cites strong lines of evidence from the disciplines of neuroscience, evolution, physics, statistics, and computer science.The search for the Master Algorithm does not have to start from scratch, Domingos tells us. The bulk of the book describes five current approaches to machine learning—or “five tribes of machine learning,” as he labels them—namely, symbolists, connectionists, evolutionaries, Bayesians, and analogizers. These tribes each have a set of core beliefs, and a central problem they must solve. Domingos’s detailed descriptions of how they do that occasionally results in dense and complex narrative, but he cleverly illustrates his points with familiar, daily-life examples, with equally familiar organizations, such as Google, Amazon, Netflix, and Facebook.Of course, the true Master Algorithm must solve the problems of all five tribes, and the reader is encouraged to stick with the narrative and even take a leap of faith in some of the more involved explanations (“Bayesian networks and Naïve Bayes classifier” was this reader’s particular leap of faith!). The author’s writing is captivating and teasing as he describes the benefits and shortcomings of each machine learning style, steadily building belief in the Master Algorithm at the end of each chapter. However, drawing from the five tribes is still not enough to satisfy specifications of the Master Algorithm: Domingos goes on to talk about the need for principal component analysis, dimensionality reduction, and metalearning.By the time one reaches the chapter, “The Pieces of the Puzzle Fall into Place,” and Domingos has pulled together the five models of learning into one elegant and beautiful schematic, the reader is convinced of the feasibility of the Master Algorithm. Domingos hammers home this conviction by explaining how his derived model handles the three necessary elements of representation (a model's formal language of expression), evaluation (a scoring function to say how good a model is), and optimization (the search for the highest-scoring model). In the closing chapter, “This is the World on Machine Learning,” Domingos anticipates how machine learning and the Master Algorithm will affect society as a whole and each and every one of us in many aspects of daily life. Overall, Domingos has crafted a thought-provoking book about a thrilling subject, as fantastic as it is believable. He deftly keeps the reader turning the pages with bursts of humor, big-picture concepts, and behind-the-scenes glimpses of existing learning models. This book is both serious entertainment and education!"
144,0465065708,http://goodreads.com/user/show/11375563-michael-huang,3,"Domingos writes eloquently and lucidly about what machine learning (ML) is doing to the society (helping scientists do them work and make Obama win elections) and how it's supposedly going to change everything (industrial and information revolution automated manual and mental work respectively, ML will automate the automation). And he points out a simple and clearly stated hypothesis, the central hypothesis of the book: ""All knowledge - past, present, and future - can be derived from data by a single, universal learning algorithm"". He then tantalizingly showed the arguments from neural science (we as a species learned knowledge didn't we?); from evolution (our brain was evolved from virtually nothing, why not some master algorithm?); from physics (witness the unreasonable effectiveness of math in natural science); from statistics (Bayes's theorem describes how you can update any belief); from Computer Science (didn't Turing show us how there is a universal machine). By the time I finished Chapter 2, the book looks up to be by far the best book I've read this year (out of 96).Unfortunately, the rest of the book seems to be written by a different person. The lucidity is out. In come weird analogies and references that impede understanding rather than helping it. Maybe he is too excited and his neurons keep firing at even weak associations, but the text would have been returned as ""Needing major revision"" if it was submitted to a journal. Nevertheless, he did explain the five different sub communities of the umbrella community of ML in the next 5 chapters; and rather unconvincingly touted his own research as potentially the ""Master Algorithm"". (I don't mean to suggest his research is bad. In fact, his description of Alchemy seems completely fine and something he should definitely continue to look into. It's just not of the table-pounding, forehead-palming why-didn't-I-think-of-that variety.) At last he closes with what the future holds store once the Master Algorithm arrives. This part is, thankfully, deprived of unnecessary analogies and similes, but is rather anticlimactic (e.g., in the future ""let your people call mine"" becomes ""let your algorithm talk to mine"")."
145,0465065708,http://goodreads.com/user/show/108995717-dan,4,"Very nice overview of the current machine learning paradigms and algorithms: symbolism and induction, connectionism and backpropagation, evolutionism and genetic algorithms, Bayesian and statistical inference, analogy and support vector machines. In its attempt to unify them, it also points to similarities/dissimilarities, weaknesses/strengths, and so on. On the other hand, the Messianic expectation of “The Master Algorithm” that will unify the five different paradigms/algorithms in the same way a Theory of Everything will unify everything in Physics is ridiculous. Most likely, in new data intensive fields completely new and specialized algorithms will emerge beyond the five mentioned in this book and they will stay distinct and specialized. Google is organizing and manipulating the Internet, Amazon is overselling to us, Facebook is selling our profiles, genetic medicine is trying to make sense of the huge amount of data it possesses, the self-driving cars are generating their own data, satellites are mapping the Earth and the sky in small details, and so on. Specialized algorithms can predict and control almost anything in these limited, commercial, and digital fields. But beyond these few data intensive fields, there is no data available and we still need to generate data in the old fashion, small, and expensive ways as we always did if we have some specific hypotheses/questions. Defining “everything that is” and “human intelligence and science” along these commercial data-algorithm ways betrays some naive ontology and epistemology. Moreover, expecting that algorithms that perform extremely well in very specific situations/fields to converge to some Mater Algorithm that explains everything and that will take our human understanding to a new level is an unjustified extrapolation."
146,0465065708,http://goodreads.com/user/show/58987379-ville,3,"Great topic – difficult approachThe book covers three different topics of which each could make a thick book on their own.-	The technical history of machine learning and development of the major algorithms-	Mr Rodriques idea of a universal learning algorithm (‘the master algorithm’)-	Ideas how machine learning has affected our lives and speculations about the futureThese are some of my favourite topics and I would love to love this book, but I can’t. The most problematic was the actual beef of the book: the master algorithm. Even as I have done my fair share of machine learning as M.Sc. in process control and worked with many of the algorithms described for years at work, I found it very difficult to follow and even understand his idea of the MLN method. It was just too difficult approach without some actual examples for me at least.The best parts of the book were some awesome insights that only a true master could state with such simple and entertaining terms.My favorite highlights.-	Believe it or not, every algorithm, no matter how complex, can be reduced to just these three operations: AND, OR, and NOT.-	People often think computers are all about numbers, but they’re not. Computers are all about logic.-	Overfitting is the central problem in machine learning. More papers have been written about it than about any other topic… Humans are not immune to overfitting, either. You could even say that it’s the root cause of a lot of our evils. Consider the little white girl who, upon seeing a Latina baby at the mall, blurted out “Look, Mom, a baby maid!” (True event.) It’s not that she’s a natural-born bigot.-	S curves are a nice halfway house between the dumbness of linear functions and the hardness of step functions.-	An autoencoder is a multilayer perceptron whose output is the same as its input. In goes a picture of your grandmother and out comes—the same picture of your grandmother …the network is forced to encode the input in fewer bits, so it can be represented in the hidden layer, and then decode those bits back to full size. …. However the neet trick was to make the hidden layer actually bigger than the input-output-layers but only allow a few of them to fire at any given moment…-	(k-) nearest neighbor is truly a superfast algorithm but with the slow database connections a trained neural network is sure to win.-	Symbolist methods, for one, are fairly good at disposing of irrelevant attributes. If an attribute has no information about the class, it’s just never included in the decision tree or rule set. But nearest-neighbor is hopelessly confused by irrelevant attributes because they all contribute to the similarity between examples.-	No learner is immune to the curse of dimensionality. It’s the second worst problem in machine learning, after overfitting.-	PCA is to unsupervised learning what linear regression is to the supervised variety.-	Random forests are some of the most accurate classifiers around. Microsoft’s Kinect uses them to figure out what you’re doing, and they regularly win machine-learning competitions.-	(The problem with) combined models can be quite opaque. (“I believe you have prostate cancer because the decision tree, the genetic algorithm, and Naïve Bayes say so, although the multilayer perceptron and the SVM disagree.”)About the future:-	The first robo-lawyers that argue for a particular verdict based on precedents have already been built…Perhaps in a future cybercourt, in session somewhere on Amazon’s cloud, a robo-lawyer will beat the speeding ticket that RoboCop issued to your driverless car, all while you go to the beach, and Leibniz’s dream of reducing all argument to calculation will finally have come true.-	Some researchers even argue that the way to create intelligent machines is to build a robot baby and let him experience the world as a human baby does…The question, of course, is what algorithm should be running in Robby’s brain at birth.-	(You have already “a digital self” living in the internet databases that is good at finding things for you that you are interested.) Even more interesting, the process doesn’t end when you find a car, a house, a doctor, a date, or a job. Your digital half is continually learning from its experiences, just as you would. It figures out what works and doesn’t, whether it’s in job interviews, dating, or real-estate hunting. -	You have your model of every person and organization you interact with, and they each have their model of you. As the models improve, their interactions become more and more like the ones you would have in the real world—except millions of times faster and in silicon. Tomorrow’s cyberspace will be a vast parallel world that selects only the most promising things to try out in the real one. It will be like a new, global subconscious, the collective id of the human race.-	(But the problem right now is that) everyone has only a sliver of it. Google sees your searches, Amazon your online purchases, AT&T your phone calls, Apple your music downloads, Safeway your groceries, Capital One your credit-card transactions. Companies like Acxiom collate and sell information about you, but if you inspect it (which in Acxiom’s case you can, at aboutthedata.com), it’s not much, and some of it is wrong. No one has anything even approaching a complete picture of you.-	Eventually, we’ll start talking about the employment rate instead of the unemployment one and reducing it will be seen as a sign of progress. (“The US is falling behind. Our employment rate is still 23 percent.”)-	People will seek meaning in human relationships, self-actualization, and spirituality, much as they do now. The need to earn a living will be a distant memory, another piece of humanity’s barbaric past that we rose above. -	Picture two strands of DNA going for a swim in their private pool, aka a bacterium’s cytoplasm, two billion years ago. They’re pondering a momentous decision. “I’m worried, Diana,” says one. “If we start making multicellular creatures, will they take over?” -	Contrary to what we like to believe today, humans quite easily fall into obeying others, and any sufficiently advanced AI is indistinguishable from God. People worry that computers will get too smart and take over the world, but the real problem is that they’re too stupid and they’ve already taken over the world. "
147,0465065708,http://goodreads.com/user/show/56609924-flaviu-vescan,3,"I was looking for a book that explains ML and AI concepts for non-practitioners. It did a great job at that. It goes through the most used 7 types of ML algorithms/concepts and explains how they work using high-level math and analogies. It blends a bit of the history of the field so that's always nice to contextualize the information. What made me only give it 3 stars are the detours it keeps making into predicting the future and the crazy soft stance it takes towards the tech giants like FB and GOOG. I'm not sure if Mr. Domingos is still willing to be have such a friendly opinion of them after the latest findings on how they use ML and the many privacy breaches they've had, but I hope not. In any case I'm judging the books version of events and it's lacking any criticism towards the uses of ML in manipulating public opinion. The book is great at teaching you the high-level workings of ML. The problem I had was it kept trying to do more than that by taking a stab at predicting the future of the field influence on humanity. Even for a specialist, it's mostly speculation. "
148,0465065708,http://goodreads.com/user/show/96942737-gautham,3,"A book for those who wish to have an aerial / Birdseye view of the subject, probably a novice in the field but I don’t think it can be of much help for a layman. It was as if Domingos wanted to explain almost all the topics / tribes of the world of Machine learning, from their basics, under one cover, which may have been possible if the book had housed at least about a 1000 or so pages maybe but his choice of including as many topics as he did has trumped the point of ‘understandability’ which a book like this should be focusing on in the first place.The slithering snake analogy for explaining SVMs was the worst of the analogies that he could come up with.However, there are certain learnings that one could get from this book but at the cost 300 pages @ your individual reading speeds is too big a price to pay.The last two chapters of the book seems like the summary of the rest of the chapters with an extension and conclusion. So, if you want to take a quick read, you know where to start."
149,0465065708,http://goodreads.com/user/show/93344337-benny,4,"A few years ago, I came across a list of machine learning algorithms that aspiring data scientists should familiarise themselves with. Since then, I have delved into various machine learning algorithms intermittently during my spare time. In this book, Pedro Domingos has broadly classified them into 5 different families of algorithms. To take these applications further, he suggested that eventually one Master Algorithm can perform that roles that each family of algorithms plays in deciphering our physical world. Below are some of the algorithms that are covered by the author.Genetic AlgorithmNeural Networks(eg. backpropagation, gradient descent)K-nearest NeighbourSupport Vector Machines(eg. kernels)Bayes NetworkK-means ClusteringPCARandom ForestEigenfaces....The book provides a neat high-level summary into the development of these algorithms and how they have come about. With prior understanding of how they work, it is pleasant way to review how these machine learning algorithms optimise, learn and automate our tasks without needing to immerse oneself in the math and computer science that are powering all these AI applications behind the scenes."
150,0465065708,http://goodreads.com/user/show/50245822-srinath-srinath,4,"Great book, gives an overall view of how 5 groups(bayesians,analogizers,symbolists,connectionists,evolutionaries) of people have been competing and trying to solve intelligence. The technical details have been very well explained for a layman to understand."
151,0465065708,http://goodreads.com/user/show/16463508-toma,4,"It is a bit technical for someone who is not in the field or used to some of the theories presented but a great read to understand Artificial Intelligence, Machine Learning and the major schools/philosophies in the field."
152,0465065708,http://goodreads.com/user/show/20064141-maureen-fitzpatrick,4,"It might be a five star book, but this is a book that is just beyond what I understand; however, what I understand is greater having read the book."
153,0465065708,http://goodreads.com/user/show/40460162-steve-jay,5,"If you're a huge nerd and have an interest in futurology, mathematics and computers, this is a must read! Blew my mind."
154,0465065708,http://goodreads.com/user/show/38024135-theodore-kinni,3,"Probably good for budding data scientists, but it's dense and too detailed for the untutored"
155,0465065708,http://goodreads.com/user/show/15317284-carlos-vasconcelos,4,A good book for a broad audience. 
156,0465065708,http://goodreads.com/user/show/50847541-florin-grigoriu,3,"OK to recap the ML notions, the fiction style is too mainstream making the book sometime too buzz-word-ish"
157,0465065708,http://goodreads.com/user/show/76014-raghu,4,"Artificial Intelligence has gradually become a part of our routine discourse. It is because we experience it in varying degrees in even our humdrum lives. We read in the news that driverless cars are already running on our roads. When we sign on to Netflix, we see movie recommendations for us. Often, they turn out to be better than what our friends and relatives suggest to us. Websites help us save money on airline tickets more than before. Google predicts flu outbreaks before CDC has been able to do so. All this is due to Artificial Intelligence or AI for short, of varying degrees. AI is a vast field and has been an area of research since the 1950s. This book is about one branch of AI which is hot today, called Machine Learning.Historically, we have written specific computer programs to solve specific problems using the computer. Each such program is in effect an algorithm to deal with that problem. Machine learning diverges from this traditional approach. It provides computers with the ability to learn. A specific problem is solved without being explicitly programmed for it. Machine learning consists of programs that can teach themselves to grow and change when exposed to more and more data. This book goes one step further. It discusses the holy grail of Machine Learning that researchers are working on, called the Master Algorithm. Right in the first chapter, the author defines this holy grail as follows: ""All knowledge - present, past and future - can be derived by a single, universal learning algorithm"".Now, this might seem ambitious to most of us, including scientists in the field. Some might even slam it as typical of the 'techno-hubris' of Silicon Valley. But the author makes a case that a master algorithm is a feature of nature itself. He shows that there are similar examples in Neuroscience and Evolution. The book captures Machine learning succinctly by the following unwritten rule through which it works:""we must induce the most widely applicable rules we can and reduce their scope only when data forces us to do so"".There are five approaches to Machine Learning today. They are classified as the Symbolists, the Connectionists, the Evolutionaries, the Bayesians and the Analogizers. Each of them is explained briefly as follows:Symbolists believe all intelligence can be reduced to manipulating symbols just as we do in Mathematics. In simple terms, Symbolists start with some existing premises and conclusions. Then, they work backward to fill in the gaps in knowledge by analyzing existing data sets. This is called inverse deduction. Connectionists believe that we must reverse engineer the brain and achieve machine learning. This approach is called 'deep learning'. It consists of creating 'digital neurons' in the computer and connecting them in a neural network model. Google uses this approach in machine translation. It is also used in image processing.Evolutionaries believe in learning through genetic programming. This method mates and evolves computer programs the way nature evolves species. It applies the ideas similar to that of Genomes and DNA in the evolutionary process to data structures. The Genetic programming model works by quantifying the performance of data. It is used to determine the retention and propagation of algorithms in an evolutionary way.Bayesians believe in using Bayes theorem and its derivatives to learn through probabilistic inference. This method proposes a few hypotheses. Then, it assigns probabilities for the likely outcomes of applying these hypotheses. By applying more and more data to test these hypotheses, some of them become more likely than the others. In this way, we arrive at the most likely solution to the problem. This is used in spam filters on emails.Analogizers believe the key to learning is recognizing similarities between situations. This principle is called the nearest neighbour principle. One important aspect of Analogy is that it lets you learn from little data. Analogizers can learn from even just one example - You are what you resemble. Charles Darwin used Malthus' theory of the struggle for survival in society to formulate the biological theory of evolution. Niels Bohr used the solar system model to formulate his theory of the atomic model. A website like Netflix uses it in the recommendations it gives to customers. For example, let us say that someone, whose profile is similar to yours, liked the movie 'Avatar'. Then it is likely that you will like Avatar as well, if you have not seen it already. So, a recommendation of Avatar is made for you. However, all these approaches are not mutually exclusive. Machine learning uses a selective combination of them, depending on the problem. For example, in medicine, the Evolutionary approach is not preferred. The way nature learns is through making mistakes - a luxury we don't have in our societies. Doctors must diagnose in a foolproof way. For example, failing to find a tumor that is really there, is potentially much worse than inferring one that isn't. It needs optimal decisions and this where the Bayesian approach is more useful. In AI, Symbolists held sway in the first few decades of cognitive psychology. Then Connectionists held sway in the 1980s and 90s, and it is the Bayesians' time in the Sun now. The author is upbeat about the future transformations that Machine Learning will bring to our societies. He suggests that in the not too distant future, we will all have a 'digital half' which will do our bidding all 24 hours of the day. They will interact with the digital halves of every person and organization we deal with. Tomorrow's cyberspace will be a giant parallel world. It will be like a new, global subconscious, the collective id of the human race. My only caveat about the book is its prognosis for the future. There is no doubt that the future will be transformed in many ways by Machine Learning. Scientists have been mostly right about predicting the future technological inventions. On the other hand, scientists from Thomas Malthus to Paul Ehrlich to the Club of Rome have made dire predictions about the future of mankind and disaster for thickly populated countries like India and China. They were woefully wrong in this. Not all scientific advances have a smooth path to their full potential. The expected potentials of Nuclear energy and Genetically Modified crops have not materialized because of resistance in our societies. There is also resistance to Stem cells and possibilities of Human cloning. Machine learning is in its infancy now. As it develops and impacts our lives more and more, the technology is bound to make mistakes in a way that affect our lives negatively. If some of them happen to be of the dimension of the Chernobyl accident in Nuclear energy, then there may be a big backlash to the advance of AI too. The other related danger is to rely on vast quantities of data on a phenomenon which leave out key attributes of representing the phenomena correctly, but use it anyway to make crucial decisions. One example in the past of such misuse of data happened in the 1960s. Sen.Robert McNamara, Secy of Defence in the Johnson administration, went about escalating the Vietnam war by relying on 'death count of US and Vietcong soldiers' as a key data indicator of how the war was progressing. The data did not capture the will and determination of the Vietnamese communists to rid themselves of foreign occupation of their land. We all know the consequences of this key error.I enjoyed reading the book as it was educational for me and I learnt much from it. The chapters elaborating the five approaches to Machine Learning need some focus and concentration to fully understand them. Readers, who find these chapters a bit hard, can still simply read just the first 60 pages to get a very good idea of the subject. All in all, it is a great effort to present this exciting subject in a simple way."
158,0465065708,http://goodreads.com/user/show/10768018-jo-o,3,"The idea of a master algorithm is a kind of computer science saint graal. An optimal model for most problems in reality, a robust super-A.I. with the best qualities of organic brains and computer power merged. For this to happen Domingos argues that the 5 tribes of machine learning have to merge as if currently they were very different communities. Those are: symbolists (e.g. logic-based models, decision trees); connectionists (e.g. neural networks); evolutionaries (genetic algorithms); bayesians (graph theory and Bayes-inspired modelling); analogizers (support vector machines, etc.). While this is a ""cool"" vision I find it hard to argue that models can be categorized under that schematic (many hybrids, or some are just specific cases of others) or that the communities of researchers are isolated in any way. Most people with MAJOR published contributions/advances in any of the ""5 tribes"", has papers in the others... usually dozens... (and some are really important as well)!From what else I've read from Domingos I'd rather recommend his short essays, and scientific papers. The big book format gives too much space for random rambling and there are a lot of cringe sentences like random name dropping e.g. ""Kant was also a fan."" with no further exposition or mention.Ultimately, Domingos has a very solid technical view of most stuff he discusses, but then he brings a lot of his personal intuitive futuristic views that can either happen or not. His conclusions and views in more social/political problems, like how should we share our data with AI companies, are also troubling for me. Overall too much utopian gut-feeling in a book about data-centred approaches."
159,0465065708,http://goodreads.com/user/show/23963235-akshith-rao,3,"This book captures the various types of machine learning techniques and how they have progressed through time. The author, being an academician, gets too technical. Even a decent understanding of math did not prevent some pages from turning into Latin for me. If you are someone who is knee deep in math and probability and would like to get an overall picture I would definitely recommend this book to you. For everyone else, it might be better to start looking somewhere else or just skip the math side of things in this book."
160,0465065708,http://goodreads.com/user/show/7297326-jim-crocker,5,"I'm not really finished. This is the kind of book that will go on and on and on with amazing insights and revelations about AI and Machine Learning. I've already heard that it is outta date. But, hey, whaddaya gonna do? Things move fast out there. With me it moves a little slower. I read and think and read and on it goes... This book was an eye-opener for me. I discovered a whole knew point of view. Essentially, it was a paradigm shift.This is a glimpse of the future of humans and the interactions, transactions and associations that will be taking place over the coming years. It's really transformational stuff that's going on. Here's two quotes that I liked (there's a ton more):** ""Most of all, we have to worry about what the Master Algorithm could do in the wrong hands.""** ""...you also have an ethical duty to share data for the common good.""I like that last one best of all!For your convenience, you can get this wonderful book right here:www.blackdogebooks.com/redhot-pick"
161,0465065708,http://goodreads.com/user/show/1173423-peter,5,"Really nice read. Serves as an accessible introduction to machine learning whilst simultaneously outlining the respective strengths and weaknesses of its 5 different ""tribes"" and ultimately showing how they can be connected. This makes the book valuable even for machine learning practitioners. Furthermore, in these days where deep learning reigns supreme and the media make it seem it is the end-all-be-all of machine learning, this book adds a valuable historical and conceptual perspective. The derivation and description of the current best stab at the Master Algorithm is more technical though, and probably more difficult to follow for the non-technical reader.The author is very bullish in the scale and scope of the application of machine learning and he offers powerful examples of AI in the form of personal agents negotiating the world on our behalf, the enabler of systems biology, and eventually designing and enhancing humans. However I think his view is quite utopian and that he downplays several potential negative scenarios of both weak and strong AI. For instance, Domingos believes that job displacement will not be grave (the argument that more new jobs that we now can't imagine will be created than will be destroyed), and that even if this were to happen, then if it reaches critical mass (>50%), then in a democracy that majority will vote for lifelong salaries for just being alive (i.e. universal basic income). However I think there is a path-dependance here on things staying the same politically. Let's contrast it with the scenario in Yuval Harari's Homo Deus of the creation of a class of ""useless"" humans who don't have to offer anything economically nor militarily. The political power of the masses would then be greatly diminished, perhaps even up to the point of threatening liberal democracy.Looking even further into the future, he does not take into account the dangers of reductionist goals. He basically argues that because machines don't have goals of their own, we are safe. Nick Bostrom belabors the dangers of strong AI in his book Superintelligence.In conclusion, although I think the dangers of AI were downplayed, I think it was a great read. I would recommend pairing this book (written by an machine learning researcher & practitioner) up with Homo Deus (written by a historian) and Superintelligence (by a philosopher) for a more holistic view if your interest is primarily on the (future) impact of AI."
162,0465065708,http://goodreads.com/user/show/38621776-an-l-tuncel,1,"Disappointing. This book has no scientific value. No one should read this book, not even teenagers (they will get confused). "
163,0465065708,http://goodreads.com/user/show/19014583-t,4,"I enjoyed this book overall but had some frustrations with it. Enough so that it was a real debate between 3 and 4 stars for me; I'm giving it 4 now as a benefit of the doubt but I may reread and drop it to 3 if it doesn't seem better.First, the topic couldn't be more relevant and interesting to our time; both for buzz word purposes and real discussion of the current state of the field the book was interesting. That said, I had several annoyances. First, the author seemed quite taken with creating fanciful allegories for things that were clear attempts to be poetic or entertaining and in practice were often just kind of dumb. In the more lower level cases they would help add to understanding, but the broader they got the more you felt like you were wasting your time while he talked about wandering through a city and spent time describing the turrets or telling you what you suddenly remembered or felt. Ick. Second, the premise at the start of the book seemed to be that anyone could understand and contribute to all of the field and the rest of the book seemed, to me at least, to rather disprove that. I think he tried to make this accessible to all and thus went a step too far; he'd have been better off saying the requirements of the field are not so high as many fear and thus are accessible to many more than would expect it. Saying anyone could do it even without complicated math just seemed inaccurate even using his own description by the end.Finally, the overall structure of the book and the discussion of the five ""tribes"" left me somewhat uncertain. I couldn't decide if that was an actually useful description or more confusing than helpful. In part this was because my reading was rather fractured through time so I'm reserving judgment of this for a more thorough reread.All that said, the book was still an interesting overview of the current state and problems of the machine learning world and, when not trying to wax poetic, was a pretty good and understandable summary of those and a nice encouragement for those of us on the edge of the field to get into it."
164,0465065708,http://goodreads.com/user/show/3550209-adrian,5,"Who knew the 'S' curve was the most important function ever?I picked up ""The Master Algorithm"" hoping it would serve as a primer as I began my journey into the world of deep learning. At first, I found it overly figurative and difficult to follow so I stopped reading it. After about 6 months of Andrew Ng YouTube videos, SciKit Learn, PyImageSearch, and other well-organized tutorials, I revisited the book and fell in love with it. What I appreciated most was the discussion of the 5 tribes of machine learning and how he was able to merge the mentality of the different camps. I'd consider myself an Analogizer and I work with a Bayesian. Often, it feels like we are talking different languages. I had to chuckle a few time as this book addressed this common dynamic.I enjoyed Chapter 9 the most with his fanciful depiction of a continent divided into 5 territories: Symbolist, Connectionists, Evolutionists, Bayesians, and Analogizers with Master Algorithm serving as the capital city. He did an excellent job conceptualizing how different aspects of each 'tribe' would contribute to the one unifying, but elusive, algorithm. He went to great lengths to establish his sci-fi bona fides with references to Lord of the Rings, The Matrix, Robocop, and much more. My favorite came when he was discussing Support Vector Machines and visualizing the border between classes as a snake slithering down the no-man's-land with the support vectors serving as mines. It's ""like the sandworms in Dune: big, tough, and able to survive a few explosions from slithering over landmines but not too many"". A five-star rating was locked after that."
165,0465065708,http://goodreads.com/user/show/5858138-nic-brisbourne,4,"Domingos provides a detailed and pretty technical explanation of five different areas of artificial intelligence:* Symbolists - observe and inducer Dix logic in the world and code it - works well in limited domains and highly explainable, but impossible to scale* Neural networks - infer rules from large amounts of data to by looking at training sets - if it's seen enough pictures of cats it can compute the probability that a new image is a cat* Genetic algorithms - define an objective and let evolve according to rules, and then keep the solutions that beat fit the desired goal, and then repeat. Key is choosing the rules and fit algorithms well* Bayesians and probabalistic influence- great at finding categories and classifying things* Analogisers and Support Vector Machines - good for spotting similarities between things and making predictions about other things that might be similar - if I have flu, and we are friends but don't live in the same town, what is the chance that you also have flu?This stuff is quite dense! I have a solid grounding in maths, science, and stats but haven't practiced for decades and understood most of it, but had to read slowly. Domingos writes well and with humour which makes reading much easier. Finally - I should also say that he does a good job of making it real with examples and a semi-good job of predicting where the future will take us. "
166,0465065708,http://goodreads.com/user/show/47032429-kenta-suzuki,4,"Pedro Domingo describes the machine learnings from its origin to now, and how it can be used in the future. He purports that the Master Algorithm be the one that is ultimate goal of machine learning or universal learner as he call it. This algorithm will be replete with or fall into the intersection of the five bailiwicks: Symbolists, Connectionists, Evolutionaries, Bayesians, and Analogizers. For symbolists, Inverse Deduction is algorithm, Gradient Descent for Connectionists, Genetic Search for Evolutionaries, Probabilistic Inference for Bayesian and Constrained Optimization for Analogizers. For instance, Netflix uses k-nearest- neighbor algorithm, which finds the correlations with each others, to create recommendation system.This algorithm is so important that recommender system consists of a third of Amazon's business. In the future, he claims, that there will be one version of yourself who or which basically do most of the things on behalf of you faster than you could. He also argues that the fears some people have toward AI or Singularity will be relinquished if humans deal with them carefully. For instance, there will no infinite growth of AI as is the case with Moore's law. It will eventually taper off as S curve deliniates. This book will gives some prelude to those areas for those who do not have solid backgrounds for statistics or machine learning. "
167,0465065708,http://goodreads.com/user/show/51672399-david,4,"Domingos' attraction to analogical learning leads him to fill this book with analogies for almost everything he talks about. I wonder if a computer develops consciousness would they find it as annoying as I did? Other than this nuisance, the book gives a great overview of the history and state of machine learning. The various subfields outlined in the novel are very well abstracted to show the significant similarities and differences between them.However, Domingos' view of the future, as stated in the last chapter, wouldn't be the most inspiring. The possibility of an algorithm that could predict cancer treatment through genome mapping is surely an excellent use of machine learning but his belief that war will be ""fought"" by between different learners isn't something I'm looking forward to. The author assures the reader of this certainty. For me, this is just a stark reminder that technology advancement does not necessarily advance society in a positive way. In the case of fighting algorithms, there will be a victor and whomever or whatever possesses this technology will be the one with the power to rule a lot of important aspects in this world. This scenario just looks like a continuation of the current trend in the concentration of wealth and power into the hands of the few and not the many."
168,0465065708,http://goodreads.com/user/show/8146846-satyabrata-mishra,5,"Pedros Domingos does a fascinating job describing complex machine learning algorithms in forms of simple (and sometimes silly) metaphors and examples; like dividing the different forms of AI-engineers into tribes and walking down the cities of their design.For someone who wants to peek into machine learning and understand the powers and faults of each algorithm, the master algorithm is a great choice. I picked it up as a pre-read before my ML classes starts and I could not have made a better choice. "
169,0465065708,http://goodreads.com/user/show/60299397-victor-villas,3,"The book starts very slowly, hyping up the idea of the master algorithm. The middle parts are really interesting, where each of the ""five tribes"" of machine learning are discussed. It ends with some self promotion for the alchemy thingy the author is part of. For serious machine learning students this book might be a waste of time, but is still entertaining for the laymen."
170,0465065708,http://goodreads.com/user/show/4696922-ushan,1,"I took Prof. Domingos's data mining course at the UW night school in 2001, and I was wondering whether this book can give a good overview of the progress of the machine learning since then. It doesn't. It is plainly badly written. If I were a layman, I wouldn't have understood anything."
171,0465065708,http://goodreads.com/user/show/2237619-josh,3,"It's been over 200 years since Babbage, and around 60 years since the first serious forays into developing intelligent electronic machines, and we finally seem to have come to a point in history where machine learning is coming of age. The history of AI cautions one against excessive optimism, but the successes of machine learning are becoming impossible to ignore. Machine learners have steadily encroached on areas of intelligence previously thought to be accessible only to the human mind. The lowlands of human thought are rapidly being filled by the flood of artificial intelligence, and there's little reason to believe that the rising tide is going to stop any time soon. There is hardly a field of academic research or sector of the economy that has not been affected in some way by machine learning, and more radical changes loom. Advances in neuroscience along with a torrent of machine learning research hint at a general learning algorithm that would make all other advances in human science seem trivial in comparison. To repeat an oft-quoted phrase, ""the first ultraintelligent machine is the last invention that man need ever make"". That, in essence, is what Pedro Domingos' book is about.It starts off with a broad overview of how machine learning algorithms (he calls them learners), are omnipresent in modern society. Algorithms help decide what you see on your social media news feed, which videos you watch, which products you buy, which stocks to add to your portfolio, which ads you see, which political candidates you vote for and who you decide to date. I don't think it's an exaggeration to say that machine learning has revolutionized almost every aspect of how we live our day-to-day lives.And that's just getting started.Domingos divides machine learning research into five 'tribes' and spends some time discussing each of them in detail: the Symbolists, the Connectionists, the Evolutionaries, the Bayesians, and the Analogizers.The Symbolists advocate a rule-based approach to learning, and use logical inference as their main tool. This was a common tactic with the expert AI systems of the 80s, and still has a large place in automated systems today. A big problem that every machine learning algorithm has to deal with when understanding large datasets is the vast set of possible interpretations for that data, and the Symbolists have a few effective ways of dealing with this. If you want to build a system that can diagnose an illness, you might go about it by forming a decision tree. Does the person have a rash? If so, does that person also have a cold? And so on. Anyone who's played the game 20 questions can probably see why this approach might be an effective way of building intelligent systems. It also has the downside that these systems are costly and time-consuming to construct, not to mention they lack a certain degree of generality. Domingos doesn't seem to be a fan of this school of research, and for the most part he quickly passes it by so he can move on to other methods. Rule-based inference, for the most part, does not seem like a particularly effective way of interpreting data, and it certainly isn't how human brains interpret data. For a more biologically inspired learning method we have the connectionists.If you've heard any of the recent headlines about DeepMind's AlphaGo beating the world Go champion, you've heard about connectionism. Connectionists are the practitioners of neural networks--artificial simulations of the sort of neurons we see in animal brains. Since human-level intelligence has so far only been exhibited in human brains, a natural approach to programming intelligence is by reverse engineering the human brain. People have been programming neural networks for about as long as programmable computers have been around--the first attempts were made in the 50s, and despite a steady following of researchers in the meantime it is only recently that neural networks have really begun to have their full potential realized. This is due in part to the fact that processors today are more powerful than ever, but also because the Internet is a rich sea of data that we can use to train our networks. Still, neural nets, despite their amazing versatility for solving problems, are quite cumbersome and aren't exact representations of the human brain. It's not even clear whether an exact simulation of how the brain works would be an efficient computational model. They also take a lot of computing power to train, so for certain situations they are not ideal.Another biologically-inspired approach to machine learning is evolutionary computing. The idea behind this one is sound: human intelligence arose through evolutionary processes, so why can't we write programs to 'evolve' through a sort of Darwinian selection process? If we select for the tributes we want a program to have, say for a self-driving car to drive safely, and reject the attributes we don't want it to have, say, crashing into stop signs, we can eventually produce a program that will be a good driver. In theory, at least. The problem, of course, is that human intelligence took hundreds of millions of years to evolve to where it is now, and researchers don't have that kind of time to spend. It also seems to be a bit of a fluke that intelligence even arose at all, considering all the time in prehistory where it wasn't around. Evolution is a tricky thing to recreate, and the successes of evolutionary computing have been overshadowed by other methods. It remains to be seen if they will one day come into the spotlight like connectionism has in recent years.The Bayesians are mostly involved in applying Bayes' theorem to machine learning problem. Thomas Bayes, a 17th century Englishman, was a statistician who formulated one of the most famous theorems in probability theory. His theorem helps us understand how events are related to each other, and how the probability of one event affects another. Applications of this fairly simple theory are among the most popular approaches to machine learning and still seen to be the most widely used. While this approach isn't as biologically inspired as the other methods, Bayesian inference does still represent something our brains have to do to interact intelligently with the world. Bayesian theory is very robust in its application and can be applied to a wide range of real-world problems. Things do tend to get a bit hairy when dealing with problems that have a lot of variables, but with the right simplifying assumptions this has proved to be a very powerful theory.The Analogizers, as Domingos calls them, aren't as unified as the other tribes. Human learning could perhaps be best characterized as learning by analogy. We learn new concepts by associating them with old concepts we already know. It turns out statistical formulations of this type of learning are also quite effective, as can be seen by various automated recommendation systems designed by companies like Netflix or Amazon. Truth be told it wasn't entirely clear to me how this approach differed significantly from the other approaches already discussed, but I guess Domingos felt the distinction was necessary.He then goes on to discuss a hodgepodge of various other learning strategies that take influence from human psychology, notably reinforcement learning. Reinforcement learning agents choose between possible actions to take in an environment based on the expectation of future rewards from that action. If pressing a button rewards a reinforcement learning agent, the agent will quickly learning to spend as much of its time pressing that button as possible. Reinforcement learning by itself doesn't generalize to other problems outside of a narrow domain especially well, but when combined with neural networks it can be a powerful approach for machine learning problems.The final chapter of the book is about the future of machine learning, and full of the typical sort of predictions that authors of this type of book seem to love. Personally I feel like most of what Domingos has to say in this chapter has been dealt with better by other authors, but I digress. Machine learning will certainly have a huge impact on every aspect of our lives. In a very real way you are the data that you create. Other people make models of you based on your behavior just like Netflix makes models of your movie-viewing habits. The reason so many companies have started racing to collect your data is because that data is powerful. It influences the choices we make at an individual level and thus influences the whole of our society. This is a scary thought to some, and is certainly something that should be taken into consideration by human rights organizations and governments. On the flipside, data is becoming democratized very quickly--a fact which is helping facilitate positive social change at a faster rate than ever before in the history of civilization. Some are worried about machines achieving human levels of intelligence, but I think those fears are misguided. It is far more advantageous for us to consider what new avenues of possibility have opened up than to dwell on the roads we will leave behind. To quote Domingos: ""The real history of automation is not what it replaces but what it enables.""Overall the book is a good general overview of the research being done in machine learning today. It does not, however, substitute for a more serious mathematical treatment of the subject, and those wishing to delve deeper into the subject would be better served elsewhere. Still, as a light introduction to the subject this book is worth looking into."
172,0465065708,http://goodreads.com/user/show/3055905-nils,4,"A useful book that lays out the five “tribes” of machine learning and ecumenically proposes that the true “master algorithm” (AGI) will combine all five: the symbolists’ inverse deduction, the connectionists’ backpropagation, the evolutionists’ genetic programming, the Bayesians’ various theorems, and the analogizers’ support vector machines.What’s most dated about this 2015 book is how utterly sanguine he is about what moving toward a master algorithm will produce in terms of social effects. It’s not just that he rejects the scaremongering of the Singulatarians (as he points out, the algorithms are never going to have wills of their own), but it’s more than he doesn’t consider except in the most glancing way what may happen if bad people control the algorithm, or the more profound problem of what it means if each of us has a shadow algorithmically optimized version of ourselves representing us in the world — how this could ironically lead to a loss of will, a surrender to the algorithmic engine that supposedly understands our preferences better than we do. Do we really want to live in a world where, “everyone has an entourage of bots, smoothing his or her way through the world.… Your digital half will be like power steering for your life.” Occasionally he glimpses the dystopian possibilities but then handwaves then away: “This does not mean that you’ll end up in a ‘filter bubble,’ seeing only what you reliably like, with no room for the unexpected,” he reassures us. “The digital you knows better than that. Part of its brief is to leave some things open to chance, to expose you to new experiences, and to look for serendipity.” Nor does he really consider the philosophical implications of a situation where “You have your model of every person in the organization you interact with, and they each have their model of you. As the models improve, their interaction becomes more and more like the ones you would have in the real world.” What’s happening in this scenario is that border between human and machine is eroding, with humans themselves evolving and in many cases likely to surrender control, happily turning over their decision making to their digital self. Are we so sure, in this scenario that the distinction between the willful human and the enslaved machines makes sense? We need not worry about silly infinite paperclip scenarios, is a world where many of us have become merely wired bundles of continuously satisfied Id a world we want to live in? Is a world where technology splinters the unity of the human race, as he predicts, not a world with truly fearsome possibilities? Consider this passage: “One of the greatest talents a politician can have is the ability to understand voters, individually or in small groups, and to speak directly to them (or seem to). Bill Clinton is the paradigmatic example of this in recent memory. The effect of machine learning is like having a dedicated Bill Clinton for every voter.” Wait, is that a promise, or a threat?! Likewise, would anyone in 2019 in good conscience be able to write that, “Democracy works better because the bandwidth of communications between voters and politicians increases enormously.... Big data and machine learning [will] change the equation. In the future, provided voter models are accurate, elected officials will be able to ask a voters what they want 1000 times a day and act accordingly – without having to pester the actual flesh and blood citizens.” Provided voter models are accurate is doing a whole lotta work there, wouldn’t you say?"
173,0465065708,http://goodreads.com/user/show/56104661-mark,3,"Pedro Domingos wastes no time in laying out his bold hypothesis on which The Master Algorithm: How The Quest for the Ultimate Learning Machine Will Remake Our World is based. Early in chapter two, he declares that: “All knowledge—past, present, and future—can be derived from data by a single, universal learning algorithm.” Clearly, Domingos believes that such an algorithm can be developed, but for the doubting Thomases among us, he cites strong lines of evidence from the disciplines of neuroscience, evolution, physics, statistics, and computer science.The search for the Master Algorithm does not have to start from scratch, Domingos tells us. The bulk of the book describes five current approaches to machine learning—or “five tribes of machine learning,” as he labels them—namely, symbolists, connectionists, evolutionaries, Bayesians, and analogizers. These tribes each have a set of core beliefs, and a central problem they must solve. Domingos’s detailed descriptions of how they do that occasionally results in dense and complex narrative, but he cleverly illustrates his points with familiar, daily-life examples, with equally familiar organizations, such as Google, Amazon, Netflix, and Facebook.Of course, the true Master Algorithm must solve the problems of all five tribes, and the reader is encouraged to stick with the narrative and even take a leap of faith in some of the more involved explanations (“Bayesian networks and Naïve Bayes classifier” was this reader’s particular leap of faith!). The author’s writing is captivating and teasing as he describes the benefits and shortcomings of each machine learning style, steadily building belief in the Master Algorithm at the end of each chapter. However, drawing from the five tribes is still not enough to satisfy specifications of the Master Algorithm: Domingos goes on to talk about the need for principal component analysis, dimensionality reduction, and metalearning.By the time one reaches the chapter, “The Pieces of the Puzzle Fall into Place,” and Domingos has pulled together the five models of learning into one elegant and beautiful schematic, the reader is convinced of the feasibility of the Master Algorithm. Domingos hammers home this conviction by explaining how his derived model handles the three necessary elements of representation (a model's formal language of expression), evaluation (a scoring function to say how good a model is), and optimization (the search for the highest-scoring model). In the closing chapter, “This is the World on Machine Learning,” Domingos anticipates how machine learning and the Master Algorithm will affect society as a whole and each and every one of us in many aspects of daily life. Overall, Domingos has crafted a thought-provoking book about a thrilling subject, as fantastic as it is believable. He deftly keeps the reader turning the pages with bursts of humor, big-picture concepts, and behind-the-scenes glimpses of existing learning models. This book is both serious entertainment and education!"
174,0465065708,http://goodreads.com/user/show/11375563-michael-huang,3,"Domingos writes eloquently and lucidly about what machine learning (ML) is doing to the society (helping scientists do them work and make Obama win elections) and how it's supposedly going to change everything (industrial and information revolution automated manual and mental work respectively, ML will automate the automation). And he points out a simple and clearly stated hypothesis, the central hypothesis of the book: ""All knowledge - past, present, and future - can be derived from data by a single, universal learning algorithm"". He then tantalizingly showed the arguments from neural science (we as a species learned knowledge didn't we?); from evolution (our brain was evolved from virtually nothing, why not some master algorithm?); from physics (witness the unreasonable effectiveness of math in natural science); from statistics (Bayes's theorem describes how you can update any belief); from Computer Science (didn't Turing show us how there is a universal machine). By the time I finished Chapter 2, the book looks up to be by far the best book I've read this year (out of 96).Unfortunately, the rest of the book seems to be written by a different person. The lucidity is out. In come weird analogies and references that impede understanding rather than helping it. Maybe he is too excited and his neurons keep firing at even weak associations, but the text would have been returned as ""Needing major revision"" if it was submitted to a journal. Nevertheless, he did explain the five different sub communities of the umbrella community of ML in the next 5 chapters; and rather unconvincingly touted his own research as potentially the ""Master Algorithm"". (I don't mean to suggest his research is bad. In fact, his description of Alchemy seems completely fine and something he should definitely continue to look into. It's just not of the table-pounding, forehead-palming why-didn't-I-think-of-that variety.) At last he closes with what the future holds store once the Master Algorithm arrives. This part is, thankfully, deprived of unnecessary analogies and similes, but is rather anticlimactic (e.g., in the future ""let your people call mine"" becomes ""let your algorithm talk to mine"")."
175,0465065708,http://goodreads.com/user/show/108995717-dan,4,"Very nice overview of the current machine learning paradigms and algorithms: symbolism and induction, connectionism and backpropagation, evolutionism and genetic algorithms, Bayesian and statistical inference, analogy and support vector machines. In its attempt to unify them, it also points to similarities/dissimilarities, weaknesses/strengths, and so on. On the other hand, the Messianic expectation of “The Master Algorithm” that will unify the five different paradigms/algorithms in the same way a Theory of Everything will unify everything in Physics is ridiculous. Most likely, in new data intensive fields completely new and specialized algorithms will emerge beyond the five mentioned in this book and they will stay distinct and specialized. Google is organizing and manipulating the Internet, Amazon is overselling to us, Facebook is selling our profiles, genetic medicine is trying to make sense of the huge amount of data it possesses, the self-driving cars are generating their own data, satellites are mapping the Earth and the sky in small details, and so on. Specialized algorithms can predict and control almost anything in these limited, commercial, and digital fields. But beyond these few data intensive fields, there is no data available and we still need to generate data in the old fashion, small, and expensive ways as we always did if we have some specific hypotheses/questions. Defining “everything that is” and “human intelligence and science” along these commercial data-algorithm ways betrays some naive ontology and epistemology. Moreover, expecting that algorithms that perform extremely well in very specific situations/fields to converge to some Mater Algorithm that explains everything and that will take our human understanding to a new level is an unjustified extrapolation."
176,0465065708,http://goodreads.com/user/show/58987379-ville,3,"Great topic – difficult approachThe book covers three different topics of which each could make a thick book on their own.-	The technical history of machine learning and development of the major algorithms-	Mr Rodriques idea of a universal learning algorithm (‘the master algorithm’)-	Ideas how machine learning has affected our lives and speculations about the futureThese are some of my favourite topics and I would love to love this book, but I can’t. The most problematic was the actual beef of the book: the master algorithm. Even as I have done my fair share of machine learning as M.Sc. in process control and worked with many of the algorithms described for years at work, I found it very difficult to follow and even understand his idea of the MLN method. It was just too difficult approach without some actual examples for me at least.The best parts of the book were some awesome insights that only a true master could state with such simple and entertaining terms.My favorite highlights.-	Believe it or not, every algorithm, no matter how complex, can be reduced to just these three operations: AND, OR, and NOT.-	People often think computers are all about numbers, but they’re not. Computers are all about logic.-	Overfitting is the central problem in machine learning. More papers have been written about it than about any other topic… Humans are not immune to overfitting, either. You could even say that it’s the root cause of a lot of our evils. Consider the little white girl who, upon seeing a Latina baby at the mall, blurted out “Look, Mom, a baby maid!” (True event.) It’s not that she’s a natural-born bigot.-	S curves are a nice halfway house between the dumbness of linear functions and the hardness of step functions.-	An autoencoder is a multilayer perceptron whose output is the same as its input. In goes a picture of your grandmother and out comes—the same picture of your grandmother …the network is forced to encode the input in fewer bits, so it can be represented in the hidden layer, and then decode those bits back to full size. …. However the neet trick was to make the hidden layer actually bigger than the input-output-layers but only allow a few of them to fire at any given moment…-	(k-) nearest neighbor is truly a superfast algorithm but with the slow database connections a trained neural network is sure to win.-	Symbolist methods, for one, are fairly good at disposing of irrelevant attributes. If an attribute has no information about the class, it’s just never included in the decision tree or rule set. But nearest-neighbor is hopelessly confused by irrelevant attributes because they all contribute to the similarity between examples.-	No learner is immune to the curse of dimensionality. It’s the second worst problem in machine learning, after overfitting.-	PCA is to unsupervised learning what linear regression is to the supervised variety.-	Random forests are some of the most accurate classifiers around. Microsoft’s Kinect uses them to figure out what you’re doing, and they regularly win machine-learning competitions.-	(The problem with) combined models can be quite opaque. (“I believe you have prostate cancer because the decision tree, the genetic algorithm, and Naïve Bayes say so, although the multilayer perceptron and the SVM disagree.”)About the future:-	The first robo-lawyers that argue for a particular verdict based on precedents have already been built…Perhaps in a future cybercourt, in session somewhere on Amazon’s cloud, a robo-lawyer will beat the speeding ticket that RoboCop issued to your driverless car, all while you go to the beach, and Leibniz’s dream of reducing all argument to calculation will finally have come true.-	Some researchers even argue that the way to create intelligent machines is to build a robot baby and let him experience the world as a human baby does…The question, of course, is what algorithm should be running in Robby’s brain at birth.-	(You have already “a digital self” living in the internet databases that is good at finding things for you that you are interested.) Even more interesting, the process doesn’t end when you find a car, a house, a doctor, a date, or a job. Your digital half is continually learning from its experiences, just as you would. It figures out what works and doesn’t, whether it’s in job interviews, dating, or real-estate hunting. -	You have your model of every person and organization you interact with, and they each have their model of you. As the models improve, their interactions become more and more like the ones you would have in the real world—except millions of times faster and in silicon. Tomorrow’s cyberspace will be a vast parallel world that selects only the most promising things to try out in the real one. It will be like a new, global subconscious, the collective id of the human race.-	(But the problem right now is that) everyone has only a sliver of it. Google sees your searches, Amazon your online purchases, AT&T your phone calls, Apple your music downloads, Safeway your groceries, Capital One your credit-card transactions. Companies like Acxiom collate and sell information about you, but if you inspect it (which in Acxiom’s case you can, at aboutthedata.com), it’s not much, and some of it is wrong. No one has anything even approaching a complete picture of you.-	Eventually, we’ll start talking about the employment rate instead of the unemployment one and reducing it will be seen as a sign of progress. (“The US is falling behind. Our employment rate is still 23 percent.”)-	People will seek meaning in human relationships, self-actualization, and spirituality, much as they do now. The need to earn a living will be a distant memory, another piece of humanity’s barbaric past that we rose above. -	Picture two strands of DNA going for a swim in their private pool, aka a bacterium’s cytoplasm, two billion years ago. They’re pondering a momentous decision. “I’m worried, Diana,” says one. “If we start making multicellular creatures, will they take over?” -	Contrary to what we like to believe today, humans quite easily fall into obeying others, and any sufficiently advanced AI is indistinguishable from God. People worry that computers will get too smart and take over the world, but the real problem is that they’re too stupid and they’ve already taken over the world. "
177,0465065708,http://goodreads.com/user/show/56609924-flaviu-vescan,3,"I was looking for a book that explains ML and AI concepts for non-practitioners. It did a great job at that. It goes through the most used 7 types of ML algorithms/concepts and explains how they work using high-level math and analogies. It blends a bit of the history of the field so that's always nice to contextualize the information. What made me only give it 3 stars are the detours it keeps making into predicting the future and the crazy soft stance it takes towards the tech giants like FB and GOOG. I'm not sure if Mr. Domingos is still willing to be have such a friendly opinion of them after the latest findings on how they use ML and the many privacy breaches they've had, but I hope not. In any case I'm judging the books version of events and it's lacking any criticism towards the uses of ML in manipulating public opinion. The book is great at teaching you the high-level workings of ML. The problem I had was it kept trying to do more than that by taking a stab at predicting the future of the field influence on humanity. Even for a specialist, it's mostly speculation. "
178,0465065708,http://goodreads.com/user/show/96942737-gautham,3,"A book for those who wish to have an aerial / Birdseye view of the subject, probably a novice in the field but I don’t think it can be of much help for a layman. It was as if Domingos wanted to explain almost all the topics / tribes of the world of Machine learning, from their basics, under one cover, which may have been possible if the book had housed at least about a 1000 or so pages maybe but his choice of including as many topics as he did has trumped the point of ‘understandability’ which a book like this should be focusing on in the first place.The slithering snake analogy for explaining SVMs was the worst of the analogies that he could come up with.However, there are certain learnings that one could get from this book but at the cost 300 pages @ your individual reading speeds is too big a price to pay.The last two chapters of the book seems like the summary of the rest of the chapters with an extension and conclusion. So, if you want to take a quick read, you know where to start."
179,0465065708,http://goodreads.com/user/show/93344337-benny,4,"A few years ago, I came across a list of machine learning algorithms that aspiring data scientists should familiarise themselves with. Since then, I have delved into various machine learning algorithms intermittently during my spare time. In this book, Pedro Domingos has broadly classified them into 5 different families of algorithms. To take these applications further, he suggested that eventually one Master Algorithm can perform that roles that each family of algorithms plays in deciphering our physical world. Below are some of the algorithms that are covered by the author.Genetic AlgorithmNeural Networks(eg. backpropagation, gradient descent)K-nearest NeighbourSupport Vector Machines(eg. kernels)Bayes NetworkK-means ClusteringPCARandom ForestEigenfaces....The book provides a neat high-level summary into the development of these algorithms and how they have come about. With prior understanding of how they work, it is pleasant way to review how these machine learning algorithms optimise, learn and automate our tasks without needing to immerse oneself in the math and computer science that are powering all these AI applications behind the scenes."
180,0465065708,http://goodreads.com/user/show/50245822-srinath-srinath,4,"Great book, gives an overall view of how 5 groups(bayesians,analogizers,symbolists,connectionists,evolutionaries) of people have been competing and trying to solve intelligence. The technical details have been very well explained for a layman to understand."
181,0465065708,http://goodreads.com/user/show/16463508-toma,4,"It is a bit technical for someone who is not in the field or used to some of the theories presented but a great read to understand Artificial Intelligence, Machine Learning and the major schools/philosophies in the field."
182,0465065708,http://goodreads.com/user/show/20064141-maureen-fitzpatrick,4,"It might be a five star book, but this is a book that is just beyond what I understand; however, what I understand is greater having read the book."
183,0465065708,http://goodreads.com/user/show/40460162-steve-jay,5,"If you're a huge nerd and have an interest in futurology, mathematics and computers, this is a must read! Blew my mind."
184,0465065708,http://goodreads.com/user/show/38024135-theodore-kinni,3,"Probably good for budding data scientists, but it's dense and too detailed for the untutored"
185,0465065708,http://goodreads.com/user/show/15317284-carlos-vasconcelos,4,A good book for a broad audience. 
186,0465065708,http://goodreads.com/user/show/50847541-florin-grigoriu,3,"OK to recap the ML notions, the fiction style is too mainstream making the book sometime too buzz-word-ish"
187,0465065708,http://goodreads.com/user/show/76014-raghu,4,"Artificial Intelligence has gradually become a part of our routine discourse. It is because we experience it in varying degrees in even our humdrum lives. We read in the news that driverless cars are already running on our roads. When we sign on to Netflix, we see movie recommendations for us. Often, they turn out to be better than what our friends and relatives suggest to us. Websites help us save money on airline tickets more than before. Google predicts flu outbreaks before CDC has been able to do so. All this is due to Artificial Intelligence or AI for short, of varying degrees. AI is a vast field and has been an area of research since the 1950s. This book is about one branch of AI which is hot today, called Machine Learning.Historically, we have written specific computer programs to solve specific problems using the computer. Each such program is in effect an algorithm to deal with that problem. Machine learning diverges from this traditional approach. It provides computers with the ability to learn. A specific problem is solved without being explicitly programmed for it. Machine learning consists of programs that can teach themselves to grow and change when exposed to more and more data. This book goes one step further. It discusses the holy grail of Machine Learning that researchers are working on, called the Master Algorithm. Right in the first chapter, the author defines this holy grail as follows: ""All knowledge - present, past and future - can be derived by a single, universal learning algorithm"".Now, this might seem ambitious to most of us, including scientists in the field. Some might even slam it as typical of the 'techno-hubris' of Silicon Valley. But the author makes a case that a master algorithm is a feature of nature itself. He shows that there are similar examples in Neuroscience and Evolution. The book captures Machine learning succinctly by the following unwritten rule through which it works:""we must induce the most widely applicable rules we can and reduce their scope only when data forces us to do so"".There are five approaches to Machine Learning today. They are classified as the Symbolists, the Connectionists, the Evolutionaries, the Bayesians and the Analogizers. Each of them is explained briefly as follows:Symbolists believe all intelligence can be reduced to manipulating symbols just as we do in Mathematics. In simple terms, Symbolists start with some existing premises and conclusions. Then, they work backward to fill in the gaps in knowledge by analyzing existing data sets. This is called inverse deduction. Connectionists believe that we must reverse engineer the brain and achieve machine learning. This approach is called 'deep learning'. It consists of creating 'digital neurons' in the computer and connecting them in a neural network model. Google uses this approach in machine translation. It is also used in image processing.Evolutionaries believe in learning through genetic programming. This method mates and evolves computer programs the way nature evolves species. It applies the ideas similar to that of Genomes and DNA in the evolutionary process to data structures. The Genetic programming model works by quantifying the performance of data. It is used to determine the retention and propagation of algorithms in an evolutionary way.Bayesians believe in using Bayes theorem and its derivatives to learn through probabilistic inference. This method proposes a few hypotheses. Then, it assigns probabilities for the likely outcomes of applying these hypotheses. By applying more and more data to test these hypotheses, some of them become more likely than the others. In this way, we arrive at the most likely solution to the problem. This is used in spam filters on emails.Analogizers believe the key to learning is recognizing similarities between situations. This principle is called the nearest neighbour principle. One important aspect of Analogy is that it lets you learn from little data. Analogizers can learn from even just one example - You are what you resemble. Charles Darwin used Malthus' theory of the struggle for survival in society to formulate the biological theory of evolution. Niels Bohr used the solar system model to formulate his theory of the atomic model. A website like Netflix uses it in the recommendations it gives to customers. For example, let us say that someone, whose profile is similar to yours, liked the movie 'Avatar'. Then it is likely that you will like Avatar as well, if you have not seen it already. So, a recommendation of Avatar is made for you. However, all these approaches are not mutually exclusive. Machine learning uses a selective combination of them, depending on the problem. For example, in medicine, the Evolutionary approach is not preferred. The way nature learns is through making mistakes - a luxury we don't have in our societies. Doctors must diagnose in a foolproof way. For example, failing to find a tumor that is really there, is potentially much worse than inferring one that isn't. It needs optimal decisions and this where the Bayesian approach is more useful. In AI, Symbolists held sway in the first few decades of cognitive psychology. Then Connectionists held sway in the 1980s and 90s, and it is the Bayesians' time in the Sun now. The author is upbeat about the future transformations that Machine Learning will bring to our societies. He suggests that in the not too distant future, we will all have a 'digital half' which will do our bidding all 24 hours of the day. They will interact with the digital halves of every person and organization we deal with. Tomorrow's cyberspace will be a giant parallel world. It will be like a new, global subconscious, the collective id of the human race. My only caveat about the book is its prognosis for the future. There is no doubt that the future will be transformed in many ways by Machine Learning. Scientists have been mostly right about predicting the future technological inventions. On the other hand, scientists from Thomas Malthus to Paul Ehrlich to the Club of Rome have made dire predictions about the future of mankind and disaster for thickly populated countries like India and China. They were woefully wrong in this. Not all scientific advances have a smooth path to their full potential. The expected potentials of Nuclear energy and Genetically Modified crops have not materialized because of resistance in our societies. There is also resistance to Stem cells and possibilities of Human cloning. Machine learning is in its infancy now. As it develops and impacts our lives more and more, the technology is bound to make mistakes in a way that affect our lives negatively. If some of them happen to be of the dimension of the Chernobyl accident in Nuclear energy, then there may be a big backlash to the advance of AI too. The other related danger is to rely on vast quantities of data on a phenomenon which leave out key attributes of representing the phenomena correctly, but use it anyway to make crucial decisions. One example in the past of such misuse of data happened in the 1960s. Sen.Robert McNamara, Secy of Defence in the Johnson administration, went about escalating the Vietnam war by relying on 'death count of US and Vietcong soldiers' as a key data indicator of how the war was progressing. The data did not capture the will and determination of the Vietnamese communists to rid themselves of foreign occupation of their land. We all know the consequences of this key error.I enjoyed reading the book as it was educational for me and I learnt much from it. The chapters elaborating the five approaches to Machine Learning need some focus and concentration to fully understand them. Readers, who find these chapters a bit hard, can still simply read just the first 60 pages to get a very good idea of the subject. All in all, it is a great effort to present this exciting subject in a simple way."
188,0465065708,http://goodreads.com/user/show/10768018-jo-o,3,"The idea of a master algorithm is a kind of computer science saint graal. An optimal model for most problems in reality, a robust super-A.I. with the best qualities of organic brains and computer power merged. For this to happen Domingos argues that the 5 tribes of machine learning have to merge as if currently they were very different communities. Those are: symbolists (e.g. logic-based models, decision trees); connectionists (e.g. neural networks); evolutionaries (genetic algorithms); bayesians (graph theory and Bayes-inspired modelling); analogizers (support vector machines, etc.). While this is a ""cool"" vision I find it hard to argue that models can be categorized under that schematic (many hybrids, or some are just specific cases of others) or that the communities of researchers are isolated in any way. Most people with MAJOR published contributions/advances in any of the ""5 tribes"", has papers in the others... usually dozens... (and some are really important as well)!From what else I've read from Domingos I'd rather recommend his short essays, and scientific papers. The big book format gives too much space for random rambling and there are a lot of cringe sentences like random name dropping e.g. ""Kant was also a fan."" with no further exposition or mention.Ultimately, Domingos has a very solid technical view of most stuff he discusses, but then he brings a lot of his personal intuitive futuristic views that can either happen or not. His conclusions and views in more social/political problems, like how should we share our data with AI companies, are also troubling for me. Overall too much utopian gut-feeling in a book about data-centred approaches."
189,0465065708,http://goodreads.com/user/show/23963235-akshith-rao,3,"This book captures the various types of machine learning techniques and how they have progressed through time. The author, being an academician, gets too technical. Even a decent understanding of math did not prevent some pages from turning into Latin for me. If you are someone who is knee deep in math and probability and would like to get an overall picture I would definitely recommend this book to you. For everyone else, it might be better to start looking somewhere else or just skip the math side of things in this book."
190,0465065708,http://goodreads.com/user/show/7297326-jim-crocker,5,"I'm not really finished. This is the kind of book that will go on and on and on with amazing insights and revelations about AI and Machine Learning. I've already heard that it is outta date. But, hey, whaddaya gonna do? Things move fast out there. With me it moves a little slower. I read and think and read and on it goes... This book was an eye-opener for me. I discovered a whole knew point of view. Essentially, it was a paradigm shift.This is a glimpse of the future of humans and the interactions, transactions and associations that will be taking place over the coming years. It's really transformational stuff that's going on. Here's two quotes that I liked (there's a ton more):** ""Most of all, we have to worry about what the Master Algorithm could do in the wrong hands.""** ""...you also have an ethical duty to share data for the common good.""I like that last one best of all!For your convenience, you can get this wonderful book right here:www.blackdogebooks.com/redhot-pick"
191,0465065708,http://goodreads.com/user/show/1173423-peter,5,"Really nice read. Serves as an accessible introduction to machine learning whilst simultaneously outlining the respective strengths and weaknesses of its 5 different ""tribes"" and ultimately showing how they can be connected. This makes the book valuable even for machine learning practitioners. Furthermore, in these days where deep learning reigns supreme and the media make it seem it is the end-all-be-all of machine learning, this book adds a valuable historical and conceptual perspective. The derivation and description of the current best stab at the Master Algorithm is more technical though, and probably more difficult to follow for the non-technical reader.The author is very bullish in the scale and scope of the application of machine learning and he offers powerful examples of AI in the form of personal agents negotiating the world on our behalf, the enabler of systems biology, and eventually designing and enhancing humans. However I think his view is quite utopian and that he downplays several potential negative scenarios of both weak and strong AI. For instance, Domingos believes that job displacement will not be grave (the argument that more new jobs that we now can't imagine will be created than will be destroyed), and that even if this were to happen, then if it reaches critical mass (>50%), then in a democracy that majority will vote for lifelong salaries for just being alive (i.e. universal basic income). However I think there is a path-dependance here on things staying the same politically. Let's contrast it with the scenario in Yuval Harari's Homo Deus of the creation of a class of ""useless"" humans who don't have to offer anything economically nor militarily. The political power of the masses would then be greatly diminished, perhaps even up to the point of threatening liberal democracy.Looking even further into the future, he does not take into account the dangers of reductionist goals. He basically argues that because machines don't have goals of their own, we are safe. Nick Bostrom belabors the dangers of strong AI in his book Superintelligence.In conclusion, although I think the dangers of AI were downplayed, I think it was a great read. I would recommend pairing this book (written by an machine learning researcher & practitioner) up with Homo Deus (written by a historian) and Superintelligence (by a philosopher) for a more holistic view if your interest is primarily on the (future) impact of AI."
192,0465065708,http://goodreads.com/user/show/38621776-an-l-tuncel,1,"Disappointing. This book has no scientific value. No one should read this book, not even teenagers (they will get confused). "
193,0465065708,http://goodreads.com/user/show/19014583-t,4,"I enjoyed this book overall but had some frustrations with it. Enough so that it was a real debate between 3 and 4 stars for me; I'm giving it 4 now as a benefit of the doubt but I may reread and drop it to 3 if it doesn't seem better.First, the topic couldn't be more relevant and interesting to our time; both for buzz word purposes and real discussion of the current state of the field the book was interesting. That said, I had several annoyances. First, the author seemed quite taken with creating fanciful allegories for things that were clear attempts to be poetic or entertaining and in practice were often just kind of dumb. In the more lower level cases they would help add to understanding, but the broader they got the more you felt like you were wasting your time while he talked about wandering through a city and spent time describing the turrets or telling you what you suddenly remembered or felt. Ick. Second, the premise at the start of the book seemed to be that anyone could understand and contribute to all of the field and the rest of the book seemed, to me at least, to rather disprove that. I think he tried to make this accessible to all and thus went a step too far; he'd have been better off saying the requirements of the field are not so high as many fear and thus are accessible to many more than would expect it. Saying anyone could do it even without complicated math just seemed inaccurate even using his own description by the end.Finally, the overall structure of the book and the discussion of the five ""tribes"" left me somewhat uncertain. I couldn't decide if that was an actually useful description or more confusing than helpful. In part this was because my reading was rather fractured through time so I'm reserving judgment of this for a more thorough reread.All that said, the book was still an interesting overview of the current state and problems of the machine learning world and, when not trying to wax poetic, was a pretty good and understandable summary of those and a nice encouragement for those of us on the edge of the field to get into it."
194,0465065708,http://goodreads.com/user/show/3550209-adrian,5,"Who knew the 'S' curve was the most important function ever?I picked up ""The Master Algorithm"" hoping it would serve as a primer as I began my journey into the world of deep learning. At first, I found it overly figurative and difficult to follow so I stopped reading it. After about 6 months of Andrew Ng YouTube videos, SciKit Learn, PyImageSearch, and other well-organized tutorials, I revisited the book and fell in love with it. What I appreciated most was the discussion of the 5 tribes of machine learning and how he was able to merge the mentality of the different camps. I'd consider myself an Analogizer and I work with a Bayesian. Often, it feels like we are talking different languages. I had to chuckle a few time as this book addressed this common dynamic.I enjoyed Chapter 9 the most with his fanciful depiction of a continent divided into 5 territories: Symbolist, Connectionists, Evolutionists, Bayesians, and Analogizers with Master Algorithm serving as the capital city. He did an excellent job conceptualizing how different aspects of each 'tribe' would contribute to the one unifying, but elusive, algorithm. He went to great lengths to establish his sci-fi bona fides with references to Lord of the Rings, The Matrix, Robocop, and much more. My favorite came when he was discussing Support Vector Machines and visualizing the border between classes as a snake slithering down the no-man's-land with the support vectors serving as mines. It's ""like the sandworms in Dune: big, tough, and able to survive a few explosions from slithering over landmines but not too many"". A five-star rating was locked after that."
195,0465065708,http://goodreads.com/user/show/5858138-nic-brisbourne,4,"Domingos provides a detailed and pretty technical explanation of five different areas of artificial intelligence:* Symbolists - observe and inducer Dix logic in the world and code it - works well in limited domains and highly explainable, but impossible to scale* Neural networks - infer rules from large amounts of data to by looking at training sets - if it's seen enough pictures of cats it can compute the probability that a new image is a cat* Genetic algorithms - define an objective and let evolve according to rules, and then keep the solutions that beat fit the desired goal, and then repeat. Key is choosing the rules and fit algorithms well* Bayesians and probabalistic influence- great at finding categories and classifying things* Analogisers and Support Vector Machines - good for spotting similarities between things and making predictions about other things that might be similar - if I have flu, and we are friends but don't live in the same town, what is the chance that you also have flu?This stuff is quite dense! I have a solid grounding in maths, science, and stats but haven't practiced for decades and understood most of it, but had to read slowly. Domingos writes well and with humour which makes reading much easier. Finally - I should also say that he does a good job of making it real with examples and a semi-good job of predicting where the future will take us. "
196,0465065708,http://goodreads.com/user/show/47032429-kenta-suzuki,4,"Pedro Domingo describes the machine learnings from its origin to now, and how it can be used in the future. He purports that the Master Algorithm be the one that is ultimate goal of machine learning or universal learner as he call it. This algorithm will be replete with or fall into the intersection of the five bailiwicks: Symbolists, Connectionists, Evolutionaries, Bayesians, and Analogizers. For symbolists, Inverse Deduction is algorithm, Gradient Descent for Connectionists, Genetic Search for Evolutionaries, Probabilistic Inference for Bayesian and Constrained Optimization for Analogizers. For instance, Netflix uses k-nearest- neighbor algorithm, which finds the correlations with each others, to create recommendation system.This algorithm is so important that recommender system consists of a third of Amazon's business. In the future, he claims, that there will be one version of yourself who or which basically do most of the things on behalf of you faster than you could. He also argues that the fears some people have toward AI or Singularity will be relinquished if humans deal with them carefully. For instance, there will no infinite growth of AI as is the case with Moore's law. It will eventually taper off as S curve deliniates. This book will gives some prelude to those areas for those who do not have solid backgrounds for statistics or machine learning. "
197,0465065708,http://goodreads.com/user/show/51672399-david,4,"Domingos' attraction to analogical learning leads him to fill this book with analogies for almost everything he talks about. I wonder if a computer develops consciousness would they find it as annoying as I did? Other than this nuisance, the book gives a great overview of the history and state of machine learning. The various subfields outlined in the novel are very well abstracted to show the significant similarities and differences between them.However, Domingos' view of the future, as stated in the last chapter, wouldn't be the most inspiring. The possibility of an algorithm that could predict cancer treatment through genome mapping is surely an excellent use of machine learning but his belief that war will be ""fought"" by between different learners isn't something I'm looking forward to. The author assures the reader of this certainty. For me, this is just a stark reminder that technology advancement does not necessarily advance society in a positive way. In the case of fighting algorithms, there will be a victor and whomever or whatever possesses this technology will be the one with the power to rule a lot of important aspects in this world. This scenario just looks like a continuation of the current trend in the concentration of wealth and power into the hands of the few and not the many."
198,0465065708,http://goodreads.com/user/show/8146846-satyabrata-mishra,5,"Pedros Domingos does a fascinating job describing complex machine learning algorithms in forms of simple (and sometimes silly) metaphors and examples; like dividing the different forms of AI-engineers into tribes and walking down the cities of their design.For someone who wants to peek into machine learning and understand the powers and faults of each algorithm, the master algorithm is a great choice. I picked it up as a pre-read before my ML classes starts and I could not have made a better choice. "
199,0465065708,http://goodreads.com/user/show/60299397-victor-villas,3,"The book starts very slowly, hyping up the idea of the master algorithm. The middle parts are really interesting, where each of the ""five tribes"" of machine learning are discussed. It ends with some self promotion for the alchemy thingy the author is part of. For serious machine learning students this book might be a waste of time, but is still entertaining for the laymen."
200,0465065708,http://goodreads.com/user/show/4696922-ushan,1,"I took Prof. Domingos's data mining course at the UW night school in 2001, and I was wondering whether this book can give a good overview of the progress of the machine learning since then. It doesn't. It is plainly badly written. If I were a layman, I wouldn't have understood anything."
201,0465065708,http://goodreads.com/user/show/2237619-josh,3,"It's been over 200 years since Babbage, and around 60 years since the first serious forays into developing intelligent electronic machines, and we finally seem to have come to a point in history where machine learning is coming of age. The history of AI cautions one against excessive optimism, but the successes of machine learning are becoming impossible to ignore. Machine learners have steadily encroached on areas of intelligence previously thought to be accessible only to the human mind. The lowlands of human thought are rapidly being filled by the flood of artificial intelligence, and there's little reason to believe that the rising tide is going to stop any time soon. There is hardly a field of academic research or sector of the economy that has not been affected in some way by machine learning, and more radical changes loom. Advances in neuroscience along with a torrent of machine learning research hint at a general learning algorithm that would make all other advances in human science seem trivial in comparison. To repeat an oft-quoted phrase, ""the first ultraintelligent machine is the last invention that man need ever make"". That, in essence, is what Pedro Domingos' book is about.It starts off with a broad overview of how machine learning algorithms (he calls them learners), are omnipresent in modern society. Algorithms help decide what you see on your social media news feed, which videos you watch, which products you buy, which stocks to add to your portfolio, which ads you see, which political candidates you vote for and who you decide to date. I don't think it's an exaggeration to say that machine learning has revolutionized almost every aspect of how we live our day-to-day lives.And that's just getting started.Domingos divides machine learning research into five 'tribes' and spends some time discussing each of them in detail: the Symbolists, the Connectionists, the Evolutionaries, the Bayesians, and the Analogizers.The Symbolists advocate a rule-based approach to learning, and use logical inference as their main tool. This was a common tactic with the expert AI systems of the 80s, and still has a large place in automated systems today. A big problem that every machine learning algorithm has to deal with when understanding large datasets is the vast set of possible interpretations for that data, and the Symbolists have a few effective ways of dealing with this. If you want to build a system that can diagnose an illness, you might go about it by forming a decision tree. Does the person have a rash? If so, does that person also have a cold? And so on. Anyone who's played the game 20 questions can probably see why this approach might be an effective way of building intelligent systems. It also has the downside that these systems are costly and time-consuming to construct, not to mention they lack a certain degree of generality. Domingos doesn't seem to be a fan of this school of research, and for the most part he quickly passes it by so he can move on to other methods. Rule-based inference, for the most part, does not seem like a particularly effective way of interpreting data, and it certainly isn't how human brains interpret data. For a more biologically inspired learning method we have the connectionists.If you've heard any of the recent headlines about DeepMind's AlphaGo beating the world Go champion, you've heard about connectionism. Connectionists are the practitioners of neural networks--artificial simulations of the sort of neurons we see in animal brains. Since human-level intelligence has so far only been exhibited in human brains, a natural approach to programming intelligence is by reverse engineering the human brain. People have been programming neural networks for about as long as programmable computers have been around--the first attempts were made in the 50s, and despite a steady following of researchers in the meantime it is only recently that neural networks have really begun to have their full potential realized. This is due in part to the fact that processors today are more powerful than ever, but also because the Internet is a rich sea of data that we can use to train our networks. Still, neural nets, despite their amazing versatility for solving problems, are quite cumbersome and aren't exact representations of the human brain. It's not even clear whether an exact simulation of how the brain works would be an efficient computational model. They also take a lot of computing power to train, so for certain situations they are not ideal.Another biologically-inspired approach to machine learning is evolutionary computing. The idea behind this one is sound: human intelligence arose through evolutionary processes, so why can't we write programs to 'evolve' through a sort of Darwinian selection process? If we select for the tributes we want a program to have, say for a self-driving car to drive safely, and reject the attributes we don't want it to have, say, crashing into stop signs, we can eventually produce a program that will be a good driver. In theory, at least. The problem, of course, is that human intelligence took hundreds of millions of years to evolve to where it is now, and researchers don't have that kind of time to spend. It also seems to be a bit of a fluke that intelligence even arose at all, considering all the time in prehistory where it wasn't around. Evolution is a tricky thing to recreate, and the successes of evolutionary computing have been overshadowed by other methods. It remains to be seen if they will one day come into the spotlight like connectionism has in recent years.The Bayesians are mostly involved in applying Bayes' theorem to machine learning problem. Thomas Bayes, a 17th century Englishman, was a statistician who formulated one of the most famous theorems in probability theory. His theorem helps us understand how events are related to each other, and how the probability of one event affects another. Applications of this fairly simple theory are among the most popular approaches to machine learning and still seen to be the most widely used. While this approach isn't as biologically inspired as the other methods, Bayesian inference does still represent something our brains have to do to interact intelligently with the world. Bayesian theory is very robust in its application and can be applied to a wide range of real-world problems. Things do tend to get a bit hairy when dealing with problems that have a lot of variables, but with the right simplifying assumptions this has proved to be a very powerful theory.The Analogizers, as Domingos calls them, aren't as unified as the other tribes. Human learning could perhaps be best characterized as learning by analogy. We learn new concepts by associating them with old concepts we already know. It turns out statistical formulations of this type of learning are also quite effective, as can be seen by various automated recommendation systems designed by companies like Netflix or Amazon. Truth be told it wasn't entirely clear to me how this approach differed significantly from the other approaches already discussed, but I guess Domingos felt the distinction was necessary.He then goes on to discuss a hodgepodge of various other learning strategies that take influence from human psychology, notably reinforcement learning. Reinforcement learning agents choose between possible actions to take in an environment based on the expectation of future rewards from that action. If pressing a button rewards a reinforcement learning agent, the agent will quickly learning to spend as much of its time pressing that button as possible. Reinforcement learning by itself doesn't generalize to other problems outside of a narrow domain especially well, but when combined with neural networks it can be a powerful approach for machine learning problems.The final chapter of the book is about the future of machine learning, and full of the typical sort of predictions that authors of this type of book seem to love. Personally I feel like most of what Domingos has to say in this chapter has been dealt with better by other authors, but I digress. Machine learning will certainly have a huge impact on every aspect of our lives. In a very real way you are the data that you create. Other people make models of you based on your behavior just like Netflix makes models of your movie-viewing habits. The reason so many companies have started racing to collect your data is because that data is powerful. It influences the choices we make at an individual level and thus influences the whole of our society. This is a scary thought to some, and is certainly something that should be taken into consideration by human rights organizations and governments. On the flipside, data is becoming democratized very quickly--a fact which is helping facilitate positive social change at a faster rate than ever before in the history of civilization. Some are worried about machines achieving human levels of intelligence, but I think those fears are misguided. It is far more advantageous for us to consider what new avenues of possibility have opened up than to dwell on the roads we will leave behind. To quote Domingos: ""The real history of automation is not what it replaces but what it enables.""Overall the book is a good general overview of the research being done in machine learning today. It does not, however, substitute for a more serious mathematical treatment of the subject, and those wishing to delve deeper into the subject would be better served elsewhere. Still, as a light introduction to the subject this book is worth looking into."
202,0465065708,http://goodreads.com/user/show/3055905-nils,4,"A useful book that lays out the five “tribes” of machine learning and ecumenically proposes that the true “master algorithm” (AGI) will combine all five: the symbolists’ inverse deduction, the connectionists’ backpropagation, the evolutionists’ genetic programming, the Bayesians’ various theorems, and the analogizers’ support vector machines.What’s most dated about this 2015 book is how utterly sanguine he is about what moving toward a master algorithm will produce in terms of social effects. It’s not just that he rejects the scaremongering of the Singulatarians (as he points out, the algorithms are never going to have wills of their own), but it’s more than he doesn’t consider except in the most glancing way what may happen if bad people control the algorithm, or the more profound problem of what it means if each of us has a shadow algorithmically optimized version of ourselves representing us in the world — how this could ironically lead to a loss of will, a surrender to the algorithmic engine that supposedly understands our preferences better than we do. Do we really want to live in a world where, “everyone has an entourage of bots, smoothing his or her way through the world.… Your digital half will be like power steering for your life.” Occasionally he glimpses the dystopian possibilities but then handwaves then away: “This does not mean that you’ll end up in a ‘filter bubble,’ seeing only what you reliably like, with no room for the unexpected,” he reassures us. “The digital you knows better than that. Part of its brief is to leave some things open to chance, to expose you to new experiences, and to look for serendipity.” Nor does he really consider the philosophical implications of a situation where “You have your model of every person in the organization you interact with, and they each have their model of you. As the models improve, their interaction becomes more and more like the ones you would have in the real world.” What’s happening in this scenario is that border between human and machine is eroding, with humans themselves evolving and in many cases likely to surrender control, happily turning over their decision making to their digital self. Are we so sure, in this scenario that the distinction between the willful human and the enslaved machines makes sense? We need not worry about silly infinite paperclip scenarios, is a world where many of us have become merely wired bundles of continuously satisfied Id a world we want to live in? Is a world where technology splinters the unity of the human race, as he predicts, not a world with truly fearsome possibilities? Consider this passage: “One of the greatest talents a politician can have is the ability to understand voters, individually or in small groups, and to speak directly to them (or seem to). Bill Clinton is the paradigmatic example of this in recent memory. The effect of machine learning is like having a dedicated Bill Clinton for every voter.” Wait, is that a promise, or a threat?! Likewise, would anyone in 2019 in good conscience be able to write that, “Democracy works better because the bandwidth of communications between voters and politicians increases enormously.... Big data and machine learning [will] change the equation. In the future, provided voter models are accurate, elected officials will be able to ask a voters what they want 1000 times a day and act accordingly – without having to pester the actual flesh and blood citizens.” Provided voter models are accurate is doing a whole lotta work there, wouldn’t you say?"
203,0465065708,http://goodreads.com/user/show/56104661-mark,3,"Pedro Domingos wastes no time in laying out his bold hypothesis on which The Master Algorithm: How The Quest for the Ultimate Learning Machine Will Remake Our World is based. Early in chapter two, he declares that: “All knowledge—past, present, and future—can be derived from data by a single, universal learning algorithm.” Clearly, Domingos believes that such an algorithm can be developed, but for the doubting Thomases among us, he cites strong lines of evidence from the disciplines of neuroscience, evolution, physics, statistics, and computer science.The search for the Master Algorithm does not have to start from scratch, Domingos tells us. The bulk of the book describes five current approaches to machine learning—or “five tribes of machine learning,” as he labels them—namely, symbolists, connectionists, evolutionaries, Bayesians, and analogizers. These tribes each have a set of core beliefs, and a central problem they must solve. Domingos’s detailed descriptions of how they do that occasionally results in dense and complex narrative, but he cleverly illustrates his points with familiar, daily-life examples, with equally familiar organizations, such as Google, Amazon, Netflix, and Facebook.Of course, the true Master Algorithm must solve the problems of all five tribes, and the reader is encouraged to stick with the narrative and even take a leap of faith in some of the more involved explanations (“Bayesian networks and Naïve Bayes classifier” was this reader’s particular leap of faith!). The author’s writing is captivating and teasing as he describes the benefits and shortcomings of each machine learning style, steadily building belief in the Master Algorithm at the end of each chapter. However, drawing from the five tribes is still not enough to satisfy specifications of the Master Algorithm: Domingos goes on to talk about the need for principal component analysis, dimensionality reduction, and metalearning.By the time one reaches the chapter, “The Pieces of the Puzzle Fall into Place,” and Domingos has pulled together the five models of learning into one elegant and beautiful schematic, the reader is convinced of the feasibility of the Master Algorithm. Domingos hammers home this conviction by explaining how his derived model handles the three necessary elements of representation (a model's formal language of expression), evaluation (a scoring function to say how good a model is), and optimization (the search for the highest-scoring model). In the closing chapter, “This is the World on Machine Learning,” Domingos anticipates how machine learning and the Master Algorithm will affect society as a whole and each and every one of us in many aspects of daily life. Overall, Domingos has crafted a thought-provoking book about a thrilling subject, as fantastic as it is believable. He deftly keeps the reader turning the pages with bursts of humor, big-picture concepts, and behind-the-scenes glimpses of existing learning models. This book is both serious entertainment and education!"
204,0465065708,http://goodreads.com/user/show/11375563-michael-huang,3,"Domingos writes eloquently and lucidly about what machine learning (ML) is doing to the society (helping scientists do them work and make Obama win elections) and how it's supposedly going to change everything (industrial and information revolution automated manual and mental work respectively, ML will automate the automation). And he points out a simple and clearly stated hypothesis, the central hypothesis of the book: ""All knowledge - past, present, and future - can be derived from data by a single, universal learning algorithm"". He then tantalizingly showed the arguments from neural science (we as a species learned knowledge didn't we?); from evolution (our brain was evolved from virtually nothing, why not some master algorithm?); from physics (witness the unreasonable effectiveness of math in natural science); from statistics (Bayes's theorem describes how you can update any belief); from Computer Science (didn't Turing show us how there is a universal machine). By the time I finished Chapter 2, the book looks up to be by far the best book I've read this year (out of 96).Unfortunately, the rest of the book seems to be written by a different person. The lucidity is out. In come weird analogies and references that impede understanding rather than helping it. Maybe he is too excited and his neurons keep firing at even weak associations, but the text would have been returned as ""Needing major revision"" if it was submitted to a journal. Nevertheless, he did explain the five different sub communities of the umbrella community of ML in the next 5 chapters; and rather unconvincingly touted his own research as potentially the ""Master Algorithm"". (I don't mean to suggest his research is bad. In fact, his description of Alchemy seems completely fine and something he should definitely continue to look into. It's just not of the table-pounding, forehead-palming why-didn't-I-think-of-that variety.) At last he closes with what the future holds store once the Master Algorithm arrives. This part is, thankfully, deprived of unnecessary analogies and similes, but is rather anticlimactic (e.g., in the future ""let your people call mine"" becomes ""let your algorithm talk to mine"")."
205,0465065708,http://goodreads.com/user/show/108995717-dan,4,"Very nice overview of the current machine learning paradigms and algorithms: symbolism and induction, connectionism and backpropagation, evolutionism and genetic algorithms, Bayesian and statistical inference, analogy and support vector machines. In its attempt to unify them, it also points to similarities/dissimilarities, weaknesses/strengths, and so on. On the other hand, the Messianic expectation of “The Master Algorithm” that will unify the five different paradigms/algorithms in the same way a Theory of Everything will unify everything in Physics is ridiculous. Most likely, in new data intensive fields completely new and specialized algorithms will emerge beyond the five mentioned in this book and they will stay distinct and specialized. Google is organizing and manipulating the Internet, Amazon is overselling to us, Facebook is selling our profiles, genetic medicine is trying to make sense of the huge amount of data it possesses, the self-driving cars are generating their own data, satellites are mapping the Earth and the sky in small details, and so on. Specialized algorithms can predict and control almost anything in these limited, commercial, and digital fields. But beyond these few data intensive fields, there is no data available and we still need to generate data in the old fashion, small, and expensive ways as we always did if we have some specific hypotheses/questions. Defining “everything that is” and “human intelligence and science” along these commercial data-algorithm ways betrays some naive ontology and epistemology. Moreover, expecting that algorithms that perform extremely well in very specific situations/fields to converge to some Mater Algorithm that explains everything and that will take our human understanding to a new level is an unjustified extrapolation."
206,0465065708,http://goodreads.com/user/show/58987379-ville,3,"Great topic – difficult approachThe book covers three different topics of which each could make a thick book on their own.-	The technical history of machine learning and development of the major algorithms-	Mr Rodriques idea of a universal learning algorithm (‘the master algorithm’)-	Ideas how machine learning has affected our lives and speculations about the futureThese are some of my favourite topics and I would love to love this book, but I can’t. The most problematic was the actual beef of the book: the master algorithm. Even as I have done my fair share of machine learning as M.Sc. in process control and worked with many of the algorithms described for years at work, I found it very difficult to follow and even understand his idea of the MLN method. It was just too difficult approach without some actual examples for me at least.The best parts of the book were some awesome insights that only a true master could state with such simple and entertaining terms.My favorite highlights.-	Believe it or not, every algorithm, no matter how complex, can be reduced to just these three operations: AND, OR, and NOT.-	People often think computers are all about numbers, but they’re not. Computers are all about logic.-	Overfitting is the central problem in machine learning. More papers have been written about it than about any other topic… Humans are not immune to overfitting, either. You could even say that it’s the root cause of a lot of our evils. Consider the little white girl who, upon seeing a Latina baby at the mall, blurted out “Look, Mom, a baby maid!” (True event.) It’s not that she’s a natural-born bigot.-	S curves are a nice halfway house between the dumbness of linear functions and the hardness of step functions.-	An autoencoder is a multilayer perceptron whose output is the same as its input. In goes a picture of your grandmother and out comes—the same picture of your grandmother …the network is forced to encode the input in fewer bits, so it can be represented in the hidden layer, and then decode those bits back to full size. …. However the neet trick was to make the hidden layer actually bigger than the input-output-layers but only allow a few of them to fire at any given moment…-	(k-) nearest neighbor is truly a superfast algorithm but with the slow database connections a trained neural network is sure to win.-	Symbolist methods, for one, are fairly good at disposing of irrelevant attributes. If an attribute has no information about the class, it’s just never included in the decision tree or rule set. But nearest-neighbor is hopelessly confused by irrelevant attributes because they all contribute to the similarity between examples.-	No learner is immune to the curse of dimensionality. It’s the second worst problem in machine learning, after overfitting.-	PCA is to unsupervised learning what linear regression is to the supervised variety.-	Random forests are some of the most accurate classifiers around. Microsoft’s Kinect uses them to figure out what you’re doing, and they regularly win machine-learning competitions.-	(The problem with) combined models can be quite opaque. (“I believe you have prostate cancer because the decision tree, the genetic algorithm, and Naïve Bayes say so, although the multilayer perceptron and the SVM disagree.”)About the future:-	The first robo-lawyers that argue for a particular verdict based on precedents have already been built…Perhaps in a future cybercourt, in session somewhere on Amazon’s cloud, a robo-lawyer will beat the speeding ticket that RoboCop issued to your driverless car, all while you go to the beach, and Leibniz’s dream of reducing all argument to calculation will finally have come true.-	Some researchers even argue that the way to create intelligent machines is to build a robot baby and let him experience the world as a human baby does…The question, of course, is what algorithm should be running in Robby’s brain at birth.-	(You have already “a digital self” living in the internet databases that is good at finding things for you that you are interested.) Even more interesting, the process doesn’t end when you find a car, a house, a doctor, a date, or a job. Your digital half is continually learning from its experiences, just as you would. It figures out what works and doesn’t, whether it’s in job interviews, dating, or real-estate hunting. -	You have your model of every person and organization you interact with, and they each have their model of you. As the models improve, their interactions become more and more like the ones you would have in the real world—except millions of times faster and in silicon. Tomorrow’s cyberspace will be a vast parallel world that selects only the most promising things to try out in the real one. It will be like a new, global subconscious, the collective id of the human race.-	(But the problem right now is that) everyone has only a sliver of it. Google sees your searches, Amazon your online purchases, AT&T your phone calls, Apple your music downloads, Safeway your groceries, Capital One your credit-card transactions. Companies like Acxiom collate and sell information about you, but if you inspect it (which in Acxiom’s case you can, at aboutthedata.com), it’s not much, and some of it is wrong. No one has anything even approaching a complete picture of you.-	Eventually, we’ll start talking about the employment rate instead of the unemployment one and reducing it will be seen as a sign of progress. (“The US is falling behind. Our employment rate is still 23 percent.”)-	People will seek meaning in human relationships, self-actualization, and spirituality, much as they do now. The need to earn a living will be a distant memory, another piece of humanity’s barbaric past that we rose above. -	Picture two strands of DNA going for a swim in their private pool, aka a bacterium’s cytoplasm, two billion years ago. They’re pondering a momentous decision. “I’m worried, Diana,” says one. “If we start making multicellular creatures, will they take over?” -	Contrary to what we like to believe today, humans quite easily fall into obeying others, and any sufficiently advanced AI is indistinguishable from God. People worry that computers will get too smart and take over the world, but the real problem is that they’re too stupid and they’ve already taken over the world. "
207,0465065708,http://goodreads.com/user/show/56609924-flaviu-vescan,3,"I was looking for a book that explains ML and AI concepts for non-practitioners. It did a great job at that. It goes through the most used 7 types of ML algorithms/concepts and explains how they work using high-level math and analogies. It blends a bit of the history of the field so that's always nice to contextualize the information. What made me only give it 3 stars are the detours it keeps making into predicting the future and the crazy soft stance it takes towards the tech giants like FB and GOOG. I'm not sure if Mr. Domingos is still willing to be have such a friendly opinion of them after the latest findings on how they use ML and the many privacy breaches they've had, but I hope not. In any case I'm judging the books version of events and it's lacking any criticism towards the uses of ML in manipulating public opinion. The book is great at teaching you the high-level workings of ML. The problem I had was it kept trying to do more than that by taking a stab at predicting the future of the field influence on humanity. Even for a specialist, it's mostly speculation. "
208,0465065708,http://goodreads.com/user/show/96942737-gautham,3,"A book for those who wish to have an aerial / Birdseye view of the subject, probably a novice in the field but I don’t think it can be of much help for a layman. It was as if Domingos wanted to explain almost all the topics / tribes of the world of Machine learning, from their basics, under one cover, which may have been possible if the book had housed at least about a 1000 or so pages maybe but his choice of including as many topics as he did has trumped the point of ‘understandability’ which a book like this should be focusing on in the first place.The slithering snake analogy for explaining SVMs was the worst of the analogies that he could come up with.However, there are certain learnings that one could get from this book but at the cost 300 pages @ your individual reading speeds is too big a price to pay.The last two chapters of the book seems like the summary of the rest of the chapters with an extension and conclusion. So, if you want to take a quick read, you know where to start."
209,0465065708,http://goodreads.com/user/show/93344337-benny,4,"A few years ago, I came across a list of machine learning algorithms that aspiring data scientists should familiarise themselves with. Since then, I have delved into various machine learning algorithms intermittently during my spare time. In this book, Pedro Domingos has broadly classified them into 5 different families of algorithms. To take these applications further, he suggested that eventually one Master Algorithm can perform that roles that each family of algorithms plays in deciphering our physical world. Below are some of the algorithms that are covered by the author.Genetic AlgorithmNeural Networks(eg. backpropagation, gradient descent)K-nearest NeighbourSupport Vector Machines(eg. kernels)Bayes NetworkK-means ClusteringPCARandom ForestEigenfaces....The book provides a neat high-level summary into the development of these algorithms and how they have come about. With prior understanding of how they work, it is pleasant way to review how these machine learning algorithms optimise, learn and automate our tasks without needing to immerse oneself in the math and computer science that are powering all these AI applications behind the scenes."
210,0465065708,http://goodreads.com/user/show/50245822-srinath-srinath,4,"Great book, gives an overall view of how 5 groups(bayesians,analogizers,symbolists,connectionists,evolutionaries) of people have been competing and trying to solve intelligence. The technical details have been very well explained for a layman to understand."
211,0465065708,http://goodreads.com/user/show/16463508-toma,4,"It is a bit technical for someone who is not in the field or used to some of the theories presented but a great read to understand Artificial Intelligence, Machine Learning and the major schools/philosophies in the field."
212,0465065708,http://goodreads.com/user/show/20064141-maureen-fitzpatrick,4,"It might be a five star book, but this is a book that is just beyond what I understand; however, what I understand is greater having read the book."
213,0465065708,http://goodreads.com/user/show/40460162-steve-jay,5,"If you're a huge nerd and have an interest in futurology, mathematics and computers, this is a must read! Blew my mind."
214,0465065708,http://goodreads.com/user/show/38024135-theodore-kinni,3,"Probably good for budding data scientists, but it's dense and too detailed for the untutored"
215,0465065708,http://goodreads.com/user/show/15317284-carlos-vasconcelos,4,A good book for a broad audience. 
216,0465065708,http://goodreads.com/user/show/50847541-florin-grigoriu,3,"OK to recap the ML notions, the fiction style is too mainstream making the book sometime too buzz-word-ish"
217,0465065708,http://goodreads.com/user/show/76014-raghu,4,"Artificial Intelligence has gradually become a part of our routine discourse. It is because we experience it in varying degrees in even our humdrum lives. We read in the news that driverless cars are already running on our roads. When we sign on to Netflix, we see movie recommendations for us. Often, they turn out to be better than what our friends and relatives suggest to us. Websites help us save money on airline tickets more than before. Google predicts flu outbreaks before CDC has been able to do so. All this is due to Artificial Intelligence or AI for short, of varying degrees. AI is a vast field and has been an area of research since the 1950s. This book is about one branch of AI which is hot today, called Machine Learning.Historically, we have written specific computer programs to solve specific problems using the computer. Each such program is in effect an algorithm to deal with that problem. Machine learning diverges from this traditional approach. It provides computers with the ability to learn. A specific problem is solved without being explicitly programmed for it. Machine learning consists of programs that can teach themselves to grow and change when exposed to more and more data. This book goes one step further. It discusses the holy grail of Machine Learning that researchers are working on, called the Master Algorithm. Right in the first chapter, the author defines this holy grail as follows: ""All knowledge - present, past and future - can be derived by a single, universal learning algorithm"".Now, this might seem ambitious to most of us, including scientists in the field. Some might even slam it as typical of the 'techno-hubris' of Silicon Valley. But the author makes a case that a master algorithm is a feature of nature itself. He shows that there are similar examples in Neuroscience and Evolution. The book captures Machine learning succinctly by the following unwritten rule through which it works:""we must induce the most widely applicable rules we can and reduce their scope only when data forces us to do so"".There are five approaches to Machine Learning today. They are classified as the Symbolists, the Connectionists, the Evolutionaries, the Bayesians and the Analogizers. Each of them is explained briefly as follows:Symbolists believe all intelligence can be reduced to manipulating symbols just as we do in Mathematics. In simple terms, Symbolists start with some existing premises and conclusions. Then, they work backward to fill in the gaps in knowledge by analyzing existing data sets. This is called inverse deduction. Connectionists believe that we must reverse engineer the brain and achieve machine learning. This approach is called 'deep learning'. It consists of creating 'digital neurons' in the computer and connecting them in a neural network model. Google uses this approach in machine translation. It is also used in image processing.Evolutionaries believe in learning through genetic programming. This method mates and evolves computer programs the way nature evolves species. It applies the ideas similar to that of Genomes and DNA in the evolutionary process to data structures. The Genetic programming model works by quantifying the performance of data. It is used to determine the retention and propagation of algorithms in an evolutionary way.Bayesians believe in using Bayes theorem and its derivatives to learn through probabilistic inference. This method proposes a few hypotheses. Then, it assigns probabilities for the likely outcomes of applying these hypotheses. By applying more and more data to test these hypotheses, some of them become more likely than the others. In this way, we arrive at the most likely solution to the problem. This is used in spam filters on emails.Analogizers believe the key to learning is recognizing similarities between situations. This principle is called the nearest neighbour principle. One important aspect of Analogy is that it lets you learn from little data. Analogizers can learn from even just one example - You are what you resemble. Charles Darwin used Malthus' theory of the struggle for survival in society to formulate the biological theory of evolution. Niels Bohr used the solar system model to formulate his theory of the atomic model. A website like Netflix uses it in the recommendations it gives to customers. For example, let us say that someone, whose profile is similar to yours, liked the movie 'Avatar'. Then it is likely that you will like Avatar as well, if you have not seen it already. So, a recommendation of Avatar is made for you. However, all these approaches are not mutually exclusive. Machine learning uses a selective combination of them, depending on the problem. For example, in medicine, the Evolutionary approach is not preferred. The way nature learns is through making mistakes - a luxury we don't have in our societies. Doctors must diagnose in a foolproof way. For example, failing to find a tumor that is really there, is potentially much worse than inferring one that isn't. It needs optimal decisions and this where the Bayesian approach is more useful. In AI, Symbolists held sway in the first few decades of cognitive psychology. Then Connectionists held sway in the 1980s and 90s, and it is the Bayesians' time in the Sun now. The author is upbeat about the future transformations that Machine Learning will bring to our societies. He suggests that in the not too distant future, we will all have a 'digital half' which will do our bidding all 24 hours of the day. They will interact with the digital halves of every person and organization we deal with. Tomorrow's cyberspace will be a giant parallel world. It will be like a new, global subconscious, the collective id of the human race. My only caveat about the book is its prognosis for the future. There is no doubt that the future will be transformed in many ways by Machine Learning. Scientists have been mostly right about predicting the future technological inventions. On the other hand, scientists from Thomas Malthus to Paul Ehrlich to the Club of Rome have made dire predictions about the future of mankind and disaster for thickly populated countries like India and China. They were woefully wrong in this. Not all scientific advances have a smooth path to their full potential. The expected potentials of Nuclear energy and Genetically Modified crops have not materialized because of resistance in our societies. There is also resistance to Stem cells and possibilities of Human cloning. Machine learning is in its infancy now. As it develops and impacts our lives more and more, the technology is bound to make mistakes in a way that affect our lives negatively. If some of them happen to be of the dimension of the Chernobyl accident in Nuclear energy, then there may be a big backlash to the advance of AI too. The other related danger is to rely on vast quantities of data on a phenomenon which leave out key attributes of representing the phenomena correctly, but use it anyway to make crucial decisions. One example in the past of such misuse of data happened in the 1960s. Sen.Robert McNamara, Secy of Defence in the Johnson administration, went about escalating the Vietnam war by relying on 'death count of US and Vietcong soldiers' as a key data indicator of how the war was progressing. The data did not capture the will and determination of the Vietnamese communists to rid themselves of foreign occupation of their land. We all know the consequences of this key error.I enjoyed reading the book as it was educational for me and I learnt much from it. The chapters elaborating the five approaches to Machine Learning need some focus and concentration to fully understand them. Readers, who find these chapters a bit hard, can still simply read just the first 60 pages to get a very good idea of the subject. All in all, it is a great effort to present this exciting subject in a simple way."
218,0465065708,http://goodreads.com/user/show/10768018-jo-o,3,"The idea of a master algorithm is a kind of computer science saint graal. An optimal model for most problems in reality, a robust super-A.I. with the best qualities of organic brains and computer power merged. For this to happen Domingos argues that the 5 tribes of machine learning have to merge as if currently they were very different communities. Those are: symbolists (e.g. logic-based models, decision trees); connectionists (e.g. neural networks); evolutionaries (genetic algorithms); bayesians (graph theory and Bayes-inspired modelling); analogizers (support vector machines, etc.). While this is a ""cool"" vision I find it hard to argue that models can be categorized under that schematic (many hybrids, or some are just specific cases of others) or that the communities of researchers are isolated in any way. Most people with MAJOR published contributions/advances in any of the ""5 tribes"", has papers in the others... usually dozens... (and some are really important as well)!From what else I've read from Domingos I'd rather recommend his short essays, and scientific papers. The big book format gives too much space for random rambling and there are a lot of cringe sentences like random name dropping e.g. ""Kant was also a fan."" with no further exposition or mention.Ultimately, Domingos has a very solid technical view of most stuff he discusses, but then he brings a lot of his personal intuitive futuristic views that can either happen or not. His conclusions and views in more social/political problems, like how should we share our data with AI companies, are also troubling for me. Overall too much utopian gut-feeling in a book about data-centred approaches."
219,0465065708,http://goodreads.com/user/show/23963235-akshith-rao,3,"This book captures the various types of machine learning techniques and how they have progressed through time. The author, being an academician, gets too technical. Even a decent understanding of math did not prevent some pages from turning into Latin for me. If you are someone who is knee deep in math and probability and would like to get an overall picture I would definitely recommend this book to you. For everyone else, it might be better to start looking somewhere else or just skip the math side of things in this book."
220,0465065708,http://goodreads.com/user/show/7297326-jim-crocker,5,"I'm not really finished. This is the kind of book that will go on and on and on with amazing insights and revelations about AI and Machine Learning. I've already heard that it is outta date. But, hey, whaddaya gonna do? Things move fast out there. With me it moves a little slower. I read and think and read and on it goes... This book was an eye-opener for me. I discovered a whole knew point of view. Essentially, it was a paradigm shift.This is a glimpse of the future of humans and the interactions, transactions and associations that will be taking place over the coming years. It's really transformational stuff that's going on. Here's two quotes that I liked (there's a ton more):** ""Most of all, we have to worry about what the Master Algorithm could do in the wrong hands.""** ""...you also have an ethical duty to share data for the common good.""I like that last one best of all!For your convenience, you can get this wonderful book right here:www.blackdogebooks.com/redhot-pick"
221,0465065708,http://goodreads.com/user/show/1173423-peter,5,"Really nice read. Serves as an accessible introduction to machine learning whilst simultaneously outlining the respective strengths and weaknesses of its 5 different ""tribes"" and ultimately showing how they can be connected. This makes the book valuable even for machine learning practitioners. Furthermore, in these days where deep learning reigns supreme and the media make it seem it is the end-all-be-all of machine learning, this book adds a valuable historical and conceptual perspective. The derivation and description of the current best stab at the Master Algorithm is more technical though, and probably more difficult to follow for the non-technical reader.The author is very bullish in the scale and scope of the application of machine learning and he offers powerful examples of AI in the form of personal agents negotiating the world on our behalf, the enabler of systems biology, and eventually designing and enhancing humans. However I think his view is quite utopian and that he downplays several potential negative scenarios of both weak and strong AI. For instance, Domingos believes that job displacement will not be grave (the argument that more new jobs that we now can't imagine will be created than will be destroyed), and that even if this were to happen, then if it reaches critical mass (>50%), then in a democracy that majority will vote for lifelong salaries for just being alive (i.e. universal basic income). However I think there is a path-dependance here on things staying the same politically. Let's contrast it with the scenario in Yuval Harari's Homo Deus of the creation of a class of ""useless"" humans who don't have to offer anything economically nor militarily. The political power of the masses would then be greatly diminished, perhaps even up to the point of threatening liberal democracy.Looking even further into the future, he does not take into account the dangers of reductionist goals. He basically argues that because machines don't have goals of their own, we are safe. Nick Bostrom belabors the dangers of strong AI in his book Superintelligence.In conclusion, although I think the dangers of AI were downplayed, I think it was a great read. I would recommend pairing this book (written by an machine learning researcher & practitioner) up with Homo Deus (written by a historian) and Superintelligence (by a philosopher) for a more holistic view if your interest is primarily on the (future) impact of AI."
222,0465065708,http://goodreads.com/user/show/38621776-an-l-tuncel,1,"Disappointing. This book has no scientific value. No one should read this book, not even teenagers (they will get confused). "
223,0465065708,http://goodreads.com/user/show/19014583-t,4,"I enjoyed this book overall but had some frustrations with it. Enough so that it was a real debate between 3 and 4 stars for me; I'm giving it 4 now as a benefit of the doubt but I may reread and drop it to 3 if it doesn't seem better.First, the topic couldn't be more relevant and interesting to our time; both for buzz word purposes and real discussion of the current state of the field the book was interesting. That said, I had several annoyances. First, the author seemed quite taken with creating fanciful allegories for things that were clear attempts to be poetic or entertaining and in practice were often just kind of dumb. In the more lower level cases they would help add to understanding, but the broader they got the more you felt like you were wasting your time while he talked about wandering through a city and spent time describing the turrets or telling you what you suddenly remembered or felt. Ick. Second, the premise at the start of the book seemed to be that anyone could understand and contribute to all of the field and the rest of the book seemed, to me at least, to rather disprove that. I think he tried to make this accessible to all and thus went a step too far; he'd have been better off saying the requirements of the field are not so high as many fear and thus are accessible to many more than would expect it. Saying anyone could do it even without complicated math just seemed inaccurate even using his own description by the end.Finally, the overall structure of the book and the discussion of the five ""tribes"" left me somewhat uncertain. I couldn't decide if that was an actually useful description or more confusing than helpful. In part this was because my reading was rather fractured through time so I'm reserving judgment of this for a more thorough reread.All that said, the book was still an interesting overview of the current state and problems of the machine learning world and, when not trying to wax poetic, was a pretty good and understandable summary of those and a nice encouragement for those of us on the edge of the field to get into it."
224,0465065708,http://goodreads.com/user/show/3550209-adrian,5,"Who knew the 'S' curve was the most important function ever?I picked up ""The Master Algorithm"" hoping it would serve as a primer as I began my journey into the world of deep learning. At first, I found it overly figurative and difficult to follow so I stopped reading it. After about 6 months of Andrew Ng YouTube videos, SciKit Learn, PyImageSearch, and other well-organized tutorials, I revisited the book and fell in love with it. What I appreciated most was the discussion of the 5 tribes of machine learning and how he was able to merge the mentality of the different camps. I'd consider myself an Analogizer and I work with a Bayesian. Often, it feels like we are talking different languages. I had to chuckle a few time as this book addressed this common dynamic.I enjoyed Chapter 9 the most with his fanciful depiction of a continent divided into 5 territories: Symbolist, Connectionists, Evolutionists, Bayesians, and Analogizers with Master Algorithm serving as the capital city. He did an excellent job conceptualizing how different aspects of each 'tribe' would contribute to the one unifying, but elusive, algorithm. He went to great lengths to establish his sci-fi bona fides with references to Lord of the Rings, The Matrix, Robocop, and much more. My favorite came when he was discussing Support Vector Machines and visualizing the border between classes as a snake slithering down the no-man's-land with the support vectors serving as mines. It's ""like the sandworms in Dune: big, tough, and able to survive a few explosions from slithering over landmines but not too many"". A five-star rating was locked after that."
225,0465065708,http://goodreads.com/user/show/5858138-nic-brisbourne,4,"Domingos provides a detailed and pretty technical explanation of five different areas of artificial intelligence:* Symbolists - observe and inducer Dix logic in the world and code it - works well in limited domains and highly explainable, but impossible to scale* Neural networks - infer rules from large amounts of data to by looking at training sets - if it's seen enough pictures of cats it can compute the probability that a new image is a cat* Genetic algorithms - define an objective and let evolve according to rules, and then keep the solutions that beat fit the desired goal, and then repeat. Key is choosing the rules and fit algorithms well* Bayesians and probabalistic influence- great at finding categories and classifying things* Analogisers and Support Vector Machines - good for spotting similarities between things and making predictions about other things that might be similar - if I have flu, and we are friends but don't live in the same town, what is the chance that you also have flu?This stuff is quite dense! I have a solid grounding in maths, science, and stats but haven't practiced for decades and understood most of it, but had to read slowly. Domingos writes well and with humour which makes reading much easier. Finally - I should also say that he does a good job of making it real with examples and a semi-good job of predicting where the future will take us. "
226,0465065708,http://goodreads.com/user/show/47032429-kenta-suzuki,4,"Pedro Domingo describes the machine learnings from its origin to now, and how it can be used in the future. He purports that the Master Algorithm be the one that is ultimate goal of machine learning or universal learner as he call it. This algorithm will be replete with or fall into the intersection of the five bailiwicks: Symbolists, Connectionists, Evolutionaries, Bayesians, and Analogizers. For symbolists, Inverse Deduction is algorithm, Gradient Descent for Connectionists, Genetic Search for Evolutionaries, Probabilistic Inference for Bayesian and Constrained Optimization for Analogizers. For instance, Netflix uses k-nearest- neighbor algorithm, which finds the correlations with each others, to create recommendation system.This algorithm is so important that recommender system consists of a third of Amazon's business. In the future, he claims, that there will be one version of yourself who or which basically do most of the things on behalf of you faster than you could. He also argues that the fears some people have toward AI or Singularity will be relinquished if humans deal with them carefully. For instance, there will no infinite growth of AI as is the case with Moore's law. It will eventually taper off as S curve deliniates. This book will gives some prelude to those areas for those who do not have solid backgrounds for statistics or machine learning. "
227,0465065708,http://goodreads.com/user/show/51672399-david,4,"Domingos' attraction to analogical learning leads him to fill this book with analogies for almost everything he talks about. I wonder if a computer develops consciousness would they find it as annoying as I did? Other than this nuisance, the book gives a great overview of the history and state of machine learning. The various subfields outlined in the novel are very well abstracted to show the significant similarities and differences between them.However, Domingos' view of the future, as stated in the last chapter, wouldn't be the most inspiring. The possibility of an algorithm that could predict cancer treatment through genome mapping is surely an excellent use of machine learning but his belief that war will be ""fought"" by between different learners isn't something I'm looking forward to. The author assures the reader of this certainty. For me, this is just a stark reminder that technology advancement does not necessarily advance society in a positive way. In the case of fighting algorithms, there will be a victor and whomever or whatever possesses this technology will be the one with the power to rule a lot of important aspects in this world. This scenario just looks like a continuation of the current trend in the concentration of wealth and power into the hands of the few and not the many."
228,0465065708,http://goodreads.com/user/show/8146846-satyabrata-mishra,5,"Pedros Domingos does a fascinating job describing complex machine learning algorithms in forms of simple (and sometimes silly) metaphors and examples; like dividing the different forms of AI-engineers into tribes and walking down the cities of their design.For someone who wants to peek into machine learning and understand the powers and faults of each algorithm, the master algorithm is a great choice. I picked it up as a pre-read before my ML classes starts and I could not have made a better choice. "
229,0465065708,http://goodreads.com/user/show/60299397-victor-villas,3,"The book starts very slowly, hyping up the idea of the master algorithm. The middle parts are really interesting, where each of the ""five tribes"" of machine learning are discussed. It ends with some self promotion for the alchemy thingy the author is part of. For serious machine learning students this book might be a waste of time, but is still entertaining for the laymen."
230,0465065708,http://goodreads.com/user/show/4696922-ushan,1,"I took Prof. Domingos's data mining course at the UW night school in 2001, and I was wondering whether this book can give a good overview of the progress of the machine learning since then. It doesn't. It is plainly badly written. If I were a layman, I wouldn't have understood anything."
231,0465065708,http://goodreads.com/user/show/2237619-josh,3,"It's been over 200 years since Babbage, and around 60 years since the first serious forays into developing intelligent electronic machines, and we finally seem to have come to a point in history where machine learning is coming of age. The history of AI cautions one against excessive optimism, but the successes of machine learning are becoming impossible to ignore. Machine learners have steadily encroached on areas of intelligence previously thought to be accessible only to the human mind. The lowlands of human thought are rapidly being filled by the flood of artificial intelligence, and there's little reason to believe that the rising tide is going to stop any time soon. There is hardly a field of academic research or sector of the economy that has not been affected in some way by machine learning, and more radical changes loom. Advances in neuroscience along with a torrent of machine learning research hint at a general learning algorithm that would make all other advances in human science seem trivial in comparison. To repeat an oft-quoted phrase, ""the first ultraintelligent machine is the last invention that man need ever make"". That, in essence, is what Pedro Domingos' book is about.It starts off with a broad overview of how machine learning algorithms (he calls them learners), are omnipresent in modern society. Algorithms help decide what you see on your social media news feed, which videos you watch, which products you buy, which stocks to add to your portfolio, which ads you see, which political candidates you vote for and who you decide to date. I don't think it's an exaggeration to say that machine learning has revolutionized almost every aspect of how we live our day-to-day lives.And that's just getting started.Domingos divides machine learning research into five 'tribes' and spends some time discussing each of them in detail: the Symbolists, the Connectionists, the Evolutionaries, the Bayesians, and the Analogizers.The Symbolists advocate a rule-based approach to learning, and use logical inference as their main tool. This was a common tactic with the expert AI systems of the 80s, and still has a large place in automated systems today. A big problem that every machine learning algorithm has to deal with when understanding large datasets is the vast set of possible interpretations for that data, and the Symbolists have a few effective ways of dealing with this. If you want to build a system that can diagnose an illness, you might go about it by forming a decision tree. Does the person have a rash? If so, does that person also have a cold? And so on. Anyone who's played the game 20 questions can probably see why this approach might be an effective way of building intelligent systems. It also has the downside that these systems are costly and time-consuming to construct, not to mention they lack a certain degree of generality. Domingos doesn't seem to be a fan of this school of research, and for the most part he quickly passes it by so he can move on to other methods. Rule-based inference, for the most part, does not seem like a particularly effective way of interpreting data, and it certainly isn't how human brains interpret data. For a more biologically inspired learning method we have the connectionists.If you've heard any of the recent headlines about DeepMind's AlphaGo beating the world Go champion, you've heard about connectionism. Connectionists are the practitioners of neural networks--artificial simulations of the sort of neurons we see in animal brains. Since human-level intelligence has so far only been exhibited in human brains, a natural approach to programming intelligence is by reverse engineering the human brain. People have been programming neural networks for about as long as programmable computers have been around--the first attempts were made in the 50s, and despite a steady following of researchers in the meantime it is only recently that neural networks have really begun to have their full potential realized. This is due in part to the fact that processors today are more powerful than ever, but also because the Internet is a rich sea of data that we can use to train our networks. Still, neural nets, despite their amazing versatility for solving problems, are quite cumbersome and aren't exact representations of the human brain. It's not even clear whether an exact simulation of how the brain works would be an efficient computational model. They also take a lot of computing power to train, so for certain situations they are not ideal.Another biologically-inspired approach to machine learning is evolutionary computing. The idea behind this one is sound: human intelligence arose through evolutionary processes, so why can't we write programs to 'evolve' through a sort of Darwinian selection process? If we select for the tributes we want a program to have, say for a self-driving car to drive safely, and reject the attributes we don't want it to have, say, crashing into stop signs, we can eventually produce a program that will be a good driver. In theory, at least. The problem, of course, is that human intelligence took hundreds of millions of years to evolve to where it is now, and researchers don't have that kind of time to spend. It also seems to be a bit of a fluke that intelligence even arose at all, considering all the time in prehistory where it wasn't around. Evolution is a tricky thing to recreate, and the successes of evolutionary computing have been overshadowed by other methods. It remains to be seen if they will one day come into the spotlight like connectionism has in recent years.The Bayesians are mostly involved in applying Bayes' theorem to machine learning problem. Thomas Bayes, a 17th century Englishman, was a statistician who formulated one of the most famous theorems in probability theory. His theorem helps us understand how events are related to each other, and how the probability of one event affects another. Applications of this fairly simple theory are among the most popular approaches to machine learning and still seen to be the most widely used. While this approach isn't as biologically inspired as the other methods, Bayesian inference does still represent something our brains have to do to interact intelligently with the world. Bayesian theory is very robust in its application and can be applied to a wide range of real-world problems. Things do tend to get a bit hairy when dealing with problems that have a lot of variables, but with the right simplifying assumptions this has proved to be a very powerful theory.The Analogizers, as Domingos calls them, aren't as unified as the other tribes. Human learning could perhaps be best characterized as learning by analogy. We learn new concepts by associating them with old concepts we already know. It turns out statistical formulations of this type of learning are also quite effective, as can be seen by various automated recommendation systems designed by companies like Netflix or Amazon. Truth be told it wasn't entirely clear to me how this approach differed significantly from the other approaches already discussed, but I guess Domingos felt the distinction was necessary.He then goes on to discuss a hodgepodge of various other learning strategies that take influence from human psychology, notably reinforcement learning. Reinforcement learning agents choose between possible actions to take in an environment based on the expectation of future rewards from that action. If pressing a button rewards a reinforcement learning agent, the agent will quickly learning to spend as much of its time pressing that button as possible. Reinforcement learning by itself doesn't generalize to other problems outside of a narrow domain especially well, but when combined with neural networks it can be a powerful approach for machine learning problems.The final chapter of the book is about the future of machine learning, and full of the typical sort of predictions that authors of this type of book seem to love. Personally I feel like most of what Domingos has to say in this chapter has been dealt with better by other authors, but I digress. Machine learning will certainly have a huge impact on every aspect of our lives. In a very real way you are the data that you create. Other people make models of you based on your behavior just like Netflix makes models of your movie-viewing habits. The reason so many companies have started racing to collect your data is because that data is powerful. It influences the choices we make at an individual level and thus influences the whole of our society. This is a scary thought to some, and is certainly something that should be taken into consideration by human rights organizations and governments. On the flipside, data is becoming democratized very quickly--a fact which is helping facilitate positive social change at a faster rate than ever before in the history of civilization. Some are worried about machines achieving human levels of intelligence, but I think those fears are misguided. It is far more advantageous for us to consider what new avenues of possibility have opened up than to dwell on the roads we will leave behind. To quote Domingos: ""The real history of automation is not what it replaces but what it enables.""Overall the book is a good general overview of the research being done in machine learning today. It does not, however, substitute for a more serious mathematical treatment of the subject, and those wishing to delve deeper into the subject would be better served elsewhere. Still, as a light introduction to the subject this book is worth looking into."
232,0465065708,http://goodreads.com/user/show/3055905-nils,4,"A useful book that lays out the five “tribes” of machine learning and ecumenically proposes that the true “master algorithm” (AGI) will combine all five: the symbolists’ inverse deduction, the connectionists’ backpropagation, the evolutionists’ genetic programming, the Bayesians’ various theorems, and the analogizers’ support vector machines.What’s most dated about this 2015 book is how utterly sanguine he is about what moving toward a master algorithm will produce in terms of social effects. It’s not just that he rejects the scaremongering of the Singulatarians (as he points out, the algorithms are never going to have wills of their own), but it’s more than he doesn’t consider except in the most glancing way what may happen if bad people control the algorithm, or the more profound problem of what it means if each of us has a shadow algorithmically optimized version of ourselves representing us in the world — how this could ironically lead to a loss of will, a surrender to the algorithmic engine that supposedly understands our preferences better than we do. Do we really want to live in a world where, “everyone has an entourage of bots, smoothing his or her way through the world.… Your digital half will be like power steering for your life.” Occasionally he glimpses the dystopian possibilities but then handwaves then away: “This does not mean that you’ll end up in a ‘filter bubble,’ seeing only what you reliably like, with no room for the unexpected,” he reassures us. “The digital you knows better than that. Part of its brief is to leave some things open to chance, to expose you to new experiences, and to look for serendipity.” Nor does he really consider the philosophical implications of a situation where “You have your model of every person in the organization you interact with, and they each have their model of you. As the models improve, their interaction becomes more and more like the ones you would have in the real world.” What’s happening in this scenario is that border between human and machine is eroding, with humans themselves evolving and in many cases likely to surrender control, happily turning over their decision making to their digital self. Are we so sure, in this scenario that the distinction between the willful human and the enslaved machines makes sense? We need not worry about silly infinite paperclip scenarios, is a world where many of us have become merely wired bundles of continuously satisfied Id a world we want to live in? Is a world where technology splinters the unity of the human race, as he predicts, not a world with truly fearsome possibilities? Consider this passage: “One of the greatest talents a politician can have is the ability to understand voters, individually or in small groups, and to speak directly to them (or seem to). Bill Clinton is the paradigmatic example of this in recent memory. The effect of machine learning is like having a dedicated Bill Clinton for every voter.” Wait, is that a promise, or a threat?! Likewise, would anyone in 2019 in good conscience be able to write that, “Democracy works better because the bandwidth of communications between voters and politicians increases enormously.... Big data and machine learning [will] change the equation. In the future, provided voter models are accurate, elected officials will be able to ask a voters what they want 1000 times a day and act accordingly – without having to pester the actual flesh and blood citizens.” Provided voter models are accurate is doing a whole lotta work there, wouldn’t you say?"
233,0465065708,http://goodreads.com/user/show/56104661-mark,3,"Pedro Domingos wastes no time in laying out his bold hypothesis on which The Master Algorithm: How The Quest for the Ultimate Learning Machine Will Remake Our World is based. Early in chapter two, he declares that: “All knowledge—past, present, and future—can be derived from data by a single, universal learning algorithm.” Clearly, Domingos believes that such an algorithm can be developed, but for the doubting Thomases among us, he cites strong lines of evidence from the disciplines of neuroscience, evolution, physics, statistics, and computer science.The search for the Master Algorithm does not have to start from scratch, Domingos tells us. The bulk of the book describes five current approaches to machine learning—or “five tribes of machine learning,” as he labels them—namely, symbolists, connectionists, evolutionaries, Bayesians, and analogizers. These tribes each have a set of core beliefs, and a central problem they must solve. Domingos’s detailed descriptions of how they do that occasionally results in dense and complex narrative, but he cleverly illustrates his points with familiar, daily-life examples, with equally familiar organizations, such as Google, Amazon, Netflix, and Facebook.Of course, the true Master Algorithm must solve the problems of all five tribes, and the reader is encouraged to stick with the narrative and even take a leap of faith in some of the more involved explanations (“Bayesian networks and Naïve Bayes classifier” was this reader’s particular leap of faith!). The author’s writing is captivating and teasing as he describes the benefits and shortcomings of each machine learning style, steadily building belief in the Master Algorithm at the end of each chapter. However, drawing from the five tribes is still not enough to satisfy specifications of the Master Algorithm: Domingos goes on to talk about the need for principal component analysis, dimensionality reduction, and metalearning.By the time one reaches the chapter, “The Pieces of the Puzzle Fall into Place,” and Domingos has pulled together the five models of learning into one elegant and beautiful schematic, the reader is convinced of the feasibility of the Master Algorithm. Domingos hammers home this conviction by explaining how his derived model handles the three necessary elements of representation (a model's formal language of expression), evaluation (a scoring function to say how good a model is), and optimization (the search for the highest-scoring model). In the closing chapter, “This is the World on Machine Learning,” Domingos anticipates how machine learning and the Master Algorithm will affect society as a whole and each and every one of us in many aspects of daily life. Overall, Domingos has crafted a thought-provoking book about a thrilling subject, as fantastic as it is believable. He deftly keeps the reader turning the pages with bursts of humor, big-picture concepts, and behind-the-scenes glimpses of existing learning models. This book is both serious entertainment and education!"
234,0465065708,http://goodreads.com/user/show/11375563-michael-huang,3,"Domingos writes eloquently and lucidly about what machine learning (ML) is doing to the society (helping scientists do them work and make Obama win elections) and how it's supposedly going to change everything (industrial and information revolution automated manual and mental work respectively, ML will automate the automation). And he points out a simple and clearly stated hypothesis, the central hypothesis of the book: ""All knowledge - past, present, and future - can be derived from data by a single, universal learning algorithm"". He then tantalizingly showed the arguments from neural science (we as a species learned knowledge didn't we?); from evolution (our brain was evolved from virtually nothing, why not some master algorithm?); from physics (witness the unreasonable effectiveness of math in natural science); from statistics (Bayes's theorem describes how you can update any belief); from Computer Science (didn't Turing show us how there is a universal machine). By the time I finished Chapter 2, the book looks up to be by far the best book I've read this year (out of 96).Unfortunately, the rest of the book seems to be written by a different person. The lucidity is out. In come weird analogies and references that impede understanding rather than helping it. Maybe he is too excited and his neurons keep firing at even weak associations, but the text would have been returned as ""Needing major revision"" if it was submitted to a journal. Nevertheless, he did explain the five different sub communities of the umbrella community of ML in the next 5 chapters; and rather unconvincingly touted his own research as potentially the ""Master Algorithm"". (I don't mean to suggest his research is bad. In fact, his description of Alchemy seems completely fine and something he should definitely continue to look into. It's just not of the table-pounding, forehead-palming why-didn't-I-think-of-that variety.) At last he closes with what the future holds store once the Master Algorithm arrives. This part is, thankfully, deprived of unnecessary analogies and similes, but is rather anticlimactic (e.g., in the future ""let your people call mine"" becomes ""let your algorithm talk to mine"")."
235,0465065708,http://goodreads.com/user/show/108995717-dan,4,"Very nice overview of the current machine learning paradigms and algorithms: symbolism and induction, connectionism and backpropagation, evolutionism and genetic algorithms, Bayesian and statistical inference, analogy and support vector machines. In its attempt to unify them, it also points to similarities/dissimilarities, weaknesses/strengths, and so on. On the other hand, the Messianic expectation of “The Master Algorithm” that will unify the five different paradigms/algorithms in the same way a Theory of Everything will unify everything in Physics is ridiculous. Most likely, in new data intensive fields completely new and specialized algorithms will emerge beyond the five mentioned in this book and they will stay distinct and specialized. Google is organizing and manipulating the Internet, Amazon is overselling to us, Facebook is selling our profiles, genetic medicine is trying to make sense of the huge amount of data it possesses, the self-driving cars are generating their own data, satellites are mapping the Earth and the sky in small details, and so on. Specialized algorithms can predict and control almost anything in these limited, commercial, and digital fields. But beyond these few data intensive fields, there is no data available and we still need to generate data in the old fashion, small, and expensive ways as we always did if we have some specific hypotheses/questions. Defining “everything that is” and “human intelligence and science” along these commercial data-algorithm ways betrays some naive ontology and epistemology. Moreover, expecting that algorithms that perform extremely well in very specific situations/fields to converge to some Mater Algorithm that explains everything and that will take our human understanding to a new level is an unjustified extrapolation."
236,0465065708,http://goodreads.com/user/show/58987379-ville,3,"Great topic – difficult approachThe book covers three different topics of which each could make a thick book on their own.-	The technical history of machine learning and development of the major algorithms-	Mr Rodriques idea of a universal learning algorithm (‘the master algorithm’)-	Ideas how machine learning has affected our lives and speculations about the futureThese are some of my favourite topics and I would love to love this book, but I can’t. The most problematic was the actual beef of the book: the master algorithm. Even as I have done my fair share of machine learning as M.Sc. in process control and worked with many of the algorithms described for years at work, I found it very difficult to follow and even understand his idea of the MLN method. It was just too difficult approach without some actual examples for me at least.The best parts of the book were some awesome insights that only a true master could state with such simple and entertaining terms.My favorite highlights.-	Believe it or not, every algorithm, no matter how complex, can be reduced to just these three operations: AND, OR, and NOT.-	People often think computers are all about numbers, but they’re not. Computers are all about logic.-	Overfitting is the central problem in machine learning. More papers have been written about it than about any other topic… Humans are not immune to overfitting, either. You could even say that it’s the root cause of a lot of our evils. Consider the little white girl who, upon seeing a Latina baby at the mall, blurted out “Look, Mom, a baby maid!” (True event.) It’s not that she’s a natural-born bigot.-	S curves are a nice halfway house between the dumbness of linear functions and the hardness of step functions.-	An autoencoder is a multilayer perceptron whose output is the same as its input. In goes a picture of your grandmother and out comes—the same picture of your grandmother …the network is forced to encode the input in fewer bits, so it can be represented in the hidden layer, and then decode those bits back to full size. …. However the neet trick was to make the hidden layer actually bigger than the input-output-layers but only allow a few of them to fire at any given moment…-	(k-) nearest neighbor is truly a superfast algorithm but with the slow database connections a trained neural network is sure to win.-	Symbolist methods, for one, are fairly good at disposing of irrelevant attributes. If an attribute has no information about the class, it’s just never included in the decision tree or rule set. But nearest-neighbor is hopelessly confused by irrelevant attributes because they all contribute to the similarity between examples.-	No learner is immune to the curse of dimensionality. It’s the second worst problem in machine learning, after overfitting.-	PCA is to unsupervised learning what linear regression is to the supervised variety.-	Random forests are some of the most accurate classifiers around. Microsoft’s Kinect uses them to figure out what you’re doing, and they regularly win machine-learning competitions.-	(The problem with) combined models can be quite opaque. (“I believe you have prostate cancer because the decision tree, the genetic algorithm, and Naïve Bayes say so, although the multilayer perceptron and the SVM disagree.”)About the future:-	The first robo-lawyers that argue for a particular verdict based on precedents have already been built…Perhaps in a future cybercourt, in session somewhere on Amazon’s cloud, a robo-lawyer will beat the speeding ticket that RoboCop issued to your driverless car, all while you go to the beach, and Leibniz’s dream of reducing all argument to calculation will finally have come true.-	Some researchers even argue that the way to create intelligent machines is to build a robot baby and let him experience the world as a human baby does…The question, of course, is what algorithm should be running in Robby’s brain at birth.-	(You have already “a digital self” living in the internet databases that is good at finding things for you that you are interested.) Even more interesting, the process doesn’t end when you find a car, a house, a doctor, a date, or a job. Your digital half is continually learning from its experiences, just as you would. It figures out what works and doesn’t, whether it’s in job interviews, dating, or real-estate hunting. -	You have your model of every person and organization you interact with, and they each have their model of you. As the models improve, their interactions become more and more like the ones you would have in the real world—except millions of times faster and in silicon. Tomorrow’s cyberspace will be a vast parallel world that selects only the most promising things to try out in the real one. It will be like a new, global subconscious, the collective id of the human race.-	(But the problem right now is that) everyone has only a sliver of it. Google sees your searches, Amazon your online purchases, AT&T your phone calls, Apple your music downloads, Safeway your groceries, Capital One your credit-card transactions. Companies like Acxiom collate and sell information about you, but if you inspect it (which in Acxiom’s case you can, at aboutthedata.com), it’s not much, and some of it is wrong. No one has anything even approaching a complete picture of you.-	Eventually, we’ll start talking about the employment rate instead of the unemployment one and reducing it will be seen as a sign of progress. (“The US is falling behind. Our employment rate is still 23 percent.”)-	People will seek meaning in human relationships, self-actualization, and spirituality, much as they do now. The need to earn a living will be a distant memory, another piece of humanity’s barbaric past that we rose above. -	Picture two strands of DNA going for a swim in their private pool, aka a bacterium’s cytoplasm, two billion years ago. They’re pondering a momentous decision. “I’m worried, Diana,” says one. “If we start making multicellular creatures, will they take over?” -	Contrary to what we like to believe today, humans quite easily fall into obeying others, and any sufficiently advanced AI is indistinguishable from God. People worry that computers will get too smart and take over the world, but the real problem is that they’re too stupid and they’ve already taken over the world. "
237,0465065708,http://goodreads.com/user/show/56609924-flaviu-vescan,3,"I was looking for a book that explains ML and AI concepts for non-practitioners. It did a great job at that. It goes through the most used 7 types of ML algorithms/concepts and explains how they work using high-level math and analogies. It blends a bit of the history of the field so that's always nice to contextualize the information. What made me only give it 3 stars are the detours it keeps making into predicting the future and the crazy soft stance it takes towards the tech giants like FB and GOOG. I'm not sure if Mr. Domingos is still willing to be have such a friendly opinion of them after the latest findings on how they use ML and the many privacy breaches they've had, but I hope not. In any case I'm judging the books version of events and it's lacking any criticism towards the uses of ML in manipulating public opinion. The book is great at teaching you the high-level workings of ML. The problem I had was it kept trying to do more than that by taking a stab at predicting the future of the field influence on humanity. Even for a specialist, it's mostly speculation. "
238,0465065708,http://goodreads.com/user/show/96942737-gautham,3,"A book for those who wish to have an aerial / Birdseye view of the subject, probably a novice in the field but I don’t think it can be of much help for a layman. It was as if Domingos wanted to explain almost all the topics / tribes of the world of Machine learning, from their basics, under one cover, which may have been possible if the book had housed at least about a 1000 or so pages maybe but his choice of including as many topics as he did has trumped the point of ‘understandability’ which a book like this should be focusing on in the first place.The slithering snake analogy for explaining SVMs was the worst of the analogies that he could come up with.However, there are certain learnings that one could get from this book but at the cost 300 pages @ your individual reading speeds is too big a price to pay.The last two chapters of the book seems like the summary of the rest of the chapters with an extension and conclusion. So, if you want to take a quick read, you know where to start."
239,0465065708,http://goodreads.com/user/show/93344337-benny,4,"A few years ago, I came across a list of machine learning algorithms that aspiring data scientists should familiarise themselves with. Since then, I have delved into various machine learning algorithms intermittently during my spare time. In this book, Pedro Domingos has broadly classified them into 5 different families of algorithms. To take these applications further, he suggested that eventually one Master Algorithm can perform that roles that each family of algorithms plays in deciphering our physical world. Below are some of the algorithms that are covered by the author.Genetic AlgorithmNeural Networks(eg. backpropagation, gradient descent)K-nearest NeighbourSupport Vector Machines(eg. kernels)Bayes NetworkK-means ClusteringPCARandom ForestEigenfaces....The book provides a neat high-level summary into the development of these algorithms and how they have come about. With prior understanding of how they work, it is pleasant way to review how these machine learning algorithms optimise, learn and automate our tasks without needing to immerse oneself in the math and computer science that are powering all these AI applications behind the scenes."
240,0465065708,http://goodreads.com/user/show/50245822-srinath-srinath,4,"Great book, gives an overall view of how 5 groups(bayesians,analogizers,symbolists,connectionists,evolutionaries) of people have been competing and trying to solve intelligence. The technical details have been very well explained for a layman to understand."
241,0465065708,http://goodreads.com/user/show/16463508-toma,4,"It is a bit technical for someone who is not in the field or used to some of the theories presented but a great read to understand Artificial Intelligence, Machine Learning and the major schools/philosophies in the field."
242,0465065708,http://goodreads.com/user/show/20064141-maureen-fitzpatrick,4,"It might be a five star book, but this is a book that is just beyond what I understand; however, what I understand is greater having read the book."
243,0465065708,http://goodreads.com/user/show/40460162-steve-jay,5,"If you're a huge nerd and have an interest in futurology, mathematics and computers, this is a must read! Blew my mind."
244,0465065708,http://goodreads.com/user/show/38024135-theodore-kinni,3,"Probably good for budding data scientists, but it's dense and too detailed for the untutored"
245,0465065708,http://goodreads.com/user/show/15317284-carlos-vasconcelos,4,A good book for a broad audience. 
246,0465065708,http://goodreads.com/user/show/50847541-florin-grigoriu,3,"OK to recap the ML notions, the fiction style is too mainstream making the book sometime too buzz-word-ish"
247,0465065708,http://goodreads.com/user/show/76014-raghu,4,"Artificial Intelligence has gradually become a part of our routine discourse. It is because we experience it in varying degrees in even our humdrum lives. We read in the news that driverless cars are already running on our roads. When we sign on to Netflix, we see movie recommendations for us. Often, they turn out to be better than what our friends and relatives suggest to us. Websites help us save money on airline tickets more than before. Google predicts flu outbreaks before CDC has been able to do so. All this is due to Artificial Intelligence or AI for short, of varying degrees. AI is a vast field and has been an area of research since the 1950s. This book is about one branch of AI which is hot today, called Machine Learning.Historically, we have written specific computer programs to solve specific problems using the computer. Each such program is in effect an algorithm to deal with that problem. Machine learning diverges from this traditional approach. It provides computers with the ability to learn. A specific problem is solved without being explicitly programmed for it. Machine learning consists of programs that can teach themselves to grow and change when exposed to more and more data. This book goes one step further. It discusses the holy grail of Machine Learning that researchers are working on, called the Master Algorithm. Right in the first chapter, the author defines this holy grail as follows: ""All knowledge - present, past and future - can be derived by a single, universal learning algorithm"".Now, this might seem ambitious to most of us, including scientists in the field. Some might even slam it as typical of the 'techno-hubris' of Silicon Valley. But the author makes a case that a master algorithm is a feature of nature itself. He shows that there are similar examples in Neuroscience and Evolution. The book captures Machine learning succinctly by the following unwritten rule through which it works:""we must induce the most widely applicable rules we can and reduce their scope only when data forces us to do so"".There are five approaches to Machine Learning today. They are classified as the Symbolists, the Connectionists, the Evolutionaries, the Bayesians and the Analogizers. Each of them is explained briefly as follows:Symbolists believe all intelligence can be reduced to manipulating symbols just as we do in Mathematics. In simple terms, Symbolists start with some existing premises and conclusions. Then, they work backward to fill in the gaps in knowledge by analyzing existing data sets. This is called inverse deduction. Connectionists believe that we must reverse engineer the brain and achieve machine learning. This approach is called 'deep learning'. It consists of creating 'digital neurons' in the computer and connecting them in a neural network model. Google uses this approach in machine translation. It is also used in image processing.Evolutionaries believe in learning through genetic programming. This method mates and evolves computer programs the way nature evolves species. It applies the ideas similar to that of Genomes and DNA in the evolutionary process to data structures. The Genetic programming model works by quantifying the performance of data. It is used to determine the retention and propagation of algorithms in an evolutionary way.Bayesians believe in using Bayes theorem and its derivatives to learn through probabilistic inference. This method proposes a few hypotheses. Then, it assigns probabilities for the likely outcomes of applying these hypotheses. By applying more and more data to test these hypotheses, some of them become more likely than the others. In this way, we arrive at the most likely solution to the problem. This is used in spam filters on emails.Analogizers believe the key to learning is recognizing similarities between situations. This principle is called the nearest neighbour principle. One important aspect of Analogy is that it lets you learn from little data. Analogizers can learn from even just one example - You are what you resemble. Charles Darwin used Malthus' theory of the struggle for survival in society to formulate the biological theory of evolution. Niels Bohr used the solar system model to formulate his theory of the atomic model. A website like Netflix uses it in the recommendations it gives to customers. For example, let us say that someone, whose profile is similar to yours, liked the movie 'Avatar'. Then it is likely that you will like Avatar as well, if you have not seen it already. So, a recommendation of Avatar is made for you. However, all these approaches are not mutually exclusive. Machine learning uses a selective combination of them, depending on the problem. For example, in medicine, the Evolutionary approach is not preferred. The way nature learns is through making mistakes - a luxury we don't have in our societies. Doctors must diagnose in a foolproof way. For example, failing to find a tumor that is really there, is potentially much worse than inferring one that isn't. It needs optimal decisions and this where the Bayesian approach is more useful. In AI, Symbolists held sway in the first few decades of cognitive psychology. Then Connectionists held sway in the 1980s and 90s, and it is the Bayesians' time in the Sun now. The author is upbeat about the future transformations that Machine Learning will bring to our societies. He suggests that in the not too distant future, we will all have a 'digital half' which will do our bidding all 24 hours of the day. They will interact with the digital halves of every person and organization we deal with. Tomorrow's cyberspace will be a giant parallel world. It will be like a new, global subconscious, the collective id of the human race. My only caveat about the book is its prognosis for the future. There is no doubt that the future will be transformed in many ways by Machine Learning. Scientists have been mostly right about predicting the future technological inventions. On the other hand, scientists from Thomas Malthus to Paul Ehrlich to the Club of Rome have made dire predictions about the future of mankind and disaster for thickly populated countries like India and China. They were woefully wrong in this. Not all scientific advances have a smooth path to their full potential. The expected potentials of Nuclear energy and Genetically Modified crops have not materialized because of resistance in our societies. There is also resistance to Stem cells and possibilities of Human cloning. Machine learning is in its infancy now. As it develops and impacts our lives more and more, the technology is bound to make mistakes in a way that affect our lives negatively. If some of them happen to be of the dimension of the Chernobyl accident in Nuclear energy, then there may be a big backlash to the advance of AI too. The other related danger is to rely on vast quantities of data on a phenomenon which leave out key attributes of representing the phenomena correctly, but use it anyway to make crucial decisions. One example in the past of such misuse of data happened in the 1960s. Sen.Robert McNamara, Secy of Defence in the Johnson administration, went about escalating the Vietnam war by relying on 'death count of US and Vietcong soldiers' as a key data indicator of how the war was progressing. The data did not capture the will and determination of the Vietnamese communists to rid themselves of foreign occupation of their land. We all know the consequences of this key error.I enjoyed reading the book as it was educational for me and I learnt much from it. The chapters elaborating the five approaches to Machine Learning need some focus and concentration to fully understand them. Readers, who find these chapters a bit hard, can still simply read just the first 60 pages to get a very good idea of the subject. All in all, it is a great effort to present this exciting subject in a simple way."
248,0465065708,http://goodreads.com/user/show/10768018-jo-o,3,"The idea of a master algorithm is a kind of computer science saint graal. An optimal model for most problems in reality, a robust super-A.I. with the best qualities of organic brains and computer power merged. For this to happen Domingos argues that the 5 tribes of machine learning have to merge as if currently they were very different communities. Those are: symbolists (e.g. logic-based models, decision trees); connectionists (e.g. neural networks); evolutionaries (genetic algorithms); bayesians (graph theory and Bayes-inspired modelling); analogizers (support vector machines, etc.). While this is a ""cool"" vision I find it hard to argue that models can be categorized under that schematic (many hybrids, or some are just specific cases of others) or that the communities of researchers are isolated in any way. Most people with MAJOR published contributions/advances in any of the ""5 tribes"", has papers in the others... usually dozens... (and some are really important as well)!From what else I've read from Domingos I'd rather recommend his short essays, and scientific papers. The big book format gives too much space for random rambling and there are a lot of cringe sentences like random name dropping e.g. ""Kant was also a fan."" with no further exposition or mention.Ultimately, Domingos has a very solid technical view of most stuff he discusses, but then he brings a lot of his personal intuitive futuristic views that can either happen or not. His conclusions and views in more social/political problems, like how should we share our data with AI companies, are also troubling for me. Overall too much utopian gut-feeling in a book about data-centred approaches."
249,0465065708,http://goodreads.com/user/show/23963235-akshith-rao,3,"This book captures the various types of machine learning techniques and how they have progressed through time. The author, being an academician, gets too technical. Even a decent understanding of math did not prevent some pages from turning into Latin for me. If you are someone who is knee deep in math and probability and would like to get an overall picture I would definitely recommend this book to you. For everyone else, it might be better to start looking somewhere else or just skip the math side of things in this book."
250,0465065708,http://goodreads.com/user/show/7297326-jim-crocker,5,"I'm not really finished. This is the kind of book that will go on and on and on with amazing insights and revelations about AI and Machine Learning. I've already heard that it is outta date. But, hey, whaddaya gonna do? Things move fast out there. With me it moves a little slower. I read and think and read and on it goes... This book was an eye-opener for me. I discovered a whole knew point of view. Essentially, it was a paradigm shift.This is a glimpse of the future of humans and the interactions, transactions and associations that will be taking place over the coming years. It's really transformational stuff that's going on. Here's two quotes that I liked (there's a ton more):** ""Most of all, we have to worry about what the Master Algorithm could do in the wrong hands.""** ""...you also have an ethical duty to share data for the common good.""I like that last one best of all!For your convenience, you can get this wonderful book right here:www.blackdogebooks.com/redhot-pick"
251,0465065708,http://goodreads.com/user/show/1173423-peter,5,"Really nice read. Serves as an accessible introduction to machine learning whilst simultaneously outlining the respective strengths and weaknesses of its 5 different ""tribes"" and ultimately showing how they can be connected. This makes the book valuable even for machine learning practitioners. Furthermore, in these days where deep learning reigns supreme and the media make it seem it is the end-all-be-all of machine learning, this book adds a valuable historical and conceptual perspective. The derivation and description of the current best stab at the Master Algorithm is more technical though, and probably more difficult to follow for the non-technical reader.The author is very bullish in the scale and scope of the application of machine learning and he offers powerful examples of AI in the form of personal agents negotiating the world on our behalf, the enabler of systems biology, and eventually designing and enhancing humans. However I think his view is quite utopian and that he downplays several potential negative scenarios of both weak and strong AI. For instance, Domingos believes that job displacement will not be grave (the argument that more new jobs that we now can't imagine will be created than will be destroyed), and that even if this were to happen, then if it reaches critical mass (>50%), then in a democracy that majority will vote for lifelong salaries for just being alive (i.e. universal basic income). However I think there is a path-dependance here on things staying the same politically. Let's contrast it with the scenario in Yuval Harari's Homo Deus of the creation of a class of ""useless"" humans who don't have to offer anything economically nor militarily. The political power of the masses would then be greatly diminished, perhaps even up to the point of threatening liberal democracy.Looking even further into the future, he does not take into account the dangers of reductionist goals. He basically argues that because machines don't have goals of their own, we are safe. Nick Bostrom belabors the dangers of strong AI in his book Superintelligence.In conclusion, although I think the dangers of AI were downplayed, I think it was a great read. I would recommend pairing this book (written by an machine learning researcher & practitioner) up with Homo Deus (written by a historian) and Superintelligence (by a philosopher) for a more holistic view if your interest is primarily on the (future) impact of AI."
252,0465065708,http://goodreads.com/user/show/38621776-an-l-tuncel,1,"Disappointing. This book has no scientific value. No one should read this book, not even teenagers (they will get confused). "
253,0465065708,http://goodreads.com/user/show/19014583-t,4,"I enjoyed this book overall but had some frustrations with it. Enough so that it was a real debate between 3 and 4 stars for me; I'm giving it 4 now as a benefit of the doubt but I may reread and drop it to 3 if it doesn't seem better.First, the topic couldn't be more relevant and interesting to our time; both for buzz word purposes and real discussion of the current state of the field the book was interesting. That said, I had several annoyances. First, the author seemed quite taken with creating fanciful allegories for things that were clear attempts to be poetic or entertaining and in practice were often just kind of dumb. In the more lower level cases they would help add to understanding, but the broader they got the more you felt like you were wasting your time while he talked about wandering through a city and spent time describing the turrets or telling you what you suddenly remembered or felt. Ick. Second, the premise at the start of the book seemed to be that anyone could understand and contribute to all of the field and the rest of the book seemed, to me at least, to rather disprove that. I think he tried to make this accessible to all and thus went a step too far; he'd have been better off saying the requirements of the field are not so high as many fear and thus are accessible to many more than would expect it. Saying anyone could do it even without complicated math just seemed inaccurate even using his own description by the end.Finally, the overall structure of the book and the discussion of the five ""tribes"" left me somewhat uncertain. I couldn't decide if that was an actually useful description or more confusing than helpful. In part this was because my reading was rather fractured through time so I'm reserving judgment of this for a more thorough reread.All that said, the book was still an interesting overview of the current state and problems of the machine learning world and, when not trying to wax poetic, was a pretty good and understandable summary of those and a nice encouragement for those of us on the edge of the field to get into it."
254,0465065708,http://goodreads.com/user/show/3550209-adrian,5,"Who knew the 'S' curve was the most important function ever?I picked up ""The Master Algorithm"" hoping it would serve as a primer as I began my journey into the world of deep learning. At first, I found it overly figurative and difficult to follow so I stopped reading it. After about 6 months of Andrew Ng YouTube videos, SciKit Learn, PyImageSearch, and other well-organized tutorials, I revisited the book and fell in love with it. What I appreciated most was the discussion of the 5 tribes of machine learning and how he was able to merge the mentality of the different camps. I'd consider myself an Analogizer and I work with a Bayesian. Often, it feels like we are talking different languages. I had to chuckle a few time as this book addressed this common dynamic.I enjoyed Chapter 9 the most with his fanciful depiction of a continent divided into 5 territories: Symbolist, Connectionists, Evolutionists, Bayesians, and Analogizers with Master Algorithm serving as the capital city. He did an excellent job conceptualizing how different aspects of each 'tribe' would contribute to the one unifying, but elusive, algorithm. He went to great lengths to establish his sci-fi bona fides with references to Lord of the Rings, The Matrix, Robocop, and much more. My favorite came when he was discussing Support Vector Machines and visualizing the border between classes as a snake slithering down the no-man's-land with the support vectors serving as mines. It's ""like the sandworms in Dune: big, tough, and able to survive a few explosions from slithering over landmines but not too many"". A five-star rating was locked after that."
255,0465065708,http://goodreads.com/user/show/5858138-nic-brisbourne,4,"Domingos provides a detailed and pretty technical explanation of five different areas of artificial intelligence:* Symbolists - observe and inducer Dix logic in the world and code it - works well in limited domains and highly explainable, but impossible to scale* Neural networks - infer rules from large amounts of data to by looking at training sets - if it's seen enough pictures of cats it can compute the probability that a new image is a cat* Genetic algorithms - define an objective and let evolve according to rules, and then keep the solutions that beat fit the desired goal, and then repeat. Key is choosing the rules and fit algorithms well* Bayesians and probabalistic influence- great at finding categories and classifying things* Analogisers and Support Vector Machines - good for spotting similarities between things and making predictions about other things that might be similar - if I have flu, and we are friends but don't live in the same town, what is the chance that you also have flu?This stuff is quite dense! I have a solid grounding in maths, science, and stats but haven't practiced for decades and understood most of it, but had to read slowly. Domingos writes well and with humour which makes reading much easier. Finally - I should also say that he does a good job of making it real with examples and a semi-good job of predicting where the future will take us. "
256,0465065708,http://goodreads.com/user/show/47032429-kenta-suzuki,4,"Pedro Domingo describes the machine learnings from its origin to now, and how it can be used in the future. He purports that the Master Algorithm be the one that is ultimate goal of machine learning or universal learner as he call it. This algorithm will be replete with or fall into the intersection of the five bailiwicks: Symbolists, Connectionists, Evolutionaries, Bayesians, and Analogizers. For symbolists, Inverse Deduction is algorithm, Gradient Descent for Connectionists, Genetic Search for Evolutionaries, Probabilistic Inference for Bayesian and Constrained Optimization for Analogizers. For instance, Netflix uses k-nearest- neighbor algorithm, which finds the correlations with each others, to create recommendation system.This algorithm is so important that recommender system consists of a third of Amazon's business. In the future, he claims, that there will be one version of yourself who or which basically do most of the things on behalf of you faster than you could. He also argues that the fears some people have toward AI or Singularity will be relinquished if humans deal with them carefully. For instance, there will no infinite growth of AI as is the case with Moore's law. It will eventually taper off as S curve deliniates. This book will gives some prelude to those areas for those who do not have solid backgrounds for statistics or machine learning. "
257,0465065708,http://goodreads.com/user/show/51672399-david,4,"Domingos' attraction to analogical learning leads him to fill this book with analogies for almost everything he talks about. I wonder if a computer develops consciousness would they find it as annoying as I did? Other than this nuisance, the book gives a great overview of the history and state of machine learning. The various subfields outlined in the novel are very well abstracted to show the significant similarities and differences between them.However, Domingos' view of the future, as stated in the last chapter, wouldn't be the most inspiring. The possibility of an algorithm that could predict cancer treatment through genome mapping is surely an excellent use of machine learning but his belief that war will be ""fought"" by between different learners isn't something I'm looking forward to. The author assures the reader of this certainty. For me, this is just a stark reminder that technology advancement does not necessarily advance society in a positive way. In the case of fighting algorithms, there will be a victor and whomever or whatever possesses this technology will be the one with the power to rule a lot of important aspects in this world. This scenario just looks like a continuation of the current trend in the concentration of wealth and power into the hands of the few and not the many."
258,0465065708,http://goodreads.com/user/show/8146846-satyabrata-mishra,5,"Pedros Domingos does a fascinating job describing complex machine learning algorithms in forms of simple (and sometimes silly) metaphors and examples; like dividing the different forms of AI-engineers into tribes and walking down the cities of their design.For someone who wants to peek into machine learning and understand the powers and faults of each algorithm, the master algorithm is a great choice. I picked it up as a pre-read before my ML classes starts and I could not have made a better choice. "
259,0465065708,http://goodreads.com/user/show/60299397-victor-villas,3,"The book starts very slowly, hyping up the idea of the master algorithm. The middle parts are really interesting, where each of the ""five tribes"" of machine learning are discussed. It ends with some self promotion for the alchemy thingy the author is part of. For serious machine learning students this book might be a waste of time, but is still entertaining for the laymen."
260,0465065708,http://goodreads.com/user/show/4696922-ushan,1,"I took Prof. Domingos's data mining course at the UW night school in 2001, and I was wondering whether this book can give a good overview of the progress of the machine learning since then. It doesn't. It is plainly badly written. If I were a layman, I wouldn't have understood anything."
261,0465065708,http://goodreads.com/user/show/2237619-josh,3,"It's been over 200 years since Babbage, and around 60 years since the first serious forays into developing intelligent electronic machines, and we finally seem to have come to a point in history where machine learning is coming of age. The history of AI cautions one against excessive optimism, but the successes of machine learning are becoming impossible to ignore. Machine learners have steadily encroached on areas of intelligence previously thought to be accessible only to the human mind. The lowlands of human thought are rapidly being filled by the flood of artificial intelligence, and there's little reason to believe that the rising tide is going to stop any time soon. There is hardly a field of academic research or sector of the economy that has not been affected in some way by machine learning, and more radical changes loom. Advances in neuroscience along with a torrent of machine learning research hint at a general learning algorithm that would make all other advances in human science seem trivial in comparison. To repeat an oft-quoted phrase, ""the first ultraintelligent machine is the last invention that man need ever make"". That, in essence, is what Pedro Domingos' book is about.It starts off with a broad overview of how machine learning algorithms (he calls them learners), are omnipresent in modern society. Algorithms help decide what you see on your social media news feed, which videos you watch, which products you buy, which stocks to add to your portfolio, which ads you see, which political candidates you vote for and who you decide to date. I don't think it's an exaggeration to say that machine learning has revolutionized almost every aspect of how we live our day-to-day lives.And that's just getting started.Domingos divides machine learning research into five 'tribes' and spends some time discussing each of them in detail: the Symbolists, the Connectionists, the Evolutionaries, the Bayesians, and the Analogizers.The Symbolists advocate a rule-based approach to learning, and use logical inference as their main tool. This was a common tactic with the expert AI systems of the 80s, and still has a large place in automated systems today. A big problem that every machine learning algorithm has to deal with when understanding large datasets is the vast set of possible interpretations for that data, and the Symbolists have a few effective ways of dealing with this. If you want to build a system that can diagnose an illness, you might go about it by forming a decision tree. Does the person have a rash? If so, does that person also have a cold? And so on. Anyone who's played the game 20 questions can probably see why this approach might be an effective way of building intelligent systems. It also has the downside that these systems are costly and time-consuming to construct, not to mention they lack a certain degree of generality. Domingos doesn't seem to be a fan of this school of research, and for the most part he quickly passes it by so he can move on to other methods. Rule-based inference, for the most part, does not seem like a particularly effective way of interpreting data, and it certainly isn't how human brains interpret data. For a more biologically inspired learning method we have the connectionists.If you've heard any of the recent headlines about DeepMind's AlphaGo beating the world Go champion, you've heard about connectionism. Connectionists are the practitioners of neural networks--artificial simulations of the sort of neurons we see in animal brains. Since human-level intelligence has so far only been exhibited in human brains, a natural approach to programming intelligence is by reverse engineering the human brain. People have been programming neural networks for about as long as programmable computers have been around--the first attempts were made in the 50s, and despite a steady following of researchers in the meantime it is only recently that neural networks have really begun to have their full potential realized. This is due in part to the fact that processors today are more powerful than ever, but also because the Internet is a rich sea of data that we can use to train our networks. Still, neural nets, despite their amazing versatility for solving problems, are quite cumbersome and aren't exact representations of the human brain. It's not even clear whether an exact simulation of how the brain works would be an efficient computational model. They also take a lot of computing power to train, so for certain situations they are not ideal.Another biologically-inspired approach to machine learning is evolutionary computing. The idea behind this one is sound: human intelligence arose through evolutionary processes, so why can't we write programs to 'evolve' through a sort of Darwinian selection process? If we select for the tributes we want a program to have, say for a self-driving car to drive safely, and reject the attributes we don't want it to have, say, crashing into stop signs, we can eventually produce a program that will be a good driver. In theory, at least. The problem, of course, is that human intelligence took hundreds of millions of years to evolve to where it is now, and researchers don't have that kind of time to spend. It also seems to be a bit of a fluke that intelligence even arose at all, considering all the time in prehistory where it wasn't around. Evolution is a tricky thing to recreate, and the successes of evolutionary computing have been overshadowed by other methods. It remains to be seen if they will one day come into the spotlight like connectionism has in recent years.The Bayesians are mostly involved in applying Bayes' theorem to machine learning problem. Thomas Bayes, a 17th century Englishman, was a statistician who formulated one of the most famous theorems in probability theory. His theorem helps us understand how events are related to each other, and how the probability of one event affects another. Applications of this fairly simple theory are among the most popular approaches to machine learning and still seen to be the most widely used. While this approach isn't as biologically inspired as the other methods, Bayesian inference does still represent something our brains have to do to interact intelligently with the world. Bayesian theory is very robust in its application and can be applied to a wide range of real-world problems. Things do tend to get a bit hairy when dealing with problems that have a lot of variables, but with the right simplifying assumptions this has proved to be a very powerful theory.The Analogizers, as Domingos calls them, aren't as unified as the other tribes. Human learning could perhaps be best characterized as learning by analogy. We learn new concepts by associating them with old concepts we already know. It turns out statistical formulations of this type of learning are also quite effective, as can be seen by various automated recommendation systems designed by companies like Netflix or Amazon. Truth be told it wasn't entirely clear to me how this approach differed significantly from the other approaches already discussed, but I guess Domingos felt the distinction was necessary.He then goes on to discuss a hodgepodge of various other learning strategies that take influence from human psychology, notably reinforcement learning. Reinforcement learning agents choose between possible actions to take in an environment based on the expectation of future rewards from that action. If pressing a button rewards a reinforcement learning agent, the agent will quickly learning to spend as much of its time pressing that button as possible. Reinforcement learning by itself doesn't generalize to other problems outside of a narrow domain especially well, but when combined with neural networks it can be a powerful approach for machine learning problems.The final chapter of the book is about the future of machine learning, and full of the typical sort of predictions that authors of this type of book seem to love. Personally I feel like most of what Domingos has to say in this chapter has been dealt with better by other authors, but I digress. Machine learning will certainly have a huge impact on every aspect of our lives. In a very real way you are the data that you create. Other people make models of you based on your behavior just like Netflix makes models of your movie-viewing habits. The reason so many companies have started racing to collect your data is because that data is powerful. It influences the choices we make at an individual level and thus influences the whole of our society. This is a scary thought to some, and is certainly something that should be taken into consideration by human rights organizations and governments. On the flipside, data is becoming democratized very quickly--a fact which is helping facilitate positive social change at a faster rate than ever before in the history of civilization. Some are worried about machines achieving human levels of intelligence, but I think those fears are misguided. It is far more advantageous for us to consider what new avenues of possibility have opened up than to dwell on the roads we will leave behind. To quote Domingos: ""The real history of automation is not what it replaces but what it enables.""Overall the book is a good general overview of the research being done in machine learning today. It does not, however, substitute for a more serious mathematical treatment of the subject, and those wishing to delve deeper into the subject would be better served elsewhere. Still, as a light introduction to the subject this book is worth looking into."
262,0465065708,http://goodreads.com/user/show/3055905-nils,4,"A useful book that lays out the five “tribes” of machine learning and ecumenically proposes that the true “master algorithm” (AGI) will combine all five: the symbolists’ inverse deduction, the connectionists’ backpropagation, the evolutionists’ genetic programming, the Bayesians’ various theorems, and the analogizers’ support vector machines.What’s most dated about this 2015 book is how utterly sanguine he is about what moving toward a master algorithm will produce in terms of social effects. It’s not just that he rejects the scaremongering of the Singulatarians (as he points out, the algorithms are never going to have wills of their own), but it’s more than he doesn’t consider except in the most glancing way what may happen if bad people control the algorithm, or the more profound problem of what it means if each of us has a shadow algorithmically optimized version of ourselves representing us in the world — how this could ironically lead to a loss of will, a surrender to the algorithmic engine that supposedly understands our preferences better than we do. Do we really want to live in a world where, “everyone has an entourage of bots, smoothing his or her way through the world.… Your digital half will be like power steering for your life.” Occasionally he glimpses the dystopian possibilities but then handwaves then away: “This does not mean that you’ll end up in a ‘filter bubble,’ seeing only what you reliably like, with no room for the unexpected,” he reassures us. “The digital you knows better than that. Part of its brief is to leave some things open to chance, to expose you to new experiences, and to look for serendipity.” Nor does he really consider the philosophical implications of a situation where “You have your model of every person in the organization you interact with, and they each have their model of you. As the models improve, their interaction becomes more and more like the ones you would have in the real world.” What’s happening in this scenario is that border between human and machine is eroding, with humans themselves evolving and in many cases likely to surrender control, happily turning over their decision making to their digital self. Are we so sure, in this scenario that the distinction between the willful human and the enslaved machines makes sense? We need not worry about silly infinite paperclip scenarios, is a world where many of us have become merely wired bundles of continuously satisfied Id a world we want to live in? Is a world where technology splinters the unity of the human race, as he predicts, not a world with truly fearsome possibilities? Consider this passage: “One of the greatest talents a politician can have is the ability to understand voters, individually or in small groups, and to speak directly to them (or seem to). Bill Clinton is the paradigmatic example of this in recent memory. The effect of machine learning is like having a dedicated Bill Clinton for every voter.” Wait, is that a promise, or a threat?! Likewise, would anyone in 2019 in good conscience be able to write that, “Democracy works better because the bandwidth of communications between voters and politicians increases enormously.... Big data and machine learning [will] change the equation. In the future, provided voter models are accurate, elected officials will be able to ask a voters what they want 1000 times a day and act accordingly – without having to pester the actual flesh and blood citizens.” Provided voter models are accurate is doing a whole lotta work there, wouldn’t you say?"
263,0465065708,http://goodreads.com/user/show/56104661-mark,3,"Pedro Domingos wastes no time in laying out his bold hypothesis on which The Master Algorithm: How The Quest for the Ultimate Learning Machine Will Remake Our World is based. Early in chapter two, he declares that: “All knowledge—past, present, and future—can be derived from data by a single, universal learning algorithm.” Clearly, Domingos believes that such an algorithm can be developed, but for the doubting Thomases among us, he cites strong lines of evidence from the disciplines of neuroscience, evolution, physics, statistics, and computer science.The search for the Master Algorithm does not have to start from scratch, Domingos tells us. The bulk of the book describes five current approaches to machine learning—or “five tribes of machine learning,” as he labels them—namely, symbolists, connectionists, evolutionaries, Bayesians, and analogizers. These tribes each have a set of core beliefs, and a central problem they must solve. Domingos’s detailed descriptions of how they do that occasionally results in dense and complex narrative, but he cleverly illustrates his points with familiar, daily-life examples, with equally familiar organizations, such as Google, Amazon, Netflix, and Facebook.Of course, the true Master Algorithm must solve the problems of all five tribes, and the reader is encouraged to stick with the narrative and even take a leap of faith in some of the more involved explanations (“Bayesian networks and Naïve Bayes classifier” was this reader’s particular leap of faith!). The author’s writing is captivating and teasing as he describes the benefits and shortcomings of each machine learning style, steadily building belief in the Master Algorithm at the end of each chapter. However, drawing from the five tribes is still not enough to satisfy specifications of the Master Algorithm: Domingos goes on to talk about the need for principal component analysis, dimensionality reduction, and metalearning.By the time one reaches the chapter, “The Pieces of the Puzzle Fall into Place,” and Domingos has pulled together the five models of learning into one elegant and beautiful schematic, the reader is convinced of the feasibility of the Master Algorithm. Domingos hammers home this conviction by explaining how his derived model handles the three necessary elements of representation (a model's formal language of expression), evaluation (a scoring function to say how good a model is), and optimization (the search for the highest-scoring model). In the closing chapter, “This is the World on Machine Learning,” Domingos anticipates how machine learning and the Master Algorithm will affect society as a whole and each and every one of us in many aspects of daily life. Overall, Domingos has crafted a thought-provoking book about a thrilling subject, as fantastic as it is believable. He deftly keeps the reader turning the pages with bursts of humor, big-picture concepts, and behind-the-scenes glimpses of existing learning models. This book is both serious entertainment and education!"
264,0465065708,http://goodreads.com/user/show/11375563-michael-huang,3,"Domingos writes eloquently and lucidly about what machine learning (ML) is doing to the society (helping scientists do them work and make Obama win elections) and how it's supposedly going to change everything (industrial and information revolution automated manual and mental work respectively, ML will automate the automation). And he points out a simple and clearly stated hypothesis, the central hypothesis of the book: ""All knowledge - past, present, and future - can be derived from data by a single, universal learning algorithm"". He then tantalizingly showed the arguments from neural science (we as a species learned knowledge didn't we?); from evolution (our brain was evolved from virtually nothing, why not some master algorithm?); from physics (witness the unreasonable effectiveness of math in natural science); from statistics (Bayes's theorem describes how you can update any belief); from Computer Science (didn't Turing show us how there is a universal machine). By the time I finished Chapter 2, the book looks up to be by far the best book I've read this year (out of 96).Unfortunately, the rest of the book seems to be written by a different person. The lucidity is out. In come weird analogies and references that impede understanding rather than helping it. Maybe he is too excited and his neurons keep firing at even weak associations, but the text would have been returned as ""Needing major revision"" if it was submitted to a journal. Nevertheless, he did explain the five different sub communities of the umbrella community of ML in the next 5 chapters; and rather unconvincingly touted his own research as potentially the ""Master Algorithm"". (I don't mean to suggest his research is bad. In fact, his description of Alchemy seems completely fine and something he should definitely continue to look into. It's just not of the table-pounding, forehead-palming why-didn't-I-think-of-that variety.) At last he closes with what the future holds store once the Master Algorithm arrives. This part is, thankfully, deprived of unnecessary analogies and similes, but is rather anticlimactic (e.g., in the future ""let your people call mine"" becomes ""let your algorithm talk to mine"")."
265,0465065708,http://goodreads.com/user/show/108995717-dan,4,"Very nice overview of the current machine learning paradigms and algorithms: symbolism and induction, connectionism and backpropagation, evolutionism and genetic algorithms, Bayesian and statistical inference, analogy and support vector machines. In its attempt to unify them, it also points to similarities/dissimilarities, weaknesses/strengths, and so on. On the other hand, the Messianic expectation of “The Master Algorithm” that will unify the five different paradigms/algorithms in the same way a Theory of Everything will unify everything in Physics is ridiculous. Most likely, in new data intensive fields completely new and specialized algorithms will emerge beyond the five mentioned in this book and they will stay distinct and specialized. Google is organizing and manipulating the Internet, Amazon is overselling to us, Facebook is selling our profiles, genetic medicine is trying to make sense of the huge amount of data it possesses, the self-driving cars are generating their own data, satellites are mapping the Earth and the sky in small details, and so on. Specialized algorithms can predict and control almost anything in these limited, commercial, and digital fields. But beyond these few data intensive fields, there is no data available and we still need to generate data in the old fashion, small, and expensive ways as we always did if we have some specific hypotheses/questions. Defining “everything that is” and “human intelligence and science” along these commercial data-algorithm ways betrays some naive ontology and epistemology. Moreover, expecting that algorithms that perform extremely well in very specific situations/fields to converge to some Mater Algorithm that explains everything and that will take our human understanding to a new level is an unjustified extrapolation."
266,0465065708,http://goodreads.com/user/show/58987379-ville,3,"Great topic – difficult approachThe book covers three different topics of which each could make a thick book on their own.-	The technical history of machine learning and development of the major algorithms-	Mr Rodriques idea of a universal learning algorithm (‘the master algorithm’)-	Ideas how machine learning has affected our lives and speculations about the futureThese are some of my favourite topics and I would love to love this book, but I can’t. The most problematic was the actual beef of the book: the master algorithm. Even as I have done my fair share of machine learning as M.Sc. in process control and worked with many of the algorithms described for years at work, I found it very difficult to follow and even understand his idea of the MLN method. It was just too difficult approach without some actual examples for me at least.The best parts of the book were some awesome insights that only a true master could state with such simple and entertaining terms.My favorite highlights.-	Believe it or not, every algorithm, no matter how complex, can be reduced to just these three operations: AND, OR, and NOT.-	People often think computers are all about numbers, but they’re not. Computers are all about logic.-	Overfitting is the central problem in machine learning. More papers have been written about it than about any other topic… Humans are not immune to overfitting, either. You could even say that it’s the root cause of a lot of our evils. Consider the little white girl who, upon seeing a Latina baby at the mall, blurted out “Look, Mom, a baby maid!” (True event.) It’s not that she’s a natural-born bigot.-	S curves are a nice halfway house between the dumbness of linear functions and the hardness of step functions.-	An autoencoder is a multilayer perceptron whose output is the same as its input. In goes a picture of your grandmother and out comes—the same picture of your grandmother …the network is forced to encode the input in fewer bits, so it can be represented in the hidden layer, and then decode those bits back to full size. …. However the neet trick was to make the hidden layer actually bigger than the input-output-layers but only allow a few of them to fire at any given moment…-	(k-) nearest neighbor is truly a superfast algorithm but with the slow database connections a trained neural network is sure to win.-	Symbolist methods, for one, are fairly good at disposing of irrelevant attributes. If an attribute has no information about the class, it’s just never included in the decision tree or rule set. But nearest-neighbor is hopelessly confused by irrelevant attributes because they all contribute to the similarity between examples.-	No learner is immune to the curse of dimensionality. It’s the second worst problem in machine learning, after overfitting.-	PCA is to unsupervised learning what linear regression is to the supervised variety.-	Random forests are some of the most accurate classifiers around. Microsoft’s Kinect uses them to figure out what you’re doing, and they regularly win machine-learning competitions.-	(The problem with) combined models can be quite opaque. (“I believe you have prostate cancer because the decision tree, the genetic algorithm, and Naïve Bayes say so, although the multilayer perceptron and the SVM disagree.”)About the future:-	The first robo-lawyers that argue for a particular verdict based on precedents have already been built…Perhaps in a future cybercourt, in session somewhere on Amazon’s cloud, a robo-lawyer will beat the speeding ticket that RoboCop issued to your driverless car, all while you go to the beach, and Leibniz’s dream of reducing all argument to calculation will finally have come true.-	Some researchers even argue that the way to create intelligent machines is to build a robot baby and let him experience the world as a human baby does…The question, of course, is what algorithm should be running in Robby’s brain at birth.-	(You have already “a digital self” living in the internet databases that is good at finding things for you that you are interested.) Even more interesting, the process doesn’t end when you find a car, a house, a doctor, a date, or a job. Your digital half is continually learning from its experiences, just as you would. It figures out what works and doesn’t, whether it’s in job interviews, dating, or real-estate hunting. -	You have your model of every person and organization you interact with, and they each have their model of you. As the models improve, their interactions become more and more like the ones you would have in the real world—except millions of times faster and in silicon. Tomorrow’s cyberspace will be a vast parallel world that selects only the most promising things to try out in the real one. It will be like a new, global subconscious, the collective id of the human race.-	(But the problem right now is that) everyone has only a sliver of it. Google sees your searches, Amazon your online purchases, AT&T your phone calls, Apple your music downloads, Safeway your groceries, Capital One your credit-card transactions. Companies like Acxiom collate and sell information about you, but if you inspect it (which in Acxiom’s case you can, at aboutthedata.com), it’s not much, and some of it is wrong. No one has anything even approaching a complete picture of you.-	Eventually, we’ll start talking about the employment rate instead of the unemployment one and reducing it will be seen as a sign of progress. (“The US is falling behind. Our employment rate is still 23 percent.”)-	People will seek meaning in human relationships, self-actualization, and spirituality, much as they do now. The need to earn a living will be a distant memory, another piece of humanity’s barbaric past that we rose above. -	Picture two strands of DNA going for a swim in their private pool, aka a bacterium’s cytoplasm, two billion years ago. They’re pondering a momentous decision. “I’m worried, Diana,” says one. “If we start making multicellular creatures, will they take over?” -	Contrary to what we like to believe today, humans quite easily fall into obeying others, and any sufficiently advanced AI is indistinguishable from God. People worry that computers will get too smart and take over the world, but the real problem is that they’re too stupid and they’ve already taken over the world. "
267,0465065708,http://goodreads.com/user/show/56609924-flaviu-vescan,3,"I was looking for a book that explains ML and AI concepts for non-practitioners. It did a great job at that. It goes through the most used 7 types of ML algorithms/concepts and explains how they work using high-level math and analogies. It blends a bit of the history of the field so that's always nice to contextualize the information. What made me only give it 3 stars are the detours it keeps making into predicting the future and the crazy soft stance it takes towards the tech giants like FB and GOOG. I'm not sure if Mr. Domingos is still willing to be have such a friendly opinion of them after the latest findings on how they use ML and the many privacy breaches they've had, but I hope not. In any case I'm judging the books version of events and it's lacking any criticism towards the uses of ML in manipulating public opinion. The book is great at teaching you the high-level workings of ML. The problem I had was it kept trying to do more than that by taking a stab at predicting the future of the field influence on humanity. Even for a specialist, it's mostly speculation. "
268,0465065708,http://goodreads.com/user/show/96942737-gautham,3,"A book for those who wish to have an aerial / Birdseye view of the subject, probably a novice in the field but I don’t think it can be of much help for a layman. It was as if Domingos wanted to explain almost all the topics / tribes of the world of Machine learning, from their basics, under one cover, which may have been possible if the book had housed at least about a 1000 or so pages maybe but his choice of including as many topics as he did has trumped the point of ‘understandability’ which a book like this should be focusing on in the first place.The slithering snake analogy for explaining SVMs was the worst of the analogies that he could come up with.However, there are certain learnings that one could get from this book but at the cost 300 pages @ your individual reading speeds is too big a price to pay.The last two chapters of the book seems like the summary of the rest of the chapters with an extension and conclusion. So, if you want to take a quick read, you know where to start."
269,0465065708,http://goodreads.com/user/show/93344337-benny,4,"A few years ago, I came across a list of machine learning algorithms that aspiring data scientists should familiarise themselves with. Since then, I have delved into various machine learning algorithms intermittently during my spare time. In this book, Pedro Domingos has broadly classified them into 5 different families of algorithms. To take these applications further, he suggested that eventually one Master Algorithm can perform that roles that each family of algorithms plays in deciphering our physical world. Below are some of the algorithms that are covered by the author.Genetic AlgorithmNeural Networks(eg. backpropagation, gradient descent)K-nearest NeighbourSupport Vector Machines(eg. kernels)Bayes NetworkK-means ClusteringPCARandom ForestEigenfaces....The book provides a neat high-level summary into the development of these algorithms and how they have come about. With prior understanding of how they work, it is pleasant way to review how these machine learning algorithms optimise, learn and automate our tasks without needing to immerse oneself in the math and computer science that are powering all these AI applications behind the scenes."
270,0465065708,http://goodreads.com/user/show/50245822-srinath-srinath,4,"Great book, gives an overall view of how 5 groups(bayesians,analogizers,symbolists,connectionists,evolutionaries) of people have been competing and trying to solve intelligence. The technical details have been very well explained for a layman to understand."
271,0465065708,http://goodreads.com/user/show/16463508-toma,4,"It is a bit technical for someone who is not in the field or used to some of the theories presented but a great read to understand Artificial Intelligence, Machine Learning and the major schools/philosophies in the field."
272,0465065708,http://goodreads.com/user/show/20064141-maureen-fitzpatrick,4,"It might be a five star book, but this is a book that is just beyond what I understand; however, what I understand is greater having read the book."
273,0465065708,http://goodreads.com/user/show/40460162-steve-jay,5,"If you're a huge nerd and have an interest in futurology, mathematics and computers, this is a must read! Blew my mind."
274,0465065708,http://goodreads.com/user/show/38024135-theodore-kinni,3,"Probably good for budding data scientists, but it's dense and too detailed for the untutored"
275,0465065708,http://goodreads.com/user/show/15317284-carlos-vasconcelos,4,A good book for a broad audience. 
276,0465065708,http://goodreads.com/user/show/50847541-florin-grigoriu,3,"OK to recap the ML notions, the fiction style is too mainstream making the book sometime too buzz-word-ish"
277,0465065708,http://goodreads.com/user/show/76014-raghu,4,"Artificial Intelligence has gradually become a part of our routine discourse. It is because we experience it in varying degrees in even our humdrum lives. We read in the news that driverless cars are already running on our roads. When we sign on to Netflix, we see movie recommendations for us. Often, they turn out to be better than what our friends and relatives suggest to us. Websites help us save money on airline tickets more than before. Google predicts flu outbreaks before CDC has been able to do so. All this is due to Artificial Intelligence or AI for short, of varying degrees. AI is a vast field and has been an area of research since the 1950s. This book is about one branch of AI which is hot today, called Machine Learning.Historically, we have written specific computer programs to solve specific problems using the computer. Each such program is in effect an algorithm to deal with that problem. Machine learning diverges from this traditional approach. It provides computers with the ability to learn. A specific problem is solved without being explicitly programmed for it. Machine learning consists of programs that can teach themselves to grow and change when exposed to more and more data. This book goes one step further. It discusses the holy grail of Machine Learning that researchers are working on, called the Master Algorithm. Right in the first chapter, the author defines this holy grail as follows: ""All knowledge - present, past and future - can be derived by a single, universal learning algorithm"".Now, this might seem ambitious to most of us, including scientists in the field. Some might even slam it as typical of the 'techno-hubris' of Silicon Valley. But the author makes a case that a master algorithm is a feature of nature itself. He shows that there are similar examples in Neuroscience and Evolution. The book captures Machine learning succinctly by the following unwritten rule through which it works:""we must induce the most widely applicable rules we can and reduce their scope only when data forces us to do so"".There are five approaches to Machine Learning today. They are classified as the Symbolists, the Connectionists, the Evolutionaries, the Bayesians and the Analogizers. Each of them is explained briefly as follows:Symbolists believe all intelligence can be reduced to manipulating symbols just as we do in Mathematics. In simple terms, Symbolists start with some existing premises and conclusions. Then, they work backward to fill in the gaps in knowledge by analyzing existing data sets. This is called inverse deduction. Connectionists believe that we must reverse engineer the brain and achieve machine learning. This approach is called 'deep learning'. It consists of creating 'digital neurons' in the computer and connecting them in a neural network model. Google uses this approach in machine translation. It is also used in image processing.Evolutionaries believe in learning through genetic programming. This method mates and evolves computer programs the way nature evolves species. It applies the ideas similar to that of Genomes and DNA in the evolutionary process to data structures. The Genetic programming model works by quantifying the performance of data. It is used to determine the retention and propagation of algorithms in an evolutionary way.Bayesians believe in using Bayes theorem and its derivatives to learn through probabilistic inference. This method proposes a few hypotheses. Then, it assigns probabilities for the likely outcomes of applying these hypotheses. By applying more and more data to test these hypotheses, some of them become more likely than the others. In this way, we arrive at the most likely solution to the problem. This is used in spam filters on emails.Analogizers believe the key to learning is recognizing similarities between situations. This principle is called the nearest neighbour principle. One important aspect of Analogy is that it lets you learn from little data. Analogizers can learn from even just one example - You are what you resemble. Charles Darwin used Malthus' theory of the struggle for survival in society to formulate the biological theory of evolution. Niels Bohr used the solar system model to formulate his theory of the atomic model. A website like Netflix uses it in the recommendations it gives to customers. For example, let us say that someone, whose profile is similar to yours, liked the movie 'Avatar'. Then it is likely that you will like Avatar as well, if you have not seen it already. So, a recommendation of Avatar is made for you. However, all these approaches are not mutually exclusive. Machine learning uses a selective combination of them, depending on the problem. For example, in medicine, the Evolutionary approach is not preferred. The way nature learns is through making mistakes - a luxury we don't have in our societies. Doctors must diagnose in a foolproof way. For example, failing to find a tumor that is really there, is potentially much worse than inferring one that isn't. It needs optimal decisions and this where the Bayesian approach is more useful. In AI, Symbolists held sway in the first few decades of cognitive psychology. Then Connectionists held sway in the 1980s and 90s, and it is the Bayesians' time in the Sun now. The author is upbeat about the future transformations that Machine Learning will bring to our societies. He suggests that in the not too distant future, we will all have a 'digital half' which will do our bidding all 24 hours of the day. They will interact with the digital halves of every person and organization we deal with. Tomorrow's cyberspace will be a giant parallel world. It will be like a new, global subconscious, the collective id of the human race. My only caveat about the book is its prognosis for the future. There is no doubt that the future will be transformed in many ways by Machine Learning. Scientists have been mostly right about predicting the future technological inventions. On the other hand, scientists from Thomas Malthus to Paul Ehrlich to the Club of Rome have made dire predictions about the future of mankind and disaster for thickly populated countries like India and China. They were woefully wrong in this. Not all scientific advances have a smooth path to their full potential. The expected potentials of Nuclear energy and Genetically Modified crops have not materialized because of resistance in our societies. There is also resistance to Stem cells and possibilities of Human cloning. Machine learning is in its infancy now. As it develops and impacts our lives more and more, the technology is bound to make mistakes in a way that affect our lives negatively. If some of them happen to be of the dimension of the Chernobyl accident in Nuclear energy, then there may be a big backlash to the advance of AI too. The other related danger is to rely on vast quantities of data on a phenomenon which leave out key attributes of representing the phenomena correctly, but use it anyway to make crucial decisions. One example in the past of such misuse of data happened in the 1960s. Sen.Robert McNamara, Secy of Defence in the Johnson administration, went about escalating the Vietnam war by relying on 'death count of US and Vietcong soldiers' as a key data indicator of how the war was progressing. The data did not capture the will and determination of the Vietnamese communists to rid themselves of foreign occupation of their land. We all know the consequences of this key error.I enjoyed reading the book as it was educational for me and I learnt much from it. The chapters elaborating the five approaches to Machine Learning need some focus and concentration to fully understand them. Readers, who find these chapters a bit hard, can still simply read just the first 60 pages to get a very good idea of the subject. All in all, it is a great effort to present this exciting subject in a simple way."
278,0465065708,http://goodreads.com/user/show/10768018-jo-o,3,"The idea of a master algorithm is a kind of computer science saint graal. An optimal model for most problems in reality, a robust super-A.I. with the best qualities of organic brains and computer power merged. For this to happen Domingos argues that the 5 tribes of machine learning have to merge as if currently they were very different communities. Those are: symbolists (e.g. logic-based models, decision trees); connectionists (e.g. neural networks); evolutionaries (genetic algorithms); bayesians (graph theory and Bayes-inspired modelling); analogizers (support vector machines, etc.). While this is a ""cool"" vision I find it hard to argue that models can be categorized under that schematic (many hybrids, or some are just specific cases of others) or that the communities of researchers are isolated in any way. Most people with MAJOR published contributions/advances in any of the ""5 tribes"", has papers in the others... usually dozens... (and some are really important as well)!From what else I've read from Domingos I'd rather recommend his short essays, and scientific papers. The big book format gives too much space for random rambling and there are a lot of cringe sentences like random name dropping e.g. ""Kant was also a fan."" with no further exposition or mention.Ultimately, Domingos has a very solid technical view of most stuff he discusses, but then he brings a lot of his personal intuitive futuristic views that can either happen or not. His conclusions and views in more social/political problems, like how should we share our data with AI companies, are also troubling for me. Overall too much utopian gut-feeling in a book about data-centred approaches."
279,0465065708,http://goodreads.com/user/show/23963235-akshith-rao,3,"This book captures the various types of machine learning techniques and how they have progressed through time. The author, being an academician, gets too technical. Even a decent understanding of math did not prevent some pages from turning into Latin for me. If you are someone who is knee deep in math and probability and would like to get an overall picture I would definitely recommend this book to you. For everyone else, it might be better to start looking somewhere else or just skip the math side of things in this book."
280,0465065708,http://goodreads.com/user/show/7297326-jim-crocker,5,"I'm not really finished. This is the kind of book that will go on and on and on with amazing insights and revelations about AI and Machine Learning. I've already heard that it is outta date. But, hey, whaddaya gonna do? Things move fast out there. With me it moves a little slower. I read and think and read and on it goes... This book was an eye-opener for me. I discovered a whole knew point of view. Essentially, it was a paradigm shift.This is a glimpse of the future of humans and the interactions, transactions and associations that will be taking place over the coming years. It's really transformational stuff that's going on. Here's two quotes that I liked (there's a ton more):** ""Most of all, we have to worry about what the Master Algorithm could do in the wrong hands.""** ""...you also have an ethical duty to share data for the common good.""I like that last one best of all!For your convenience, you can get this wonderful book right here:www.blackdogebooks.com/redhot-pick"
281,0465065708,http://goodreads.com/user/show/1173423-peter,5,"Really nice read. Serves as an accessible introduction to machine learning whilst simultaneously outlining the respective strengths and weaknesses of its 5 different ""tribes"" and ultimately showing how they can be connected. This makes the book valuable even for machine learning practitioners. Furthermore, in these days where deep learning reigns supreme and the media make it seem it is the end-all-be-all of machine learning, this book adds a valuable historical and conceptual perspective. The derivation and description of the current best stab at the Master Algorithm is more technical though, and probably more difficult to follow for the non-technical reader.The author is very bullish in the scale and scope of the application of machine learning and he offers powerful examples of AI in the form of personal agents negotiating the world on our behalf, the enabler of systems biology, and eventually designing and enhancing humans. However I think his view is quite utopian and that he downplays several potential negative scenarios of both weak and strong AI. For instance, Domingos believes that job displacement will not be grave (the argument that more new jobs that we now can't imagine will be created than will be destroyed), and that even if this were to happen, then if it reaches critical mass (>50%), then in a democracy that majority will vote for lifelong salaries for just being alive (i.e. universal basic income). However I think there is a path-dependance here on things staying the same politically. Let's contrast it with the scenario in Yuval Harari's Homo Deus of the creation of a class of ""useless"" humans who don't have to offer anything economically nor militarily. The political power of the masses would then be greatly diminished, perhaps even up to the point of threatening liberal democracy.Looking even further into the future, he does not take into account the dangers of reductionist goals. He basically argues that because machines don't have goals of their own, we are safe. Nick Bostrom belabors the dangers of strong AI in his book Superintelligence.In conclusion, although I think the dangers of AI were downplayed, I think it was a great read. I would recommend pairing this book (written by an machine learning researcher & practitioner) up with Homo Deus (written by a historian) and Superintelligence (by a philosopher) for a more holistic view if your interest is primarily on the (future) impact of AI."
282,0465065708,http://goodreads.com/user/show/38621776-an-l-tuncel,1,"Disappointing. This book has no scientific value. No one should read this book, not even teenagers (they will get confused). "
283,0465065708,http://goodreads.com/user/show/19014583-t,4,"I enjoyed this book overall but had some frustrations with it. Enough so that it was a real debate between 3 and 4 stars for me; I'm giving it 4 now as a benefit of the doubt but I may reread and drop it to 3 if it doesn't seem better.First, the topic couldn't be more relevant and interesting to our time; both for buzz word purposes and real discussion of the current state of the field the book was interesting. That said, I had several annoyances. First, the author seemed quite taken with creating fanciful allegories for things that were clear attempts to be poetic or entertaining and in practice were often just kind of dumb. In the more lower level cases they would help add to understanding, but the broader they got the more you felt like you were wasting your time while he talked about wandering through a city and spent time describing the turrets or telling you what you suddenly remembered or felt. Ick. Second, the premise at the start of the book seemed to be that anyone could understand and contribute to all of the field and the rest of the book seemed, to me at least, to rather disprove that. I think he tried to make this accessible to all and thus went a step too far; he'd have been better off saying the requirements of the field are not so high as many fear and thus are accessible to many more than would expect it. Saying anyone could do it even without complicated math just seemed inaccurate even using his own description by the end.Finally, the overall structure of the book and the discussion of the five ""tribes"" left me somewhat uncertain. I couldn't decide if that was an actually useful description or more confusing than helpful. In part this was because my reading was rather fractured through time so I'm reserving judgment of this for a more thorough reread.All that said, the book was still an interesting overview of the current state and problems of the machine learning world and, when not trying to wax poetic, was a pretty good and understandable summary of those and a nice encouragement for those of us on the edge of the field to get into it."
284,0465065708,http://goodreads.com/user/show/3550209-adrian,5,"Who knew the 'S' curve was the most important function ever?I picked up ""The Master Algorithm"" hoping it would serve as a primer as I began my journey into the world of deep learning. At first, I found it overly figurative and difficult to follow so I stopped reading it. After about 6 months of Andrew Ng YouTube videos, SciKit Learn, PyImageSearch, and other well-organized tutorials, I revisited the book and fell in love with it. What I appreciated most was the discussion of the 5 tribes of machine learning and how he was able to merge the mentality of the different camps. I'd consider myself an Analogizer and I work with a Bayesian. Often, it feels like we are talking different languages. I had to chuckle a few time as this book addressed this common dynamic.I enjoyed Chapter 9 the most with his fanciful depiction of a continent divided into 5 territories: Symbolist, Connectionists, Evolutionists, Bayesians, and Analogizers with Master Algorithm serving as the capital city. He did an excellent job conceptualizing how different aspects of each 'tribe' would contribute to the one unifying, but elusive, algorithm. He went to great lengths to establish his sci-fi bona fides with references to Lord of the Rings, The Matrix, Robocop, and much more. My favorite came when he was discussing Support Vector Machines and visualizing the border between classes as a snake slithering down the no-man's-land with the support vectors serving as mines. It's ""like the sandworms in Dune: big, tough, and able to survive a few explosions from slithering over landmines but not too many"". A five-star rating was locked after that."
285,0465065708,http://goodreads.com/user/show/5858138-nic-brisbourne,4,"Domingos provides a detailed and pretty technical explanation of five different areas of artificial intelligence:* Symbolists - observe and inducer Dix logic in the world and code it - works well in limited domains and highly explainable, but impossible to scale* Neural networks - infer rules from large amounts of data to by looking at training sets - if it's seen enough pictures of cats it can compute the probability that a new image is a cat* Genetic algorithms - define an objective and let evolve according to rules, and then keep the solutions that beat fit the desired goal, and then repeat. Key is choosing the rules and fit algorithms well* Bayesians and probabalistic influence- great at finding categories and classifying things* Analogisers and Support Vector Machines - good for spotting similarities between things and making predictions about other things that might be similar - if I have flu, and we are friends but don't live in the same town, what is the chance that you also have flu?This stuff is quite dense! I have a solid grounding in maths, science, and stats but haven't practiced for decades and understood most of it, but had to read slowly. Domingos writes well and with humour which makes reading much easier. Finally - I should also say that he does a good job of making it real with examples and a semi-good job of predicting where the future will take us. "
286,0465065708,http://goodreads.com/user/show/47032429-kenta-suzuki,4,"Pedro Domingo describes the machine learnings from its origin to now, and how it can be used in the future. He purports that the Master Algorithm be the one that is ultimate goal of machine learning or universal learner as he call it. This algorithm will be replete with or fall into the intersection of the five bailiwicks: Symbolists, Connectionists, Evolutionaries, Bayesians, and Analogizers. For symbolists, Inverse Deduction is algorithm, Gradient Descent for Connectionists, Genetic Search for Evolutionaries, Probabilistic Inference for Bayesian and Constrained Optimization for Analogizers. For instance, Netflix uses k-nearest- neighbor algorithm, which finds the correlations with each others, to create recommendation system.This algorithm is so important that recommender system consists of a third of Amazon's business. In the future, he claims, that there will be one version of yourself who or which basically do most of the things on behalf of you faster than you could. He also argues that the fears some people have toward AI or Singularity will be relinquished if humans deal with them carefully. For instance, there will no infinite growth of AI as is the case with Moore's law. It will eventually taper off as S curve deliniates. This book will gives some prelude to those areas for those who do not have solid backgrounds for statistics or machine learning. "
287,0465065708,http://goodreads.com/user/show/51672399-david,4,"Domingos' attraction to analogical learning leads him to fill this book with analogies for almost everything he talks about. I wonder if a computer develops consciousness would they find it as annoying as I did? Other than this nuisance, the book gives a great overview of the history and state of machine learning. The various subfields outlined in the novel are very well abstracted to show the significant similarities and differences between them.However, Domingos' view of the future, as stated in the last chapter, wouldn't be the most inspiring. The possibility of an algorithm that could predict cancer treatment through genome mapping is surely an excellent use of machine learning but his belief that war will be ""fought"" by between different learners isn't something I'm looking forward to. The author assures the reader of this certainty. For me, this is just a stark reminder that technology advancement does not necessarily advance society in a positive way. In the case of fighting algorithms, there will be a victor and whomever or whatever possesses this technology will be the one with the power to rule a lot of important aspects in this world. This scenario just looks like a continuation of the current trend in the concentration of wealth and power into the hands of the few and not the many."
288,0465065708,http://goodreads.com/user/show/8146846-satyabrata-mishra,5,"Pedros Domingos does a fascinating job describing complex machine learning algorithms in forms of simple (and sometimes silly) metaphors and examples; like dividing the different forms of AI-engineers into tribes and walking down the cities of their design.For someone who wants to peek into machine learning and understand the powers and faults of each algorithm, the master algorithm is a great choice. I picked it up as a pre-read before my ML classes starts and I could not have made a better choice. "
289,0465065708,http://goodreads.com/user/show/60299397-victor-villas,3,"The book starts very slowly, hyping up the idea of the master algorithm. The middle parts are really interesting, where each of the ""five tribes"" of machine learning are discussed. It ends with some self promotion for the alchemy thingy the author is part of. For serious machine learning students this book might be a waste of time, but is still entertaining for the laymen."
290,0465065708,http://goodreads.com/user/show/4696922-ushan,1,"I took Prof. Domingos's data mining course at the UW night school in 2001, and I was wondering whether this book can give a good overview of the progress of the machine learning since then. It doesn't. It is plainly badly written. If I were a layman, I wouldn't have understood anything."
291,0465065708,http://goodreads.com/user/show/2237619-josh,3,"It's been over 200 years since Babbage, and around 60 years since the first serious forays into developing intelligent electronic machines, and we finally seem to have come to a point in history where machine learning is coming of age. The history of AI cautions one against excessive optimism, but the successes of machine learning are becoming impossible to ignore. Machine learners have steadily encroached on areas of intelligence previously thought to be accessible only to the human mind. The lowlands of human thought are rapidly being filled by the flood of artificial intelligence, and there's little reason to believe that the rising tide is going to stop any time soon. There is hardly a field of academic research or sector of the economy that has not been affected in some way by machine learning, and more radical changes loom. Advances in neuroscience along with a torrent of machine learning research hint at a general learning algorithm that would make all other advances in human science seem trivial in comparison. To repeat an oft-quoted phrase, ""the first ultraintelligent machine is the last invention that man need ever make"". That, in essence, is what Pedro Domingos' book is about.It starts off with a broad overview of how machine learning algorithms (he calls them learners), are omnipresent in modern society. Algorithms help decide what you see on your social media news feed, which videos you watch, which products you buy, which stocks to add to your portfolio, which ads you see, which political candidates you vote for and who you decide to date. I don't think it's an exaggeration to say that machine learning has revolutionized almost every aspect of how we live our day-to-day lives.And that's just getting started.Domingos divides machine learning research into five 'tribes' and spends some time discussing each of them in detail: the Symbolists, the Connectionists, the Evolutionaries, the Bayesians, and the Analogizers.The Symbolists advocate a rule-based approach to learning, and use logical inference as their main tool. This was a common tactic with the expert AI systems of the 80s, and still has a large place in automated systems today. A big problem that every machine learning algorithm has to deal with when understanding large datasets is the vast set of possible interpretations for that data, and the Symbolists have a few effective ways of dealing with this. If you want to build a system that can diagnose an illness, you might go about it by forming a decision tree. Does the person have a rash? If so, does that person also have a cold? And so on. Anyone who's played the game 20 questions can probably see why this approach might be an effective way of building intelligent systems. It also has the downside that these systems are costly and time-consuming to construct, not to mention they lack a certain degree of generality. Domingos doesn't seem to be a fan of this school of research, and for the most part he quickly passes it by so he can move on to other methods. Rule-based inference, for the most part, does not seem like a particularly effective way of interpreting data, and it certainly isn't how human brains interpret data. For a more biologically inspired learning method we have the connectionists.If you've heard any of the recent headlines about DeepMind's AlphaGo beating the world Go champion, you've heard about connectionism. Connectionists are the practitioners of neural networks--artificial simulations of the sort of neurons we see in animal brains. Since human-level intelligence has so far only been exhibited in human brains, a natural approach to programming intelligence is by reverse engineering the human brain. People have been programming neural networks for about as long as programmable computers have been around--the first attempts were made in the 50s, and despite a steady following of researchers in the meantime it is only recently that neural networks have really begun to have their full potential realized. This is due in part to the fact that processors today are more powerful than ever, but also because the Internet is a rich sea of data that we can use to train our networks. Still, neural nets, despite their amazing versatility for solving problems, are quite cumbersome and aren't exact representations of the human brain. It's not even clear whether an exact simulation of how the brain works would be an efficient computational model. They also take a lot of computing power to train, so for certain situations they are not ideal.Another biologically-inspired approach to machine learning is evolutionary computing. The idea behind this one is sound: human intelligence arose through evolutionary processes, so why can't we write programs to 'evolve' through a sort of Darwinian selection process? If we select for the tributes we want a program to have, say for a self-driving car to drive safely, and reject the attributes we don't want it to have, say, crashing into stop signs, we can eventually produce a program that will be a good driver. In theory, at least. The problem, of course, is that human intelligence took hundreds of millions of years to evolve to where it is now, and researchers don't have that kind of time to spend. It also seems to be a bit of a fluke that intelligence even arose at all, considering all the time in prehistory where it wasn't around. Evolution is a tricky thing to recreate, and the successes of evolutionary computing have been overshadowed by other methods. It remains to be seen if they will one day come into the spotlight like connectionism has in recent years.The Bayesians are mostly involved in applying Bayes' theorem to machine learning problem. Thomas Bayes, a 17th century Englishman, was a statistician who formulated one of the most famous theorems in probability theory. His theorem helps us understand how events are related to each other, and how the probability of one event affects another. Applications of this fairly simple theory are among the most popular approaches to machine learning and still seen to be the most widely used. While this approach isn't as biologically inspired as the other methods, Bayesian inference does still represent something our brains have to do to interact intelligently with the world. Bayesian theory is very robust in its application and can be applied to a wide range of real-world problems. Things do tend to get a bit hairy when dealing with problems that have a lot of variables, but with the right simplifying assumptions this has proved to be a very powerful theory.The Analogizers, as Domingos calls them, aren't as unified as the other tribes. Human learning could perhaps be best characterized as learning by analogy. We learn new concepts by associating them with old concepts we already know. It turns out statistical formulations of this type of learning are also quite effective, as can be seen by various automated recommendation systems designed by companies like Netflix or Amazon. Truth be told it wasn't entirely clear to me how this approach differed significantly from the other approaches already discussed, but I guess Domingos felt the distinction was necessary.He then goes on to discuss a hodgepodge of various other learning strategies that take influence from human psychology, notably reinforcement learning. Reinforcement learning agents choose between possible actions to take in an environment based on the expectation of future rewards from that action. If pressing a button rewards a reinforcement learning agent, the agent will quickly learning to spend as much of its time pressing that button as possible. Reinforcement learning by itself doesn't generalize to other problems outside of a narrow domain especially well, but when combined with neural networks it can be a powerful approach for machine learning problems.The final chapter of the book is about the future of machine learning, and full of the typical sort of predictions that authors of this type of book seem to love. Personally I feel like most of what Domingos has to say in this chapter has been dealt with better by other authors, but I digress. Machine learning will certainly have a huge impact on every aspect of our lives. In a very real way you are the data that you create. Other people make models of you based on your behavior just like Netflix makes models of your movie-viewing habits. The reason so many companies have started racing to collect your data is because that data is powerful. It influences the choices we make at an individual level and thus influences the whole of our society. This is a scary thought to some, and is certainly something that should be taken into consideration by human rights organizations and governments. On the flipside, data is becoming democratized very quickly--a fact which is helping facilitate positive social change at a faster rate than ever before in the history of civilization. Some are worried about machines achieving human levels of intelligence, but I think those fears are misguided. It is far more advantageous for us to consider what new avenues of possibility have opened up than to dwell on the roads we will leave behind. To quote Domingos: ""The real history of automation is not what it replaces but what it enables.""Overall the book is a good general overview of the research being done in machine learning today. It does not, however, substitute for a more serious mathematical treatment of the subject, and those wishing to delve deeper into the subject would be better served elsewhere. Still, as a light introduction to the subject this book is worth looking into."
292,0465065708,http://goodreads.com/user/show/3055905-nils,4,"A useful book that lays out the five “tribes” of machine learning and ecumenically proposes that the true “master algorithm” (AGI) will combine all five: the symbolists’ inverse deduction, the connectionists’ backpropagation, the evolutionists’ genetic programming, the Bayesians’ various theorems, and the analogizers’ support vector machines.What’s most dated about this 2015 book is how utterly sanguine he is about what moving toward a master algorithm will produce in terms of social effects. It’s not just that he rejects the scaremongering of the Singulatarians (as he points out, the algorithms are never going to have wills of their own), but it’s more than he doesn’t consider except in the most glancing way what may happen if bad people control the algorithm, or the more profound problem of what it means if each of us has a shadow algorithmically optimized version of ourselves representing us in the world — how this could ironically lead to a loss of will, a surrender to the algorithmic engine that supposedly understands our preferences better than we do. Do we really want to live in a world where, “everyone has an entourage of bots, smoothing his or her way through the world.… Your digital half will be like power steering for your life.” Occasionally he glimpses the dystopian possibilities but then handwaves then away: “This does not mean that you’ll end up in a ‘filter bubble,’ seeing only what you reliably like, with no room for the unexpected,” he reassures us. “The digital you knows better than that. Part of its brief is to leave some things open to chance, to expose you to new experiences, and to look for serendipity.” Nor does he really consider the philosophical implications of a situation where “You have your model of every person in the organization you interact with, and they each have their model of you. As the models improve, their interaction becomes more and more like the ones you would have in the real world.” What’s happening in this scenario is that border between human and machine is eroding, with humans themselves evolving and in many cases likely to surrender control, happily turning over their decision making to their digital self. Are we so sure, in this scenario that the distinction between the willful human and the enslaved machines makes sense? We need not worry about silly infinite paperclip scenarios, is a world where many of us have become merely wired bundles of continuously satisfied Id a world we want to live in? Is a world where technology splinters the unity of the human race, as he predicts, not a world with truly fearsome possibilities? Consider this passage: “One of the greatest talents a politician can have is the ability to understand voters, individually or in small groups, and to speak directly to them (or seem to). Bill Clinton is the paradigmatic example of this in recent memory. The effect of machine learning is like having a dedicated Bill Clinton for every voter.” Wait, is that a promise, or a threat?! Likewise, would anyone in 2019 in good conscience be able to write that, “Democracy works better because the bandwidth of communications between voters and politicians increases enormously.... Big data and machine learning [will] change the equation. In the future, provided voter models are accurate, elected officials will be able to ask a voters what they want 1000 times a day and act accordingly – without having to pester the actual flesh and blood citizens.” Provided voter models are accurate is doing a whole lotta work there, wouldn’t you say?"
293,0465065708,http://goodreads.com/user/show/56104661-mark,3,"Pedro Domingos wastes no time in laying out his bold hypothesis on which The Master Algorithm: How The Quest for the Ultimate Learning Machine Will Remake Our World is based. Early in chapter two, he declares that: “All knowledge—past, present, and future—can be derived from data by a single, universal learning algorithm.” Clearly, Domingos believes that such an algorithm can be developed, but for the doubting Thomases among us, he cites strong lines of evidence from the disciplines of neuroscience, evolution, physics, statistics, and computer science.The search for the Master Algorithm does not have to start from scratch, Domingos tells us. The bulk of the book describes five current approaches to machine learning—or “five tribes of machine learning,” as he labels them—namely, symbolists, connectionists, evolutionaries, Bayesians, and analogizers. These tribes each have a set of core beliefs, and a central problem they must solve. Domingos’s detailed descriptions of how they do that occasionally results in dense and complex narrative, but he cleverly illustrates his points with familiar, daily-life examples, with equally familiar organizations, such as Google, Amazon, Netflix, and Facebook.Of course, the true Master Algorithm must solve the problems of all five tribes, and the reader is encouraged to stick with the narrative and even take a leap of faith in some of the more involved explanations (“Bayesian networks and Naïve Bayes classifier” was this reader’s particular leap of faith!). The author’s writing is captivating and teasing as he describes the benefits and shortcomings of each machine learning style, steadily building belief in the Master Algorithm at the end of each chapter. However, drawing from the five tribes is still not enough to satisfy specifications of the Master Algorithm: Domingos goes on to talk about the need for principal component analysis, dimensionality reduction, and metalearning.By the time one reaches the chapter, “The Pieces of the Puzzle Fall into Place,” and Domingos has pulled together the five models of learning into one elegant and beautiful schematic, the reader is convinced of the feasibility of the Master Algorithm. Domingos hammers home this conviction by explaining how his derived model handles the three necessary elements of representation (a model's formal language of expression), evaluation (a scoring function to say how good a model is), and optimization (the search for the highest-scoring model). In the closing chapter, “This is the World on Machine Learning,” Domingos anticipates how machine learning and the Master Algorithm will affect society as a whole and each and every one of us in many aspects of daily life. Overall, Domingos has crafted a thought-provoking book about a thrilling subject, as fantastic as it is believable. He deftly keeps the reader turning the pages with bursts of humor, big-picture concepts, and behind-the-scenes glimpses of existing learning models. This book is both serious entertainment and education!"
294,0465065708,http://goodreads.com/user/show/11375563-michael-huang,3,"Domingos writes eloquently and lucidly about what machine learning (ML) is doing to the society (helping scientists do them work and make Obama win elections) and how it's supposedly going to change everything (industrial and information revolution automated manual and mental work respectively, ML will automate the automation). And he points out a simple and clearly stated hypothesis, the central hypothesis of the book: ""All knowledge - past, present, and future - can be derived from data by a single, universal learning algorithm"". He then tantalizingly showed the arguments from neural science (we as a species learned knowledge didn't we?); from evolution (our brain was evolved from virtually nothing, why not some master algorithm?); from physics (witness the unreasonable effectiveness of math in natural science); from statistics (Bayes's theorem describes how you can update any belief); from Computer Science (didn't Turing show us how there is a universal machine). By the time I finished Chapter 2, the book looks up to be by far the best book I've read this year (out of 96).Unfortunately, the rest of the book seems to be written by a different person. The lucidity is out. In come weird analogies and references that impede understanding rather than helping it. Maybe he is too excited and his neurons keep firing at even weak associations, but the text would have been returned as ""Needing major revision"" if it was submitted to a journal. Nevertheless, he did explain the five different sub communities of the umbrella community of ML in the next 5 chapters; and rather unconvincingly touted his own research as potentially the ""Master Algorithm"". (I don't mean to suggest his research is bad. In fact, his description of Alchemy seems completely fine and something he should definitely continue to look into. It's just not of the table-pounding, forehead-palming why-didn't-I-think-of-that variety.) At last he closes with what the future holds store once the Master Algorithm arrives. This part is, thankfully, deprived of unnecessary analogies and similes, but is rather anticlimactic (e.g., in the future ""let your people call mine"" becomes ""let your algorithm talk to mine"")."
295,0465065708,http://goodreads.com/user/show/108995717-dan,4,"Very nice overview of the current machine learning paradigms and algorithms: symbolism and induction, connectionism and backpropagation, evolutionism and genetic algorithms, Bayesian and statistical inference, analogy and support vector machines. In its attempt to unify them, it also points to similarities/dissimilarities, weaknesses/strengths, and so on. On the other hand, the Messianic expectation of “The Master Algorithm” that will unify the five different paradigms/algorithms in the same way a Theory of Everything will unify everything in Physics is ridiculous. Most likely, in new data intensive fields completely new and specialized algorithms will emerge beyond the five mentioned in this book and they will stay distinct and specialized. Google is organizing and manipulating the Internet, Amazon is overselling to us, Facebook is selling our profiles, genetic medicine is trying to make sense of the huge amount of data it possesses, the self-driving cars are generating their own data, satellites are mapping the Earth and the sky in small details, and so on. Specialized algorithms can predict and control almost anything in these limited, commercial, and digital fields. But beyond these few data intensive fields, there is no data available and we still need to generate data in the old fashion, small, and expensive ways as we always did if we have some specific hypotheses/questions. Defining “everything that is” and “human intelligence and science” along these commercial data-algorithm ways betrays some naive ontology and epistemology. Moreover, expecting that algorithms that perform extremely well in very specific situations/fields to converge to some Mater Algorithm that explains everything and that will take our human understanding to a new level is an unjustified extrapolation."
296,0465065708,http://goodreads.com/user/show/58987379-ville,3,"Great topic – difficult approachThe book covers three different topics of which each could make a thick book on their own.-	The technical history of machine learning and development of the major algorithms-	Mr Rodriques idea of a universal learning algorithm (‘the master algorithm’)-	Ideas how machine learning has affected our lives and speculations about the futureThese are some of my favourite topics and I would love to love this book, but I can’t. The most problematic was the actual beef of the book: the master algorithm. Even as I have done my fair share of machine learning as M.Sc. in process control and worked with many of the algorithms described for years at work, I found it very difficult to follow and even understand his idea of the MLN method. It was just too difficult approach without some actual examples for me at least.The best parts of the book were some awesome insights that only a true master could state with such simple and entertaining terms.My favorite highlights.-	Believe it or not, every algorithm, no matter how complex, can be reduced to just these three operations: AND, OR, and NOT.-	People often think computers are all about numbers, but they’re not. Computers are all about logic.-	Overfitting is the central problem in machine learning. More papers have been written about it than about any other topic… Humans are not immune to overfitting, either. You could even say that it’s the root cause of a lot of our evils. Consider the little white girl who, upon seeing a Latina baby at the mall, blurted out “Look, Mom, a baby maid!” (True event.) It’s not that she’s a natural-born bigot.-	S curves are a nice halfway house between the dumbness of linear functions and the hardness of step functions.-	An autoencoder is a multilayer perceptron whose output is the same as its input. In goes a picture of your grandmother and out comes—the same picture of your grandmother …the network is forced to encode the input in fewer bits, so it can be represented in the hidden layer, and then decode those bits back to full size. …. However the neet trick was to make the hidden layer actually bigger than the input-output-layers but only allow a few of them to fire at any given moment…-	(k-) nearest neighbor is truly a superfast algorithm but with the slow database connections a trained neural network is sure to win.-	Symbolist methods, for one, are fairly good at disposing of irrelevant attributes. If an attribute has no information about the class, it’s just never included in the decision tree or rule set. But nearest-neighbor is hopelessly confused by irrelevant attributes because they all contribute to the similarity between examples.-	No learner is immune to the curse of dimensionality. It’s the second worst problem in machine learning, after overfitting.-	PCA is to unsupervised learning what linear regression is to the supervised variety.-	Random forests are some of the most accurate classifiers around. Microsoft’s Kinect uses them to figure out what you’re doing, and they regularly win machine-learning competitions.-	(The problem with) combined models can be quite opaque. (“I believe you have prostate cancer because the decision tree, the genetic algorithm, and Naïve Bayes say so, although the multilayer perceptron and the SVM disagree.”)About the future:-	The first robo-lawyers that argue for a particular verdict based on precedents have already been built…Perhaps in a future cybercourt, in session somewhere on Amazon’s cloud, a robo-lawyer will beat the speeding ticket that RoboCop issued to your driverless car, all while you go to the beach, and Leibniz’s dream of reducing all argument to calculation will finally have come true.-	Some researchers even argue that the way to create intelligent machines is to build a robot baby and let him experience the world as a human baby does…The question, of course, is what algorithm should be running in Robby’s brain at birth.-	(You have already “a digital self” living in the internet databases that is good at finding things for you that you are interested.) Even more interesting, the process doesn’t end when you find a car, a house, a doctor, a date, or a job. Your digital half is continually learning from its experiences, just as you would. It figures out what works and doesn’t, whether it’s in job interviews, dating, or real-estate hunting. -	You have your model of every person and organization you interact with, and they each have their model of you. As the models improve, their interactions become more and more like the ones you would have in the real world—except millions of times faster and in silicon. Tomorrow’s cyberspace will be a vast parallel world that selects only the most promising things to try out in the real one. It will be like a new, global subconscious, the collective id of the human race.-	(But the problem right now is that) everyone has only a sliver of it. Google sees your searches, Amazon your online purchases, AT&T your phone calls, Apple your music downloads, Safeway your groceries, Capital One your credit-card transactions. Companies like Acxiom collate and sell information about you, but if you inspect it (which in Acxiom’s case you can, at aboutthedata.com), it’s not much, and some of it is wrong. No one has anything even approaching a complete picture of you.-	Eventually, we’ll start talking about the employment rate instead of the unemployment one and reducing it will be seen as a sign of progress. (“The US is falling behind. Our employment rate is still 23 percent.”)-	People will seek meaning in human relationships, self-actualization, and spirituality, much as they do now. The need to earn a living will be a distant memory, another piece of humanity’s barbaric past that we rose above. -	Picture two strands of DNA going for a swim in their private pool, aka a bacterium’s cytoplasm, two billion years ago. They’re pondering a momentous decision. “I’m worried, Diana,” says one. “If we start making multicellular creatures, will they take over?” -	Contrary to what we like to believe today, humans quite easily fall into obeying others, and any sufficiently advanced AI is indistinguishable from God. People worry that computers will get too smart and take over the world, but the real problem is that they’re too stupid and they’ve already taken over the world. "
297,0465065708,http://goodreads.com/user/show/56609924-flaviu-vescan,3,"I was looking for a book that explains ML and AI concepts for non-practitioners. It did a great job at that. It goes through the most used 7 types of ML algorithms/concepts and explains how they work using high-level math and analogies. It blends a bit of the history of the field so that's always nice to contextualize the information. What made me only give it 3 stars are the detours it keeps making into predicting the future and the crazy soft stance it takes towards the tech giants like FB and GOOG. I'm not sure if Mr. Domingos is still willing to be have such a friendly opinion of them after the latest findings on how they use ML and the many privacy breaches they've had, but I hope not. In any case I'm judging the books version of events and it's lacking any criticism towards the uses of ML in manipulating public opinion. The book is great at teaching you the high-level workings of ML. The problem I had was it kept trying to do more than that by taking a stab at predicting the future of the field influence on humanity. Even for a specialist, it's mostly speculation. "
298,0465065708,http://goodreads.com/user/show/96942737-gautham,3,"A book for those who wish to have an aerial / Birdseye view of the subject, probably a novice in the field but I don’t think it can be of much help for a layman. It was as if Domingos wanted to explain almost all the topics / tribes of the world of Machine learning, from their basics, under one cover, which may have been possible if the book had housed at least about a 1000 or so pages maybe but his choice of including as many topics as he did has trumped the point of ‘understandability’ which a book like this should be focusing on in the first place.The slithering snake analogy for explaining SVMs was the worst of the analogies that he could come up with.However, there are certain learnings that one could get from this book but at the cost 300 pages @ your individual reading speeds is too big a price to pay.The last two chapters of the book seems like the summary of the rest of the chapters with an extension and conclusion. So, if you want to take a quick read, you know where to start."
299,0465065708,http://goodreads.com/user/show/93344337-benny,4,"A few years ago, I came across a list of machine learning algorithms that aspiring data scientists should familiarise themselves with. Since then, I have delved into various machine learning algorithms intermittently during my spare time. In this book, Pedro Domingos has broadly classified them into 5 different families of algorithms. To take these applications further, he suggested that eventually one Master Algorithm can perform that roles that each family of algorithms plays in deciphering our physical world. Below are some of the algorithms that are covered by the author.Genetic AlgorithmNeural Networks(eg. backpropagation, gradient descent)K-nearest NeighbourSupport Vector Machines(eg. kernels)Bayes NetworkK-means ClusteringPCARandom ForestEigenfaces....The book provides a neat high-level summary into the development of these algorithms and how they have come about. With prior understanding of how they work, it is pleasant way to review how these machine learning algorithms optimise, learn and automate our tasks without needing to immerse oneself in the math and computer science that are powering all these AI applications behind the scenes."
