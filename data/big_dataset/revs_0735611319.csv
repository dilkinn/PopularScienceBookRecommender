,isbn,user_link,ranking,review
0,0735611319,http://goodreads.com/user/show/4248907-craig,5,"I'll be honest. I only read this book because it was quoted as a must read by Joel Spolsky on a stackexchange answer about how to go about learning programming (and finding out if you want/should be a programmer).I was a little hesitant due to the year of release. Being at least some 11 years old that's a lot of time in the tech world. Ultimately though that doesn't matter. I defy any developer/programmer/system builder to read this book and not blitz through it lapping it up. Yes if you've done some schooling in computing or computer science you may be happy with much of the content but you'll surely find things you've either not thought about before in much depth or just wasn't explained in quite the elegant way that Petzold does. For me, whether it was due to age, experience or just maturity through both I found it filled gaps in my memory and indeed gaps in student course material.Petzold opens up the world of computing through a concise linear storytelling format. Starting with a basis in Morse Code and Braille through the telegraph system, barcodes, boolean logic, circuits with memory, von neumann machines, adding peripherals, I/O devices and GUI interfaces we just about catch up to the modern era with talk of HTTP and the world wide web. Having pretty much built the systems (or simplified versions of) we're discussing in the incremental circuit and systems diagrams on the way.Admittedly there's some rather 'of their time' phrases and facts that raise a smile (low resolutions, high costs for 'small' HD storage sizes, usage of cassette tapes by consumers) but this is all still valid information when taken in the context of the time of writing.If you are a Developer/Programmer you're not going to go into work having had an epiphany of how better to do things, but you may have a new found respect for what you're doing and the many, many ingenious shoulders you are standing upon."
1,0735611319,http://goodreads.com/user/show/6751318-naessens,3,"My opinion on this book is really divided : on the one hand I enjoy some chapters, on the other hand I hardly managed to restrain myself from flipping through other chapters. Basically, this book designs and builds a basic computer by introducing in each chapter a concept or a technology used inside computers. It was written from 1987 to 1999, consequently one shouldn't expect any description of newest technologies.It starts really slowly with the first chapters, but then things get more and more complicated. One of the things that bother me with this book is the difference in complexity between chapters. Some chapters can be easily understood by a junior school or high school student while some of the latest chapters remind me bad memories of electronic circuits from my engineering school years. For example, a whole chapter is dedicated to explain how to communicate with your neighbour using a flashlight, an other chapter tackles the same issue with light bulbs and electrical wires, whereas all the gates or all the flip-flops are dealt with in a single chapter. I admit I have never been either fond of or good at electrokinetics, but I confess I didn't try to understand how all the electronic circuits of these later chapters work. I guess these chapters mostly interest hard code computer enthusiasts, but don't they already know these stuffs ?Besides, few chapters are a little boring : a whole chapter to describe every op-code of Intel 8080, come on ! Does the decimal system really deserve a whole chapter ? In my opinion, decimal and alternative number systems should have been presented in a single chapter instead of two.Moreover, the huge difference in complexity leads to some contradiction. The binary number system is so well described that a high school student can easily understand it, binary addition and subtraction are very detailed, but multiplication is done with a simple inefficient loop ! In my opinion, it would have been opportune to present at least a more efficient version based on the binary representation of the multiplicand as well as introduce exponentiation by squaring (a.k.a. square-and-multiply or binary exponentiation).Additionally, I think that Charles Petzold tries to explain in too many details how each part works so that readers with less technical knowledge can understand, but in the end I guess these readers get lost or confused by so many details anyway, whereas a few technical references are missing. For instance, both Von Neumann and Harvard architectures are described but I don't recall them being mentioned.Nevertheless, I really liked when the author gives historical anecdotes or references. The chapters I enjoyed the most are the ones where Charles Petzold gives readers some background history to introduce a concept or technology (for instance, Morse and Braille's codes, Bell's telegraph, the invention of telegraph relays, the evolution of transistors, chips or programming languages).Eventually, I find it a bit contradictory for this book that most of the interesting chapters are the less technical ones indeed. Moreover, due to the important difference of knowledge required to understand chapters, I don't think someone may understand or find interesting every chapter."
2,0735611319,http://goodreads.com/user/show/7557125-cardinal-biggles,5,"Raise your hand if you think metaphors and analogies should be used sparingly. I'll raise my hand with you. This book is for us.After reading this book, I can see behind the pixels on my computer screen. I know what I'm really looking at. So many layers of abstraction are removed by learning about how logic gates can be arranged as processors and RAM, how code is simply a representation of those microscopic switches being flipped, and how pixels are simply a graphical interpretation of the state of particular switches. Moreover, I also have a little bit of an understanding of the historical evolutions these inventions and conventions went through: not just how computers work, but why they work that way and how they came to be.The book was tougher to grasp than I thought it would be (I do not have an extensive background in electronics or programming). Although it started off easily, it became progressively more complicated except for the last chapter or two. Of course, this was to be expected, as the book began with the basic building blocks of a computer, and built progressively more complicated systems from those initial components. However, the problem wasn't really a result of the subject matter, but of the writing style, which seemed to grow more terse in later chapters. I was left with the impression that the author felt he was running out of space, which I'm sure he was; it must be difficult to keep a book with such a vast scope to a manageable size and prevent it from turning into a reference manual. I would characterize this book as grueling, but that might be because I was obstinate in making sure I fully understood every detail of every page. There were a few pages that I had to pore over repeatedly until I received a eureka moment. A few more explanatory sentences here and there would have alleviated this, but ultimately, drawing my own conclusions was very rewarding. The book seemed to recover from its gradually adopted terseness with an appreciated but sudden reference to the first chapter in the very last sentence. Someone less focused and more inclined to skim might find this book to be a bit lighter reading, but it still only took me a few days to read the whole thing.I was surprised to see that the book did not really cover how transistors work at the electron level, which leaves what I consider to be a major gap in any understanding of how modern computers based on integrated circuits work. The text says that transistors are functionally equivalent to electromechanical relays or vacuum tubes and work similarly, but hardly any more than that. This missing knowledge is something that would have been appreciated and wouldn't have taken up much space. It seems like an especially glaring omission when juxtaposed with the inclusion of a few pages on EBCDIC, an obsolete alternative to ASCII text codes descended from paper punch cards.Despite these minor gripes, this is a really great book, and I highly recommend it to anyone who has the interest and persistence to get through it. It teaches and ties together many mathematical and electrical concepts, and the payoff for the reader is a new perspective on computing. Despite being first published in 1999, it hardly seems dated at all, probably because it's really a history book and most of the computing history it covers happened in the 1980s and earlier. All computing history after that is basically just increasingly complex variations on those simpler foundations. A sequel would be welcome.P.S. I think I've discovered a typo in the assembly code program on page 322. It seems to me that there should be an additional ""AND A,0Fh"" after the four lines of ""RRC"" and before the first ""CALL NibbleToAscii"" line. If I'm wrong, would anyone mind explaining why? And if I'm correct, would anyone mind giving me peace of mind by confirming this? Thanks! :)"
3,0735611319,http://goodreads.com/user/show/172457-mike,5,"Electricity is like nothing else in this universe, and we must confront it on it's own terms. That sentence, casually buried near the beginning of the book, exemplifies the engineer's muse: a striving to become aware of the inhuman, how it operates, and to find means of creating a socket for human enterprise, something to extend the fallible chassis of our flesh.The first two-thirds or so of this book follows a double track. One track covers the ways in which meaning may be encoded into messages, the other weaves repetitions of a relatively simple device — the telegraph relay — into machines that marshall electricity into the forms of logic and memory. These two tracks eventually coincide at the device we know as a computer. Though it would be impossible to build a computer from telegraph relays, the machines we use today perform the same tricks with electricity that were possible in the 19th century.The last third of the book is more concerned with the makeup and successive improvements in implementation of the devices that embody the marriage of electricity and meaning. For someone like me, accustomed to the elves of the internet bringing me a regular helpings of news, porn, and status updates from the virtual smörgåsbord, it was interesting to see how they have been made so much easier to use since the era of assembly code and text terminals.Regarding electricity, that prime mover of the information age, it has struck me that electricity is the stuff minerals dream with, and we may have subjected an alien order to the vagaries of our desire without being prepared to one day pay the price. We live, all of us, in an era of debt, making allowances for even a future of cities submerged and massive conflicts fostered by drought. When it finally comes time to pay off our mineral deficit, will it be our dreams — that which makes us human — to ultimately be forfeit?"
4,0735611319,http://goodreads.com/user/show/1363537-yevgeniy-brikman,5,"Every single person in tech should read this book. Or if you're just interested in tech. Or if you just want a basic appreciation of one of the most important technologies in human history—the computer. This book contains the best, most accessible explanation I've seen of how computers work, from hardware to software. The author manages to cover a huge range of topics—electricity, circuits, relays, binary, logic, gates, microprocessors, code, and much more—while doing a remarkable job of gradually building up your mental model using lots of analogies, diagrams, and examples, so just about everyone should be able to understand the majority of the book, and gain a deep appreciation of what's really happening every time you use your laptop or smartphone or read this review online. I wish I had this book back in high school and college. I've been coding for 20 years and I still found a vast array of insights in the book. Some of the topics I knew already, and this book helped me appreciate them more; others, I knew poorly, and now understand with better clarity; still others were totally new. A small sampling of the insights:* Current is the number of electrons flowing past a point per second. Voltage is a measure of potential energy. The resistance is how much the substance through which electricity is flowing resists the passage of those electrons. The water/pipes analogy is great: current is similar to the amount of water flowing through a pipe; voltage is similar to the water pressure; resistance is similar to the width of the pipe. I took an E&M physics course in college and while I learned all the current/voltage/etc equations, I never got this simple, intuitive understanding of what it actually means!* We use base 10 because we have 10 fingers; a ""digit,"" after all, is just a finger (so obvious when you actually take a second to think about it!). Had we been born with 8 fingers, like most cartoon characters, we'd probably use base 8 math. Computers use base 2 because building circuitry based on two states—the presence or absence of voltage (on and off, 1 or 0)—is much easier than circuitry based on ten states. * The notation we use in math is essential. It's not about looking pretty or not, but actually making the math easier or harder. For example, addition and subtraction is easy in Roman numerals but multiplication and division are much harder. Arabic numerals make multiplication and division much easier, especially as they introduce a 0. Sometimes in math, you switch to different coordinate systems or different geometries to make solving a problem easier. So it's no surprise that different programming languages would have the same properties: while any language can, in theory, solve the same problems as any other, in practice, some languages make certain problems much easier than others.* This book does a superb job of showing how logic gates (AND, OR, etc) can be built from simple physical circuits—e.g., from relays, which are much easier to imagine and think about than, for example, transistors—and how easy it is to do math with simple logic gates. I remember learning this back in college, but it still amazes me every time I see it, and with the crystal-clear examples in this book, I found myself smiling when I could picture a simple physical circuit of relays that could do arithmetic just by entering numbers with switches and passing some electricity through the system (e.g., to add, you have a sum and a carry, where the sum is an XOR and the carry is an AND).* The explanation of circuits that can ""remember"" (e.g., the memory in your computer) was superb and something I don't remember learning at all in college (how ironic). I love the idea that circuits with memory (e.g., latches) work based on a feedback mechanism: the output of the circuit is fed back into the same circuit, so if it gets into one state (e.g., on, because electricity is flowing through it), that feedback mechanism keeps it in that state (e.g., by continuing to the flow of electricity through it), effectively ""remembering"" the value. And all of this is possible because it takes a finite amount of time for electricity to travel through a circuit and for that circuit to switch state.* The opcodes in a CPU consist of an operation to perform (e.g., load) and an address. You can write assembly code to express the opcodes, but each assembly instruction is just a human-friendly way to represent an exactly equivalent binary string (e.g., 32 or 64 binary digits in modern CPUs). You can enter these opcodes in manually (e.g., via switches on a board that control ""on"" and ""off"") and each instruction becomes a high or low voltage. These high and low voltages pass through the physical circuitry of the CPU, which consist of logic gates. Based purely on the layout of these logic gates, voltage comes out the ""other end,"" triggering new actions: e.g., they may result in low and high voltages in a memory chip that then ""remembers"" the information (store) or returns information that was previously ""remembered"" (load); they may result in low and high voltages being passed to a video adapter that, based on the layout of its own logic gates, results in an image being drawn on a screen; or they may result in low and high voltages being fed back into the CPU itself, resulting in it reading another opcode (e.g., perhaps from ROM or a hard drive, rather than physical switches), and repeating the whole process again. This is my lame attempt at describing, end-to-end, how software affects hardware and results in something happening in the real world, solely based on the ""physical layout"" of a bunch of circuits with electricity passing through them. I think there is something magical about the fact that the ""shape"" of an object is what makes it possible to send emails, watch movies, listen to music, and browse the Internet. But then again, the ""shape"" of DNA molecules, plus the laws of physics, is what makes all of life possible too! And, of course, you can't help but wonder what sort of ""opcodes"" and ""logic gates"" are used in your brain, as your very consciousness consists entirely of electricity passing through the physical ""shape"" of your neurons and the connections between them.There are a few places the book seems to go into a little too much detail—e.g., going over all the opcodes of a specific Intel CPU—and a few places where it seems to skip over all the important details—e.g., the final chapter on modern software and the web—but overall, I have not found another book anywhere that provides as complete of a picture of how a computer works. Given the ubiquity of computers today, I'd recommend this book to just about everyone. It'll make you appreciate just how simple computers really are—and how that simplicity can be used to create something truly magical.As always, I've saved a few of my favorite quotes from the book:A computer processor does moronically simple things—it moves a byte from memory to register, adds a byte to another byte, moves the result back to memory. The only reason anything substantial gets completed is that these operations occur very quickly. To quote Robert Noyce, “After you become reconciled to the nanosecond, computer operations are conceptually fairly simple.”The first person to write the first assembler had to hand-assemble the program, of course. A person who writes a new (perhaps improved) assembler for the same computer can write it in assembly language and then use the first assembler to assemble it. Once the new assembler is assembled, it can assemble itself."
5,0735611319,http://goodreads.com/user/show/8940497-alex-palcuie,5,"If you work with computers and didn't read this book, you are lame."
6,0735611319,http://goodreads.com/user/show/10471943-igor-ljubuncic,5,"This is a great book. Surprisingly interesting.While the subject matter is not a new thing to me - far from it - the way the author goes about telling the story of how modern computers came to life is exciting, engaging and fun. He starts with morse and braille, talks about the principles of mathematics and information, explains the critical concept of switches, and finally moves into the world of circuit boards and binary data, cultimating in ALU. After that, he discusses the idea of analytical and computational engines and machines developed through the late 19th and early 20th century, before we finally start seeing the modern computer around 1940s, with Turing and von Neumann laying down the foundations of what we know and use today.The book is really cool because it's also a nostalgic trip down the memory lane. Charles mentions the famous Bell Labs, the legendary Shannon, Ritchie, Noyce, Moore, UNIX, C language, and other people and concepts without which we would not be sitting here, writing reviews on Goodreads. Or we might, but the fundamentals of the computing devices would be completely different.Computers sound like magic, but the thing is, they are a culmination of 150 years of electric progress, 200 years of data/information progress, and about 350 years of math progress. The first boards, the first programs, the first assembler and the first compiler, they were all written by hand. Control signals are still essentially the same, and if you look at a typical x86 Intel processor, the legacy support for machine instructions goes back to the first microprocessor. The problem is, when you condense the centuries of hard work into a cool, whirring appliance, it does feel like magic.The author wrote the book in the late 80s and then revised it in the late 90s, so some of the stuff may look quaint to us, like the mention of floppy disks, VGA displays and such. But then he also shows uncanny foresight around overall information exchange, because the information principles are universal, and he correctly predicted that Moore's Law would taper out around 2015.He also cheated a little.He described the flip-flop as a perpetuum mobile, which can be sort of excused, and he also skimmed on the concepts of oscillators, transistors (and did not mention capacitors), but then those are fairly complex, and I guess it's not really possible to do that without going deep into the fields of physics and electric engineering. Excusable, because the book is compelling and delightful.Even if you have a PhD in Physics from a top university or have done computer science all your life, you can rap in ASM and name all LoTR characters by heart, this is still a good read. Do not feel like you'd be highschooling yourself with silly analogies. Far from it. This is a splendid combo of history, technology, mathematics, information, and nostalgia.Highly recommended,x49 x67 x6F x72"
7,0735611319,http://goodreads.com/user/show/7970562-lynn,4,"I have been an IT professional for 20 years, but I never knew what the switches on the front panel of the Altar computer were for. I do now.In fact, because of this book, I know many things about how a computer really works that I never did before. I think this book is great for anyone, except Electrical Engineers who would be bored. Having some background in computers probably makes this book easier to get through, but Petzold assumes nothing and starts from scratch. He does a good job of making potentially dry subjects fairly interesting.I think an update to this book would be great, because the discussion of 1999 capacity and pricing makes the book feel dated. Also, the last chapter seemed rushed and not as well focused as the rest of the book.So, if you want to know how any computer really works, read this book."
8,0735611319,http://goodreads.com/user/show/19846169-jan-martinek,5,"What a ride! A book about computers “without pictures of trains carrying a cargo of zeroes and ones” — the absolute no-nonsense book on the internals of the computer. From circuits with a battery, switch and bulb to logic gates to a thorough description of the Intel 8080. Great way to fill blanks in my computer knowledge.The book takes the approach of constructing the computer “on the paper and in our minds” — that's great when you're at least a little familiar with the topic, maybe not so when trying to discover a completely unknown territory (but the author takes great lengths to go through everything step by step — e. g. the various gates, binary subtraction, memory handling, etc.).In a way, this is a perfect book on the topic. If you know a better one, I want to read it."
9,0735611319,http://goodreads.com/user/show/104131377-miranda-sikorsky,5,"It is a great book, I demystified some thoughts I had about software architecture."
10,0735611319,http://goodreads.com/user/show/1525909-jule,5,"I LOVE this book. I regard myself an innocent computer illiterate. And Petzold helps me to walk inside an electrical circuit, a telephone, a telegraph, an adding machine, a computer, and to understand the basics behind the design, of what is going on inside. I start getting the math, the logic behind all this technology that has become pretty much the center of my life today. And I should understand the logic behind the center of my life, right? What is so good about this book: it is written in a simple language anyone can understand. It uses examples that are entertaining and amusing. Like explaining an electrical circuit with AND, OR, NOR and NAND gates to pick your favourite kitty from a bunch of neutered, unneutered, black, white, brown, tan, male and female cats in their various combinations. Also, he interlinks the historical evolution to the logic and development of technology as we use it today, so you get pretty much a round picture of the whole thing. Love it!"
11,0735611319,http://goodreads.com/user/show/2298410-damon,4,"This book basicaly tries to take you from the very basics of how to encode information, such as how binary is used to represent complex information, to understanding how a computer uses information like this to perform intricate operations. The route between those two points is the interesting part, and there was some parts that I foudn really illuminating and important. For example, I didn't understand hexadecimal numbers (or indeed what base 4, base 8, etc) numbers meant before I read this book. Similarly I knew a fair amount about how various electrical gates work but not how by pairing multiple gates together you eventually get to RAM, a CPU, etc.It did lose me at times, however, and I zoned out a bit when Petzold was talking about the way in which math calculations are carried out using gates and binary information. I probably should have paid more attention, because this is fundamental to understanding how higher level systems work. I really enjoyed the explanatuon of how certain chipsets were important, especially the 8080 and the 6800, and then the creation of assembly language and compilers. Most striking to me was the realisation that modern computing is essentially a brute force operation. We are using the same switches that were invented 150 years ago or so but now they are gigantically faster, smaller and on a exponentially more massive scale. "
12,0735611319,http://goodreads.com/user/show/29089487-alex-telfar,5,"Very close to my ideal book. Starts from understandable foundations and builds from there. Charles doesnt try to explain through high level metaphors (that do a poor job of capturing the truth -- I am frustrated after picking up another apparently interesting physics book only to find it contains no math), rather, he slowly builds on simple examples. And while it does get pretty complex, Charles doesnt avoid it. !!!For a while I have been frustrated about my understanding of computers. I understood how bits can encode information, what the von Neumann architecture was and some of it flaws, how programming languages are compiled to assembly/machine code, what transistors are and how to make logical circuits. But I could never really link them together. I am still a little hazy, and I think I will have to go over a couple of chapters from no. 17 onward (automation, buses, OS) just to cement and clarify, but understanding feels close.More thoughts to come on my blog. Just drafting atm."
13,0735611319,http://goodreads.com/user/show/4216776-baq,5,"Wow. I wish I had had this book back when I was taking my first Computer Architecture course in college! It carries you along from the very fundamentals of both codes (like braille) and electric circuits in the telegraph days all the way to the web in a way that even a layperson could understand, with plenty of verbal and diagrammatic explanation. It does at points get pretty deep into the weeds but I really appreciated the author's efforts to provide such an exhaustive dive into how computers work (and I regained much of my awe at these machines we take so for granted nowadays). The final chapter was a rushed overview of the web and felt almost like an afterthought after the thoroughness of the rest of the book, but I didn't ding the author on it--there's plenty of great writing about how the web works that you can read elsewhere. Read this book to gain a deeper understanding and appreciation for the birth of the modern digital age. Thank you Charles Petzold!"
14,0735611319,http://goodreads.com/user/show/47635748-laura-marelic,5,"This book is the perfect depth for novices but also people who are “in tech” and don’t really understand how it all works (like me). I can now look around at all the electronics in my house and feel like I know what’s fundamentally going on. Knowledge is empowering! The last chapter of the book felt a bit rushed and ended abruptly, but maybe that’s just my wanting the book to go on longer/end at present day. Overall, I loved it and will surely be recommending it to anyone who asks how computers work. 👩🏻‍💻🤖👾Oh, also I am simultaneously reading The Innovators (Isaacson) on audio and the two books pair very nicely. It was great to read about the tech in Code and then the story of who’s behind it in The Innovators. I recommend this pairing!"
15,0735611319,http://goodreads.com/user/show/1239910-rik-eberhardt,4,"In brief: be prepared to skim through at least 25% of this book! If I had this book in a seminar freshman year, I might have completed the Computer Science program. In a very fun manner, this book presents 3 years of introductory CS curricula: discrete structures, algorithms, logic gates, ... After reading this during two cross-country flights, I better understand (and remember) classes I took 10 years ago. Almost makes me want to try again (*almost*)."
16,0735611319,http://goodreads.com/user/show/3126915-imi,4,"This book has really taught me a lot, despite the fact that many of the later chapters lost me somewhat; it felt like it became much more complicated and hard to follow after the earlier chapters, which were great, slowly paced and well explained. While Petzold does assume the reader is starting from scratch, I think it would be easier to follow later on if you had some background in computers/technology. As it was, I had to bombard my dad (an electronic engineer) with questions to even make it to the end of some chapters, but then I haven't attended regular maths/science classes since about age 14, so maybe it's not surprising that I'm missing some of the needed background information.It is outdated, having been written in 1999, but I guess the history, which Petzold follows nearly chronologically, hasn't changed, and the early history is necessary to understand what has come since this book was written. Having said that, the last chapter (on the 'graphical revolution') was strangely rushed and an updated edition would do it some good, I think. Even if I couldn't grasp all of the technical detail, the majority of this book was extremely eye-opening and I have definitely come away from it with new found respect for these devices that we now use day-to-day. Even while using this laptop to complete a supposedly ""simple"" task such as writing this review, I am fascinated by how much work has gone on behind the scenes to allow me to do this. It's fairly awe-inspiring, the more you think about it."
17,0735611319,http://goodreads.com/user/show/4073465-carlos-martinez,5,"Such a fun and interesting book. Petzold goes back to the very basics to explain how to build a computer (of sorts) from the ground up. First he explains binary (via morse code and Braille), then he introduces relays and switches, then gates and Boolean logic, and before you know it you're building an electronic counting machine. He continues with a potted history of transistors, microchips, RAM, ROM, character encoding and all sorts of other fun stuff.I skipped over some pages, because I don't actually need to know the full set of opcodes for a 1970s CPU, no matter how significant they are to computing history.The only obvious 'flaw' is that the book has aged a bit. Written in 2000, it just about manages a mention of the internet/HTTP/TCP-IP and modems, but not wifi, cloud computing, touchscreen devices, and the brave new world of machine learning. Personally I don't think that detracts from the book at all - the really interesting stuff runs from around 1870 to 1970.Definitely recommended for those that didn't study (or don't remember much) computer science."
18,0735611319,http://goodreads.com/user/show/83327216-alisa-mansurova,5,"Just finished reading my b-day gift, the 'Code' by Charles Petzold - probably the best engineering book I've ever read. By saying 'engineering', I mean it. Unlike other computer science books, the 'Code' teaches how computers work in a nutshell. It leads you from the very basics like morse & braille codes to boolean algebra and various numeric systems, from simple tiny electric circuits which bulb the lamp to primitive adding machine (built from relays, hehe), up to history of development and enhancement of computers in the 20th century. There's not much programming or CS (apart from some machine code and assembly language examples). Still, the purpose of the book, as I mentioned, is rather to explain the nature of computer codes and hardware at the very low-level. Written in 1999, the book yet actual nowadays (well, there are funny moments regarding computers' capacity and performance, and probably some other stuff but those don't matter much).Highly recommended for those (like myself...) who work closely with computers but have a lack of engineering education to feel comfortable with this magic going on around when you write your code"
19,0735611319,http://goodreads.com/user/show/6645592-mark-seemann,4,"Since I loved Charles Petzold's The Annotated Turing: A Guided Tour Through Alan Turing's Historic Paper on Computability and the Turing Machine, I wondered if he'd written other books about the foundations of computer science. Code seemed like an obvious candidate.This book explains, in as much details as you could possibly hope, and then some, how a computer works.Since I've been a professional software developer for about two decades, the title of the book, Code, gave me an impression that it'd mostly be about the logic of software - something that I already know intimately. The first chapters seemed to meet my expectations with their introductions to binary and hexadecimal numbers, Boolean logic, and the like.Soon, though, I was pleasantly surprised that the book was teaching me something I didn't know: how a computer actually works. It starts by explaining how one can construct logic gates from relays, and then builds on those physical creations to explain how logic gates can be used to add numbers, how RAM works, and so on!Like The Annotated Turing, this part of the book met me at exactly the level I needed. So technical, with no shortcuts, and nothing swept under the rug, that I felt that I deeply understand how things work, but still thrilling and engaging. Whenever I found myself with a question like, ...but how about..? or ...but what if..?, I soon learned to read on with confidence because I consistently found answers to my questions two or three paragraphs further on.The final part of the book, again, moves into territory that should be familiar for any programmers, such as ASCII, high-level programming languages, graphical user interfaces, and such, and that, unfortunately, bored me somewhat. Thus, the overall reading experience was uneven, which is why I only give it four stars.Would someone who's not a professional programmer rate it higher? I don't know. I could imagine that for some, the explanation of logical gates, adders, latches, etc. made from relays would be too technical."
20,0735611319,http://goodreads.com/user/show/3335829-geoff-rich,4,"I really enjoyed most of this book. The slow unfolding of how computers are built actually work was extremely fascinating - from simple lightbulb circuits to logic gates to RAM to keyboards and monitors. Unfortunately, parts of this book seem quite dated (most anything discussing ""contemporary"" technology, i.e. 1990s computers) and the final chapter on the graphical revolution goes through way too much, way too fast to be of any use. A few chapters were tempting to skim For example, Petzold includes 25 pages on the machine code instructions of an Intel 8080 microprocessor - did we really need all that detail? The majority of the book, however, is great - I had never really delved into logic gates and circuitry, so it was truly eye-opening even if I couldn't fully understand some parts. I think if I read this when it was released it would manage to eke out 5 stars from me. From a 2017 viewpoint, however, it only manages 4. I'd still recommend it to anyone curious how computers work, down to the nitty-gritty of ones and zeroes. Most of it should be accessible to a layperson, though I may be blinded by my own CS experience. Even if there are parts you don't understand, you'll come out of it with a greater understanding and appreciation of the technology you use daily."
21,0735611319,http://goodreads.com/user/show/14897481-trevan-hetzel,5,"With a desire to learn how the high level code (HTML, CSS, JavaScript, etc.) I write on a daily basis actually makes its way through the magical land that is a computer and returns pleasantries to a human being behind the screen, I sat down with this ""Code"" book. The book is very intriguing from the start, beginning with the earliest forms of code (Morse, Braille, etc.). Petzold spends a long time laying down the basic blocks of electrical engineering before progressing to how bits flow through a circuit board and control things. I'll admit that I got very confused at times as to how a computer works, but Petzold gives you all the information you need. It's just a matter of how much time you're willing to spend re-reading and studying each piece of information he gives (there's a LOT to take in). If you have a background in electrical engineering, this book would probably make a lot more sense to you than it did to me. But, nonetheless, it will sit on my shelf awaiting the time I start playing with Arduinos and hacking on things. At that point, the book will REALLY come in handy!"
22,0735611319,http://goodreads.com/user/show/54320432-ieva-gr,4,"The book reminds me of the courses that students usually have during the first year of the University. It provides a general overview of how computers function. Starting from workings of an electrical circuit and building up to various logical elements with gradually increasing complexity. It also discusses some relevant historical moments as a typical professor in a typical lecture would do and ends with a broad overview of personal computers as they were in 1999. The summary on the back of the book says “No matter what your level of technical savvy, CODE will charm you – and perhaps even awaken the technophile in you”. That didn’t happen at all. At some more detailed and complex parts reading the book felt like going through a swamp waste deep. But I think it really helped me to gain some overview on the history of computers and a better understanding of things I sort of kind of heard of but never bothered to read about. "
23,0735611319,http://goodreads.com/user/show/972512-k-c,4,"This was a wonderful non-fiction read, especially the first 15 or so chapters. Chapter 17 (""Automation""), however, was where I began to feel a bit in over my head. While that chapter was fairly thorough, when I got to later chapters and realized I couldn't quite grok what was going on in these chips, it was hard for me to tell whether I was holding myself back by not fully understanding the concepts of Chapter 17, or if Petzold was simply glossing over some of the details that might have clued me in. It was probably a combination of both. While I did enjoy the later chapters as well, much of it felt so rushed compared to the earlier, slower pace of the book. Recommended for anyone who would really like to understand the basic concepts behind computer technology, but doesn't want to go back to graduate school."
24,0735611319,http://goodreads.com/user/show/4644723-eva,5,"This book is quite incredible. You start with braille and simple light switches, make your way to oscillators, flip-flops and multiplexer, and suddenly you understand how computer hardware works. And that's coming from someone who already thought they ""sorta"" understood how it worked. I didn't really. Now I do. Best bottom-up education ever. "
25,0735611319,http://goodreads.com/user/show/2645334-travis-johnson,5,"I really, really truly love this book. The beginning is slightly slow, but after the 1/3 mark or so, I couldn't put it down(literally. hello, 5am.)I probably learned more about architecture from this book than the quarter in my Architecture & OS class at university."
26,0735611319,http://goodreads.com/user/show/3494451-randall-hunt,5,"Definitely one of the greats. If not already, it soon will be, a staple of computer science literature. It's both a narrative history of Computer Science and a brilliant introduction to systems and programming. This book should be a pre-requisite for introductory CS classes."
27,0735611319,http://goodreads.com/user/show/16730283-ondrej-urban,5,"One - in this case one in how the Queen would use this - cannot really talk about this book without comparing it to But How Do It Know? - The Basic Principles of Computers for Everyone, since they cover a lot of the same ground (and one has read the other one first).Code's mission in life is to help the user understand the basic principles behind the computer design and convince them that it's not actually that tricky and that your great-grandparents could have build one themselves. Naturally, there is a lot of overlap with But How Do It Know, since there don't seem to be better ways do design a basic RAM. Starting with looking for ways to transfer information, Code goes from flashlights to telegraph to relays to the logical gates, doing a better job than the other book, which introduces the NAND gate as the basic black box and goes from there. Point Code, reading about that is super enlightening and exciting!The middle part of both books is kind of similar, spend building basic computer parts out of logical gates. I'd maybe lean towards Code doing a bit of a better job reminding the reader of the basics but the other book prevails in its focus and overall a better teaching approach, explaining every single thing done, while computer parts seems to start randomly appearing at some point of Code (buses and registers being two examples).In the final part, Code goes a bit overboard with talking about not-so-basic stuff that at this level needs to necessarily happen at a bit of a high level. Disregarding it having been written in the later 90s and talking about DVDs will at some point take over from CDs as the main software distribution channel, I had a feeling that the author could have stopped a bit sooner, or perhaps expand the chapter on compilers a bit more. In any case, when it comes to the overall impression, the How book wins thanks to its laser-tight focus on building a computer and nothing else, while Code seems more open-ended and talking about particular technologies specific for a given time period makes it feel a bit aged. That said, Code is a great book to read to refresh your knowledge of the basic computer design that can add a lot of basics and fill in the picture. Highly recommended!"
28,0735611319,http://goodreads.com/user/show/6274559-angelos,4,"A very nice introduction into what makes computers tick. It's detailed enough to give you a sense on how things work, yet not overly complicated to intimidate you. I really liked the gradual introduction to concepts of increasing complexity where each builds on the one before it. I feel like I've learned a lot by reading this book, especially since we had no relevant computer architecture courses in college.That said, I have a couple of complaints.One is that I feel the author covers the initial, simple, concepts like Morse code, binary numbers, Braille etc in excruciating detail, yet is quick to cover complex concepts and areas as the book progresses on digital circuits, CPUs etc. Ideally I'd like fewer details on the initial concepts and a better and more detailed explanation of later ones.The second complaint, which is to be expected, is that the book was written in 1999. Although still highly relevant when it comes to computer architecture, it contains a lot of references that feel a bit dated, especially in the later chapters that cover multimedia (CDs, DVDs), GUIs, the WWW, etc.So, I highly recommend this book to anyone interested in how computers are built, from the ground up. I find it's a good fit even for CompSci students/graduates that want to fill-in their knowledge gaps like me. That said, this book is not an easy/quick read. It's pretty technical so prepare to put in some time to grok some concepts if you really want to understand how things work."
29,0735611319,http://goodreads.com/user/show/28989798-andrew,4,"Although there are a few chapters that I probably gained very little from (I’m looking at you flip flops!) , there were a majority of them that was incredibly useful in taking what seems a complicated subject matter and simplified it in ways that makes it accessible. When I was near the end I sort of circled back to the chapters on binary and hexadecimal and it definitely helped me with the conversions. I also really like how the author tied in the use of a flashlight for on and off, to morse code, to the computer age we are in currently. I would love for this book to be updated now that fiber optics and blu-ray are prevalent and that we are going more towards cloud computing. I’ll be using this for a reference for years to come. The downside is that this type of book really needs some sort of practicals because when there are just random pages of assembly code and hexadecimal reference codes for a chipset that I am sure is no longer in any of my devices, it doesn’t add any sort of value to the reader."
30,0735611319,http://goodreads.com/user/show/35899146-jakub,5,"I wish I discovered this book earlier. It is a great introduction to computation and I do recommend it to everybody that would like to understand what is going on inside their laptops or phones.I found the ""big picture"" to ""the actual details"" ratio very suitable for a casual read. There are some parts that require more attention though - especially when the author explains the details of a data flow in the computer or the way Intel 8080 chip works. Nevertheless that's an inherent characteristics of any subject related to computation - some thinking is required to grasp the concept.All in all great introduction for non-programmers and even better refresher for people that are into programming but treat all the layers below the OS as a 'back box'. This is highly recommended."
31,0735611319,http://goodreads.com/user/show/11199869-prashant-ghabak,5,The author starts from electrons then electricity and builds right up to a high level programming language to explain fundamentals of a computer science while walking us through the history of the field. Very well written. 
32,0735611319,http://goodreads.com/user/show/37846711-andrew-alkema,5,"This was an excellent book. I love Charles' approach to explaining how a computer works. All of a sudden this collection of electrical circuits was a microprocessor. I really enjoyed the history of computing mixed in as well, that's something we did not learn enough of in CS at university, so I really enjoyed getting more of that here. Even though this book was written in 2000, the information is still just as relevant. To make the concepts simpler, most of the hardware he looks at in detail is from the 1970's anyway, so that part hasn't changed. The rest of the concept haven't gone anywhere. Don't let the age turn you off."
33,0735611319,http://goodreads.com/user/show/74276701-chad-lavimoniere,4,"A good overview of the basics of CS and early history, but at this point hilariously outdated. Could do with a major second edition. "
34,0735611319,http://goodreads.com/user/show/31121633-leonid,5,"Absolutely great book.It starts from the general idea of codes, like Morse or Braille, and then shows how computers designed and built, starting from relays, and finishing with asm (and then moves on to memory, storage, cpu design, text and graphics i/o)."
35,0735611319,http://goodreads.com/user/show/21307031,5,"A fascinating journey into the history and ""nature"" of computers written with an effort to make things easy to understand. A very interesting and important read for anyone related to IT"
36,0735611319,http://goodreads.com/user/show/4130219-moayyed-almizyen,5,Thank you Charles Pertzold ..
37,0735611319,http://goodreads.com/user/show/45773827-rick-sam,5,"An excellent book to learn about bottom-up details of Computers. It starts with two friends trying to communicate with each other, Morse Code, Braille, Flashlights... Gates, ... Assembly Language, Operating System and finally Graphical Revolution. Overall, this would help you to understand from First Principles, you can build from there. What an impressive accomplishment and progress! I would recommend this to anyone interested in Software, Hardware, Computer Science. Deus Vult, Gottfriend"
38,0735611319,http://goodreads.com/user/show/84459920-nick,4,"When I started reading this book I had an inkling that this book is suitable for nerds/technical people but after reading the first few chapters I thought that probably I was wrong. As it turned out in the end, it's at best a mixture of two with a heavy hilt towards first.The book explains in detail the working of a computer system along with the history of its progress over the year. It starts with a very innocuous example of communication between two close by living friend using just a torch. After that, chapter after chapter, it builds upon that by explaining in subsequent chapters the shortcomings and the solutions developed by industry, until it reaches the working of high-level languages and how a computer does calculations!!While the language of the book is lucid and definitely an improvement over dry engineering books that a lot of people here would be so used to, it couldn't help falling in that trap as it progresses. If you don't follow the writing closely and sequentially the preceding chapters may just be undecipherable to you. The book goes deep into circuits and their working and although it starts with a very good example and maintains continuity, it becomes very tech oriented and complex. Even after having studied a lot of the topics from the book during graduation, I myself couldn't help but skim over some parts as the writing became too technical and fully resembles an engineering book. Guess you can't escape that however much you try!!This book is more suitable for nerds/technical-oriented readers. If you want to know how and what of your system, this book can give you a very good idea. I may even say that if that's how the engineering books were written a lot more people would benefit. If someone here, during their course of engineering, is starting with the subject of digital systems; I strongly suggest reading this book cover to cover over (say over a period of two weeks or a month) before they start with their assigned books. You would be thanking me and the author later!! For others, if you pay close attention from the very start, this is the book to gain some understanding system since a very complex topic is explained in a very easy language starting with a very basic and relatable example and improving upon it. If this book doesn't do it for you, nothing would."
39,0735611319,http://goodreads.com/user/show/15643804-gustav-ton-r,5,"Basically everything you need to build a modern computer, both hardware and software, from scratch. Perfect read after the apocalypse. Too few people grasp these relatively easy concepts that power modern society through the internet and the cell phones in our pockets. This book summarizes computer technology in a clear and concise way."
40,0735611319,http://goodreads.com/user/show/8017610-james-millikan-sj,5,"A fascinating account of how electronics work, using stories, clever examples, and clear illustrations. Starting with elementary logic, examples from Morse code, and basic circuits, Petzold explains how to build a computer.This sounds like a rather dry read, but in reality it is an engaging and well written journey that weaves electrical engineering and history together into a compelling synthesis.If you’ve ever wondered how your digital watch works, or the structure of binary, or how erasable digital memory is possible, look no further than Petzold’s classic. Highly recommended."
41,0735611319,http://goodreads.com/user/show/4606766-scott-johnson,5,"This, finally, was what I was looking for in my quest to understand computers.We start with some really boring, basic things about the most elementary circuits. It gets a pass because it's necessary if you're coming in blind, but I've taken courses in things like the physics of transistors, so I wasn't a fan personally. The same goes for assorted later sections on number systems (already overly familiar with Binary and Hex, thanks).Then we move into how you take very simple components and construct logic gates. I was vaguely familiar with their use, but had not actually seen one built from relays.The theme of building further complexity just by stacking blocks is introduced, and is the key to everything. Once I understand how a NOR gate works, I don't need to constantly trace the paths, we can shortcut now to using the correct symbol in the circuit with two (or more) inputs and an output. Similarly, 3+ input gates that are really cascades of 2+ gates being abbreviated as what without context looked like a new component makes complete sense.Using that, we construct a simple circuit to add binary bits. My only big criticism is that this is where we're building up to how a microprocessor works, but we suddenly veer left to look at memory.This was the most enlightening and involved portion. We gradually build up from a single bit being stored as a consequence of a quirky configuration of logic gates that ""trap"" a bit to adding things like control mechanisms (only write to the bit if this input is on), refreshes, and, most importantly, arrays of these storage bits.This was where I finally started to settle into this paradigm. Trying to think about the big picture is impossible. We're talking about quantities of components that the human mind cannot track, time spans we can't conceive, and frequencies that are impossible to imagine.Faith in the process is the key. I understood the science behind relays and transistors. I understood how these allow us to introduce logic. I understood how combining these gates leads to operations like addition or controlling the routing of a circuit. I understand how a moderate array of these things leads to a useful component like a byte of memory. I understand how each bit can be addressed to be written, read, and cleared.So I just needed to learn to relax and remember that I know these things, and that all we're doing now is that same thing....a few million times. Yes, that seems impossible, but you don't need to deal with all of that. You just have to do what we did with cascading logic gates being combined into 3+ input gates: Simplify it into a known component. Who cares what's happening in each of the 500 black boxes that all do the same thing. We just know we need this input and this is how output behaves.Once you understand how to chain them together into large arrays, why not simplify this into just ONE big black box, the DIMM. I now know how a signal from the processor (or, later, storage device) goes through an unimaginably long branching addressing system.I could not easily trace exactly which circuit a signal will follow to access a certain memory address, but I have faith that, given what I understand, I COULD do it if I really had to. I know what I understand really well on a small scale still works perfectly fine even if there are a few tens of thousands of branches now. It's not even complicated, every single node in the branching decision tree is identical, it's just big.This was a little more fuzzy when we returned to the microprocessor and the idea of instructions and opcodes, but I think I get it. This was unfortunately not covered in as much detail, and it's the one section I do want to do more reading about specifically.My understanding is that instruction sets are hard-wired into the processor. Similar to memory addressing, there seems to be some kind of input gate where the opcode instruction is interpreted to route the data it's carrying to the right part of the chip? Or there could be dedicated inputs for the specific operations, and the routing is done on the motherboard or by a secondary controller chip? Or both?It's a little unclear to me exactly how that control process happens, but I DO understand the important part: That processors have a finite instruction set, and perform very simple operations......but really, really fast. Another revelation was the idea of a clock signal as an input that ratchets the data forward one step through the circuits per iteration. I guess a lemma to my ""it's not complicated, just big"" theorem would be, ""don't think of circuits as continuously evolving, they are discretely iterating"".I was struggling at first to fathom how just adding these two bits together in any way led to these characters being displayed on my screen right now. I kept thinking, ""But you still have to do this, and this, and....."" Ok.....so then we do those things. In 2018 we're doing BILLIONS of things EACH SECOND. Response times are in nanoseconds. Sure, it's a lot....but that's fine. It's not complicated, it's just a tediously long chain of really simple events.Storage was easy. There was a bit of hand waving about how the addressing translates to moving the read head to this part of the disk or whatever, but I know enough about RAM addressing now to assume how it works. I can assume that logic is built into a controller on that disk that's hard-wired for that particular hardware configuration (hence why you don't really need drivers for components like these.....and also makes me realize why drivers are necessary to essentially tell the rest of the computer what a new component's inputs, outputs, and instruction sets are).Displays were REALLY simple thanks to one phrase: ""visual memory"". This wasn't from this book, it was from my last read, Turing's Cathedral, in discussing the use of CRTs as memory devices briefly, so you could see the memory live. They said something offhanded about, ""That's all the display on your monitor is anyway, showing an array of memory as pixel values, "" or something like that. The video card just constantly accesses that visual memory, turns it into pixel instructions, and sends it out the adapter for the monitor (with its own hard-wired controller) to translate to the actual pixels.The last piece was....how does everything know where to send the data? Answer: BUS! I now get how you can have so many things on so few buses and not have every component getting useless data from the rest. I had never heard of three-state logic, but it makes total sense (especially after an explanation that ""0 and 1"" are really more like ""high and low"") that there could be a state that would essentially block a component from the circuit so it has the ""state"" that it's neither high nor low. It then follows quite simply that the address of that component on the bus would trigger that control circuit to leave that non-state and connect to the bus again.Put all of this together, and I get it now. It's kind of like one of those Magic Eye pictures: If I relax and let my eyes go fuzzy, I can see the kitty, but as soon as I try to focus on anything it dissolves into chaos, and at best I can resolve a few of the dots. I just need to stop worrying about the 4 billion dots on the paper, just relax my eyes and have confidence that they're all still there.Aside from the sequencing of memory and processors, I think this was really well structured to flow logically and build up these complicated ideas from just a few simpler ones. A big point in its favor, also, was introducing that idea itself at the very beginning so it doesn't blindside the reader. It lets you read seemingly scary ideas with the context that once you get it you can just file it away as another building block for later use.10/10 would recommend to anyone who, like me, really wants to understand how you get from simple circuits to complex operating systems without resorting to magic."
42,0735611319,http://goodreads.com/user/show/117278-simmoril,4,"One of the biggest difficulties that is unique to Computer Science is this idea of 'layers of abstraction' - interfaces created to help hide the complexity of the underlying layer. While this can be a boon when developing, it becomes a problem when those lower layers start misbehaving, and you don't know why. Or, at a more basic level, these layers of abstraction can make it hard to understand why things are the way that they are (like why computers don't count in base 10, or why I can't run Unix programs in Windows). Petzold's book attempts to resolve this issue by starting out at the absolute most basic, physical level of a computer and working up through the different layers until he gets to what is pretty much a modern day computer. Through the use of good examples and an informal style of writing, Petzold introduces the reader to a large number of fundamental topics in Computer Science/Engineering, such as binary, logic gates, processor design, assembly, operating systems and programming languages. Petzold does a great job of not getting too bogged down in the details, and only giving the reader enough information to move up to the next layer.I enjoyed Code a great deal. Although much of this wasn't new to me, Petzold still surprised me with some historical facts I was not aware of, and the book itself served as a nice refresher course for some of the things that I studied and promptly forgotten in college. Although this book won't turn you into an expert by any means, it is a great starting point for understanding just how computers actually work.The only small issue I had with Code were that some areas were a little tough to get through. Towards the middle of the book, where Petzold starts to assemble memory circuits and building a rudimentary CPU, I found myself glossing over a lot of the details. For a complete understanding, these chapters would probably require a couple of passes. Also, the last couple of chapters seemed a little more hodge-podge than the rest. While they are good tidbits of information to know, it just seemed a little less organized than the rest of the book.Overall, Code is a fantastic book, and I highly recommend it as a starting point for anyone who wants to learn more about computers. In fact, I'd nearly go so far as to say it should be required reading!"
43,0735611319,http://goodreads.com/user/show/53697998-dave-voyles,5,"While looking for an answer on Stack Overflow one day, I saw several people recommend this book, to get a grasp on what was happening under the hood of my computer -- specifically, from beginning to end, how is a computer made?This book broke it down in such a way that I now understand it completely. The author starts of small and slow, and gradually builds up, from explaining how different number systems work as well as why we have so many, and the shortcomings of each (hex, binary, decimal, etc). From there, he goes into the use of relays, a bit about electrical engineering, and next thing you know, you're looking at Assembly code. It all starts with communication, languages (I’m talking Morse code and brail), and goes from there. Incredibly useful.code-bookI now have a far better understanding of the things my friends were speaking of on technical threads before, largely from the terms I learned in this book:carry bit, high-order bit, lower-order bit, etc,.I wish I had read something like this when I first started programming. If you know anyone who wants to get started in coding, then I'd start here, not because of the code it will teach you (you won't learn much on that here), but understanding what your code is doing to the actual hardware. The computer no longer appears like a black box.It was published by Microsoft Press in 2000, and the author, Charles Petzold, actually works for Microsoft (now Xamarin).Read this if you want to understand how your computer really works."
44,0735611319,http://goodreads.com/user/show/25094561-elijah-oyekunle,5,"Really good read for newbies looking to understand computers, behind the scenes."
45,0735611319,http://goodreads.com/user/show/981470-clarence,4,"Most people nowadays, if they wanted to explain how computers work, would probably ensure that the reader knew binary arithmetic, then talk about processor instructions, and from there work up through the higher levels of programming.Petzold takes an entirely different tack, which is completely centered around hardware. In fact, he starts with electric circuits, describing how a boy might build a circuit to light a lamp in his friend's house. He builds on that, getting into circuits that with multiple lamps, talks about telegraphs, and on and on. He does eventually take a detour in one chapter to talk about number bases, but even goes to the trouble of using not just base 10 or base 2 but unusual others to ensure that the reader understands both that the concepts are independent of the base, and yet also why base 2 is particularly useful in building digital computers.In addition, whether you know the subject matter or not, this books is an enjoyable read. People who recognize the name Petzold will most likely think of his old ""Programming Windows"" and similar books, which were dry textbooks. Not so this volume. I was very pleasantly surprised at what a fun read this is.Highly recommended to anyone, whether they have an interest in computers or not."
46,0735611319,http://goodreads.com/user/show/28438106-michael,5,"This book covers a variety of topics about what is going on under the hood of a computer, without muddling up the explanations with too many technical details. The author favors explaining the big picture and the components that make up that big picture, rather than staying too focused on one topic for too long and providing too many technical and insignificant details.For example, the concepts of logic gates and boolean functions are worthy of having entire books dedicated to them, but this book instead spends a concise two or three chapters on them, explaining the essentials to understand the big picture of what they are, and how they relate to the inside of a CPU. These concepts are then utilized later in the book to help explain other topics such as how a computer's memory works by utilizing those logic gates.Perhaps this books best feature is that, as I was reading and questions popped into my head, the very next paragraph would often open with something like, ""You might be wondering..."", and time and time again, I *was* wondering exactly what the author thought I might be wondering.It's all about the big picture, and this book absolutely nails it."
47,0735611319,http://goodreads.com/user/show/44327766,5,"This is the first book I would recommend to anyone wanting to learn about how computers work. It was written in 1999 and shows its age in some respects, but overall I would consider it a timeless classic.The one thing I was a bit sad to see was the incorrect use of the metric unit prefixes when refering to binary quantities. In the context of the time this book was written, the authors usage of metric units was common, and even today there is much confusion about it. A year before this book was published, the IEC and others published standards recommending binary prefixes. https://en.wikipedia.org/wiki/Binary_...Unicode was also only briefly mentioned. I would LOVE to see a revision of this book to update dated references, go over (and properly use) the differences between metric and binary prefixes, and to expand the content with details about advances that have happened since 1999.I was made aware of this book by Fabian Sanglard's blog: http://fabiensanglard.net/books_recom...He recommends ""Computer Organization and Design"" as a more in-depth follow-up. Expect a review of the 5th edition from me in the future!"
48,0735611319,http://goodreads.com/user/show/4090833-lingliang,5,"Excellent lucid explanation of the legacy of genius that has left us with the incredible abstracted world of computers. The abstraction allows us to accomplish creations of unimaginable complexity. This is a delight to read, as it clearly goes through layers and layers of genius, great minds building upon the remarkable history of computing, leaving us with a much more worthy appreciation of the beautiful creation that is the modern computer. It goes through each step of abstraction, starting with a compute relay and how it works (in terms of electromagnetics), and then goes step by step, all the way to the implementation of modern operating systems and programming languages. It's complexity is sufficient to leave little lingering questions but not so complex to be burdened by unnecessary rigor, leaving this boom a delight to read for both experts and laymen alike. This is an essential read for any computer scientist or even anyone who wants an appreciation of the creation that is a cornerstone of the modern human experience."
49,0735611319,http://goodreads.com/user/show/2478866-sonofabit,5,"Absolutely phenomenal book that's not so much about code but rather about the deep underlying concepts behind how a computer works, how it ""thinks"". If you've ever wanted to know more about bits and bytes and the mechanics behind the ones and zeros that everyone takes for granted as they browse facebook or listen to mp3s, this is the book for you!There were several ""AHA!"" moments that FINALLY cleared up unresolved questions from my Digital Circuits class back in college; I don't know why this wasn't the textbook they used :) However it's more than just a book about logic and circuits; it takes you so deep into the lowest levels of code and logic that it's almost an Anatomy course for computers. You literally get to see what happens at the smallest level, such as a circuit diagram for storing a byte!A truly fascinating read for anyone interested in programming, digital circuitry, or electrical engineering. Pick this one up today!"
50,0735611319,http://goodreads.com/user/show/676492-jean-luc,5,"There's a long, long list of books where my common reaction to them is ""I wish I'd read this in high school, it could've set me straight much earlier!"" Unfortunately, this isn't one of them... because I graduated in 1998 and this was published in 1999.At some point in your computer science career, you will take a courses and labs in digital systems. At Stevens, when I was your age, this was 381 (Switching Theory and Logical Design) and 383 (Computer Organization). This book combines both of those courses, starting from counting numbers all the way to building a programmable computer. The main difference is that the author, Charles Petzold, actually cares about the subject and makes it interesting. I would gladly have payed $4800 to read this book instead of paying that amount to take those 2 courses because I actually learned something from this book.Would make a great, great, great gift for any high school student considering a career in programming."
51,0735611319,http://goodreads.com/user/show/121883-mike,4,"I'd definitely recommend this to anyone who is even remotely curious how computers work, and doesn't mind going all the way back to basic physics to find out. The author builds a very basic but working computer all the way from the ground up, and giving you a unique view of the concepts involved that certainly wasn't taught in any engineering or computer science class I've ever taken (B.S.E.E./Rutgers '01). Although he gets a little lost near the end and doesn't adequately show how everything since the basics came out has just been ""making it better"", showing you the basics is the hard part, and combined with the complexity that comes later its all you really need to understand the emergent behavior of computing. "
52,0735611319,http://goodreads.com/user/show/11831233-jon,5,"Intimidated by digital technology? Think your computer secretly hates you? Can't understand why your device won't do what you tell it to? (Even though it is doing exactly what you told it to do...)Read this book. All complicated technology is made up of layer-upon-layer of less complicated pieces down to some very simple straight forward parts that do only one thing in response to something else that only does one other thing. Learn from the bottom up how digital, and in some cases analog, machines that we have allowed to control our live exist and do more in a second than you would want to do in your lifetime.And... No I will not fix your computer, that's what children are for now-a-days."
53,0735611319,http://goodreads.com/user/show/50247467-matthew-porche,3,"I will not lie, this book was tough to read. It flowed in some chapters, but not others. Petzold likes to talk about how much he hates analogies, but I seem to require them to understand a lot of things. I love computers, and this book helped me understand how they work, but it took forever before he started talking about them. I learned a lot on the small end of the scale, but he didn't discuss a whole lot about computers that I didn't already know. I was planning on citing this book for a research paper on cyber security, but this will not make it in the paper. There were a lot of dry spots in the book where I recall having to force myself to read the book. I cannot say I'd recommend this to anyone else, but I would not deter anyone from reading this book either. "
54,0735611319,http://goodreads.com/user/show/54838935-aaron-manley,5,"This is the book to read if you want to ""get"" computers. Not just how code executes programs, or how your operating system is what you use to run everything else - this goes all the way down to the computer architecture at the microcode level (relatively speaking). The book looks at basic human problems, discovers some ingenious quirks of nature involving switches and eventually electricity that allow us to use code to represent information to help us solve problems. Starting at a on/off relay, and ending in a full-fledged computer processor with memory, this is the book to read to understand how computer hardware and computer software are truly connected. It's also a good primer if you want to give nand2tetris a try and build your own virtual computer online."
55,0735611319,http://goodreads.com/user/show/7962528-michael,5,"What a great book! I asked myself why I didn't read this as a freshman in college, and then realized that it was published in 1999 when I was a sophomore.This book distills the workings of computers down to their most basic elements - voltages moving across circuits in a controlled way - and builds on itself until you get to a 1970s era microprocessor. From there, everything modern computers is simply layered on top one step at a time.What's going on inside your computer (or phone!) is simply amazing, but it's also completely understandable. I'm going to have my kids read this when they're old enough to understand the concepts. "
56,0735611319,http://goodreads.com/user/show/31061871-alex,4,"Good intro to Computer Science. Last few chapters didn't age too well since the book was written, but provide a valuable history lesson for younger programmers."
57,0735611319,http://goodreads.com/user/show/10165915-yogesh,5,"Perfect book if you want to understand how computer works at the very low level. This book answers most of the questions I had during my under graduation, didnt only help me bruis my engg concepts but also placed everything at one place. This is a must read for tech enthusiast. Reading this book does not require expertise abt computers, a person having bare minimum knowledge will also be able to understand though in between sometimes it becomes a little confusing but if you are attentive and is putting all of it in one place you will be able to understand it comfortably."
58,0735611319,http://goodreads.com/user/show/32751589-amy,4,"This book does a good job explaining a lot of the basics of computing along with explaining some of the history of computers. It goes from explaining the basics of circuits, relays, and binary to assembly languages and the breakdown of basic parts of computers. Even though technology today has come so far since this book was written, I still recommend this book if you want to understand many of the basic concepts of computing and where a lot of it started."
59,0735611319,http://goodreads.com/user/show/6036930-alex-linschoten,4,"Extraordinary and rightly a classic of its kind. Petzold explains how computers work, starting with a simple story about binary information, relays and circuits, moving on to ASCII and interpreters and how code interacts with the electrical circuitry.Parts were heavy-going, but it was always exhaustively and clearly explained. I couldn't absorb it all on the first reading, but I will gladly return to reread this."
60,0735611319,http://goodreads.com/user/show/4249244-michiel,4,"One of these popular science books you wish you have read them when you were younger. Petzold builds a computer using relays and imagination. Though somewhat dated, this is a gentle overview of computer architecture. "
61,0735611319,http://goodreads.com/user/show/7495733-marjorie,4,"A very well-thought-out introduction to how computing works, starting from very basic concepts like sending messages to your neighbor with a flashlight as a small child. It would totally make computing make sense to my parents, if I could ever convince them to read it. :-)"
62,0735611319,http://goodreads.com/user/show/17141964-axel-prieto,3,Interesting and well written. I skimmed some parts since it gets dense with electric specifics at some momments.
63,0735611319,http://goodreads.com/user/show/58851414-markusq,5,"Used this for an intro to programming; students loved it, and I found it very effective at introducing all the core topics I wanted to hit."
64,0735611319,http://goodreads.com/user/show/58663239-vladimir-fomenko,5,"Back in high school, this book made me excited about computer engineering and, consequently, heavily influenced my decision to become a software engineer. Strongly recommend."
65,0735611319,http://goodreads.com/user/show/71658-aj,3,"I am always interested in learning new ways to teach my students the fundamentals of digital logic, not to mention I also teach a follow-up class on microcontrollers, and sometimes teaching students how they go from the digital logic they learned last semester to something that computes can be challenging. So I'll always happily grab a book aimed for laypeople to see if I can grab a few nuggets from it.There were things I liked about this book, and things I didn't like about this book. I enjoyed the chapters on different types of code (Morse and Braille really), and, although dated, I did appreciate the discussion on microprocessors, (4004 and 8080, 68000), etc. Some discussions of memory I thought were good (although I teach and work with Harvard architecture microcontrollers). I skipped over the chapters about flip-flops (which, non-clocked, are actually latches, which the author took a couple chapters to state in the book) and computing hardware as that's all review for me. I agree with other commenters in that learning about every single opCode of a non-RISC-architecture microprocessor was just way too much, so I skimmed that part.Personally, if I were going to write a book like this, I probably would have used a RISC-architecture instruction set to explain assembly. I only know RISC-type instructions, being that I do not program or write assembly for computers, only 8-bit micocontrollers, and reading a thousand different memory addressing mode instructions for AND just made my eyes water. If it was inaccessible to me, who writes assembly for fun, then I can't imagine an average Joe reading this at the airport (not that people go to airports and travel lately, but I digress) is going to have a fun time with these instructions either. The author brings up the concept of RISC very briefly. I'm just guessing the author spends more time with complex architectures and that's probably just what he's more familiar and comfortable with.I guess I didn't not like the chapters I skipped, I just thought they were either way TMI, or not super interesting because I already knew the content. I suppose I appreciated how the author went from modulating a flash light beam to digital logic. But I know it's not exactly that easy to teach students binary and Boolean algebra, regardless of the analogies you use. Being that I literally teach this stuff and already have a very firm grasp on the concepts, I have no idea how understandable and relatable it is with people who are not already familiar with the concepts.Another thing to note, is that this book suffers somewhat from being 20 years old, but not a lot. When the author talks about memory and storage and clock speeds (and also how things like CD-ROMS are in ""nearly every computer""), the book seriously betrays its age. I mean, back in 1999 I never thought I'd need much more than a floppy disk to store things, CDs were for playing Sim Tower and listening to the Foo Fighter's first album on my dad's really expensive portable CD player that I always ""borrowed"", and we finally had a 56K modem, although in the middle of rural CDNY, we couldn't actually achieve such blazingly fast speeds in practice. I never would have guessed that 20 years later, everybody would stream music, store files on ""the Cloud"", spend more time on phones and tablets than computers (which certainly don't have CRT monitors anymore), and all of the other things we take for granted now. I would say the worst anachronism was the focus on single processor computers, but again, back in 1999 we just figured processors would always get faster, smaller, and more powerful, and didn't really know that the future (which is only true writing this in 2020, who knows what another 20 years will bring) was more on parallelizing operations and creating multi-core processors.But really, other than the anachronism here and there, this book does not suffer from age. Boolean logic is all still relevant, learning how you jump from a ""dumb"" finite state machine to a stored program computer kind of requires that you learn about the first stored program computers, regardless of how outdated they are.Usually the end of my reviews is where I recommend the book and to whom. I have a hard time deciding whom I'd recommend this to. See, anybody who has no idea about digital logic may enjoy the chapters on how logic gates are built but might not appreciate the later chapters in the book. Anybody who already has a grasp on Boolean logic and the basics of computer hardware is going to want to skip over almost the entire first half of the book. I guess, read this book if you're interested in how computers went from taking up an entire room to merely fitting onto a large desk, and don't be the type of person who has to read every page, open yourself up to the possibility that you'll want to skim or skip some parts."
66,0735611319,http://goodreads.com/user/show/59446308-samiron-ray,5,"There’s much to be distressed about the state of the technology industry these days. From ubiquitous smartphone addiction to Facebook’s undermining of democracy and mental health, it seems like we might be rushing headlong into building a dystopia. Maybe recovering a sense of awe at the underlying ingenuity of the technologies we take for granted will help us realize our responsibility to help steer the ship back in the right direction.And while CODE has no pretensions towards this lofty aim, it succeeds in proving a point often overlooked - that the computer as we know it is a work of high art in its own right, with great intrinsic beauty. Reading CODE felt like reading a work of great art criticism, a genre in which authors often illuminate how layers of simple structures can form greater systems of compelling aesthetic merit. In CODE, Petzold guides the reader through a deceptively simple yet thorough explanation of electrical circuits and Boolean logic by starting off with mere flashlights and counting with binary. By the time you’re only a little bit over a hundred pages into the book, you’ve already intuitively grasped the enormously consequential and sublime logic of Claude Shannon’s 1938 M.I.T. master’s thesis. Shannon’s paper was the first to establish that electrical engineers could use all of the tools of Boolean algebra to design circuits with switches. Shannon happened to chance upon a philosophy class teaching mathematical logic, after which he realized he could be the first person to apply the theories of Boolean logic to the vagaries of electric circuits. You might wonder what other fields of human knowledge have yet to be advanced due to lost opportunities of interdisciplinary synthesis. Later on, you’re treated to a marvelously lucid explanation of how we can design flip-flop circuits to store information, something which I found to be strangely moving in its rigorous logic. Then, we’re off to the races as Petzold builds circuits and systems of ever-increasing complexity, all the way until we get to the modern day computer (as of 2000). Like other reviewers, I must admit that the last third of the book felt rushed and lacking in the elegance of explanations that were abundant in the first two-thirds. But these flaws are well-counterbalanced by how admirably Petzold succeeded in his main task to enlighten us about how computers really work, and for that, I commend CODE highly. "
67,0735611319,http://goodreads.com/user/show/101748139-angel-castro,4,"This is the book I would like to read when I was 12 years old. For me, this book is a little piece of art for several reasons. The first chapters connected with me so deeply, because I was a child that played with circuits, lamp, and batteries (probably because my father was an electrician). And connecting electric circuits, logic, and computers was very exciting. Reading that part was like being a young man with lots of things to discover and experiment with. Another important good thing about this book is the writing style of Charles Petzold. The explanation of the morse code and the Braille system is very clear and didactic. Charles has a great skill to elaborate a technical elaboration without keeping the focus in the storytelling (especially this so technical texts). It's delightful to read this kind of book.The mid part of the book was a complete remainder of my first course in the college, learning the math foundations of computer science. Some portions were too deep in my opinion, but you can flip them off to the next chapter. If you, like me, have studied computer science, probably this part of the book is not going to teach you anything new, or something you can use to improve in your work. But I feel that the point of this book is not to be a reference book, but a discovery and remembering journey to the very foundation of this industry: to solve problems using your ideas that eventually will become pieces of technology. Here you will not find something that you can use tomorrow at work, but definitely it will become you a more grounded professional.The last chapters were an addendum to the original book conceived in 1987, so the edition I read was fro 1999. So expect references to how a floppy disk works. Computers were connected using modems or network cards, so no mention of Wi-Fi, nor mobile phones using GPRS, EDGE, UMTS, or LTE. So no state of the art technical details here. But anyway, it's something that you can start to discover own your own."
68,0735611319,http://goodreads.com/user/show/95027792-brendan-byrne,5,"In what other book would you learn how to count in binary by pretending to be a dolphin? In what other book would you learn hexadecimal by picturing a 10-gall hat, a football, a dozen doughnuts, a black cat, the moon, and a knife? Here's a hint: there aren't any.Charles Petzold takes you on a voyage from 0 to 1 and then from 1 to 10 with this incredible book that's really just a textbook for a difficult intimidating subject in disguise. By the end of this book, you will have learned new mathematical languages, built a computer, programmed an operating system, and glimpse the future of technology... from the year 1999. I only realized the publication year halfway through the book when there was a reference to what at the time seemed like an excessive amount of RAM which is by today's standards trifling. Despite this, the book remains a classic. I can imagine myself recommending it to anyone I meet and returning to it years from now.That's not to say, the book can be very challenging. I stuck with the concepts pretty closely, until the chapter on assembly programming. Like any kind of programming, the only way to understand it is by doing it, and the book makes no references or recommendations as to how a hobbyist could go about exploring the subject further. All of this isn't helped by the fact that programming is introduced before keyboard input is, so as a reader, I felt only the most tenuous connection to what was occurring on the pages. Trade-offs have been made with tackling a daunting subject matter through an accessible lens. At the end of each chapter, I'd have appreciated more resources, clarifications, applications, or maybe even some questions. But the entire mood and light feeling of the book would have been lost if any of these had been included. You can read it straight through and not feel oppressed by the knowledge contained within. In other words, there isn't any other book like it."
69,0735611319,http://goodreads.com/user/show/74555970-dan-drake,3,"3.5 stars.Petzold does a great job of showing the historical and technical trajectory of going from a problem such as ""how can I communicate with someone using just a flashlight?"" to a full-fledged modern computer with a keyboard and display that can run arbitrary programs.It does seem to start slow and then accelerate dramatically. It all seemed pretty ho-hum to me until the chapter where he went from logic gates built out of relays up to a full adder. From there, it's surprising how quickly you can work your way up to a pretty modern computer.This is a great book for getting a sense for how a computer is, in a way, an amazing emergent system: you start with relatively simple physical phenomena (the idea of an electrical circuit that may or may not have current flowing through it -- that is, it's on or off) and some simple concepts (basic logic like 'and', 'or', and so on, as well as arithmetic) and suddenly you have something complex and amazing. For anyone who enjoys this book, I'd recommend the game/puzzle Turing Tumble, where you can build marble-powered computers. (Yes, it's Turing complete!). If you insist on a book -- this is Goodreads, after all -- I'd recommend The Information: A History, a Theory, a Flood for the mathematical/information side of computing. There's also The Secret Life of Programs: Understand Computers -- Craft Better Code although I haven't read that.One quibble: Petzold writes hexadecimal numbers using an ""h"" postfix, such as ""5Ah"". I'd prefer he used the more common ""0x"" convention: 0x5A."
70,0735611319,http://goodreads.com/user/show/16474436-jinn,3,"This is not the kind of book I would normally read. But I found a free PDF of it somewhere online, put it in Evernote to read someday, and started it because I'm at my new job for 5 hours every day and I have about 1.5 hours of work per day.Code is an interesting book. It takes you through the technology from the telegraph to the computer, and explains a lot of concepts in the meantime. Reading it was the first time I felt like I actually understood Boolean algebra or non-base-10 numbering systems like base-8, base-12, and even binary (base-2).On the other hand, computers are complicated. I'll admit that the part where he explained how computers use circuits to store information and read it back out went way over my head. If you don't have an extremely mathematical, mechanical, or engineering mind, it might not be a bad idea to have an engineer or computer expert on hand to explain some of this stuff to you.This book is a little outdated - copyrighted in 2000 - and doesn't cover a lot of newer technological advances like smartphones or even the video capabilities of computers. (Towards the end, Charles mentions that videos displayed on computers are poor quality and jumpy.) It's a good book to understand how computers exist, how coding works, and the way electrical currents can store things as complicated as text and images, but you're not going to get anything about the sheer power of modern computing.This is a short review because I really don't have a lot to say about this book. It was interesting. I learned a lot. Some of it was complicated and I really didn't understand, even though Charles did his best to put it in simple English. Code was interesting and useful, but there wasn't anything really spectacular about it."
71,0735611319,http://goodreads.com/user/show/31164641-michael-gaudet,4,"This book was a good low-level explanation of how computers function, starting with the absolute basic electrical level right on up to macro-level things like user interfaces and codecs. Overall, it was very informative but not altogether engaging— and I’m a developer up to my eyes in computers all day every day! Some of the chapters are really showing their age, especially given the rapid increase in tech over the last 10-15 years. This book probably hasn’t been updated since before 2000, and hardly even mentions anything beyond a 300-baud modem. I appreciated that the author takes the time to explain all the basic concepts of each thing mentioned, whether explaining how electricity is measured, to “modem” being modulator/demodulator, to how to pronounce “JPEG.” There are no assumptions made here.On the other hand, some chapters are extremely dry and hard to follow, though probably not the authors fault. The middle of the book, discussing mid-tier processor functions, I must have put the book down every other page. It’s a slog, but the end of the book was very interesting for a person of my age. I was too young to have a PC around during the initial years of the internet, so those early 90s developments (that ended up guiding current tech) were interesting to hear about.Still, I feel like the first part of the book is done in painstaking detail, and the last third of the book glosses over a lot of things at a high level. I’m not sure if the author is still writing, but this one is badly in need of a refresh. (Maybe that in itself is a commentary on how tech has changed in the years since this book was first published! Books are no longer a fire and forget work. Consumers expect to download them electronically and get updates. Odd!)"
72,0735611319,http://goodreads.com/user/show/3273779-mirek-kukla,4,"A must-read if you're a software engineer (though likely pass if not). While ""Code"" tries to be a pop computer science book, I can't imagine recommending it to anyone that doesn't have some kind of technical degree (insofar as that's a proxy for ""being into this kinda thing""). That said, if you are into this kinda thing, ""Code"" is a delightful way to learn a lot, and a borderline CS classic.In the first half, Petzold walks you through ""building"" a basic computer unit from scratch, using nothing but morse-code like relay gates. You'll construct various logic gates, which you'll use to piece together things like an adder chip, a RAM circuit, and eventually a basic computer.In the second, you'll learn how to program said computer via machine code. Along the way you'll cover topics big / small endian integer encoding, ASCII character representation, and floating arithmetic. All of which is to say: you probably already know whether or not you're interested.The book is pretty technical, and arguably closer to a textbook than, say, your average pop math book. It's also a bit rough around the edges: a few chapters are entirely skimmable, due to being either overly basic (e.g. explaining binary arithmetic) or overly specific (e.g. detailing machine code quirks specific to the long-outdated Intel 8080).But on the whole, ""Code"" is pretty great, and packs a dense punch of learning in an impressive approachable package. I had countless delightful ""aha"" moments, and I left thinking it's a shame there aren't more books like this. ""Code"" is one of those books that ought be on every engineer's bookshelf - except this one you should actually read. You might even enjoy it."
73,0735611319,http://goodreads.com/user/show/27472296-paulina,3,"The summary is a bit misleading, suggesting a lighter tech non fiction book. I picked it up in a bookshop and knew what I was getting into - it’s my jam; people who don’t spend that much time in this neck of the woods and would rather read something a bit gentler and more introductory, might find this daunting.Code suffers from a popular science nonfiction malady, in that it attempts to pander to both very technical people and beginners. It goes into too much detail, some of which is negligible, and then it only skims over certain theories that would be more interesting. For some, even circuits will be a bit much as there is a deceptively easy jump between gates and making complex circuits that many people will find hard to visualise and build on. I supplemented this with the Build a Computer course on coursera which is pretty rad and enables you to build circuits with the use of software (quite fun!). It is in historical anecdotes that the book’s strengths lie. Charles Petzold is quite good at establishing the narrative of an invention, giving it sense and background that make science easier to grasp. It may be that it’s also my way of grounding knowledge, in all fairness. But even these historical anecdotes are dated; he depicts Ada Lovelace as merely an amanuensis whereas it has been established since then that she was instrumental in Babbage’s work and contributed a lot to its development. But on the whole, the book is quite good even if it should not be read in isolation."
74,0735611319,http://goodreads.com/user/show/6764338-simon,4,"This was recommended to me by MichaelBolton while he taught me and others on a software testing course, advising that this book would be a good way to get a grounding in how computers work, and that this would be beneficial for a tester.I agree with Michael's idea. I for one don't have a computer science background, so some of this information was very new to me indeed, and I simply wasn't interested in electrical engineering (and most physics) while at school. Now it is much more interesting to me, and the author tells it in such an engaging way too! He deserves great credit for this.I believe this book came out around 2000? Obviously technology has changed significantly in some aspects since then, though not so much in others. Well written, creative books like this will always have a place, he describes some of the history while also exposing how things work. My only (small) gripe is the last chapter. It just seemed rushed, tearing through a wide area of scope (and one that was seriously taking off from the late 90s so it would have been a big deal at the time of writing), I felt it wasn't in keeping with the pace of the rest of the book. Furthermore, that same chapter finishes with a one paragraph kind-of-prologue rather than a dedicated few pages. Given the author has just entertained us through 300 years of computer-related thinking and inventions, I'd have liked more of a 'farewell' from the author - shows how much I was enjoying it I guess."
75,0735611319,http://goodreads.com/user/show/17363208-higaguin,5,"It took me a while finish this book, first because was on English (it's not my native language), and second because it's a complex, semi-tecnical book that decerve all the reader attention. I keep in mind that it's not an easy book to write; Charles Petzold had to assume that the reader doesn't know anything about computers and further more, it doesn't know (or doesn't remember) some maths, physics, etc..., Like i'm discribing it, it start like a very simple book, but only in the begining, from the middle to the end it's really a journey, a kinda difficult and unusual for a book journey, but most important, a pleasent journey.It's hard to critic this book because achieves the gold, make the reader understant how a computer works, but i have some reserves mainly in the too technical parts, i think that Petzold could remove some pages about how a byte adds to other byte, or how is a substraction between bytes, or that kind of stuffs. As i said, it must be very difficult to write a book like that. Other than that, i really enjoyed, especially the history briefs that involves the conception and the evolution of the machines that i use every day and got me a way to live.Just to finish this short resume, i (like many others) am a Software Engeneer and i can detect many proofs of love by Petzold, if you are a coder or an engeneer, make sure to have a look at least a few pages. I recommend the final chapter,a really wonderful one."
76,0735611319,http://goodreads.com/user/show/75521131-joao-almeida-domingues,4,"3.5######I had seen this book in just about every CS intro “must-read” list and I finally picked it due to a recommendation of my intro to systems lecturer. I needed two questions to be answered since my Boolean algebra lessons in highschool (that somehow I never decided to google)1. Once a gate is off, its output becomes 0. But how can then inputs be carried forward? How can “nothing” be a input? It was answered roughly 200 pages in, and it confirmed my suspicion that a 0 was not really a 0, but a range of voltage values which map into 0.2. What the heck is a transistor really?This again was answered about 250 pages in. Until I got my answers I got to hear even neater facts, and anecdotes of electronic systems. The birth of ASCII (who knew Braille was involved?!), how telegraphs were automated with relays, and in turn how relays can be represented by transistors... and how cool are oscillators and flip-flop switches... loads of interesting stuff that really delved into the inners of computing.At times though I think that Mr.Petzold went a bit overboard,I felt that there were a lot of material which killed the flow of the book, and the work would have benefited from an appendix. (Were 3 pages of opcodes really necessary? )TL;DRIt is a very broad book that goes from morse code until html, in the meantime connecting every chapter almost seamlessly which is pretty cool. However, one can tell that Mr.Petzold is a buts & bolts kind of guy, and his writing suffers from it. Need to add it to my physical library for re-reading"
77,0735611319,http://goodreads.com/user/show/20168840-alexander,5,"a much better way of looking at this book is not as reading it as an introduction into coding - but a fantastic introduction into the evolution of how man communicates with technology (which will no doubt enhance your programming experience, and, as the book claims, “awaken the the technophile within.”) this book is as much of a history book - maybe moreso - as it is a practical “introductory” text about coding the discussions of concepts such as machine coding and computer science terminology like the ASCll standards are of no doubt of invaluable importance to anyone who is interested about coding, but in the case someone (like me) is wanting to pick this up for a “hands-on” introduction into coding, you wont find it here, but you should definitely still pick this up. the author doesn’t discuss any (in the modern sense) coding, let alone any programming languages until the last 100 or so pages, but he does this for very good reason. he traces the history of communication and truly helps you appreciate the importance of all the important technological concepts from things like floating and binary numbers to transistors and processors.i fully recommend this book, but not as an introduction into coding as for a history of computer science and computers. anyone interested in coding should still definitely read this though, as it will immensely appreciate your love for programming "
78,0735611319,http://goodreads.com/user/show/7030881-xavier,3,"I wanted to like this book more, but because of the dense explanations detailing the smallest of details in a way that, for me, was hard to follow made this an average 3 star book. I do not feel it is beginner friendly, and I had to bulldoze my way through at times. This is not just my observation; author admits multiple times this is very dense material (pages 206 and 308), and it’s not without its typos (pg 232 “distinquish”) nor without stretches of what I would safely assume to be objectively boring parts namely the lengthy explanation on printer machines and punch cards (but if you liked these parts all the more power to you!). The printing quality is also to be desired as the lines are not always perpendicular to the page. Re-explaining key concepts and major parts of the computer would’ve greatly helped in understanding this very dense material (complex material starts at around 100 pages in). It’s odd he instead chooses to reiterate over simpler terms like complex numbers and compilers (pages 354 and 362). However, the upsides of this book is that you can at least obtain a general idea of what the major concepts of computer science and computers are, but for me it will require rereading over the content and finding further material on computer architecture."
79,0735611319,http://goodreads.com/user/show/90375695-chris-vaughan,5,"A truly remarkable book. In under 400 pages it takes the reader on a journey through the birth of computing, and does so in an amazingly coherent fashion.If you've ever wondered how computers really work, then this is the book I would recommend. No knowledge is assumed. The important concepts are explained from first principles, and then built on. If it seems like this would be dry, it really isn't.Throughout, explanations are clear and concise. If you flip through the book you'll probably spot dozens of impenetrable-looking diagrams. Read along, and you'll understand them.The the opening 10 or so chapters are simply magical. Unfortunately this can't be sustained the whole way through. I think this is a consequence of it needing to cover ground quickly and also the goals becoming more abstract. It's much easier to tell a story about the need for Morse code than it is to tell one about the need for a system bus inside a computer (and if you don't know what a system bus is, you will if you read the book!). That said, you'll either be hooked by this point or you won't.The only real let down is the last couple of chapters. Both felt a bit rushed and slightly. But these chapters in no way diminish the brilliance of what precedes them. A very special book indeed."
80,0735611319,http://goodreads.com/user/show/18402070-daniel,5,"This book was clear and illuminating. The core theme of communication allowed it to cover many topics related to history, hardware, software, discrete mathematics, etc.I read this book after my first year of studying computer science at university. It gave me exactly the broad foundation that I was looking for. Petzold's straightforward style and use of diagrams helped make topics that could have been counterintuitive feel understandable. That being said, I wouldn't exactly call it light reading--some of the chapters, especially the later ones, require a lot of time/thought to follow. I'll admit not every section of the book sunk in for me, but I still got a lot out of it. (Though, I think Petzold did as well as one could in simplifying such technical topics). It's also worth noting this book was written in 1999, so statements about 'modern day' technologies are outdated, but the history/fundamentals remain the same.This book made me gain a much deeper appreciation for the complexity and elegance of computers. I was a little sad when I finished it, which isn't something I can say about many nonfiction books."
81,0735611319,http://goodreads.com/user/show/30793608-andrei-faur,5,"I wish I had this book during my undergraduate studies. It wonderfully ties together concepts from basic electronics, digital logic, assembly programming, computer architecture and a few other topics related to computers in a way that is extremely accessible and easy to understand. I would make this book and the nand2tetris course mandatory readings for undergraduate programs in computer science (and related areas).This books focuses on the _why_ of things, which is a question often overlooked. My undergraduate program focused a lot on the _how_ and I feel that that led to a decrease in critical thinking and analytical skills. We should never stop asking ourselves why things are the way they are for surely that can only lead to blindly following rules and being unable to see improvements (this reminds me a bit of Feynman's story on the educational system in Brazil).The latter chapters are perhaps a bit dense for a layman but the first ones are extremely accessible for everyone, no matter their background.I hope this gets updated at some point with a few chapters on the modern state of computing."
82,0735611319,http://goodreads.com/user/show/9277530-kimee,4,"I am embarrassingly returning this book three days late to the library, because it is so good and there is that much to digest. I blazed through the last half to try to finish as fast as I could, which was unfortunate because I do feel like there is a gap between the first and second half of the book that I missed and made it a lot more difficult for me to understand. The first half was fantastic, though. I felt like I could understand binary and how morse code could lead to computing. Highly recommend, will likely re-read. // Raw notes to remember - Concept of Earth, ground, as source for electrons - Electromagnets and the telegraph - A wire, a switch, a light bulb, can be a binary digit - Bit: basic building block of information - Morse code converted to bits - Adding and multiplying classes with logical operators - Input and output devices with light bulbs - AND, OR, XOR gates visualized through lightbulbs - Sum bits and carry bits; going from this to computer addition - RAM (Random Access Memory) - I need to better understand and practice the metric system "
83,0735611319,http://goodreads.com/user/show/27464243-evan-oman,5,"I absolutely loved this book. Petzold builds up the ideas behind computation from basic concepts (like using codes to talk to a friend with a flashlight) all the way to actual microprocessors and programmable computers. Petzold wonderfully motivates each new enhancement (read: complication) in service of the goal to communicate or add numbers or write general programs. He explains technological advances as clear, logical progressions in a very engaging way.This book filled so many gaps for me as a professional software developer and I now have a much better understanding of what is going on deep inside the machines I work with. I also loved all of the historical notes about the (sometimes distant) origins for all the tech we take for granted.Word of warning, however: the chapters where he builds a programmable computer from scratch using basic circuitry is very dense. I can't say I completely internalized those chapters but I still learned a lot. One benefit is that you will certainly feel good about yourself if you can make it through -- after summiting that peak the chapters that followed seemed to fly by!"
84,0735611319,http://goodreads.com/user/show/95838095-alex-galea,5,"This book is simply a must read for programmers. Charles goes into incredible detail in building a computer from the ground up, much of which I admittedly skimmed over. This detail and his clarity in writing would make it a great book for those studying electric circuits (I certainly wish I had read this before my 3rd year undergrad electronics course).The first thing that really blew my mind in this book was the authors explanation of different base number systems, such as base 2 (binary), base 8, base 16 (hexadecimal) and so on. It was mind-altering to see how arithmetic works in these systems and to realize that base 10 was only selected because we happened to have 10 fingers on our hand.It was cool to learn about the origins of the bit and indeed the byte, which originated at IBM in the 1950s. I learned why I keep seeing ""x86"" and 32 bit/ 64 bit processors, how single and double precision numbers came to be and how they are stored in bits, and even - surprisingly - how a CD-ROM works. In fact, there are tons of little surprises in here that make this a must read for everyone interested in computers."
85,0735611319,http://goodreads.com/user/show/43542157-nishant,4,"A wild, familiar ride throughout the history and engineering behind the computer. The book is written in an engaging manner, and elucidates the importance of the union of electric circuitry and logic operations in the birth of the computer. It also delves into topics addressed by multiple courses of an undergraduate CS degree (in a much more interesting way), and I came out with a better appreciation for these topics than I did when I studied those courses for my degree.I'm not altogether sure how much of the book would be an easy read for a complete beginner though. Certainly, the initial chapters are very engaging and I read through the first half of the book in a sitting. It's the latter half of the book that's relatively dense (and the topics are too, to be fair). In the chapter where Petzold dives deep into 8080 opcodes, I found that my cursory knowledge gleaned from college helped ease my reading a bit. For people interested in tech I'd say this is a great refresher and fun read in general. Reading this makes me want to re-watch Halt and Catch Fire, and I probably will."
86,0735611319,http://goodreads.com/user/show/83997847-leo-desmedt,4,"This is a smart way to explain how computer works. I genuinely enjoyed the simplicity and technicality of what the author communicates. The components are explained one by one together with some very basic courses on electricity and a quick history of how we happened to have the firs laptop and components.Those components being explained from the first circuit ever created till the micro\nano-processor most commonly used nowadays across all our devices. This book is truly immersive in the science of computer and made me realize how far and how fast tech changed. A few decades ago we were still in KB and now nobody would ever think under a GB would be possible in terms of memory, storage..This book is written with a real passion and understanding. I would recommend to anyone if you truly want to understand how our daily devices work. It's written simply but not so easy to understand as it contains quite a bit of coding languages in the explanation. Highly advised take some notes to help you following the whole story without missing a byte! "
87,0735611319,http://goodreads.com/user/show/101128473-christopher-johnson,3,"While an older book focused on an ever-changed topic (computing), this was nevertheless a timeless read that is valuable for anyone with an interest in computers, hardware, programming, or technology. Overall, Petzold uses a good progression, starting from understandable concepts like morse code or braille, and slowly moving into the computer world through simple circuits, accumulators, CPUs, and ending with the ""graphical revolution"" of the 1990s. I give this book a 3/5 as even with some context of the technology and functionality of code/computers/programming/etc., it was still fairly difficult to digest, and I would go so far as to say it leans towards functioning as more of a textbook. Moreso, there are several points where the focus becomes too narrow, and it fails to deliver the ""big picture view"" (i.e. an entire chapter is dedicated to discussing two different types of microprocessors). All-in-all, it is nevertheless a fascinating read with a wealth of knowledge on the topic, and a great foray into code and computing for those who want to learn more."
88,0735611319,http://goodreads.com/user/show/4806621-andrew-russell,3,"I am, like some other readers, somewhat conflicted about the book. It starts out really engaging, funny, and informative. I found myself however losing interest with each passing chapter as the important basic concepts seemed to be overwritten with overly detailed explanations of less essential information. Occasionally you could find super interesting information buried in such chapters, but it was so hard to get through some of the more dry information (such as extremely drawn out details of the 8080 microprocessor...) that I found myself simply glancing through lots of paragraphs without focusing on each word or table. I think the book combines too many potential goal audiences in one and dedicates too much time to very niche details. The book does deserve lots of credit. It amazes me the amount of knowledge the author has and dedication in putting all this information in one book. There are many historical aspects that are fascinating to read and understand why certain things that are so commonplace today are the way they are and how they came to be."
89,0735611319,http://goodreads.com/user/show/60635443-gil,5,"From the title, I was not expecting this book to go so much into the hardware. It really helped my understanding of how computers work, introducing the concepts from the very beginning in a straightforward manner. One could build a basic computer by building the explained components and putting them together.One should also not be turned away by the fact that this book has been written in 1999. There is a lot of change in the field of computer science but this book covers the absolute basics, so it will remain relevant. It's only on the last few chapters, that it becomes apparent that this is no longer the way that things are done. Some of the ""new up- and coming"" technologies discussed in the last chapter are the internet or DVDs.It would have been very beneficial to me if I had read this book at the beginning of my university studies as it really provides an excellent overview of all the different parts of a computer which work together and can be studied in more detail in individual courses (e.g. operating systems)."
90,0735611319,http://goodreads.com/user/show/1666575-senthil-kumaran,5,"This is a highly influential book in the subject of how Computers work from ground up. They author deals with the subject and introduces computers as if they were a natural evolution of inventions that had already taken effect and had proved useful to the society.After introducing the various needs for communication, the author explains how it can achieved using bulbs, and then chips, and then how it is stored and done at the higher scale using Computers. He goes both in the Hardware as well as Software section of how computers work, and why we need operating systems and programming languages.The section on float point arithmetic caught my attention and imagination completely. This was a lucid explanation on storing decimal valued numbers using binary digits.I throughly enjoyed this, and is already helping me appreciate some of the basic concepts used in Computers and Computer Science. "
91,0735611319,http://goodreads.com/user/show/10738211-oliver-stevenson,5,"Long and thorough, this isn't a read for the faint of heart. But for time put in, it rewards in spades.If you enjoy understanding how things work, and you are determined to understand (early) computers, this book is for you. It will take you from first principles you probably learnt in physics at school, all the way up through the inventions and discoveries of the 20th century that culminated in the first commercial computers.Be prepared if you do have some basics down you may want to skip some early chapters, but the book still reads well as they are self contained. Later chapters reference the computers of yesteryear as this is a slightly dated book, but all of the concepts are still the same.This helped me become an embedded programmer despite a total lack of experience in it specifically (computer science degrees just don't cover this stuff generally) - so I consider that a ringing endorsement."
92,0735611319,http://goodreads.com/user/show/45939582-salman-mustafa-husain,4,"A constant problem I feel many books attempting to explain obscure stuff have is the compromise between covering the fundamentals and going deep into the subject. While the former pleases the tyro and bores the experienced, the latter leaves the beginner in doldrums in an effort to interest the advanced. And the intermediate-level readers? They are often left uncatered, and their search for a Goldilocks book is seldom fulfilled. Well, for those interested in how computers work, this is close to being the Goldilocks. This book patiently drils in all the basics (for roughly the first 10-12 chapters) before embarking onto new territories. Yes, there are some daunting terrains, but Charles is there to lend a helping hand, linking everything together so that you can stay with him. And if you manage to do so, you'll come out knowing a lot more about how those ubiquitous machines which have become indispensable to all of us do their magic."
93,0735611319,http://goodreads.com/user/show/32471094-anthony,5,"I must admit that I couldn't get through the whole book. My brain could handle all the chapters up to a discussion of memory. I could understand how RAM works, but from there on, it got increasingly abstract and increasingly difficult to comprehend. With all that said, the first half of the book explained what computer is and how it generally works. As I understand it now, a computer is a logical system. Circuits (doesn't matter what they are made of) are designed to respond to input information in a predetermined manner. Computers work on a binary numerical system. While it is possible to program in 0s and 1s, the process would be very inconvenient, therefore we use programming languages. Commands in programming languages correspond to specific binary codes, which when input to computer, go through computer circuitry and produce a certain result.  "
94,0735611319,http://goodreads.com/user/show/46237218-swann-polydor,3,"While there are no doubts about the quality of this book, I remain hesitant about it.The first few chapters introduce concepts and stories as to why Morse and Braille codes came to be a thing and how your 10 years old self could have used it to communicate with your neighbors without your parents figuring out or how you could read at night without the need for light.The construction of Braille is very interesting by the way, it allows for a lot of shortcut and it looks quite optimal.The problem comes from the many others chapters talking about electrical circuits and not using much analogies anymore. I believe this schemas are a bit too simple and overlooked for anyone wanting to grasp the insight behind it, and I believe they are too complicated for someone who just wanted to enjoy a good book about code as a whole."
95,0735611319,http://goodreads.com/user/show/83437626-mauro,4,"I've been a programmer for decades, and even played with assembly language and wrote emulators for ancient arcade games. But I must confess that, before reading this book, what went on inside a CPU looked a bit like mysterious black box technology brought by aliens from outer space. This book goes a long way toward dispelling the magic as it introduces Boolean algebra, shows you how you'd build logic gates from relays, then arithmetic circuits, flip-flops, and a simple CPU.I ended up skimming through the later chapters as it covers outdated material (EBCDIC...) or stuff I'm already familiar with, but the chapters on logic circuits are great. I had a bit of fun playing with some of the circuits in the book with a simulator. Now I really want to learn VHDL, get a FPGA dev kit, and who knows, maybe build my own CPU."
96,0735611319,http://goodreads.com/user/show/91599624-andrew,5,"I cannot recommend this book enough for anyone interested in the inner workings of computers. Beginning with telegraph relays and simple circuits, Petzold builds through logic gates and other small circuits like latches and converters. This culminates in a machine which can perform all four basic arithmetical operations, store results in memory, and provides input and output to the user. All of this is built step-by-step in easy-to-follow exposition. Before this book, I've programmed in C, C++, Java, and other high-level languages. This book makes me want to learn Assembly so I can get closer to the machine, following the examples set out in this book. I will likely read it again, and I reiterate, I cannot recommend this enough for anyone involved in software development or programming of any kind."
97,0735611319,http://goodreads.com/user/show/17947807-ally,5,"This book is what I imagine the middle would be if you had a spectrum of “CS/SE/CPE Textbook……Biography of Bill Gates (on Netflix!)”. The author is very very patient. Like seriously, it start with blinking flashlights. I Get It Now. I read this book because a student came into a writing lab and asked if their figure in a scholarly article “adequately explained the CRISP module in a neural network”. I realized that my lack of “computer language” was actually starting to be a problem. I don’t mean of the can-you-print-to-PDF variety, but, that I don’t know – how coders/programmers/software engineers/computer engineers/etc. approach/solve/structure problems and the basic vocab terms around computer stuff. Amazingly well written, highly recommend to understand how information is communicated and problems are solved today. "
98,0735611319,http://goodreads.com/user/show/34638954-kirill,5,"This is a must-read for anyone interested in computers, computer science, electrical engineering and the history of computing. The book is like the Powers Of Ten (https://www.youtube.com/watch?v=0fKBh...) for computers. It achieves an ambitious goal of explaining how computers are built right from the most basic electronic components: switches, which later change to telegraph relays and transistors. In the book guides you through building a simple Turing-complete computer, and later explains a high-level overview of how software builds upon hardware level-by-level. In the end, it overviews operating systems, programming languages and peripherical devices like monitors and disk drives. And all of this is supplemented with interesting historical facts, which make the book quite a journey. "
99,0735611319,http://goodreads.com/user/show/107722441-robbe-sneyders,4,"In this book, the author 'invents' a computer starting from nothing but logic, and builds it using the most basic components. The first chapters progress quite slowly, but are so well written that there is never a moment of boredom, just a desire to keep reading to learn more. At the end, the reader is left with a complete picture of how a computer works, and at least for me, a deeper understanding than any of my university courses could provide.Once the book gets passed the chapter on Assembly though, the pace increases and the chapters seem less focused. Instead of explaining a single concept, they mostly provide an overview of available technology at the time of writing (1999). While they still contain a lot of useful information, the reader has to put in quite some effort to extract it.5 stars for the first 16 chapters. 4 in total."
100,0735611319,http://goodreads.com/user/show/49504536-alex-korbonits,4,"In < 400 pages we went from simple circuits, to a whole computer that can run programs compiled or interpreted from high level programming languages. Wow. Relays, circuits, logic gates, adders, memory, registers, machine code, assembly, ROM, hard disks, operating systems, floating point numbers, and high-level languages.It's at a high level -- very accessible -- and now I feel like Neo in the Matrix when he learns Kung Fu. Now I know how a computer works.Didn't rate a 5 because it's a tad outdated (1999!) and I thought too much time was spent on specific op codes for the Intel 8080 and Motorola 6800 -- this section got a little boring. So did some of the advanced circuitry. But overall I was impressed."
101,0735611319,http://goodreads.com/user/show/108962401-aziz-m,4,"When you think about modern computing devices like laptops or smartphones there are always some level of abstraction of how you interact with it. Users interact and navigate through touches/clicks to instruct computer to do smth. Programmers use high-level programming language to instruct computer to do smth. But how does it really work under the hood? That's the question this book is trying to answer. It's structured so that you have layers of abstractions and it starts from bottom like flashlights, morse code, binary system, logical gates, expressing text, storing in memory and all the way to graphical interfaces. This can be useful for programmers who want to understand lower level abstractions than what they work on."
102,0735611319,http://goodreads.com/user/show/2591322-jodie,5,"This is an excellent book which I would recommend to anyone, not just computer scientists. It manages to explain the evolution of computers and how they work from the ground up, in a way that is entertaining, non-condescending, and technical but can be understood by anyone. I was excited to see concepts from many of the classes I've taken at Stanford here (CS107, CS103, E40M, Math110) such as assembly language, floats, logic, circuits (switches, buses, etc), and error-correcting code. This book explains all these concepts really well and ties them together in a way that is breathtaking. It's really quite amazing to think about how far computers have come due to the insights of many talented people. And I'm glad that I now understand more about how they work from reading this book!"
103,0735611319,http://goodreads.com/user/show/36733921-oscar,4,"This book finally answered some of the questions about computers that I had kept for a long time, or that I had tried asking to some people (who didn't manifest a great depth of knowledge or an ability to make things intelligible) in a way finally understandable, complete and at the same time synthetic.The only catch is that some points of the book are unusually dense, so that the reader will need to pause a little in order to digest the concepts or ponder accurately over what was explained, or be content with only giving a cursory read to the explanations in order to progress smoothly. These, in my opinion, had to be expected characteristics of the book, and every reader should tackle them as they prefer.Overall, though, this is a very good text and highly recommended (presupposing a bit of interest from the reader) for learning about the fundamentals of computers, and even though I started reading it more than a decade after it was published, I doubt that the fundamental functioning of today's digital technology has changed so much since the time of its writing. That said, it deserves a solid 4.5 stars evaluation."
104,0735611319,http://goodreads.com/user/show/5076380-connor-stack,5,"The title sounds like some shallow pop science best seller, but it's actually very deep and technical. At the same time, it starts from a point that nearly anyone could understand: how a flashlight works. From there it builds up in complexity until you've designed a computer. The last few chapters talk more about special topics, history, and ""modern"" technologies (from the early 90s when the book was written).Highly recommended to anyone interested in how computers work. It's a weird mix of a college-level computer architecture course and an ""explain like I'm five"" description of computers, but the style really appealed to me."
105,0735611319,http://goodreads.com/user/show/69576845-shubhang-goswami,5,"What an AMAZING book, I wish I had 10 stars to give. I ABSOLUTELY love it, something I will read again for the sheer joy it brought me. I had always wondered how a computer works and was not interested in analogies and metaphors but the actual components. Charles treats you like an computer engineering undergrad and takes you from bare bones morse to sophisticated Mac n Windows PC’s with visual interfaces. All the while telling you about actual components and how they work together.What a fabulous read. If you ever wonder what voodoo magic makes your computer work, this is a must read for you."
106,0735611319,http://goodreads.com/user/show/12454268-pablo,4,"In this book, Petzold walks you through the process of building a computer from first principles: binary code, logical gates, and integrated circuits. Even though is a bit outdated, the content is tremendously useful to acquire a deep understanding about what is going under the hood when you write code (on higher-level languages like Python or Java) or simply using a computer in general. It really answered several unknowns that I have been carrying since I started to learn how to code. It is the type of knowledge that can make you a better programmer as you get to understand things like memory allocation, data representation, and the discrete mathematics underlying boolean algebra. "
107,0735611319,http://goodreads.com/user/show/57645120-tony-cheang,5,"I had taken an in-depth class on the transistor and been programming consistently for a few months now, but I didn't know what happens when you compile and run code. This book filled in the gaps. It builds up a computer from simple circuits. Petzold starts with light bulbs, wires, electromagnets, and logic, then builds that into logic gates, adders, and memory. Automation comes next with assembly/machine code programming, then he finishes the book with some history of computation/computers. A few of the chapters were difficult to get through (he sometimes even mentions this), but overall the book was very illuminating and contains accessible examples."
108,0735611319,http://goodreads.com/user/show/1767240-adrian,5,"Extraordinary book! Highly recommendedCODE is one of those rarest books which make me worry when getting half way through because it means it's going to end and I will miss it. Charles Petzold is a most accomplished writer with huge technical skills who manages to explain complex issues by breaking them down into small edible chunks.Furthermore, by providing the history and the why of how something came to be, he makes sure you will have a clearer understanding of the discussed issues. As a long time programmer, radio amateur and electronics aficionado, I enjoyed every bit of this book. Highly recommended!"
109,0735611319,http://goodreads.com/user/show/28363317-andrei,5,"well this year was kinda slow in terms of reading and this will be the last piece i finish till the next one and honestly i should have finished it earlier as some of the concepts presented were actually used in an exam i had. very good resource if you wanna learn about how a computer works from ground up. very good introduction to electronics as well. tons of useful and interesting information, also nifty tech jokes and sarcasm here and there, loved the way it was written.only downside would be some things mentioned are outdated but given the book was published around 2000 its no wonder the most common display resolution back then was 640x480"
110,0735611319,http://goodreads.com/user/show/102463935-ethan-fischer,4,"Loved the history lessons and the nitty-gritty descriptions of how circuits and logic gates all build on each other to create the computers we all know and love today. The first 2 thirds were exciting because it felt like the knowledge was building on itself and you were going to arrive at a firm understanding of how everything works. But then the last third or so sort of lost the feeling of cohesion, and felt more like a laundry list of how different things work. The ending was especially abrupt and fizzled out. But I learned a lot and appreciate the approach this book took. Would recommend for anyone interested in programming and computers"
111,0735611319,http://goodreads.com/user/show/74032104-rowan-lawrence,5,"Excellent guide of how digital computers work at a fundamental level, and despite the original publication date it would be difficult to call this book out-dated until we truly move past the use of silicon. Excellent depth for those with a little prior knowledge and the gentle lead-in provides a fantastic introduction.Very rarely gets weighed down with ill-fitting metaphors and examples, instead using (as the name suggests) codes, such as Braille, Morse, and Telegraphs to explore the growing complexity of computers."
112,0735611319,http://goodreads.com/user/show/54277876-vadim-yanko,5,"One of the best tech books I've ever read. It is really fascinating how simple problems such as communicating with your friend living next building via flashlights or how you are deciding which kitten to buy lead to solutions related to math, engineering, and programming. Which I like most in this book that the author describes a problem underneath every solution or breaking point in technology evolution. I recommend this book to everybody who is willing to understand how devices you are using every day were built."
113,0735611319,http://goodreads.com/user/show/87391015-panagiotis-jones,4,"This is an excellent approach to the computing world from the bottom (actually even lower!) all the way to computers in the author's era (late 1990s). It unfolds as an imaginatively interactive story that gives you a sense of participation in the conception and evolution of computers (and more generally digital signals).I would not recommend this to someone already fairly knowledgeable in the field except for leisure reading. I would recommend this to someone who is exploring the realm of computing and who appreciates a slow approach, from the very beginning of the beginning."
114,0735611319,http://goodreads.com/user/show/103093632-max,4,"I enjoyed this book and thought of it as a good companion / follow up to the mooc nand2tetris.4 stars b/c I enjoyed learning about the history and design of computers down to the bits and hardware. I also enjoyed the author’s sense of humor.1 star off b/c it sometimes felt dated (mostly near the end) and that it sometimes lacked explanation I would have appreciated (e.g. fixed and floating point numbers, and some of the circuits). I’ll definitely return for enjoyment and deeper understanding."
115,0735611319,http://goodreads.com/user/show/27266054-ally,3,"Code details the history of computing from Morse code to Braille to binary to modern day high level languages. This book was recommended by my manager and I enjoyed the information I gained and the storytelling style of Petzold. That said, the book is dense and not a quick read for those of us for whom most of this is new information, myself included. After a year and a half of reading a chapter here and a chapter there, I feel a weight lifted from my shoulders as I can finally mark this book finished."
116,0735611319,http://goodreads.com/user/show/19044567-dallin-coons,5,"This is the kind of book I’ve always wanted to read. It’s basically “how computers work”, but somehow accomplished to be simultaneously simple, yet not dumbed down. This feat was achieved brilliantly, in that the author started from the simplest possible mechanism that could be termed a “computer” using machinery that was available over 100 years ago. Every chapter got a little more complex, and I’m not going to claim to have perfectly understood every electrical engineering concept introduced, but that’s what I appreciated about this book: It doesn’t hide behind analogy."
117,0735611319,http://goodreads.com/user/show/7854466-pablo-mar-a-fern-ndez,2,"I read this book because I was doing some research on the art of coding and computers in general. The cover design is amazing and probably that caught mainly my attention. Unfortunately when I start reading I realized that the type of approach to explain the content and his style weren't very interesting, at least for me. They seem not technical enough for the techie but not user friendly for the newbie neither. I skimmed through the book and read completely two chapters: 24 (Languages High and Low) and 25 (The Graphical Revolution) that gave my some cool info that I didn´t know."
118,0735611319,http://goodreads.com/user/show/6015296-jenni,5,"Very well written and clear book that explains how we get from a simple idea such as using candles to signal to our friends to modern computers. The book was written about 15 years ago so the final chapter on ""modern"" developments isn't modern anymore but other than that the information is very very solid and well presented. There are some pieces that have a bit of math and which might be a bit obscure. Highly recommended."
119,0735611319,http://goodreads.com/user/show/15812258-elie-de-brauwer,2,"Oooooh, I enjoy reading some vintage programming book every now and then, this book dates from the late 90s when 486DX were still mainstream and the dawn of the Pentium was coming. The book starts from low level binary notation, electrical schematics, transistors, logic gates and builds all the way up to ICs, x86 architecture up to the level of 'high level' code. Although this all sounds very romantic ... it actually felt as if was reading my digital electronics course again :s. "
120,0735611319,http://goodreads.com/user/show/43623936-karen-radcliff,4,"This was excellent. As someone who really wants to know what is behind the magic of the computers I use, this really helped me explore from the beginning the concepts that physically build the workings of these machines. I'll admit that the last two or three chapters left me struggling to stay interested, not because I didn't understand but because by then, my initial questions had been answered and I was no longer... interested. But I'd absolutely recommend it."
121,0735611319,http://goodreads.com/user/show/8699203-charlie-harrington,5,"If you've ever seen those YouTube videos of people who created entire computers in Minecraft or Super Mario Maker - and want to be more like them - then look no further. This book demonstrates how computers are built from absolute first principles, along with excellent diagrams, examples, and historical references to put everything in context. This is a book that demands re-reading and will likely reward you handsomely for it. "
122,0735611319,http://goodreads.com/user/show/75053800-jestarray,5,"If you want to learn about the historical underpinnings of code(that is, communication with the computer), this is it. It provides a lot of analogies and fun stories to explain the development of how we got here today, however, for those who want a more hands on pragmatic approach without the history, I recommend ""The Elements of Computing Systems"", in which you build a computer from scratch from primitive logic gates."
123,0735611319,http://goodreads.com/user/show/70296246-allen,4,"This book is unique in that it was a very slow read, but I loved slogging through it. Even though I do a lot with computers, I long ago wrote off the idea of ever understanding the nitty gritty magic of how they work. This book explains it in a way that's possible to understand. It starts with how things like flashlights and Morse code work, and then little step by little step it builds up to how to create things like 64kb of memory for a computer."
124,0735611319,http://goodreads.com/user/show/33004524-ashar-malik,5,"I think this is a great book. While I had gone through all of it previously as subject in my undergrad it served as a refresher. Moreover, the bit by bit construction of a computer was good. While I didn't read the date of publication at the time of purchase (2000), I was reminded by the archaic concepts, however, since this book puts everything into a historical context - I think these archaic concepts are needed, especially to show how far along we have come. "
125,0735611319,http://goodreads.com/user/show/88643086-filip-mih,5,"Even though this book is as old as I am, I found it profoundly impactful. It guided me throughout the history of computer science and thanks to it I finally understood how a computer works on the low-level. It starts slowly but then the difficulty raises linearly with the following chapters. Despite some deprecated information, the content of this book is still relevant as it describes the beginnings of this wonderful phenomenon called a personal computer. "
126,0735611319,http://goodreads.com/user/show/108595403-andreas-ellison,5,"This book is perfect for learning about the history of computers and the science behind it. Its fun to read and the author mixes in some humor while explaining how computers work in detail, starting from the lowest level of abstraction (electric circuits and logic gates) up to machine language and memory. It explains the basic concepts in computer science and electrical engineering and builds on each chapter to show the steps and insights that were needed to make the first computers. "
127,0735611319,http://goodreads.com/user/show/51305665-patrick-taylor,5,"An excellent, approachable work suited for anyone interested in computers, demanding no need for technical background. As an individual with large amounts of experience in several of the topics presented within, I still found this work enjoyable and it filled in some gaps in the entire stack of the computer. While the later chapters show the age of the text, the combined historical summary of events and technical deep dive into operation was highly enjoyable."
128,0735611319,http://goodreads.com/user/show/3274122-nicholas-martinez,4,"Petzold warmly details a computer’s anatomy, from the rudimentary electronic bit all the way up to the diverse family of programming languages. Although the bridge between circuits and operations is admittedly dense, Petzold does not alienate with esoteric language, and he addresses intuitively spotted inconsistencies and arbitrariness throughout computing. Here is a welcoming and thorough history and blueprint of computation that everyone can benefit from reading."
129,0735611319,http://goodreads.com/user/show/1389623-andr-s,4,"This was a fantastically fun and geeky read. The last few chapters are hilariously dated which is not surprising due to the age of the book, but disappointing that a book which so seamlessly tackles the history of computing dated itself so thoroughly by referring to the technology levels at the time of writing using present tense language. Glad I read this!"
130,0735611319,http://goodreads.com/user/show/12330926-syed,5,"Wish I had read it during my early university time....if you want to know about the thin line dividing hardware and software, if you ever wonder that just a software click stops the physical power of a computer or just soft click ejects dvd tray physically, then this book is for you and it will answer all your questions by driving you in a journey of centuries that made it happen."
131,0735611319,http://goodreads.com/user/show/11952838-fionnt-n,2,all right. That's it. I realise I have never or will ever find computer hardware anything but boring. In my defence this book seems to be written for those that luuuve hardware and switches and XOR gates already. None of the sparkle or romance that takes a dry topic and turns in to a subject you didn't know you cared about. This was a real labour to get through. 
132,0735611319,http://goodreads.com/user/show/60044259-alistair-murphy,5,"Loved this book, no messing around or gibberish to lengthen the book, precise and most of all clarity. Learned so much in this book, if you are a noob like me don't worry this book Starts of with the basics , then by the end of it your feel real smart. Though it does get complex as you get halfway, just over."
133,0735611319,http://goodreads.com/user/show/66658580-max-makhrov,5,"I love the logic of this book, you create a computer from a flashlight. This is a must-read book for everyone who loves coding, and want to understand the basic principles standing behind every electrical device.The book is not only about computers, it's about the logic itself. Now I understand how any device work if it has 2 numbers inside: 0 and 1."
134,0735611319,http://goodreads.com/user/show/79628073-matthew-sullivan,5,"Fantastic explanations of computers from the ground up. I love how Charles Petzold starts as simple as possible, and then without even realizing it, he has developed something more complex. Learning the history behind tech innovations was helpful for the overall understanding of why things are the way they are today. A great way to study for my Computer Organization and Architecture class"
135,0735611319,http://goodreads.com/user/show/61080386-retrobot,5,"Was looking for a book that would explain in detail the 'how' of computers. After getting frustrated with crap explanations online, I saw this book recommended.It's exactly what I was looking for.If you want to know, in detail, how a computer works (hardware and software) and what all of the abbreviations mean, this is THE book."
136,0735611319,http://goodreads.com/user/show/5817790-steve,4,"That was a lot of fun to read, for me at least. I already knew most of what was in the book, from several college classes (digital circuits, digital devices, etc) and from a career in computers, but it was nice to see it all laid out together. Of course a little dated, but the fundamentals are all there."
137,0735611319,http://goodreads.com/user/show/33253397-yury,5,"This book is really good. It brought back so many good memories of my childhood. The miracle of experiencing noisy computer with 8086, clicking 20mb hard drive and glowing yellow letters of turbo pascal code. I was 15. Besides that this books gives very detailed description of how CPUs are built. It connected a few dots about hardware. "
138,0735611319,http://goodreads.com/user/show/34168196-uday-sikand,5,"This is a well written book that gives the reader a solid foundation in workings of a computer and the electronics behind it. The author works his way from simple latches to RAM, ALU etcFor those who don't have any formal training in electronics or computer science, the learning curve can be steep but rewarding."
139,0735611319,http://goodreads.com/user/show/17155711-jason-kim,5,"This book provides a ground up view of how computer works. What is code? What is data? The book opens by discussing very big philosophical questions about computers. Then we get into discussing electricity, and how electricity can be used to represent data using binary code. Then the book discusses how simple circuits can be used to represent logical gates. And more."
140,0735611319,http://goodreads.com/user/show/65397105-kevin,4,"No description of computing, neither the hardware nor software, had ever made sense to me. I came across this book as a recommendation for those wishing to learn ab initio. The author starts with simple computing like Morse code and binary, then builds to Boolean logic and electronic computing. Probably worth a re-read every few years!"
141,0735611319,http://goodreads.com/user/show/22638723-cindy,3,"This book had great information, but I found that even though the author broke all of the technical electrical circuits and math down into the smallest pieces of information, it was still too hard to understand for me. I have no background in those areas. I preferred the written explanations, history of computing, and definitions of computing terms."
142,0735611319,http://goodreads.com/user/show/10470899-a-ron,4,"Really fascinating to learn in depth-ish how computer architecture works. I do know now that I don’t want to be an electrical engineer. Some of it was hard to get my head around, but I’m sure it is just a process of sitting down and diagramming it out myself, which I won’t do. I’m ok just working from high-level languages instead. "
143,0735611319,http://goodreads.com/user/show/111253702-tapani-lehtonen,3,Thr first half of the book is excellently educative. The other half felt like an enumeration of the old microprocessors and widgets that were used in the computers of the 20th century. It might be interesting for people who enjoy to know historical facts about the creation of computers. It was too detailed in my opinion as opposed to general enough for me to actually care about.
144,0735611319,http://goodreads.com/user/show/92179457-charles-dalton,5,"Amazing. Comprehensive. Simple. As many other reviewers have pointed out, this book doesn't discuss code or how to write it but rather how it works and its broader role within computers. This was an amazing intro to CS, especially for someone who has already programmed for many years.10/10 Petzold knocked it out of the park with this one."
145,0735611319,http://goodreads.com/user/show/7331155-alex,5,"One of the best books I have ever read. I wish it had a longer section on compilers and languages, as it seems to spend a very long time on hardware but nonetheless an excellent book.It complements the Nand2tetris course/book very well and despite its age hasn't dated too badly. I can't believe I didn't discover the book sooner."
146,0735611319,http://goodreads.com/user/show/20460133-peter-krevenets,5,"This book is kind of old, but it's amazing how it helped me to finally get the whole picture of the world of computers and programming. It was always a good read, despite all the technical stuff being discussed, but really - don't rush, don't push, just let it soak in, reread paragraphs and go back a few chapters if needed - this is worth it."
147,0735611319,http://goodreads.com/user/show/27185666-evren-yortu-boylu,3,"As a software engineer, it was interesting to see how you can build a comluter (hardware) with relays. But that’s it. I had to skip some chapters, especially last 3 because they were boring as hell for a software person.In the end, I realized that i am more into the calculation than calculator itself. "
148,0735611319,http://goodreads.com/user/show/17506961-afref-fetter-fetter,4,A good book. I liked the treatment of electric circuits more than the treatment of the microprocessor and higher level abstractions. Would be a good reference book to keep around and flip through a few pages when bored.
149,0735611319,http://goodreads.com/user/show/1011336-mike-arvela,4,"Such a good layman's intro to how computers work. A bit intense at times, but having the guts to deliberately skip the finer details of bit-mangling when adding together floating point numbers pays off. Wish this was mandatory reading in the university computer science class."
